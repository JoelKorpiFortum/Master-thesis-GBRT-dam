{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb60609e-9b1f-4738-aacf-42bcdf8f28ea",
   "metadata": {},
   "source": [
    "## Notebook execution in Jupyter for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b04d890-fbb2-47ef-82a5-272960b9bd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/Master-thesis-GBRT-dam'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2cdcc61-9e01-4102-9e94-fc1e2c57aa42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-03-31 13:34:47,667]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV1\u001b[0m\n",
      "3it [00:00,  4.20it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.1985\n",
      "2th fold: LGBMRegressor RMSE: 1.1401\n",
      "3th fold: LGBMRegressor RMSE: 27.8259\n",
      "\n",
      "LGBMRegressor average RMSE: 10.3882\n",
      "LGBMRegressor worst RMSE: 27.8259\n",
      "Corresponding penalty value: 12.1319\n",
      "\u001b[32m[I 2025-03-31 13:34:48,385]\u001b[0m Trial 0 finished with value: 12.131936345294791 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.5700000000000001, 'feature_fraction': 0.32, 'min_gain_to_split': 0.87, 'reg_alpha': 8.67, 'reg_lambda': 6.01, 'linear_tree': True}. Best is trial 0 with value: 12.131936345294791.\u001b[0m\n",
      "3it [00:01,  2.13it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.3939\n",
      "2th fold: LGBMRegressor RMSE: 0.1781\n",
      "3th fold: LGBMRegressor RMSE: 0.3145\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9622\n",
      "LGBMRegressor worst RMSE: 2.3939\n",
      "Corresponding penalty value: 1.1053\n",
      "\u001b[32m[I 2025-03-31 13:34:49,798]\u001b[0m Trial 1 finished with value: 1.1053442249834446 and parameters: {'n_estimators': 2925, 'learning_rate': 0.08301, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.59, 'feature_fraction': 0.44, 'min_gain_to_split': 7.87, 'reg_alpha': 4.32, 'reg_lambda': 2.91, 'linear_tree': True}. Best is trial 1 with value: 1.1053442249834446.\u001b[0m\n",
      "3it [00:00,  3.77it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9443\n",
      "2th fold: LGBMRegressor RMSE: 0.9323\n",
      "3th fold: LGBMRegressor RMSE: 1.6625\n",
      "\n",
      "LGBMRegressor average RMSE: 1.1797\n",
      "LGBMRegressor worst RMSE: 1.6625\n",
      "Corresponding penalty value: 1.2280\n",
      "\u001b[32m[I 2025-03-31 13:34:50,597]\u001b[0m Trial 2 finished with value: 1.2279648601986994 and parameters: {'n_estimators': 1230, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.6, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 8.89, 'reg_alpha': 0.46, 'reg_lambda': 6.08, 'linear_tree': True}. Best is trial 1 with value: 1.1053442249834446.\u001b[0m\n",
      "3it [00:01,  2.32it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4730\n",
      "2th fold: LGBMRegressor RMSE: 0.3208\n",
      "3th fold: LGBMRegressor RMSE: 0.8950\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5629\n",
      "LGBMRegressor worst RMSE: 0.8950\n",
      "Corresponding penalty value: 0.5961\n",
      "\u001b[32m[I 2025-03-31 13:34:51,889]\u001b[0m Trial 3 finished with value: 0.5960991469690746 and parameters: {'n_estimators': 2873, 'learning_rate': 0.09601, 'max_depth': 11, 'num_leaves': 10, 'subsample': 0.54, 'feature_fraction': 0.75, 'min_gain_to_split': 6.6000000000000005, 'reg_alpha': 1.22, 'reg_lambda': 4.95, 'linear_tree': False}. Best is trial 3 with value: 0.5960991469690746.\u001b[0m\n",
      "3it [00:00,  4.97it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.7081\n",
      "2th fold: LGBMRegressor RMSE: 0.9408\n",
      "3th fold: LGBMRegressor RMSE: 1.7294\n",
      "\n",
      "LGBMRegressor average RMSE: 2.1261\n",
      "LGBMRegressor worst RMSE: 3.7081\n",
      "Corresponding penalty value: 2.2843\n",
      "\u001b[32m[I 2025-03-31 13:34:52,494]\u001b[0m Trial 4 finished with value: 2.2843173645148505 and parameters: {'n_estimators': 1147, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.77, 'feature_fraction': 0.34, 'min_gain_to_split': 14.55, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'linear_tree': True}. Best is trial 3 with value: 0.5960991469690746.\u001b[0m\n",
      "3it [00:01,  2.60it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4144\n",
      "2th fold: LGBMRegressor RMSE: 0.2898\n",
      "3th fold: LGBMRegressor RMSE: 0.7556\n",
      "\n",
      "LGBMRegressor average RMSE: 0.4866\n",
      "LGBMRegressor worst RMSE: 0.7556\n",
      "Corresponding penalty value: 0.5135\n",
      "\u001b[32m[I 2025-03-31 13:34:53,649]\u001b[0m Trial 5 finished with value: 0.5135260299908375 and parameters: {'n_estimators': 2805, 'learning_rate': 0.00801, 'max_depth': 4, 'num_leaves': 3, 'subsample': 0.66, 'feature_fraction': 0.51, 'min_gain_to_split': 4.07, 'reg_alpha': 8.290000000000001, 'reg_lambda': 3.5700000000000003, 'linear_tree': False}. Best is trial 5 with value: 0.5135260299908375.\u001b[0m\n",
      "3it [00:00,  8.66it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4540\n",
      "2th fold: LGBMRegressor RMSE: 0.3520\n",
      "3th fold: LGBMRegressor RMSE: 0.8329\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5463\n",
      "LGBMRegressor worst RMSE: 0.8329\n",
      "Corresponding penalty value: 0.5750\n",
      "\u001b[32m[I 2025-03-31 13:34:53,997]\u001b[0m Trial 6 finished with value: 0.5749795867514409 and parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 5 with value: 0.5135260299908375.\u001b[0m\n",
      "3it [00:00,  5.74it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.3339\n",
      "2th fold: LGBMRegressor RMSE: 2.2694\n",
      "3th fold: LGBMRegressor RMSE: 0.9667\n",
      "\n",
      "LGBMRegressor average RMSE: 1.8567\n",
      "LGBMRegressor worst RMSE: 2.3339\n",
      "Corresponding penalty value: 1.9044\n",
      "\u001b[32m[I 2025-03-31 13:34:54,522]\u001b[0m Trial 7 finished with value: 1.9043904907674922 and parameters: {'n_estimators': 685, 'learning_rate': 0.035010000000000006, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.81, 'feature_fraction': 0.46, 'min_gain_to_split': 0.9500000000000001, 'reg_alpha': 3.11, 'reg_lambda': 3.25, 'linear_tree': True}. Best is trial 5 with value: 0.5135260299908375.\u001b[0m\n",
      "3it [00:01,  2.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6614\n",
      "2th fold: LGBMRegressor RMSE: 1.2428\n",
      "3th fold: LGBMRegressor RMSE: 0.8660\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9234\n",
      "LGBMRegressor worst RMSE: 1.2428\n",
      "Corresponding penalty value: 0.9553\n",
      "\u001b[32m[I 2025-03-31 13:34:56,026]\u001b[0m Trial 8 finished with value: 0.9553312886823437 and parameters: {'n_estimators': 2718, 'learning_rate': 0.04701, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.88, 'feature_fraction': 0.65, 'min_gain_to_split': 11.57, 'reg_alpha': 4.94, 'reg_lambda': 5.23, 'linear_tree': True}. Best is trial 5 with value: 0.5135260299908375.\u001b[0m\n",
      "3it [00:01,  1.76it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.5922\n",
      "2th fold: LGBMRegressor RMSE: 4.9742\n",
      "3th fold: LGBMRegressor RMSE: 0.4648\n",
      "\n",
      "LGBMRegressor average RMSE: 2.0104\n",
      "LGBMRegressor worst RMSE: 4.9742\n",
      "Corresponding penalty value: 2.3068\n",
      "\u001b[32m[I 2025-03-31 13:34:57,738]\u001b[0m Trial 9 finished with value: 2.3068123506006186 and parameters: {'n_estimators': 769, 'learning_rate': 0.00301, 'max_depth': 9, 'num_leaves': 11, 'subsample': 0.75, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 3.74, 'reg_alpha': 4.1, 'reg_lambda': 7.5600000000000005, 'linear_tree': True}. Best is trial 5 with value: 0.5135260299908375.\u001b[0m\n",
      "3it [00:01,  2.19it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.9029\n",
      "2th fold: LGBMRegressor RMSE: 2.1189\n",
      "3th fold: LGBMRegressor RMSE: 3.5954\n",
      "\n",
      "LGBMRegressor average RMSE: 2.5391\n",
      "LGBMRegressor worst RMSE: 3.5954\n",
      "Corresponding penalty value: 2.6447\n",
      "\u001b[32m[I 2025-03-31 13:34:59,145]\u001b[0m Trial 10 finished with value: 2.6447075270836535 and parameters: {'n_estimators': 2157, 'learning_rate': 1e-05, 'max_depth': 8, 'num_leaves': 2, 'subsample': 0.66, 'feature_fraction': 0.8400000000000001, 'min_gain_to_split': 3.87, 'reg_alpha': 9.75, 'reg_lambda': 0.64, 'linear_tree': False}. Best is trial 5 with value: 0.5135260299908375.\u001b[0m\n",
      "3it [00:00,  5.43it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.5203\n",
      "2th fold: LGBMRegressor RMSE: 0.4286\n",
      "3th fold: LGBMRegressor RMSE: 1.0229\n",
      "\n",
      "LGBMRegressor average RMSE: 0.6573\n",
      "LGBMRegressor worst RMSE: 1.0229\n",
      "Corresponding penalty value: 0.6938\n",
      "\u001b[32m[I 2025-03-31 13:34:59,732]\u001b[0m Trial 11 finished with value: 0.6938162963462363 and parameters: {'n_estimators': 2081, 'learning_rate': 0.02001, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.98, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 3.44, 'reg_alpha': 7.0600000000000005, 'reg_lambda': 8.23, 'linear_tree': False}. Best is trial 5 with value: 0.5135260299908375.\u001b[0m\n",
      "3it [00:00,  3.91it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.3855\n",
      "2th fold: LGBMRegressor RMSE: 0.2690\n",
      "3th fold: LGBMRegressor RMSE: 0.7723\n",
      "\n",
      "LGBMRegressor average RMSE: 0.4756\n",
      "LGBMRegressor worst RMSE: 0.7723\n",
      "Corresponding penalty value: 0.5053\n",
      "\u001b[32m[I 2025-03-31 13:35:00,535]\u001b[0m Trial 12 finished with value: 0.5052618487465913 and parameters: {'n_estimators': 1851, 'learning_rate': 0.06801, 'max_depth': 3, 'num_leaves': 3, 'subsample': 0.99, 'feature_fraction': 0.48000000000000004, 'min_gain_to_split': 0.04, 'reg_alpha': 6.53, 'reg_lambda': 2.77, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.36it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.5173\n",
      "2th fold: LGBMRegressor RMSE: 0.3165\n",
      "3th fold: LGBMRegressor RMSE: 0.6785\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5041\n",
      "LGBMRegressor worst RMSE: 0.6785\n",
      "Corresponding penalty value: 0.5215\n",
      "\u001b[32m[I 2025-03-31 13:35:01,464]\u001b[0m Trial 13 finished with value: 0.5215288554367374 and parameters: {'n_estimators': 2359, 'learning_rate': 0.06401, 'max_depth': 6, 'num_leaves': 2, 'subsample': 0.6799999999999999, 'feature_fraction': 0.53, 'min_gain_to_split': 5.2, 'reg_alpha': 6.18, 'reg_lambda': 2.06, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.95it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4189\n",
      "2th fold: LGBMRegressor RMSE: 0.3543\n",
      "3th fold: LGBMRegressor RMSE: 0.8536\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5423\n",
      "LGBMRegressor worst RMSE: 0.8536\n",
      "Corresponding penalty value: 0.5734\n",
      "\u001b[32m[I 2025-03-31 13:35:02,260]\u001b[0m Trial 14 finished with value: 0.5733876580709535 and parameters: {'n_estimators': 1692, 'learning_rate': 0.06201, 'max_depth': 5, 'num_leaves': 6, 'subsample': 0.67, 'feature_fraction': 0.72, 'min_gain_to_split': 2.6, 'reg_alpha': 6.18, 'reg_lambda': 0.11, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:01,  2.98it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4252\n",
      "2th fold: LGBMRegressor RMSE: 0.3591\n",
      "3th fold: LGBMRegressor RMSE: 0.8878\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5574\n",
      "LGBMRegressor worst RMSE: 0.8878\n",
      "Corresponding penalty value: 0.5904\n",
      "\u001b[32m[I 2025-03-31 13:35:03,305]\u001b[0m Trial 15 finished with value: 0.5904083832852294 and parameters: {'n_estimators': 2499, 'learning_rate': 0.02201, 'max_depth': 3, 'num_leaves': 12, 'subsample': 0.97, 'feature_fraction': 0.53, 'min_gain_to_split': 2.11, 'reg_alpha': 9.8, 'reg_lambda': 3.2800000000000002, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  6.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.5175\n",
      "2th fold: LGBMRegressor RMSE: 0.3497\n",
      "3th fold: LGBMRegressor RMSE: 0.8802\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5825\n",
      "LGBMRegressor worst RMSE: 0.8802\n",
      "Corresponding penalty value: 0.6123\n",
      "\u001b[32m[I 2025-03-31 13:35:03,792]\u001b[0m Trial 16 finished with value: 0.6122559446818319 and parameters: {'n_estimators': 1764, 'learning_rate': 0.048010000000000004, 'max_depth': 12, 'num_leaves': 6, 'subsample': 0.5, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 6.48, 'reg_alpha': 6.2700000000000005, 'reg_lambda': 1.6300000000000001, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.47it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4425\n",
      "2th fold: LGBMRegressor RMSE: 0.3263\n",
      "3th fold: LGBMRegressor RMSE: 0.9124\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5604\n",
      "LGBMRegressor worst RMSE: 0.9124\n",
      "Corresponding penalty value: 0.5956\n",
      "\u001b[32m[I 2025-03-31 13:35:04,695]\u001b[0m Trial 17 finished with value: 0.5955769183421846 and parameters: {'n_estimators': 1934, 'learning_rate': 0.01701, 'max_depth': 5, 'num_leaves': 13, 'subsample': 0.8400000000000001, 'feature_fraction': 0.51, 'min_gain_to_split': 10.24, 'reg_alpha': 8.92, 'reg_lambda': 4.74, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:01,  2.90it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.3747\n",
      "2th fold: LGBMRegressor RMSE: 0.3303\n",
      "3th fold: LGBMRegressor RMSE: 0.7675\n",
      "\n",
      "LGBMRegressor average RMSE: 0.4909\n",
      "LGBMRegressor worst RMSE: 0.7675\n",
      "Corresponding penalty value: 0.5185\n",
      "\u001b[32m[I 2025-03-31 13:35:05,770]\u001b[0m Trial 18 finished with value: 0.5185258057768213 and parameters: {'n_estimators': 2527, 'learning_rate': 0.07901, 'max_depth': 7, 'num_leaves': 4, 'subsample': 0.72, 'feature_fraction': 0.6799999999999999, 'min_gain_to_split': 5.42, 'reg_alpha': 2.57, 'reg_lambda': 4.1, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  4.97it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4838\n",
      "2th fold: LGBMRegressor RMSE: 0.3761\n",
      "3th fold: LGBMRegressor RMSE: 0.9082\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5893\n",
      "LGBMRegressor worst RMSE: 0.9082\n",
      "Corresponding penalty value: 0.6212\n",
      "\u001b[32m[I 2025-03-31 13:35:06,412]\u001b[0m Trial 19 finished with value: 0.6212212577781712 and parameters: {'n_estimators': 1610, 'learning_rate': 0.057010000000000005, 'max_depth': 4, 'num_leaves': 8, 'subsample': 0.94, 'feature_fraction': 0.41000000000000003, 'min_gain_to_split': 1.93, 'reg_alpha': 6.83, 'reg_lambda': 1.7, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.09it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4095\n",
      "2th fold: LGBMRegressor RMSE: 0.3304\n",
      "3th fold: LGBMRegressor RMSE: 0.9107\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5502\n",
      "LGBMRegressor worst RMSE: 0.9107\n",
      "Corresponding penalty value: 0.5862\n",
      "\u001b[32m[I 2025-03-31 13:35:07,420]\u001b[0m Trial 20 finished with value: 0.5862495727462447 and parameters: {'n_estimators': 2212, 'learning_rate': 0.03601000000000001, 'max_depth': 6, 'num_leaves': 14, 'subsample': 0.63, 'feature_fraction': 0.5800000000000001, 'min_gain_to_split': 4.86, 'reg_alpha': 5.37, 'reg_lambda': 3.74, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:01,  2.85it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4028\n",
      "2th fold: LGBMRegressor RMSE: 0.3238\n",
      "3th fold: LGBMRegressor RMSE: 0.7608\n",
      "\n",
      "LGBMRegressor average RMSE: 0.4958\n",
      "LGBMRegressor worst RMSE: 0.7608\n",
      "Corresponding penalty value: 0.5223\n",
      "\u001b[32m[I 2025-03-31 13:35:08,514]\u001b[0m Trial 21 finished with value: 0.5223054469547224 and parameters: {'n_estimators': 2558, 'learning_rate': 0.07601, 'max_depth': 7, 'num_leaves': 4, 'subsample': 0.73, 'feature_fraction': 0.7, 'min_gain_to_split': 5.48, 'reg_alpha': 2.1, 'reg_lambda': 3.89, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:01,  2.24it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4429\n",
      "2th fold: LGBMRegressor RMSE: 0.3148\n",
      "3th fold: LGBMRegressor RMSE: 0.7870\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5149\n",
      "LGBMRegressor worst RMSE: 0.7870\n",
      "Corresponding penalty value: 0.5421\n",
      "\u001b[32m[I 2025-03-31 13:35:09,896]\u001b[0m Trial 22 finished with value: 0.54210984622367 and parameters: {'n_estimators': 2999, 'learning_rate': 0.08601, 'max_depth': 9, 'num_leaves': 4, 'subsample': 0.71, 'feature_fraction': 0.8, 'min_gain_to_split': 8.25, 'reg_alpha': 2.83, 'reg_lambda': 2.59, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:01,  2.79it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4798\n",
      "2th fold: LGBMRegressor RMSE: 0.2892\n",
      "3th fold: LGBMRegressor RMSE: 0.8778\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5489\n",
      "LGBMRegressor worst RMSE: 0.8778\n",
      "Corresponding penalty value: 0.5818\n",
      "\u001b[32m[I 2025-03-31 13:35:11,012]\u001b[0m Trial 23 finished with value: 0.5818106534697607 and parameters: {'n_estimators': 2623, 'learning_rate': 0.07201, 'max_depth': 4, 'num_leaves': 9, 'subsample': 0.79, 'feature_fraction': 0.64, 'min_gain_to_split': 6.3100000000000005, 'reg_alpha': 7.55, 'reg_lambda': 4.23, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.23it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4337\n",
      "2th fold: LGBMRegressor RMSE: 0.3050\n",
      "3th fold: LGBMRegressor RMSE: 0.7379\n",
      "\n",
      "LGBMRegressor average RMSE: 0.4922\n",
      "LGBMRegressor worst RMSE: 0.7379\n",
      "Corresponding penalty value: 0.5168\n",
      "\u001b[32m[I 2025-03-31 13:35:11,982]\u001b[0m Trial 24 finished with value: 0.516767702567552 and parameters: {'n_estimators': 1947, 'learning_rate': 0.08800999999999999, 'max_depth': 8, 'num_leaves': 4, 'subsample': 0.71, 'feature_fraction': 0.96, 'min_gain_to_split': 4.41, 'reg_alpha': 3.63, 'reg_lambda': 0.92, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.20it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6185\n",
      "2th fold: LGBMRegressor RMSE: 0.4054\n",
      "3th fold: LGBMRegressor RMSE: 0.6226\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5488\n",
      "LGBMRegressor worst RMSE: 0.6226\n",
      "Corresponding penalty value: 0.5562\n",
      "\u001b[32m[I 2025-03-31 13:35:12,962]\u001b[0m Trial 25 finished with value: 0.5561827941476757 and parameters: {'n_estimators': 1855, 'learning_rate': 0.08601, 'max_depth': 8, 'num_leaves': 2, 'subsample': 0.63, 'feature_fraction': 0.94, 'min_gain_to_split': 2.77, 'reg_alpha': 3.72, 'reg_lambda': 1.12, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.97it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4569\n",
      "2th fold: LGBMRegressor RMSE: 0.3252\n",
      "3th fold: LGBMRegressor RMSE: 0.8497\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5439\n",
      "LGBMRegressor worst RMSE: 0.8497\n",
      "Corresponding penalty value: 0.5745\n",
      "\u001b[32m[I 2025-03-31 13:35:13,760]\u001b[0m Trial 26 finished with value: 0.5744976525042101 and parameters: {'n_estimators': 1471, 'learning_rate': 0.05401, 'max_depth': 10, 'num_leaves': 5, 'subsample': 0.8400000000000001, 'feature_fraction': 0.8400000000000001, 'min_gain_to_split': 1.27, 'reg_alpha': 4.8100000000000005, 'reg_lambda': 2.46, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.02it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4545\n",
      "2th fold: LGBMRegressor RMSE: 0.3524\n",
      "3th fold: LGBMRegressor RMSE: 0.9278\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5782\n",
      "LGBMRegressor worst RMSE: 0.9278\n",
      "Corresponding penalty value: 0.6132\n",
      "\u001b[32m[I 2025-03-31 13:35:14,796]\u001b[0m Trial 27 finished with value: 0.6131882264398965 and parameters: {'n_estimators': 2019, 'learning_rate': 0.09101, 'max_depth': 3, 'num_leaves': 15, 'subsample': 0.91, 'feature_fraction': 1.0, 'min_gain_to_split': 0.05, 'reg_alpha': 5.55, 'reg_lambda': 0.96, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  4.76it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4442\n",
      "2th fold: LGBMRegressor RMSE: 0.3831\n",
      "3th fold: LGBMRegressor RMSE: 0.8871\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5715\n",
      "LGBMRegressor worst RMSE: 0.8871\n",
      "Corresponding penalty value: 0.6030\n",
      "\u001b[32m[I 2025-03-31 13:35:15,470]\u001b[0m Trial 28 finished with value: 0.6030374618991607 and parameters: {'n_estimators': 2277, 'learning_rate': 0.07101, 'max_depth': 5, 'num_leaves': 8, 'subsample': 0.7, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 3.87, 'reg_alpha': 8.84, 'reg_lambda': 0.32, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  3.32it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4485\n",
      "2th fold: LGBMRegressor RMSE: 0.3266\n",
      "3th fold: LGBMRegressor RMSE: 0.9341\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5697\n",
      "LGBMRegressor worst RMSE: 0.9341\n",
      "Corresponding penalty value: 0.6062\n",
      "\u001b[32m[I 2025-03-31 13:35:16,418]\u001b[0m Trial 29 finished with value: 0.6061661313034685 and parameters: {'n_estimators': 1198, 'learning_rate': 0.00901, 'max_depth': 9, 'num_leaves': 21, 'subsample': 0.56, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 9.32, 'reg_alpha': 8.3, 'reg_lambda': 5.64, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  5.26it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.3779\n",
      "2th fold: LGBMRegressor RMSE: 0.3175\n",
      "3th fold: LGBMRegressor RMSE: 0.8856\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5270\n",
      "LGBMRegressor worst RMSE: 0.8856\n",
      "Corresponding penalty value: 0.5628\n",
      "\u001b[32m[I 2025-03-31 13:35:17,034]\u001b[0m Trial 30 finished with value: 0.5628384277417722 and parameters: {'n_estimators': 1466, 'learning_rate': 0.09301, 'max_depth': 10, 'num_leaves': 17, 'subsample': 0.62, 'feature_fraction': 0.48000000000000004, 'min_gain_to_split': 12.23, 'reg_alpha': 7.08, 'reg_lambda': 1.35, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  4.13it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.3748\n",
      "2th fold: LGBMRegressor RMSE: 0.3813\n",
      "3th fold: LGBMRegressor RMSE: 0.7887\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5149\n",
      "LGBMRegressor worst RMSE: 0.7887\n",
      "Corresponding penalty value: 0.5423\n",
      "\u001b[32m[I 2025-03-31 13:35:17,806]\u001b[0m Trial 31 finished with value: 0.542306155031153 and parameters: {'n_estimators': 2422, 'learning_rate': 0.07601, 'max_depth': 7, 'num_leaves': 4, 'subsample': 0.77, 'feature_fraction': 0.37, 'min_gain_to_split': 4.8100000000000005, 'reg_alpha': 2.19, 'reg_lambda': 4.39, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:01,  2.70it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4622\n",
      "2th fold: LGBMRegressor RMSE: 0.2686\n",
      "3th fold: LGBMRegressor RMSE: 0.7764\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5024\n",
      "LGBMRegressor worst RMSE: 0.7764\n",
      "Corresponding penalty value: 0.5298\n",
      "\u001b[32m[I 2025-03-31 13:35:18,963]\u001b[0m Trial 32 finished with value: 0.5297643861267526 and parameters: {'n_estimators': 2764, 'learning_rate': 0.09901, 'max_depth': 8, 'num_leaves': 3, 'subsample': 0.73, 'feature_fraction': 0.67, 'min_gain_to_split': 5.87, 'reg_alpha': 3.36, 'reg_lambda': 3.15, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:00,  4.10it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4775\n",
      "2th fold: LGBMRegressor RMSE: 0.3153\n",
      "3th fold: LGBMRegressor RMSE: 0.8550\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5493\n",
      "LGBMRegressor worst RMSE: 0.8550\n",
      "Corresponding penalty value: 0.5798\n",
      "\u001b[32m[I 2025-03-31 13:35:19,743]\u001b[0m Trial 33 finished with value: 0.5798340505216076 and parameters: {'n_estimators': 2748, 'learning_rate': 0.08101, 'max_depth': 6, 'num_leaves': 7, 'subsample': 0.65, 'feature_fraction': 0.28, 'min_gain_to_split': 7.28, 'reg_alpha': 2.3000000000000003, 'reg_lambda': 2.1, 'linear_tree': False}. Best is trial 12 with value: 0.5052618487465913.\u001b[0m\n",
      "3it [00:01,  2.16it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.5885\n",
      "2th fold: LGBMRegressor RMSE: 0.2334\n",
      "3th fold: LGBMRegressor RMSE: 0.2377\n",
      "\n",
      "LGBMRegressor average RMSE: 0.3532\n",
      "LGBMRegressor worst RMSE: 0.5885\n",
      "Corresponding penalty value: 0.3767\n",
      "\u001b[32m[I 2025-03-31 13:35:21,177]\u001b[0m Trial 34 finished with value: 0.37671461585947236 and parameters: {'n_estimators': 2867, 'learning_rate': 0.08800999999999999, 'max_depth': 7, 'num_leaves': 5, 'subsample': 0.7, 'feature_fraction': 0.44, 'min_gain_to_split': 7.36, 'reg_alpha': 1.28, 'reg_lambda': 2.8000000000000003, 'linear_tree': True}. Best is trial 34 with value: 0.37671461585947236.\u001b[0m\n",
      "3it [00:00,  5.61it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8697\n",
      "2th fold: LGBMRegressor RMSE: 0.5429\n",
      "3th fold: LGBMRegressor RMSE: 0.5833\n",
      "\n",
      "LGBMRegressor average RMSE: 0.6653\n",
      "LGBMRegressor worst RMSE: 0.8697\n",
      "Corresponding penalty value: 0.6857\n",
      "\u001b[32m[I 2025-03-31 13:35:21,759]\u001b[0m Trial 35 finished with value: 0.6857471762492754 and parameters: {'n_estimators': 966, 'learning_rate': 0.09000999999999999, 'max_depth': 4, 'num_leaves': 6, 'subsample': 0.59, 'feature_fraction': 0.41000000000000003, 'min_gain_to_split': 6.94, 'reg_alpha': 1.54, 'reg_lambda': 2.75, 'linear_tree': True}. Best is trial 34 with value: 0.37671461585947236.\u001b[0m\n",
      "3it [00:00,  7.70it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.4319\n",
      "2th fold: LGBMRegressor RMSE: 0.6176\n",
      "3th fold: LGBMRegressor RMSE: 1.0169\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3555\n",
      "LGBMRegressor worst RMSE: 2.4319\n",
      "Corresponding penalty value: 1.4631\n",
      "\u001b[32m[I 2025-03-31 13:35:22,195]\u001b[0m Trial 36 finished with value: 1.4631210243636104 and parameters: {'n_estimators': 543, 'learning_rate': 0.042010000000000006, 'max_depth': 11, 'num_leaves': 9, 'subsample': 0.7, 'feature_fraction': 0.42000000000000004, 'min_gain_to_split': 8.08, 'reg_alpha': 0.89, 'reg_lambda': 6.24, 'linear_tree': True}. Best is trial 34 with value: 0.37671461585947236.\u001b[0m\n",
      "3it [00:01,  2.27it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0522\n",
      "2th fold: LGBMRegressor RMSE: 1.9438\n",
      "3th fold: LGBMRegressor RMSE: 0.2609\n",
      "\n",
      "LGBMRegressor average RMSE: 1.0856\n",
      "LGBMRegressor worst RMSE: 1.9438\n",
      "Corresponding penalty value: 1.1715\n",
      "\u001b[32m[I 2025-03-31 13:35:23,565]\u001b[0m Trial 37 finished with value: 1.1714625797801035 and parameters: {'n_estimators': 2883, 'learning_rate': 0.07001, 'max_depth': 3, 'num_leaves': 11, 'subsample': 1.0, 'feature_fraction': 0.49, 'min_gain_to_split': 9.0, 'reg_alpha': 0.65, 'reg_lambda': 3.49, 'linear_tree': True}. Best is trial 34 with value: 0.37671461585947236.\u001b[0m\n",
      "3it [00:00,  3.89it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4181\n",
      "2th fold: LGBMRegressor RMSE: 0.2503\n",
      "3th fold: LGBMRegressor RMSE: 0.1591\n",
      "\n",
      "LGBMRegressor average RMSE: 0.2758\n",
      "LGBMRegressor worst RMSE: 0.4181\n",
      "Corresponding penalty value: 0.2901\n",
      "\u001b[32m[I 2025-03-31 13:35:24,384]\u001b[0m Trial 38 finished with value: 0.2900625568792666 and parameters: {'n_estimators': 1302, 'learning_rate': 0.05901000000000001, 'max_depth': 5, 'num_leaves': 5, 'subsample': 0.81, 'feature_fraction': 0.5900000000000001, 'min_gain_to_split': 10.03, 'reg_alpha': 0.19, 'reg_lambda': 2.09, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  4.50it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2504\n",
      "2th fold: LGBMRegressor RMSE: 0.2273\n",
      "3th fold: LGBMRegressor RMSE: 0.3042\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5940\n",
      "LGBMRegressor worst RMSE: 1.2504\n",
      "Corresponding penalty value: 0.6596\n",
      "\u001b[32m[I 2025-03-31 13:35:25,100]\u001b[0m Trial 39 finished with value: 0.6596082542519864 and parameters: {'n_estimators': 1067, 'learning_rate': 0.05901000000000001, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.8300000000000001, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 10.22, 'reg_alpha': 0.19, 'reg_lambda': 2.15, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  3.58it/s]\n",
      "1th fold: LGBMRegressor RMSE: 14.2349\n",
      "2th fold: LGBMRegressor RMSE: 0.6678\n",
      "3th fold: LGBMRegressor RMSE: 1.1509\n",
      "\n",
      "LGBMRegressor average RMSE: 5.3512\n",
      "LGBMRegressor worst RMSE: 14.2349\n",
      "Corresponding penalty value: 6.2395\n",
      "\u001b[32m[I 2025-03-31 13:35:25,988]\u001b[0m Trial 40 finished with value: 6.239530189377093 and parameters: {'n_estimators': 1309, 'learning_rate': 0.032010000000000004, 'max_depth': 6, 'num_leaves': 19, 'subsample': 0.88, 'feature_fraction': 0.55, 'min_gain_to_split': 12.91, 'reg_alpha': 1.57, 'reg_lambda': 2.84, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  3.80it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6704\n",
      "2th fold: LGBMRegressor RMSE: 0.3010\n",
      "3th fold: LGBMRegressor RMSE: 0.1767\n",
      "\n",
      "LGBMRegressor average RMSE: 0.3827\n",
      "LGBMRegressor worst RMSE: 0.6704\n",
      "Corresponding penalty value: 0.4115\n",
      "\u001b[32m[I 2025-03-31 13:35:26,826]\u001b[0m Trial 41 finished with value: 0.4114632233783047 and parameters: {'n_estimators': 1571, 'learning_rate': 0.05401, 'max_depth': 5, 'num_leaves': 2, 'subsample': 0.77, 'feature_fraction': 0.46, 'min_gain_to_split': 10.22, 'reg_alpha': 0.39, 'reg_lambda': 0.81, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  4.63it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7570\n",
      "2th fold: LGBMRegressor RMSE: 0.3053\n",
      "3th fold: LGBMRegressor RMSE: 0.1797\n",
      "\n",
      "LGBMRegressor average RMSE: 0.4140\n",
      "LGBMRegressor worst RMSE: 0.7570\n",
      "Corresponding penalty value: 0.4483\n",
      "\u001b[32m[I 2025-03-31 13:35:27,524]\u001b[0m Trial 42 finished with value: 0.4483016496290002 and parameters: {'n_estimators': 1297, 'learning_rate': 0.05201000000000001, 'max_depth': 4, 'num_leaves': 2, 'subsample': 0.76, 'feature_fraction': 0.45, 'min_gain_to_split': 10.3, 'reg_alpha': 0.15, 'reg_lambda': 9.97, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  4.32it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8863\n",
      "2th fold: LGBMRegressor RMSE: 0.3049\n",
      "3th fold: LGBMRegressor RMSE: 0.1785\n",
      "\n",
      "LGBMRegressor average RMSE: 0.4566\n",
      "LGBMRegressor worst RMSE: 0.8863\n",
      "Corresponding penalty value: 0.4995\n",
      "\u001b[32m[I 2025-03-31 13:35:28,269]\u001b[0m Trial 43 finished with value: 0.49953930239144595 and parameters: {'n_estimators': 1338, 'learning_rate': 0.05301, 'max_depth': 5, 'num_leaves': 2, 'subsample': 0.75, 'feature_fraction': 0.45, 'min_gain_to_split': 10.73, 'reg_alpha': 1.07, 'reg_lambda': 8.4, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  4.73it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9313\n",
      "2th fold: LGBMRegressor RMSE: 0.3419\n",
      "3th fold: LGBMRegressor RMSE: 0.3261\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5331\n",
      "LGBMRegressor worst RMSE: 0.9313\n",
      "Corresponding penalty value: 0.5729\n",
      "\u001b[32m[I 2025-03-31 13:35:28,953]\u001b[0m Trial 44 finished with value: 0.5729395859765921 and parameters: {'n_estimators': 1343, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'num_leaves': 2, 'subsample': 0.76, 'feature_fraction': 0.38, 'min_gain_to_split': 10.89, 'reg_alpha': 0.12, 'reg_lambda': 9.69, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  3.66it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1177\n",
      "2th fold: LGBMRegressor RMSE: 0.2976\n",
      "3th fold: LGBMRegressor RMSE: 0.2059\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5404\n",
      "LGBMRegressor worst RMSE: 1.1177\n",
      "Corresponding penalty value: 0.5981\n",
      "\u001b[32m[I 2025-03-31 13:35:29,823]\u001b[0m Trial 45 finished with value: 0.5981478779732263 and parameters: {'n_estimators': 1576, 'learning_rate': 0.04301000000000001, 'max_depth': 5, 'num_leaves': 5, 'subsample': 0.79, 'feature_fraction': 0.45, 'min_gain_to_split': 13.61, 'reg_alpha': 1.12, 'reg_lambda': 9.02, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  5.62it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0268\n",
      "2th fold: LGBMRegressor RMSE: 0.4495\n",
      "3th fold: LGBMRegressor RMSE: 0.2670\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5811\n",
      "LGBMRegressor worst RMSE: 1.0268\n",
      "Corresponding penalty value: 0.6257\n",
      "\u001b[32m[I 2025-03-31 13:35:30,410]\u001b[0m Trial 46 finished with value: 0.6256540905751867 and parameters: {'n_estimators': 1101, 'learning_rate': 0.04401, 'max_depth': 6, 'num_leaves': 2, 'subsample': 0.81, 'feature_fraction': 0.33, 'min_gain_to_split': 9.61, 'reg_alpha': 0.59, 'reg_lambda': 8.72, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  4.16it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.5790\n",
      "2th fold: LGBMRegressor RMSE: 0.5332\n",
      "3th fold: LGBMRegressor RMSE: 0.2277\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7800\n",
      "LGBMRegressor worst RMSE: 1.5790\n",
      "Corresponding penalty value: 0.8599\n",
      "\u001b[32m[I 2025-03-31 13:35:31,183]\u001b[0m Trial 47 finished with value: 0.8598784193314372 and parameters: {'n_estimators': 1313, 'learning_rate': 0.058010000000000006, 'max_depth': 4, 'num_leaves': 25, 'subsample': 0.75, 'feature_fraction': 0.44, 'min_gain_to_split': 11.24, 'reg_alpha': 1.6300000000000001, 'reg_lambda': 7.87, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  5.05it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4670\n",
      "2th fold: LGBMRegressor RMSE: 0.2260\n",
      "3th fold: LGBMRegressor RMSE: 0.1305\n",
      "\n",
      "LGBMRegressor average RMSE: 0.2745\n",
      "LGBMRegressor worst RMSE: 0.4670\n",
      "Corresponding penalty value: 0.2938\n",
      "\u001b[32m[I 2025-03-31 13:35:31,830]\u001b[0m Trial 48 finished with value: 0.29376922720344756 and parameters: {'n_estimators': 935, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'num_leaves': 5, 'subsample': 0.79, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 10.3, 'reg_alpha': 1.1300000000000001, 'reg_lambda': 9.99, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "3it [00:00,  5.06it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6406\n",
      "2th fold: LGBMRegressor RMSE: 0.3501\n",
      "3th fold: LGBMRegressor RMSE: 1.3724\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7877\n",
      "LGBMRegressor worst RMSE: 1.3724\n",
      "Corresponding penalty value: 0.8462\n",
      "\u001b[32m[I 2025-03-31 13:35:32,476]\u001b[0m Trial 49 finished with value: 0.8461828993521281 and parameters: {'n_estimators': 915, 'learning_rate': 0.06501, 'max_depth': 7, 'num_leaves': 10, 'subsample': 0.86, 'feature_fraction': 0.6000000000000001, 'min_gain_to_split': 8.540000000000001, 'reg_alpha': 0.22, 'reg_lambda': 9.540000000000001, 'linear_tree': True}. Best is trial 38 with value: 0.2900625568792666.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1302, 'learning_rate': 0.05901000000000001, 'max_depth': 5, 'num_leaves': 5, 'subsample': 0.81, 'feature_fraction': 0.5900000000000001, 'min_gain_to_split': 10.03, 'reg_alpha': 0.19, 'reg_lambda': 2.09, 'linear_tree': True}\n",
      "3it [00:00,  3.91it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4877\n",
      "2th fold: LGBMRegressor RMSE: 0.2708\n",
      "3th fold: LGBMRegressor RMSE: 0.1589\n",
      "\n",
      "LGBMRegressor average RMSE: 0.3058\n",
      "LGBMRegressor worst RMSE: 0.4877\n",
      "Corresponding penalty value: 0.3240\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV1\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1302, 'learning_rate': 0.05901000000000001, 'max_depth': 5, 'num_leaves': 5, 'subsample': 0.81, 'feature_fraction': 0.5900000000000001, 'min_gain_to_split': 10.03, 'reg_alpha': 0.19, 'reg_lambda': 2.09, 'linear_tree': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.108\n",
      "RMSE_crossval: 0.306\n",
      "RMSE_test: 0.300\n",
      "MAE_test: 0.219\n",
      "Nash-Sutcliffe Test: 0.991\n",
      "Kling-Gupta Test: 0.965\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 46.6363 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:35:34,265]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV3\u001b[0m\n",
      "3it [00:00,  4.40it/s]\n",
      "1th fold: LGBMRegressor RMSE: 11.2571\n",
      "2th fold: LGBMRegressor RMSE: 16.6502\n",
      "3th fold: LGBMRegressor RMSE: 1.7677\n",
      "\n",
      "LGBMRegressor average RMSE: 9.8917\n",
      "LGBMRegressor worst RMSE: 16.6502\n",
      "Corresponding penalty value: 10.5675\n",
      "\u001b[32m[I 2025-03-31 13:35:34,949]\u001b[0m Trial 0 finished with value: 10.567534263651368 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.5700000000000001, 'feature_fraction': 0.32, 'min_gain_to_split': 0.87, 'reg_alpha': 8.67, 'reg_lambda': 6.01, 'linear_tree': True}. Best is trial 0 with value: 10.567534263651368.\u001b[0m\n",
      "3it [00:01,  2.12it/s]\n",
      "1th fold: LGBMRegressor RMSE: 25.0251\n",
      "2th fold: LGBMRegressor RMSE: 1.1620\n",
      "3th fold: LGBMRegressor RMSE: 1.1380\n",
      "\n",
      "LGBMRegressor average RMSE: 9.1084\n",
      "LGBMRegressor worst RMSE: 25.0251\n",
      "Corresponding penalty value: 10.7000\n",
      "\u001b[32m[I 2025-03-31 13:35:36,367]\u001b[0m Trial 1 finished with value: 10.700031046916418 and parameters: {'n_estimators': 2925, 'learning_rate': 0.08301, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.59, 'feature_fraction': 0.44, 'min_gain_to_split': 7.87, 'reg_alpha': 4.32, 'reg_lambda': 2.91, 'linear_tree': True}. Best is trial 0 with value: 10.567534263651368.\u001b[0m\n",
      "3it [00:00,  3.63it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.7440\n",
      "2th fold: LGBMRegressor RMSE: 0.7173\n",
      "3th fold: LGBMRegressor RMSE: 1.1737\n",
      "\n",
      "LGBMRegressor average RMSE: 1.5450\n",
      "LGBMRegressor worst RMSE: 2.7440\n",
      "Corresponding penalty value: 1.6649\n",
      "\u001b[32m[I 2025-03-31 13:35:37,196]\u001b[0m Trial 2 finished with value: 1.664892273145763 and parameters: {'n_estimators': 1230, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.6, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 8.89, 'reg_alpha': 0.46, 'reg_lambda': 6.08, 'linear_tree': True}. Best is trial 2 with value: 1.664892273145763.\u001b[0m\n",
      "3it [00:01,  2.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8528\n",
      "2th fold: LGBMRegressor RMSE: 0.2549\n",
      "3th fold: LGBMRegressor RMSE: 1.3293\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8123\n",
      "LGBMRegressor worst RMSE: 1.3293\n",
      "Corresponding penalty value: 0.8640\n",
      "\u001b[32m[I 2025-03-31 13:35:38,394]\u001b[0m Trial 3 finished with value: 0.8640307694664193 and parameters: {'n_estimators': 2873, 'learning_rate': 0.09601, 'max_depth': 11, 'num_leaves': 10, 'subsample': 0.54, 'feature_fraction': 0.75, 'min_gain_to_split': 6.6000000000000005, 'reg_alpha': 1.22, 'reg_lambda': 4.95, 'linear_tree': False}. Best is trial 3 with value: 0.8640307694664193.\u001b[0m\n",
      "3it [00:00,  5.23it/s]\n",
      "1th fold: LGBMRegressor RMSE: 8.3894\n",
      "2th fold: LGBMRegressor RMSE: 10.7416\n",
      "3th fold: LGBMRegressor RMSE: 1.1432\n",
      "\n",
      "LGBMRegressor average RMSE: 6.7580\n",
      "LGBMRegressor worst RMSE: 10.7416\n",
      "Corresponding penalty value: 7.1564\n",
      "\u001b[32m[I 2025-03-31 13:35:38,969]\u001b[0m Trial 4 finished with value: 7.156396901596244 and parameters: {'n_estimators': 1147, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.77, 'feature_fraction': 0.34, 'min_gain_to_split': 14.55, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'linear_tree': True}. Best is trial 3 with value: 0.8640307694664193.\u001b[0m\n",
      "3it [00:01,  2.46it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8571\n",
      "2th fold: LGBMRegressor RMSE: 0.2332\n",
      "3th fold: LGBMRegressor RMSE: 1.4964\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8622\n",
      "LGBMRegressor worst RMSE: 1.4964\n",
      "Corresponding penalty value: 0.9257\n",
      "\u001b[32m[I 2025-03-31 13:35:40,193]\u001b[0m Trial 5 finished with value: 0.9256543038177804 and parameters: {'n_estimators': 2805, 'learning_rate': 0.00801, 'max_depth': 4, 'num_leaves': 3, 'subsample': 0.66, 'feature_fraction': 0.51, 'min_gain_to_split': 4.07, 'reg_alpha': 8.290000000000001, 'reg_lambda': 3.5700000000000003, 'linear_tree': False}. Best is trial 3 with value: 0.8640307694664193.\u001b[0m\n",
      "3it [00:00,  8.30it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7225\n",
      "2th fold: LGBMRegressor RMSE: 0.4463\n",
      "3th fold: LGBMRegressor RMSE: 1.5472\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9053\n",
      "LGBMRegressor worst RMSE: 1.5472\n",
      "Corresponding penalty value: 0.9695\n",
      "\u001b[32m[I 2025-03-31 13:35:40,557]\u001b[0m Trial 6 finished with value: 0.9695284252634135 and parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 3 with value: 0.8640307694664193.\u001b[0m\n",
      "3it [00:00,  5.62it/s]\n",
      "1th fold: LGBMRegressor RMSE: 15.1224\n",
      "2th fold: LGBMRegressor RMSE: 2.1594\n",
      "3th fold: LGBMRegressor RMSE: 1.6668\n",
      "\n",
      "LGBMRegressor average RMSE: 6.3162\n",
      "LGBMRegressor worst RMSE: 15.1224\n",
      "Corresponding penalty value: 7.1968\n",
      "\u001b[32m[I 2025-03-31 13:35:41,093]\u001b[0m Trial 7 finished with value: 7.1968015703568895 and parameters: {'n_estimators': 685, 'learning_rate': 0.035010000000000006, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.81, 'feature_fraction': 0.46, 'min_gain_to_split': 0.9500000000000001, 'reg_alpha': 3.11, 'reg_lambda': 3.25, 'linear_tree': True}. Best is trial 3 with value: 0.8640307694664193.\u001b[0m\n",
      "3it [00:01,  1.95it/s]\n",
      "1th fold: LGBMRegressor RMSE: 44.1810\n",
      "2th fold: LGBMRegressor RMSE: 1.2498\n",
      "3th fold: LGBMRegressor RMSE: 1.0786\n",
      "\n",
      "LGBMRegressor average RMSE: 15.5032\n",
      "LGBMRegressor worst RMSE: 44.1810\n",
      "Corresponding penalty value: 18.3709\n",
      "\u001b[32m[I 2025-03-31 13:35:42,633]\u001b[0m Trial 8 finished with value: 18.37094371588244 and parameters: {'n_estimators': 2718, 'learning_rate': 0.04701, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.88, 'feature_fraction': 0.65, 'min_gain_to_split': 11.57, 'reg_alpha': 4.94, 'reg_lambda': 5.23, 'linear_tree': True}. Best is trial 3 with value: 0.8640307694664193.\u001b[0m\n",
      "3it [00:01,  1.55it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.9669\n",
      "2th fold: LGBMRegressor RMSE: 0.8918\n",
      "3th fold: LGBMRegressor RMSE: 1.2837\n",
      "\n",
      "LGBMRegressor average RMSE: 2.3808\n",
      "LGBMRegressor worst RMSE: 4.9669\n",
      "Corresponding penalty value: 2.6394\n",
      "\u001b[32m[I 2025-03-31 13:35:44,568]\u001b[0m Trial 9 finished with value: 2.639410481082044 and parameters: {'n_estimators': 769, 'learning_rate': 0.00301, 'max_depth': 9, 'num_leaves': 11, 'subsample': 0.75, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 3.74, 'reg_alpha': 4.1, 'reg_lambda': 7.5600000000000005, 'linear_tree': True}. Best is trial 3 with value: 0.8640307694664193.\u001b[0m\n",
      "3it [00:01,  2.84it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8796\n",
      "2th fold: LGBMRegressor RMSE: 0.2145\n",
      "3th fold: LGBMRegressor RMSE: 1.3377\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8106\n",
      "LGBMRegressor worst RMSE: 1.3377\n",
      "Corresponding penalty value: 0.8633\n",
      "\u001b[32m[I 2025-03-31 13:35:45,661]\u001b[0m Trial 10 finished with value: 0.8633088446566531 and parameters: {'n_estimators': 2144, 'learning_rate': 0.06801, 'max_depth': 12, 'num_leaves': 12, 'subsample': 0.5, 'feature_fraction': 0.8300000000000001, 'min_gain_to_split': 5.42, 'reg_alpha': 0.11, 'reg_lambda': 0.97, 'linear_tree': False}. Best is trial 10 with value: 0.8633088446566531.\u001b[0m\n",
      "3it [00:01,  2.73it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8492\n",
      "2th fold: LGBMRegressor RMSE: 0.2584\n",
      "3th fold: LGBMRegressor RMSE: 1.3439\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8171\n",
      "LGBMRegressor worst RMSE: 1.3439\n",
      "Corresponding penalty value: 0.8698\n",
      "\u001b[32m[I 2025-03-31 13:35:46,795]\u001b[0m Trial 11 finished with value: 0.8698070311981667 and parameters: {'n_estimators': 2195, 'learning_rate': 0.06301, 'max_depth': 12, 'num_leaves': 13, 'subsample': 0.5, 'feature_fraction': 0.8300000000000001, 'min_gain_to_split': 5.8, 'reg_alpha': 0.04, 'reg_lambda': 0.15, 'linear_tree': False}. Best is trial 10 with value: 0.8633088446566531.\u001b[0m\n",
      "3it [00:00,  3.22it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8302\n",
      "2th fold: LGBMRegressor RMSE: 0.2267\n",
      "3th fold: LGBMRegressor RMSE: 1.3477\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8015\n",
      "LGBMRegressor worst RMSE: 1.3477\n",
      "Corresponding penalty value: 0.8561\n",
      "\u001b[32m[I 2025-03-31 13:35:47,764]\u001b[0m Trial 12 finished with value: 0.8561319989078723 and parameters: {'n_estimators': 2133, 'learning_rate': 0.09901, 'max_depth': 12, 'num_leaves': 9, 'subsample': 0.5, 'feature_fraction': 0.78, 'min_gain_to_split': 5.73, 'reg_alpha': 2.27, 'reg_lambda': 0.77, 'linear_tree': False}. Best is trial 12 with value: 0.8561319989078723.\u001b[0m\n",
      "3it [00:01,  2.89it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6886\n",
      "2th fold: LGBMRegressor RMSE: 0.2574\n",
      "3th fold: LGBMRegressor RMSE: 1.4083\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7848\n",
      "LGBMRegressor worst RMSE: 1.4083\n",
      "Corresponding penalty value: 0.8471\n",
      "\u001b[32m[I 2025-03-31 13:35:48,841]\u001b[0m Trial 13 finished with value: 0.8471337924943382 and parameters: {'n_estimators': 2144, 'learning_rate': 0.07001, 'max_depth': 12, 'num_leaves': 5, 'subsample': 0.99, 'feature_fraction': 1.0, 'min_gain_to_split': 4.12, 'reg_alpha': 2.13, 'reg_lambda': 0.17, 'linear_tree': False}. Best is trial 13 with value: 0.8471337924943382.\u001b[0m\n",
      "3it [00:00,  3.15it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7203\n",
      "2th fold: LGBMRegressor RMSE: 0.2247\n",
      "3th fold: LGBMRegressor RMSE: 1.5373\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8274\n",
      "LGBMRegressor worst RMSE: 1.5373\n",
      "Corresponding penalty value: 0.8984\n",
      "\u001b[32m[I 2025-03-31 13:35:49,831]\u001b[0m Trial 14 finished with value: 0.8984185158674125 and parameters: {'n_estimators': 1994, 'learning_rate': 0.08201, 'max_depth': 9, 'num_leaves': 4, 'subsample': 0.95, 'feature_fraction': 0.99, 'min_gain_to_split': 2.9, 'reg_alpha': 2.05, 'reg_lambda': 1.58, 'linear_tree': False}. Best is trial 13 with value: 0.8471337924943382.\u001b[0m\n",
      "3it [00:00,  5.24it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0442\n",
      "2th fold: LGBMRegressor RMSE: 0.4022\n",
      "3th fold: LGBMRegressor RMSE: 1.5130\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9864\n",
      "LGBMRegressor worst RMSE: 1.5130\n",
      "Corresponding penalty value: 1.0391\n",
      "\u001b[32m[I 2025-03-31 13:35:50,440]\u001b[0m Trial 15 finished with value: 1.0391045785805666 and parameters: {'n_estimators': 2461, 'learning_rate': 0.09701, 'max_depth': 10, 'num_leaves': 7, 'subsample': 0.66, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 8.78, 'reg_alpha': 6.26, 'reg_lambda': 0.02, 'linear_tree': False}. Best is trial 13 with value: 0.8471337924943382.\u001b[0m\n",
      "3it [00:00,  3.71it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7984\n",
      "2th fold: LGBMRegressor RMSE: 0.4051\n",
      "3th fold: LGBMRegressor RMSE: 1.3560\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8532\n",
      "LGBMRegressor worst RMSE: 1.3560\n",
      "Corresponding penalty value: 0.9035\n",
      "\u001b[32m[I 2025-03-31 13:35:51,287]\u001b[0m Trial 16 finished with value: 0.9034708763252873 and parameters: {'n_estimators': 1773, 'learning_rate': 0.05501, 'max_depth': 12, 'num_leaves': 2, 'subsample': 0.96, 'feature_fraction': 0.8900000000000001, 'min_gain_to_split': 10.31, 'reg_alpha': 2.57, 'reg_lambda': 2.0, 'linear_tree': False}. Best is trial 13 with value: 0.8471337924943382.\u001b[0m\n",
      "3it [00:01,  2.85it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8463\n",
      "2th fold: LGBMRegressor RMSE: 0.2315\n",
      "3th fold: LGBMRegressor RMSE: 1.3401\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8059\n",
      "LGBMRegressor worst RMSE: 1.3401\n",
      "Corresponding penalty value: 0.8594\n",
      "\u001b[32m[I 2025-03-31 13:35:52,377]\u001b[0m Trial 17 finished with value: 0.8593542025093852 and parameters: {'n_estimators': 2446, 'learning_rate': 0.07701, 'max_depth': 8, 'num_leaves': 7, 'subsample': 0.67, 'feature_fraction': 0.72, 'min_gain_to_split': 2.5500000000000003, 'reg_alpha': 6.5600000000000005, 'reg_lambda': 2.07, 'linear_tree': False}. Best is trial 13 with value: 0.8471337924943382.\u001b[0m\n",
      "3it [00:01,  2.84it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9017\n",
      "2th fold: LGBMRegressor RMSE: 0.2554\n",
      "3th fold: LGBMRegressor RMSE: 1.3718\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8430\n",
      "LGBMRegressor worst RMSE: 1.3718\n",
      "Corresponding penalty value: 0.8959\n",
      "\u001b[32m[I 2025-03-31 13:35:53,474]\u001b[0m Trial 18 finished with value: 0.8958508495621252 and parameters: {'n_estimators': 1641, 'learning_rate': 0.02701, 'max_depth': 11, 'num_leaves': 15, 'subsample': 1.0, 'feature_fraction': 1.0, 'min_gain_to_split': 4.82, 'reg_alpha': 3.21, 'reg_lambda': 4.17, 'linear_tree': False}. Best is trial 13 with value: 0.8471337924943382.\u001b[0m\n",
      "3it [00:01,  2.87it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8168\n",
      "2th fold: LGBMRegressor RMSE: 0.2245\n",
      "3th fold: LGBMRegressor RMSE: 1.3527\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7980\n",
      "LGBMRegressor worst RMSE: 1.3527\n",
      "Corresponding penalty value: 0.8535\n",
      "\u001b[32m[I 2025-03-31 13:35:54,559]\u001b[0m Trial 19 finished with value: 0.8534515281948755 and parameters: {'n_estimators': 2471, 'learning_rate': 0.08800999999999999, 'max_depth': 11, 'num_leaves': 9, 'subsample': 0.8300000000000001, 'feature_fraction': 0.75, 'min_gain_to_split': 6.7, 'reg_alpha': 9.82, 'reg_lambda': 1.12, 'linear_tree': False}. Best is trial 13 with value: 0.8471337924943382.\u001b[0m\n",
      "3it [00:01,  2.77it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7341\n",
      "2th fold: LGBMRegressor RMSE: 0.1915\n",
      "3th fold: LGBMRegressor RMSE: 1.3847\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7701\n",
      "LGBMRegressor worst RMSE: 1.3847\n",
      "Corresponding penalty value: 0.8315\n",
      "\u001b[32m[I 2025-03-31 13:35:55,680]\u001b[0m Trial 20 finished with value: 0.8315329192623214 and parameters: {'n_estimators': 2526, 'learning_rate': 0.05201000000000001, 'max_depth': 10, 'num_leaves': 6, 'subsample': 0.8500000000000001, 'feature_fraction': 0.67, 'min_gain_to_split': 11.59, 'reg_alpha': 6.37, 'reg_lambda': 2.5, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:01,  2.87it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7684\n",
      "2th fold: LGBMRegressor RMSE: 0.2307\n",
      "3th fold: LGBMRegressor RMSE: 1.4012\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8001\n",
      "LGBMRegressor worst RMSE: 1.4012\n",
      "Corresponding penalty value: 0.8602\n",
      "\u001b[32m[I 2025-03-31 13:35:56,768]\u001b[0m Trial 21 finished with value: 0.8602350670603778 and parameters: {'n_estimators': 2418, 'learning_rate': 0.05101000000000001, 'max_depth': 10, 'num_leaves': 5, 'subsample': 0.8500000000000001, 'feature_fraction': 0.7, 'min_gain_to_split': 12.94, 'reg_alpha': 5.78, 'reg_lambda': 2.09, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:01,  2.98it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8828\n",
      "2th fold: LGBMRegressor RMSE: 0.3085\n",
      "3th fold: LGBMRegressor RMSE: 1.4451\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8788\n",
      "LGBMRegressor worst RMSE: 1.4451\n",
      "Corresponding penalty value: 0.9354\n",
      "\u001b[32m[I 2025-03-31 13:35:57,817]\u001b[0m Trial 22 finished with value: 0.9353955269728603 and parameters: {'n_estimators': 2537, 'learning_rate': 0.07300999999999999, 'max_depth': 11, 'num_leaves': 6, 'subsample': 0.8200000000000001, 'feature_fraction': 0.55, 'min_gain_to_split': 7.63, 'reg_alpha': 10.0, 'reg_lambda': 1.11, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:00,  3.59it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7836\n",
      "2th fold: LGBMRegressor RMSE: 0.2532\n",
      "3th fold: LGBMRegressor RMSE: 1.3437\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7935\n",
      "LGBMRegressor worst RMSE: 1.3437\n",
      "Corresponding penalty value: 0.8485\n",
      "\u001b[32m[I 2025-03-31 13:35:58,695]\u001b[0m Trial 23 finished with value: 0.8485429254254746 and parameters: {'n_estimators': 1915, 'learning_rate': 0.057010000000000005, 'max_depth': 9, 'num_leaves': 9, 'subsample': 0.91, 'feature_fraction': 0.65, 'min_gain_to_split': 10.36, 'reg_alpha': 9.42, 'reg_lambda': 2.69, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:00,  3.90it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7835\n",
      "2th fold: LGBMRegressor RMSE: 0.4801\n",
      "3th fold: LGBMRegressor RMSE: 1.3884\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8840\n",
      "LGBMRegressor worst RMSE: 1.3884\n",
      "Corresponding penalty value: 0.9345\n",
      "\u001b[32m[I 2025-03-31 13:35:59,507]\u001b[0m Trial 24 finished with value: 0.9344733468198785 and parameters: {'n_estimators': 1754, 'learning_rate': 0.05901000000000001, 'max_depth': 7, 'num_leaves': 2, 'subsample': 0.9199999999999999, 'feature_fraction': 0.64, 'min_gain_to_split': 11.02, 'reg_alpha': 6.61, 'reg_lambda': 2.62, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:00,  3.43it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7587\n",
      "2th fold: LGBMRegressor RMSE: 0.2426\n",
      "3th fold: LGBMRegressor RMSE: 1.3630\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7881\n",
      "LGBMRegressor worst RMSE: 1.3630\n",
      "Corresponding penalty value: 0.8456\n",
      "\u001b[32m[I 2025-03-31 13:36:00,426]\u001b[0m Trial 25 finished with value: 0.8455956299302969 and parameters: {'n_estimators': 2024, 'learning_rate': 0.04301000000000001, 'max_depth': 9, 'num_leaves': 14, 'subsample': 0.96, 'feature_fraction': 0.56, 'min_gain_to_split': 12.5, 'reg_alpha': 7.37, 'reg_lambda': 3.96, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:00,  3.34it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7210\n",
      "2th fold: LGBMRegressor RMSE: 0.2591\n",
      "3th fold: LGBMRegressor RMSE: 1.3951\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7917\n",
      "LGBMRegressor worst RMSE: 1.3951\n",
      "Corresponding penalty value: 0.8521\n",
      "\u001b[32m[I 2025-03-31 13:36:01,368]\u001b[0m Trial 26 finished with value: 0.8520648219983851 and parameters: {'n_estimators': 2269, 'learning_rate': 0.042010000000000006, 'max_depth': 8, 'num_leaves': 20, 'subsample': 1.0, 'feature_fraction': 0.51, 'min_gain_to_split': 14.4, 'reg_alpha': 7.01, 'reg_lambda': 4.43, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:00,  3.06it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7385\n",
      "2th fold: LGBMRegressor RMSE: 0.3503\n",
      "3th fold: LGBMRegressor RMSE: 1.4188\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8359\n",
      "LGBMRegressor worst RMSE: 1.4188\n",
      "Corresponding penalty value: 0.8942\n",
      "\u001b[32m[I 2025-03-31 13:36:02,393]\u001b[0m Trial 27 finished with value: 0.8941847232270668 and parameters: {'n_estimators': 2632, 'learning_rate': 0.02401, 'max_depth': 10, 'num_leaves': 14, 'subsample': 0.96, 'feature_fraction': 0.42000000000000004, 'min_gain_to_split': 13.13, 'reg_alpha': 5.55, 'reg_lambda': 3.97, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:00,  3.74it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7009\n",
      "2th fold: LGBMRegressor RMSE: 0.2057\n",
      "3th fold: LGBMRegressor RMSE: 1.4117\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7728\n",
      "LGBMRegressor worst RMSE: 1.4117\n",
      "Corresponding penalty value: 0.8367\n",
      "\u001b[32m[I 2025-03-31 13:36:03,240]\u001b[0m Trial 28 finished with value: 0.8366563234682793 and parameters: {'n_estimators': 1936, 'learning_rate': 0.04501, 'max_depth': 9, 'num_leaves': 5, 'subsample': 0.9299999999999999, 'feature_fraction': 0.5900000000000001, 'min_gain_to_split': 12.4, 'reg_alpha': 7.49, 'reg_lambda': 5.22, 'linear_tree': False}. Best is trial 20 with value: 0.8315329192623214.\u001b[0m\n",
      "3it [00:00,  3.44it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7332\n",
      "2th fold: LGBMRegressor RMSE: 0.1893\n",
      "3th fold: LGBMRegressor RMSE: 1.3069\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7431\n",
      "LGBMRegressor worst RMSE: 1.3069\n",
      "Corresponding penalty value: 0.7995\n",
      "\u001b[32m[I 2025-03-31 13:36:04,157]\u001b[0m Trial 29 finished with value: 0.7995134018978644 and parameters: {'n_estimators': 1527, 'learning_rate': 0.01601, 'max_depth': 8, 'num_leaves': 16, 'subsample': 0.86, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 12.790000000000001, 'reg_alpha': 7.390000000000001, 'reg_lambda': 5.83, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.75it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6905\n",
      "2th fold: LGBMRegressor RMSE: 0.2128\n",
      "3th fold: LGBMRegressor RMSE: 1.3397\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7477\n",
      "LGBMRegressor worst RMSE: 1.3397\n",
      "Corresponding penalty value: 0.8069\n",
      "\u001b[32m[I 2025-03-31 13:36:05,003]\u001b[0m Trial 30 finished with value: 0.8068533041732638 and parameters: {'n_estimators': 1475, 'learning_rate': 0.01701, 'max_depth': 8, 'num_leaves': 17, 'subsample': 0.86, 'feature_fraction': 0.56, 'min_gain_to_split': 15.0, 'reg_alpha': 8.8, 'reg_lambda': 6.1000000000000005, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.31it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7672\n",
      "2th fold: LGBMRegressor RMSE: 0.1945\n",
      "3th fold: LGBMRegressor RMSE: 1.3081\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7566\n",
      "LGBMRegressor worst RMSE: 1.3081\n",
      "Corresponding penalty value: 0.8117\n",
      "\u001b[32m[I 2025-03-31 13:36:05,956]\u001b[0m Trial 31 finished with value: 0.8117136338484432 and parameters: {'n_estimators': 1543, 'learning_rate': 0.015009999999999999, 'max_depth': 8, 'num_leaves': 18, 'subsample': 0.79, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 13.86, 'reg_alpha': 8.97, 'reg_lambda': 6.29, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.78it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7515\n",
      "2th fold: LGBMRegressor RMSE: 0.2815\n",
      "3th fold: LGBMRegressor RMSE: 1.3863\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8064\n",
      "LGBMRegressor worst RMSE: 1.3863\n",
      "Corresponding penalty value: 0.8644\n",
      "\u001b[32m[I 2025-03-31 13:36:06,796]\u001b[0m Trial 32 finished with value: 0.8643993823756301 and parameters: {'n_estimators': 1532, 'learning_rate': 0.015009999999999999, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.78, 'feature_fraction': 0.49, 'min_gain_to_split': 14.790000000000001, 'reg_alpha': 9.11, 'reg_lambda': 6.49, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.73it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7221\n",
      "2th fold: LGBMRegressor RMSE: 0.1995\n",
      "3th fold: LGBMRegressor RMSE: 1.3117\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7444\n",
      "LGBMRegressor worst RMSE: 1.3117\n",
      "Corresponding penalty value: 0.8012\n",
      "\u001b[32m[I 2025-03-31 13:36:07,649]\u001b[0m Trial 33 finished with value: 0.8011638611297065 and parameters: {'n_estimators': 1339, 'learning_rate': 0.01701, 'max_depth': 8, 'num_leaves': 20, 'subsample': 0.87, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 13.75, 'reg_alpha': 8.69, 'reg_lambda': 8.06, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.27it/s]\n",
      "1th fold: LGBMRegressor RMSE: 8.0076\n",
      "2th fold: LGBMRegressor RMSE: 9.5200\n",
      "3th fold: LGBMRegressor RMSE: 1.8287\n",
      "\n",
      "LGBMRegressor average RMSE: 6.4521\n",
      "LGBMRegressor worst RMSE: 9.5200\n",
      "Corresponding penalty value: 6.7589\n",
      "\u001b[32m[I 2025-03-31 13:36:08,613]\u001b[0m Trial 34 finished with value: 6.7588924252702505 and parameters: {'n_estimators': 1300, 'learning_rate': 0.01701, 'max_depth': 8, 'num_leaves': 19, 'subsample': 0.73, 'feature_fraction': 0.41000000000000003, 'min_gain_to_split': 13.67, 'reg_alpha': 8.83, 'reg_lambda': 8.49, 'linear_tree': True}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.90it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7220\n",
      "2th fold: LGBMRegressor RMSE: 0.2187\n",
      "3th fold: LGBMRegressor RMSE: 1.3098\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7502\n",
      "LGBMRegressor worst RMSE: 1.3098\n",
      "Corresponding penalty value: 0.8061\n",
      "\u001b[32m[I 2025-03-31 13:36:09,431]\u001b[0m Trial 35 finished with value: 0.8061435878749025 and parameters: {'n_estimators': 1023, 'learning_rate': 0.01201, 'max_depth': 7, 'num_leaves': 22, 'subsample': 0.87, 'feature_fraction': 0.6000000000000001, 'min_gain_to_split': 13.93, 'reg_alpha': 8.43, 'reg_lambda': 7.890000000000001, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:01,  1.53it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.8217\n",
      "2th fold: LGBMRegressor RMSE: 1.1023\n",
      "3th fold: LGBMRegressor RMSE: 1.1006\n",
      "\n",
      "LGBMRegressor average RMSE: 2.0082\n",
      "LGBMRegressor worst RMSE: 3.8217\n",
      "Corresponding penalty value: 2.1896\n",
      "\u001b[32m[I 2025-03-31 13:36:11,436]\u001b[0m Trial 36 finished with value: 2.1895628580182374 and parameters: {'n_estimators': 1070, 'learning_rate': 0.00301, 'max_depth': 6, 'num_leaves': 22, 'subsample': 0.87, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 14.86, 'reg_alpha': 8.19, 'reg_lambda': 8.08, 'linear_tree': True}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  5.23it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7158\n",
      "2th fold: LGBMRegressor RMSE: 0.2293\n",
      "3th fold: LGBMRegressor RMSE: 1.3435\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7629\n",
      "LGBMRegressor worst RMSE: 1.3435\n",
      "Corresponding penalty value: 0.8209\n",
      "\u001b[32m[I 2025-03-31 13:36:12,058]\u001b[0m Trial 37 finished with value: 0.8209314182162412 and parameters: {'n_estimators': 983, 'learning_rate': 0.02501, 'max_depth': 7, 'num_leaves': 25, 'subsample': 0.71, 'feature_fraction': 0.54, 'min_gain_to_split': 13.77, 'reg_alpha': 8.540000000000001, 'reg_lambda': 9.78, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.33it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7004\n",
      "2th fold: LGBMRegressor RMSE: 0.2678\n",
      "3th fold: LGBMRegressor RMSE: 1.3545\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7742\n",
      "LGBMRegressor worst RMSE: 1.3545\n",
      "Corresponding penalty value: 0.8323\n",
      "\u001b[32m[I 2025-03-31 13:36:13,006]\u001b[0m Trial 38 finished with value: 0.8322674220580346 and parameters: {'n_estimators': 1353, 'learning_rate': 0.00901, 'max_depth': 7, 'num_leaves': 21, 'subsample': 0.9, 'feature_fraction': 0.47000000000000003, 'min_gain_to_split': 12.030000000000001, 'reg_alpha': 7.91, 'reg_lambda': 8.78, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  4.49it/s]\n",
      "1th fold: LGBMRegressor RMSE: 10.9215\n",
      "2th fold: LGBMRegressor RMSE: 19.3418\n",
      "3th fold: LGBMRegressor RMSE: 1.4265\n",
      "\n",
      "LGBMRegressor average RMSE: 10.5632\n",
      "LGBMRegressor worst RMSE: 19.3418\n",
      "Corresponding penalty value: 11.4411\n",
      "\u001b[32m[I 2025-03-31 13:36:13,724]\u001b[0m Trial 39 finished with value: 11.441097032706175 and parameters: {'n_estimators': 1152, 'learning_rate': 0.032010000000000004, 'max_depth': 5, 'num_leaves': 16, 'subsample': 0.8500000000000001, 'feature_fraction': 0.37, 'min_gain_to_split': 8.96, 'reg_alpha': 9.6, 'reg_lambda': 6.99, 'linear_tree': True}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  8.16it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7230\n",
      "2th fold: LGBMRegressor RMSE: 0.3530\n",
      "3th fold: LGBMRegressor RMSE: 1.4142\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8301\n",
      "LGBMRegressor worst RMSE: 1.4142\n",
      "Corresponding penalty value: 0.8885\n",
      "\u001b[32m[I 2025-03-31 13:36:14,140]\u001b[0m Trial 40 finished with value: 0.8884980785519526 and parameters: {'n_estimators': 557, 'learning_rate': 0.02001, 'max_depth': 6, 'num_leaves': 25, 'subsample': 0.8, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 13.120000000000001, 'reg_alpha': 7.33, 'reg_lambda': 5.82, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.33it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7244\n",
      "2th fold: LGBMRegressor RMSE: 0.1988\n",
      "3th fold: LGBMRegressor RMSE: 1.3264\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7499\n",
      "LGBMRegressor worst RMSE: 1.3264\n",
      "Corresponding penalty value: 0.8075\n",
      "\u001b[32m[I 2025-03-31 13:36:15,090]\u001b[0m Trial 41 finished with value: 0.8075100956158174 and parameters: {'n_estimators': 1439, 'learning_rate': 0.01201, 'max_depth': 8, 'num_leaves': 18, 'subsample': 0.79, 'feature_fraction': 0.6000000000000001, 'min_gain_to_split': 13.99, 'reg_alpha': 9.01, 'reg_lambda': 6.0, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.29it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6937\n",
      "2th fold: LGBMRegressor RMSE: 0.2296\n",
      "3th fold: LGBMRegressor RMSE: 1.3335\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7523\n",
      "LGBMRegressor worst RMSE: 1.3335\n",
      "Corresponding penalty value: 0.8104\n",
      "\u001b[32m[I 2025-03-31 13:36:16,050]\u001b[0m Trial 42 finished with value: 0.8104005458578392 and parameters: {'n_estimators': 1332, 'learning_rate': 0.00901, 'max_depth': 8, 'num_leaves': 23, 'subsample': 0.88, 'feature_fraction': 0.51, 'min_gain_to_split': 14.01, 'reg_alpha': 8.49, 'reg_lambda': 5.79, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.1823\n",
      "2th fold: LGBMRegressor RMSE: 2.9026\n",
      "3th fold: LGBMRegressor RMSE: 4.5546\n",
      "\n",
      "LGBMRegressor average RMSE: 3.2132\n",
      "LGBMRegressor worst RMSE: 4.5546\n",
      "Corresponding penalty value: 3.3473\n",
      "\u001b[32m[I 2025-03-31 13:36:19,006]\u001b[0m Trial 43 finished with value: 3.347308749549243 and parameters: {'n_estimators': 1440, 'learning_rate': 1e-05, 'max_depth': 7, 'num_leaves': 19, 'subsample': 0.76, 'feature_fraction': 0.62, 'min_gain_to_split': 14.96, 'reg_alpha': 9.17, 'reg_lambda': 7.5, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  4.18it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7814\n",
      "2th fold: LGBMRegressor RMSE: 0.2186\n",
      "3th fold: LGBMRegressor RMSE: 1.3298\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7766\n",
      "LGBMRegressor worst RMSE: 1.3298\n",
      "Corresponding penalty value: 0.8319\n",
      "\u001b[32m[I 2025-03-31 13:36:19,774]\u001b[0m Trial 44 finished with value: 0.831926098415249 and parameters: {'n_estimators': 929, 'learning_rate': 0.01301, 'max_depth': 7, 'num_leaves': 17, 'subsample': 0.8400000000000001, 'feature_fraction': 0.7, 'min_gain_to_split': 13.14, 'reg_alpha': 7.82, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  4.65it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7651\n",
      "2th fold: LGBMRegressor RMSE: 0.1980\n",
      "3th fold: LGBMRegressor RMSE: 1.3309\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7647\n",
      "LGBMRegressor worst RMSE: 1.3309\n",
      "Corresponding penalty value: 0.8213\n",
      "\u001b[32m[I 2025-03-31 13:36:20,470]\u001b[0m Trial 45 finished with value: 0.8213020323801327 and parameters: {'n_estimators': 1212, 'learning_rate': 0.03001, 'max_depth': 8, 'num_leaves': 28, 'subsample': 0.87, 'feature_fraction': 0.5800000000000001, 'min_gain_to_split': 14.13, 'reg_alpha': 8.63, 'reg_lambda': 8.93, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:01,  2.83it/s]\n",
      "1th fold: LGBMRegressor RMSE: 25.6357\n",
      "2th fold: LGBMRegressor RMSE: 2.4840\n",
      "3th fold: LGBMRegressor RMSE: 1.1005\n",
      "\n",
      "LGBMRegressor average RMSE: 9.7401\n",
      "LGBMRegressor worst RMSE: 25.6357\n",
      "Corresponding penalty value: 11.3296\n",
      "\u001b[32m[I 2025-03-31 13:36:21,580]\u001b[0m Trial 46 finished with value: 11.32962132348501 and parameters: {'n_estimators': 1654, 'learning_rate': 0.02001, 'max_depth': 6, 'num_leaves': 20, 'subsample': 0.8200000000000001, 'feature_fraction': 0.53, 'min_gain_to_split': 11.34, 'reg_alpha': 9.35, 'reg_lambda': 6.67, 'linear_tree': True}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  4.30it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7411\n",
      "2th fold: LGBMRegressor RMSE: 0.2304\n",
      "3th fold: LGBMRegressor RMSE: 1.3271\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7662\n",
      "LGBMRegressor worst RMSE: 1.3271\n",
      "Corresponding penalty value: 0.8223\n",
      "\u001b[32m[I 2025-03-31 13:36:22,329]\u001b[0m Trial 47 finished with value: 0.8223197074212523 and parameters: {'n_estimators': 1430, 'learning_rate': 0.03601000000000001, 'max_depth': 9, 'num_leaves': 16, 'subsample': 0.72, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 12.540000000000001, 'reg_alpha': 8.09, 'reg_lambda': 7.68, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  3.02it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7179\n",
      "2th fold: LGBMRegressor RMSE: 0.2767\n",
      "3th fold: LGBMRegressor RMSE: 1.3439\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7795\n",
      "LGBMRegressor worst RMSE: 1.3439\n",
      "Corresponding penalty value: 0.8359\n",
      "\u001b[32m[I 2025-03-31 13:36:23,375]\u001b[0m Trial 48 finished with value: 0.8359277108752 and parameters: {'n_estimators': 1073, 'learning_rate': 0.00601, 'max_depth': 5, 'num_leaves': 18, 'subsample': 0.8, 'feature_fraction': 0.44, 'min_gain_to_split': 10.43, 'reg_alpha': 8.78, 'reg_lambda': 4.93, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "3it [00:00,  4.91it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7857\n",
      "2th fold: LGBMRegressor RMSE: 0.2109\n",
      "3th fold: LGBMRegressor RMSE: 1.3593\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7853\n",
      "LGBMRegressor worst RMSE: 1.3593\n",
      "Corresponding penalty value: 0.8427\n",
      "\u001b[32m[I 2025-03-31 13:36:24,037]\u001b[0m Trial 49 finished with value: 0.8426994900553977 and parameters: {'n_estimators': 814, 'learning_rate': 0.02201, 'max_depth': 7, 'num_leaves': 23, 'subsample': 0.9299999999999999, 'feature_fraction': 0.8, 'min_gain_to_split': 11.9, 'reg_alpha': 6.96, 'reg_lambda': 5.57, 'linear_tree': False}. Best is trial 29 with value: 0.7995134018978644.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1527, 'learning_rate': 0.01601, 'max_depth': 8, 'num_leaves': 16, 'subsample': 0.86, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 12.790000000000001, 'reg_alpha': 7.390000000000001, 'reg_lambda': 5.83, 'linear_tree': False}\n",
      "3it [00:00,  3.34it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7259\n",
      "2th fold: LGBMRegressor RMSE: 0.2119\n",
      "3th fold: LGBMRegressor RMSE: 1.3098\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7492\n",
      "LGBMRegressor worst RMSE: 1.3098\n",
      "Corresponding penalty value: 0.8053\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV3\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1527, 'learning_rate': 0.01601, 'max_depth': 8, 'num_leaves': 16, 'subsample': 0.86, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 12.790000000000001, 'reg_alpha': 7.390000000000001, 'reg_lambda': 5.83, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.112\n",
      "RMSE_crossval: 0.749\n",
      "RMSE_test: 0.651\n",
      "MAE_test: 0.413\n",
      "Nash-Sutcliffe Test: 0.974\n",
      "Kling-Gupta Test: 0.950\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 51.7682 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:36:26,032]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV51\u001b[0m\n",
      "3it [00:00,  4.32it/s]\n",
      "1th fold: LGBMRegressor RMSE: 53.4240\n",
      "2th fold: LGBMRegressor RMSE: 71.2067\n",
      "3th fold: LGBMRegressor RMSE: 10.0918\n",
      "\n",
      "LGBMRegressor average RMSE: 44.9075\n",
      "LGBMRegressor worst RMSE: 71.2067\n",
      "Corresponding penalty value: 47.5374\n",
      "\u001b[32m[I 2025-03-31 13:36:26,728]\u001b[0m Trial 0 finished with value: 47.53742327441624 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.5700000000000001, 'feature_fraction': 0.32, 'min_gain_to_split': 0.87, 'reg_alpha': 8.67, 'reg_lambda': 6.01, 'linear_tree': True}. Best is trial 0 with value: 47.53742327441624.\u001b[0m\n",
      "3it [00:01,  2.11it/s]\n",
      "1th fold: LGBMRegressor RMSE: 23.5300\n",
      "2th fold: LGBMRegressor RMSE: 0.7647\n",
      "3th fold: LGBMRegressor RMSE: 0.7392\n",
      "\n",
      "LGBMRegressor average RMSE: 8.3447\n",
      "LGBMRegressor worst RMSE: 23.5300\n",
      "Corresponding penalty value: 9.8632\n",
      "\u001b[32m[I 2025-03-31 13:36:28,155]\u001b[0m Trial 1 finished with value: 9.863200569186198 and parameters: {'n_estimators': 2925, 'learning_rate': 0.08301, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.59, 'feature_fraction': 0.44, 'min_gain_to_split': 7.87, 'reg_alpha': 4.32, 'reg_lambda': 2.91, 'linear_tree': True}. Best is trial 1 with value: 9.863200569186198.\u001b[0m\n",
      "3it [00:00,  3.52it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.3541\n",
      "2th fold: LGBMRegressor RMSE: 1.6876\n",
      "3th fold: LGBMRegressor RMSE: 0.9294\n",
      "\n",
      "LGBMRegressor average RMSE: 1.9904\n",
      "LGBMRegressor worst RMSE: 3.3541\n",
      "Corresponding penalty value: 2.1267\n",
      "\u001b[32m[I 2025-03-31 13:36:29,011]\u001b[0m Trial 2 finished with value: 2.126746794717974 and parameters: {'n_estimators': 1230, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.6, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 8.89, 'reg_alpha': 0.46, 'reg_lambda': 6.08, 'linear_tree': True}. Best is trial 2 with value: 2.126746794717974.\u001b[0m\n",
      "3it [00:01,  2.44it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0874\n",
      "2th fold: LGBMRegressor RMSE: 0.4097\n",
      "3th fold: LGBMRegressor RMSE: 1.0936\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8636\n",
      "LGBMRegressor worst RMSE: 1.0936\n",
      "Corresponding penalty value: 0.8866\n",
      "\u001b[32m[I 2025-03-31 13:36:30,245]\u001b[0m Trial 3 finished with value: 0.8865594799637719 and parameters: {'n_estimators': 2873, 'learning_rate': 0.09601, 'max_depth': 11, 'num_leaves': 10, 'subsample': 0.54, 'feature_fraction': 0.75, 'min_gain_to_split': 6.6000000000000005, 'reg_alpha': 1.22, 'reg_lambda': 4.95, 'linear_tree': False}. Best is trial 3 with value: 0.8865594799637719.\u001b[0m\n",
      "3it [00:00,  5.06it/s]\n",
      "1th fold: LGBMRegressor RMSE: 31.5185\n",
      "2th fold: LGBMRegressor RMSE: 2.6564\n",
      "3th fold: LGBMRegressor RMSE: 3.7456\n",
      "\n",
      "LGBMRegressor average RMSE: 12.6402\n",
      "LGBMRegressor worst RMSE: 31.5185\n",
      "Corresponding penalty value: 14.5280\n",
      "\u001b[32m[I 2025-03-31 13:36:30,840]\u001b[0m Trial 4 finished with value: 14.528034601342856 and parameters: {'n_estimators': 1147, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.77, 'feature_fraction': 0.34, 'min_gain_to_split': 14.55, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'linear_tree': True}. Best is trial 3 with value: 0.8865594799637719.\u001b[0m\n",
      "3it [00:01,  2.50it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4253\n",
      "2th fold: LGBMRegressor RMSE: 0.3723\n",
      "3th fold: LGBMRegressor RMSE: 1.0956\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9644\n",
      "LGBMRegressor worst RMSE: 1.4253\n",
      "Corresponding penalty value: 1.0105\n",
      "\u001b[32m[I 2025-03-31 13:36:32,045]\u001b[0m Trial 5 finished with value: 1.0105017317283715 and parameters: {'n_estimators': 2805, 'learning_rate': 0.00801, 'max_depth': 4, 'num_leaves': 3, 'subsample': 0.66, 'feature_fraction': 0.51, 'min_gain_to_split': 4.07, 'reg_alpha': 8.290000000000001, 'reg_lambda': 3.5700000000000003, 'linear_tree': False}. Best is trial 3 with value: 0.8865594799637719.\u001b[0m\n",
      "3it [00:00,  8.26it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3215\n",
      "2th fold: LGBMRegressor RMSE: 0.3782\n",
      "3th fold: LGBMRegressor RMSE: 1.1694\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9564\n",
      "LGBMRegressor worst RMSE: 1.3215\n",
      "Corresponding penalty value: 0.9929\n",
      "\u001b[32m[I 2025-03-31 13:36:32,411]\u001b[0m Trial 6 finished with value: 0.9928809741949369 and parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 3 with value: 0.8865594799637719.\u001b[0m\n",
      "3it [00:00,  5.37it/s]\n",
      "1th fold: LGBMRegressor RMSE: 70.1228\n",
      "2th fold: LGBMRegressor RMSE: 10.8313\n",
      "3th fold: LGBMRegressor RMSE: 3.8644\n",
      "\n",
      "LGBMRegressor average RMSE: 28.2728\n",
      "LGBMRegressor worst RMSE: 70.1228\n",
      "Corresponding penalty value: 32.4578\n",
      "\u001b[32m[I 2025-03-31 13:36:32,972]\u001b[0m Trial 7 finished with value: 32.45783321729036 and parameters: {'n_estimators': 685, 'learning_rate': 0.035010000000000006, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.81, 'feature_fraction': 0.46, 'min_gain_to_split': 0.9500000000000001, 'reg_alpha': 3.11, 'reg_lambda': 3.25, 'linear_tree': True}. Best is trial 3 with value: 0.8865594799637719.\u001b[0m\n",
      "3it [00:01,  1.96it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.9274\n",
      "2th fold: LGBMRegressor RMSE: 0.8418\n",
      "3th fold: LGBMRegressor RMSE: 0.8728\n",
      "\n",
      "LGBMRegressor average RMSE: 1.5473\n",
      "LGBMRegressor worst RMSE: 2.9274\n",
      "Corresponding penalty value: 1.6854\n",
      "\u001b[32m[I 2025-03-31 13:36:34,507]\u001b[0m Trial 8 finished with value: 1.685355099921598 and parameters: {'n_estimators': 2718, 'learning_rate': 0.04701, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.88, 'feature_fraction': 0.65, 'min_gain_to_split': 11.57, 'reg_alpha': 4.94, 'reg_lambda': 5.23, 'linear_tree': True}. Best is trial 3 with value: 0.8865594799637719.\u001b[0m\n",
      "3it [00:02,  1.48it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.2130\n",
      "2th fold: LGBMRegressor RMSE: 0.7573\n",
      "3th fold: LGBMRegressor RMSE: 0.7324\n",
      "\n",
      "LGBMRegressor average RMSE: 1.2342\n",
      "LGBMRegressor worst RMSE: 2.2130\n",
      "Corresponding penalty value: 1.3321\n",
      "\u001b[32m[I 2025-03-31 13:36:36,543]\u001b[0m Trial 9 finished with value: 1.3321258233324766 and parameters: {'n_estimators': 769, 'learning_rate': 0.00301, 'max_depth': 9, 'num_leaves': 11, 'subsample': 0.75, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 3.74, 'reg_alpha': 4.1, 'reg_lambda': 7.5600000000000005, 'linear_tree': True}. Best is trial 3 with value: 0.8865594799637719.\u001b[0m\n",
      "3it [00:01,  2.79it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9987\n",
      "2th fold: LGBMRegressor RMSE: 0.4293\n",
      "3th fold: LGBMRegressor RMSE: 1.0986\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8422\n",
      "LGBMRegressor worst RMSE: 1.0986\n",
      "Corresponding penalty value: 0.8678\n",
      "\u001b[32m[I 2025-03-31 13:36:37,653]\u001b[0m Trial 10 finished with value: 0.8678413012684828 and parameters: {'n_estimators': 2144, 'learning_rate': 0.06801, 'max_depth': 12, 'num_leaves': 12, 'subsample': 0.5, 'feature_fraction': 0.8300000000000001, 'min_gain_to_split': 5.42, 'reg_alpha': 0.11, 'reg_lambda': 0.97, 'linear_tree': False}. Best is trial 10 with value: 0.8678413012684828.\u001b[0m\n",
      "3it [00:01,  2.68it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2156\n",
      "2th fold: LGBMRegressor RMSE: 0.4343\n",
      "3th fold: LGBMRegressor RMSE: 1.0738\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9079\n",
      "LGBMRegressor worst RMSE: 1.2156\n",
      "Corresponding penalty value: 0.9386\n",
      "\u001b[32m[I 2025-03-31 13:36:38,807]\u001b[0m Trial 11 finished with value: 0.9386390882290289 and parameters: {'n_estimators': 2195, 'learning_rate': 0.06301, 'max_depth': 12, 'num_leaves': 13, 'subsample': 0.5, 'feature_fraction': 0.8300000000000001, 'min_gain_to_split': 5.8, 'reg_alpha': 0.04, 'reg_lambda': 0.15, 'linear_tree': False}. Best is trial 10 with value: 0.8678413012684828.\u001b[0m\n",
      "3it [00:00,  3.20it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9853\n",
      "2th fold: LGBMRegressor RMSE: 0.4281\n",
      "3th fold: LGBMRegressor RMSE: 1.1561\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8565\n",
      "LGBMRegressor worst RMSE: 1.1561\n",
      "Corresponding penalty value: 0.8865\n",
      "\u001b[32m[I 2025-03-31 13:36:39,782]\u001b[0m Trial 12 finished with value: 0.8864836397092869 and parameters: {'n_estimators': 2133, 'learning_rate': 0.09901, 'max_depth': 12, 'num_leaves': 9, 'subsample': 0.5, 'feature_fraction': 0.78, 'min_gain_to_split': 5.73, 'reg_alpha': 2.27, 'reg_lambda': 0.77, 'linear_tree': False}. Best is trial 10 with value: 0.8678413012684828.\u001b[0m\n",
      "3it [00:01,  2.92it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7166\n",
      "2th fold: LGBMRegressor RMSE: 0.4373\n",
      "3th fold: LGBMRegressor RMSE: 1.0313\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7284\n",
      "LGBMRegressor worst RMSE: 1.0313\n",
      "Corresponding penalty value: 0.7587\n",
      "\u001b[32m[I 2025-03-31 13:36:40,845]\u001b[0m Trial 13 finished with value: 0.7586944768315097 and parameters: {'n_estimators': 2144, 'learning_rate': 0.07001, 'max_depth': 12, 'num_leaves': 5, 'subsample': 0.99, 'feature_fraction': 1.0, 'min_gain_to_split': 4.12, 'reg_alpha': 2.13, 'reg_lambda': 0.17, 'linear_tree': False}. Best is trial 13 with value: 0.7586944768315097.\u001b[0m\n",
      "3it [00:00,  3.15it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6082\n",
      "2th fold: LGBMRegressor RMSE: 0.4352\n",
      "3th fold: LGBMRegressor RMSE: 1.0413\n",
      "\n",
      "LGBMRegressor average RMSE: 0.6949\n",
      "LGBMRegressor worst RMSE: 1.0413\n",
      "Corresponding penalty value: 0.7295\n",
      "\u001b[32m[I 2025-03-31 13:36:41,835]\u001b[0m Trial 14 finished with value: 0.7295191387192693 and parameters: {'n_estimators': 1994, 'learning_rate': 0.06401, 'max_depth': 9, 'num_leaves': 4, 'subsample': 0.95, 'feature_fraction': 0.99, 'min_gain_to_split': 3.39, 'reg_alpha': 2.0100000000000002, 'reg_lambda': 1.58, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.43it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7453\n",
      "2th fold: LGBMRegressor RMSE: 0.3698\n",
      "3th fold: LGBMRegressor RMSE: 1.0491\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7214\n",
      "LGBMRegressor worst RMSE: 1.0491\n",
      "Corresponding penalty value: 0.7542\n",
      "\u001b[32m[I 2025-03-31 13:36:42,746]\u001b[0m Trial 15 finished with value: 0.7541531795132748 and parameters: {'n_estimators': 1779, 'learning_rate': 0.05501, 'max_depth': 9, 'num_leaves': 3, 'subsample': 1.0, 'feature_fraction': 0.98, 'min_gain_to_split': 2.7, 'reg_alpha': 6.26, 'reg_lambda': 2.11, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  6.77it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.0301\n",
      "2th fold: LGBMRegressor RMSE: 0.4053\n",
      "3th fold: LGBMRegressor RMSE: 1.1875\n",
      "\n",
      "LGBMRegressor average RMSE: 1.2076\n",
      "LGBMRegressor worst RMSE: 2.0301\n",
      "Corresponding penalty value: 1.2899\n",
      "\u001b[32m[I 2025-03-31 13:36:43,228]\u001b[0m Trial 16 finished with value: 1.289873460404551 and parameters: {'n_estimators': 1764, 'learning_rate': 0.05201000000000001, 'max_depth': 8, 'num_leaves': 2, 'subsample': 1.0, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 2.56, 'reg_alpha': 6.2700000000000005, 'reg_lambda': 2.22, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.64it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7281\n",
      "2th fold: LGBMRegressor RMSE: 0.4951\n",
      "3th fold: LGBMRegressor RMSE: 1.0373\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7535\n",
      "LGBMRegressor worst RMSE: 1.0373\n",
      "Corresponding penalty value: 0.7819\n",
      "\u001b[32m[I 2025-03-31 13:36:44,402]\u001b[0m Trial 17 finished with value: 0.7818797880818091 and parameters: {'n_estimators': 1686, 'learning_rate': 0.01701, 'max_depth': 9, 'num_leaves': 6, 'subsample': 0.9299999999999999, 'feature_fraction': 0.95, 'min_gain_to_split': 2.23, 'reg_alpha': 6.5600000000000005, 'reg_lambda': 1.94, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.70it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1298\n",
      "2th fold: LGBMRegressor RMSE: 0.3429\n",
      "3th fold: LGBMRegressor RMSE: 1.0983\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8570\n",
      "LGBMRegressor worst RMSE: 1.1298\n",
      "Corresponding penalty value: 0.8843\n",
      "\u001b[32m[I 2025-03-31 13:36:45,553]\u001b[0m Trial 18 finished with value: 0.8843117319725028 and parameters: {'n_estimators': 2486, 'learning_rate': 0.050010000000000006, 'max_depth': 8, 'num_leaves': 2, 'subsample': 0.9299999999999999, 'feature_fraction': 0.8900000000000001, 'min_gain_to_split': 9.6, 'reg_alpha': 6.33, 'reg_lambda': 4.18, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.17it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9633\n",
      "2th fold: LGBMRegressor RMSE: 0.3800\n",
      "3th fold: LGBMRegressor RMSE: 1.0750\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8061\n",
      "LGBMRegressor worst RMSE: 1.0750\n",
      "Corresponding penalty value: 0.8329\n",
      "\u001b[32m[I 2025-03-31 13:36:46,539]\u001b[0m Trial 19 finished with value: 0.8329490746619361 and parameters: {'n_estimators': 1830, 'learning_rate': 0.032010000000000004, 'max_depth': 10, 'num_leaves': 15, 'subsample': 0.8400000000000001, 'feature_fraction': 0.69, 'min_gain_to_split': 2.58, 'reg_alpha': 9.82, 'reg_lambda': 1.9100000000000001, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.53it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0202\n",
      "2th fold: LGBMRegressor RMSE: 0.3862\n",
      "3th fold: LGBMRegressor RMSE: 1.0656\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8240\n",
      "LGBMRegressor worst RMSE: 1.0656\n",
      "Corresponding penalty value: 0.8481\n",
      "\u001b[32m[I 2025-03-31 13:36:47,764]\u001b[0m Trial 20 finished with value: 0.8481322101186856 and parameters: {'n_estimators': 2426, 'learning_rate': 0.05901000000000001, 'max_depth': 7, 'num_leaves': 8, 'subsample': 0.96, 'feature_fraction': 1.0, 'min_gain_to_split': 4.32, 'reg_alpha': 3.3200000000000003, 'reg_lambda': 1.37, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.16it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7416\n",
      "2th fold: LGBMRegressor RMSE: 0.4541\n",
      "3th fold: LGBMRegressor RMSE: 1.0207\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7388\n",
      "LGBMRegressor worst RMSE: 1.0207\n",
      "Corresponding penalty value: 0.7670\n",
      "\u001b[32m[I 2025-03-31 13:36:48,756]\u001b[0m Trial 21 finished with value: 0.767007138762463 and parameters: {'n_estimators': 1992, 'learning_rate': 0.07601, 'max_depth': 10, 'num_leaves': 5, 'subsample': 1.0, 'feature_fraction': 1.0, 'min_gain_to_split': 3.36, 'reg_alpha': 2.11, 'reg_lambda': 0.27, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.99it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7559\n",
      "2th fold: LGBMRegressor RMSE: 0.4370\n",
      "3th fold: LGBMRegressor RMSE: 1.0246\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7392\n",
      "LGBMRegressor worst RMSE: 1.0246\n",
      "Corresponding penalty value: 0.7677\n",
      "\u001b[32m[I 2025-03-31 13:36:49,548]\u001b[0m Trial 22 finished with value: 0.7677196948125007 and parameters: {'n_estimators': 1518, 'learning_rate': 0.07300999999999999, 'max_depth': 9, 'num_leaves': 5, 'subsample': 0.96, 'feature_fraction': 0.8900000000000001, 'min_gain_to_split': 1.56, 'reg_alpha': 1.75, 'reg_lambda': 2.59, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.41it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7464\n",
      "2th fold: LGBMRegressor RMSE: 0.4242\n",
      "3th fold: LGBMRegressor RMSE: 1.0163\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7290\n",
      "LGBMRegressor worst RMSE: 1.0163\n",
      "Corresponding penalty value: 0.7577\n",
      "\u001b[32m[I 2025-03-31 13:36:50,837]\u001b[0m Trial 23 finished with value: 0.7576992824730145 and parameters: {'n_estimators': 2386, 'learning_rate': 0.057010000000000005, 'max_depth': 11, 'num_leaves': 5, 'subsample': 0.89, 'feature_fraction': 1.0, 'min_gain_to_split': 4.83, 'reg_alpha': 3.17, 'reg_lambda': 1.31, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.76it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7194\n",
      "2th fold: LGBMRegressor RMSE: 0.3957\n",
      "3th fold: LGBMRegressor RMSE: 1.0365\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7172\n",
      "LGBMRegressor worst RMSE: 1.0365\n",
      "Corresponding penalty value: 0.7491\n",
      "\u001b[32m[I 2025-03-31 13:36:51,965]\u001b[0m Trial 24 finished with value: 0.7491229069531136 and parameters: {'n_estimators': 2373, 'learning_rate': 0.056010000000000004, 'max_depth': 11, 'num_leaves': 4, 'subsample': 0.88, 'feature_fraction': 0.8600000000000001, 'min_gain_to_split': 7.140000000000001, 'reg_alpha': 5.47, 'reg_lambda': 1.33, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.42it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2306\n",
      "2th fold: LGBMRegressor RMSE: 0.4250\n",
      "3th fold: LGBMRegressor RMSE: 1.0574\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9043\n",
      "LGBMRegressor worst RMSE: 1.2306\n",
      "Corresponding penalty value: 0.9369\n",
      "\u001b[32m[I 2025-03-31 13:36:52,886]\u001b[0m Trial 25 finished with value: 0.9369498770619342 and parameters: {'n_estimators': 1920, 'learning_rate': 0.04301000000000001, 'max_depth': 11, 'num_leaves': 2, 'subsample': 0.8400000000000001, 'feature_fraction': 0.8600000000000001, 'min_gain_to_split': 10.42, 'reg_alpha': 5.2700000000000005, 'reg_lambda': 4.04, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.72it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0912\n",
      "2th fold: LGBMRegressor RMSE: 0.3687\n",
      "3th fold: LGBMRegressor RMSE: 1.0811\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8470\n",
      "LGBMRegressor worst RMSE: 1.0912\n",
      "Corresponding penalty value: 0.8714\n",
      "\u001b[32m[I 2025-03-31 13:36:54,030]\u001b[0m Trial 26 finished with value: 0.8714115676690629 and parameters: {'n_estimators': 2583, 'learning_rate': 0.08701, 'max_depth': 9, 'num_leaves': 8, 'subsample': 0.71, 'feature_fraction': 0.76, 'min_gain_to_split': 6.86, 'reg_alpha': 7.01, 'reg_lambda': 2.1, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.28it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1669\n",
      "2th fold: LGBMRegressor RMSE: 0.3815\n",
      "3th fold: LGBMRegressor RMSE: 1.1084\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8856\n",
      "LGBMRegressor worst RMSE: 1.1669\n",
      "Corresponding penalty value: 0.9137\n",
      "\u001b[32m[I 2025-03-31 13:36:54,989]\u001b[0m Trial 27 finished with value: 0.913729121784323 and parameters: {'n_estimators': 1580, 'learning_rate': 0.058010000000000006, 'max_depth': 8, 'num_leaves': 14, 'subsample': 0.9299999999999999, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 7.7, 'reg_alpha': 5.55, 'reg_lambda': 1.21, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.98it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2847\n",
      "2th fold: LGBMRegressor RMSE: 0.4164\n",
      "3th fold: LGBMRegressor RMSE: 1.1002\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9338\n",
      "LGBMRegressor worst RMSE: 1.2847\n",
      "Corresponding penalty value: 0.9688\n",
      "\u001b[32m[I 2025-03-31 13:36:56,039]\u001b[0m Trial 28 finished with value: 0.968844433513306 and parameters: {'n_estimators': 2304, 'learning_rate': 0.040010000000000004, 'max_depth': 10, 'num_leaves': 4, 'subsample': 0.8500000000000001, 'feature_fraction': 0.71, 'min_gain_to_split': 10.93, 'reg_alpha': 4.42, 'reg_lambda': 2.98, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.81it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9969\n",
      "2th fold: LGBMRegressor RMSE: 0.3859\n",
      "3th fold: LGBMRegressor RMSE: 1.1146\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8325\n",
      "LGBMRegressor worst RMSE: 1.1146\n",
      "Corresponding penalty value: 0.8607\n",
      "\u001b[32m[I 2025-03-31 13:36:57,153]\u001b[0m Trial 29 finished with value: 0.86069743821936 and parameters: {'n_estimators': 1952, 'learning_rate': 0.02701, 'max_depth': 10, 'num_leaves': 21, 'subsample': 0.95, 'feature_fraction': 0.8200000000000001, 'min_gain_to_split': 12.790000000000001, 'reg_alpha': 7.29, 'reg_lambda': 3.91, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.34it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2797\n",
      "2th fold: LGBMRegressor RMSE: 0.3599\n",
      "3th fold: LGBMRegressor RMSE: 1.0796\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9064\n",
      "LGBMRegressor worst RMSE: 1.2797\n",
      "Corresponding penalty value: 0.9437\n",
      "\u001b[32m[I 2025-03-31 13:36:58,481]\u001b[0m Trial 30 finished with value: 0.943724888620701 and parameters: {'n_estimators': 1341, 'learning_rate': 0.02401, 'max_depth': 11, 'num_leaves': 17, 'subsample': 0.91, 'feature_fraction': 0.9099999999999999, 'min_gain_to_split': 0.03, 'reg_alpha': 9.48, 'reg_lambda': 4.75, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.36it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9588\n",
      "2th fold: LGBMRegressor RMSE: 0.4282\n",
      "3th fold: LGBMRegressor RMSE: 1.0194\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8021\n",
      "LGBMRegressor worst RMSE: 1.0194\n",
      "Corresponding penalty value: 0.8239\n",
      "\u001b[32m[I 2025-03-31 13:36:59,796]\u001b[0m Trial 31 finished with value: 0.8238633026442082 and parameters: {'n_estimators': 2361, 'learning_rate': 0.056010000000000004, 'max_depth': 11, 'num_leaves': 7, 'subsample': 0.88, 'feature_fraction': 0.97, 'min_gain_to_split': 5.01, 'reg_alpha': 3.34, 'reg_lambda': 1.55, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.61it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6088\n",
      "2th fold: LGBMRegressor RMSE: 0.4177\n",
      "3th fold: LGBMRegressor RMSE: 1.0748\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7004\n",
      "LGBMRegressor worst RMSE: 1.0748\n",
      "Corresponding penalty value: 0.7379\n",
      "\u001b[32m[I 2025-03-31 13:37:00,992]\u001b[0m Trial 32 finished with value: 0.7378745259884077 and parameters: {'n_estimators': 2495, 'learning_rate': 0.06101, 'max_depth': 11, 'num_leaves': 4, 'subsample': 0.8, 'feature_fraction': 0.95, 'min_gain_to_split': 8.6, 'reg_alpha': 5.79, 'reg_lambda': 0.76, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8904\n",
      "2th fold: LGBMRegressor RMSE: 0.4341\n",
      "3th fold: LGBMRegressor RMSE: 1.0455\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7900\n",
      "LGBMRegressor worst RMSE: 1.0455\n",
      "Corresponding penalty value: 0.8155\n",
      "\u001b[32m[I 2025-03-31 13:37:02,232]\u001b[0m Trial 33 finished with value: 0.815535281558363 and parameters: {'n_estimators': 2642, 'learning_rate': 0.08701, 'max_depth': 9, 'num_leaves': 7, 'subsample': 0.8, 'feature_fraction': 0.8700000000000001, 'min_gain_to_split': 8.0, 'reg_alpha': 5.59, 'reg_lambda': 0.62, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.21it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.0941\n",
      "2th fold: LGBMRegressor RMSE: 0.4435\n",
      "3th fold: LGBMRegressor RMSE: 0.6932\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4103\n",
      "LGBMRegressor worst RMSE: 3.0941\n",
      "Corresponding penalty value: 1.5787\n",
      "\u001b[32m[I 2025-03-31 13:37:03,636]\u001b[0m Trial 34 finished with value: 1.5786636464654016 and parameters: {'n_estimators': 2007, 'learning_rate': 0.06401, 'max_depth': 6, 'num_leaves': 10, 'subsample': 0.97, 'feature_fraction': 0.94, 'min_gain_to_split': 9.02, 'reg_alpha': 6.03, 'reg_lambda': 2.8000000000000003, 'linear_tree': True}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.59it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.5948\n",
      "2th fold: LGBMRegressor RMSE: 0.4274\n",
      "3th fold: LGBMRegressor RMSE: 1.0528\n",
      "\n",
      "LGBMRegressor average RMSE: 1.0250\n",
      "LGBMRegressor worst RMSE: 1.5948\n",
      "Corresponding penalty value: 1.0820\n",
      "\u001b[32m[I 2025-03-31 13:37:04,841]\u001b[0m Trial 35 finished with value: 1.0819800701409095 and parameters: {'n_estimators': 2955, 'learning_rate': 0.04501, 'max_depth': 10, 'num_leaves': 4, 'subsample': 0.75, 'feature_fraction': 0.54, 'min_gain_to_split': 6.57, 'reg_alpha': 4.7700000000000005, 'reg_lambda': 2.49, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  4.09it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1438\n",
      "2th fold: LGBMRegressor RMSE: 0.4030\n",
      "3th fold: LGBMRegressor RMSE: 0.7905\n",
      "\n",
      "LGBMRegressor average RMSE: 2.1124\n",
      "LGBMRegressor worst RMSE: 5.1438\n",
      "Corresponding penalty value: 2.4155\n",
      "\u001b[32m[I 2025-03-31 13:37:05,620]\u001b[0m Trial 36 finished with value: 2.415547449220351 and parameters: {'n_estimators': 1063, 'learning_rate': 0.05201000000000001, 'max_depth': 7, 'num_leaves': 4, 'subsample': 0.7, 'feature_fraction': 0.8, 'min_gain_to_split': 8.8, 'reg_alpha': 7.04, 'reg_lambda': 0.66, 'linear_tree': True}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.55it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9429\n",
      "2th fold: LGBMRegressor RMSE: 0.4106\n",
      "3th fold: LGBMRegressor RMSE: 1.1255\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8263\n",
      "LGBMRegressor worst RMSE: 1.1255\n",
      "Corresponding penalty value: 0.8562\n",
      "\u001b[32m[I 2025-03-31 13:37:06,843]\u001b[0m Trial 37 finished with value: 0.8562385737224583 and parameters: {'n_estimators': 2531, 'learning_rate': 0.07601, 'max_depth': 8, 'num_leaves': 9, 'subsample': 0.79, 'feature_fraction': 0.8700000000000001, 'min_gain_to_split': 6.72, 'reg_alpha': 3.96, 'reg_lambda': 1.68, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.02it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1854\n",
      "2th fold: LGBMRegressor RMSE: 0.4363\n",
      "3th fold: LGBMRegressor RMSE: 1.0014\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8744\n",
      "LGBMRegressor worst RMSE: 1.1854\n",
      "Corresponding penalty value: 0.9055\n",
      "\u001b[32m[I 2025-03-31 13:37:07,885]\u001b[0m Trial 38 finished with value: 0.9054865013005321 and parameters: {'n_estimators': 2268, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 3, 'subsample': 0.86, 'feature_fraction': 0.72, 'min_gain_to_split': 1.43, 'reg_alpha': 0.8200000000000001, 'reg_lambda': 8.69, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  1.72it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.3592\n",
      "2th fold: LGBMRegressor RMSE: 0.4691\n",
      "3th fold: LGBMRegressor RMSE: 0.7237\n",
      "\n",
      "LGBMRegressor average RMSE: 1.1840\n",
      "LGBMRegressor worst RMSE: 2.3592\n",
      "Corresponding penalty value: 1.3015\n",
      "\u001b[32m[I 2025-03-31 13:37:09,680]\u001b[0m Trial 39 finished with value: 1.3015326672543417 and parameters: {'n_estimators': 2707, 'learning_rate': 0.08301, 'max_depth': 10, 'num_leaves': 6, 'subsample': 0.91, 'feature_fraction': 0.96, 'min_gain_to_split': 14.68, 'reg_alpha': 7.6000000000000005, 'reg_lambda': 5.4, 'linear_tree': True}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.62it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2345\n",
      "2th fold: LGBMRegressor RMSE: 0.4369\n",
      "3th fold: LGBMRegressor RMSE: 1.1373\n",
      "\n",
      "LGBMRegressor average RMSE: 0.9362\n",
      "LGBMRegressor worst RMSE: 1.2345\n",
      "Corresponding penalty value: 0.9661\n",
      "\u001b[32m[I 2025-03-31 13:37:10,872]\u001b[0m Trial 40 finished with value: 0.9660526785707774 and parameters: {'n_estimators': 2821, 'learning_rate': 0.03901, 'max_depth': 11, 'num_leaves': 3, 'subsample': 0.63, 'feature_fraction': 0.6000000000000001, 'min_gain_to_split': 12.35, 'reg_alpha': 8.84, 'reg_lambda': 0.0, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.60it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7189\n",
      "2th fold: LGBMRegressor RMSE: 0.5022\n",
      "3th fold: LGBMRegressor RMSE: 1.0160\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7457\n",
      "LGBMRegressor worst RMSE: 1.0160\n",
      "Corresponding penalty value: 0.7727\n",
      "\u001b[32m[I 2025-03-31 13:37:12,076]\u001b[0m Trial 41 finished with value: 0.7727311143478035 and parameters: {'n_estimators': 2397, 'learning_rate': 0.05901000000000001, 'max_depth': 11, 'num_leaves': 6, 'subsample': 0.9, 'feature_fraction': 0.97, 'min_gain_to_split': 3.15, 'reg_alpha': 2.68, 'reg_lambda': 1.28, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.41it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9817\n",
      "2th fold: LGBMRegressor RMSE: 0.3292\n",
      "3th fold: LGBMRegressor RMSE: 1.0824\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7977\n",
      "LGBMRegressor worst RMSE: 1.0824\n",
      "Corresponding penalty value: 0.8262\n",
      "\u001b[32m[I 2025-03-31 13:37:13,004]\u001b[0m Trial 42 finished with value: 0.826202051416029 and parameters: {'n_estimators': 1670, 'learning_rate': 0.05401, 'max_depth': 12, 'num_leaves': 2, 'subsample': 0.8300000000000001, 'feature_fraction': 0.9199999999999999, 'min_gain_to_split': 4.7700000000000005, 'reg_alpha': 1.33, 'reg_lambda': 3.5100000000000002, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  8.74it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.5860\n",
      "2th fold: LGBMRegressor RMSE: 0.4219\n",
      "3th fold: LGBMRegressor RMSE: 1.0685\n",
      "\n",
      "LGBMRegressor average RMSE: 0.6921\n",
      "LGBMRegressor worst RMSE: 1.0685\n",
      "Corresponding penalty value: 0.7298\n",
      "\u001b[32m[I 2025-03-31 13:37:13,398]\u001b[0m Trial 43 finished with value: 0.7297784760794035 and parameters: {'n_estimators': 526, 'learning_rate': 0.06101, 'max_depth': 11, 'num_leaves': 4, 'subsample': 0.86, 'feature_fraction': 1.0, 'min_gain_to_split': 8.45, 'reg_alpha': 5.78, 'reg_lambda': 1.1500000000000001, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  8.34it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9572\n",
      "2th fold: LGBMRegressor RMSE: 0.4497\n",
      "3th fold: LGBMRegressor RMSE: 1.0695\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8255\n",
      "LGBMRegressor worst RMSE: 1.0695\n",
      "Corresponding penalty value: 0.8499\n",
      "\u001b[32m[I 2025-03-31 13:37:13,808]\u001b[0m Trial 44 finished with value: 0.8498609473140725 and parameters: {'n_estimators': 514, 'learning_rate': 0.06401, 'max_depth': 9, 'num_leaves': 7, 'subsample': 0.77, 'feature_fraction': 0.8500000000000001, 'min_gain_to_split': 8.59, 'reg_alpha': 5.75, 'reg_lambda': 0.67, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.93it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1353\n",
      "2th fold: LGBMRegressor RMSE: 0.3352\n",
      "3th fold: LGBMRegressor RMSE: 1.0896\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8534\n",
      "LGBMRegressor worst RMSE: 1.1353\n",
      "Corresponding penalty value: 0.8816\n",
      "\u001b[32m[I 2025-03-31 13:37:14,621]\u001b[0m Trial 45 finished with value: 0.8815662588289724 and parameters: {'n_estimators': 1433, 'learning_rate': 0.07101, 'max_depth': 11, 'num_leaves': 26, 'subsample': 0.87, 'feature_fraction': 0.9000000000000001, 'min_gain_to_split': 10.03, 'reg_alpha': 4.91, 'reg_lambda': 2.22, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:01,  2.30it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5569\n",
      "2th fold: LGBMRegressor RMSE: 0.5676\n",
      "3th fold: LGBMRegressor RMSE: 0.7666\n",
      "\n",
      "LGBMRegressor average RMSE: 1.2970\n",
      "LGBMRegressor worst RMSE: 2.5569\n",
      "Corresponding penalty value: 1.4230\n",
      "\u001b[32m[I 2025-03-31 13:37:15,977]\u001b[0m Trial 46 finished with value: 1.4230033410371585 and parameters: {'n_estimators': 1865, 'learning_rate': 0.04701, 'max_depth': 12, 'num_leaves': 11, 'subsample': 0.8200000000000001, 'feature_fraction': 0.97, 'min_gain_to_split': 8.31, 'reg_alpha': 4.54, 'reg_lambda': 0.99, 'linear_tree': True}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  5.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7552\n",
      "2th fold: LGBMRegressor RMSE: 0.4084\n",
      "3th fold: LGBMRegressor RMSE: 1.0661\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7432\n",
      "LGBMRegressor worst RMSE: 1.0661\n",
      "Corresponding penalty value: 0.7755\n",
      "\u001b[32m[I 2025-03-31 13:37:16,572]\u001b[0m Trial 47 finished with value: 0.7755052970734312 and parameters: {'n_estimators': 932, 'learning_rate': 0.06001, 'max_depth': 10, 'num_leaves': 3, 'subsample': 0.98, 'feature_fraction': 0.94, 'min_gain_to_split': 7.38, 'reg_alpha': 6.640000000000001, 'reg_lambda': 6.59, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  3.26it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.7978\n",
      "2th fold: LGBMRegressor RMSE: 0.3956\n",
      "3th fold: LGBMRegressor RMSE: 1.0697\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7544\n",
      "LGBMRegressor worst RMSE: 1.0697\n",
      "Corresponding penalty value: 0.7859\n",
      "\u001b[32m[I 2025-03-31 13:37:17,544]\u001b[0m Trial 48 finished with value: 0.7858938285221154 and parameters: {'n_estimators': 2057, 'learning_rate': 0.06801, 'max_depth': 9, 'num_leaves': 19, 'subsample': 0.94, 'feature_fraction': 0.64, 'min_gain_to_split': 6.12, 'reg_alpha': 3.72, 'reg_lambda': 1.6500000000000001, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "3it [00:00,  4.79it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2317\n",
      "2th fold: LGBMRegressor RMSE: 0.3520\n",
      "3th fold: LGBMRegressor RMSE: 1.0801\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8879\n",
      "LGBMRegressor worst RMSE: 1.2317\n",
      "Corresponding penalty value: 0.9223\n",
      "\u001b[32m[I 2025-03-31 13:37:18,222]\u001b[0m Trial 49 finished with value: 0.9223108362060626 and parameters: {'n_estimators': 1206, 'learning_rate': 0.07801, 'max_depth': 3, 'num_leaves': 9, 'subsample': 0.73, 'feature_fraction': 0.8, 'min_gain_to_split': 9.67, 'reg_alpha': 8.21, 'reg_lambda': 3.19, 'linear_tree': False}. Best is trial 14 with value: 0.7295191387192693.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1994, 'learning_rate': 0.06401, 'max_depth': 9, 'num_leaves': 4, 'subsample': 0.95, 'feature_fraction': 0.99, 'min_gain_to_split': 3.39, 'reg_alpha': 2.0100000000000002, 'reg_lambda': 1.58, 'linear_tree': False}\n",
      "3it [00:00,  3.09it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.6082\n",
      "2th fold: LGBMRegressor RMSE: 0.4352\n",
      "3th fold: LGBMRegressor RMSE: 1.0413\n",
      "\n",
      "LGBMRegressor average RMSE: 0.6949\n",
      "LGBMRegressor worst RMSE: 1.0413\n",
      "Corresponding penalty value: 0.7295\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV51\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1994, 'learning_rate': 0.06401, 'max_depth': 9, 'num_leaves': 4, 'subsample': 0.95, 'feature_fraction': 0.99, 'min_gain_to_split': 3.39, 'reg_alpha': 2.0100000000000002, 'reg_lambda': 1.58, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.149\n",
      "RMSE_crossval: 0.695\n",
      "RMSE_test: 0.432\n",
      "MAE_test: 0.298\n",
      "Nash-Sutcliffe Test: 0.990\n",
      "Kling-Gupta Test: 0.933\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 54.2013 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:37:20,232]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB4\u001b[0m\n",
      "3it [00:00,  4.38it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.2303\n",
      "2th fold: LGBMRegressor RMSE: 2102.4638\n",
      "3th fold: LGBMRegressor RMSE: 13.4330\n",
      "\n",
      "LGBMRegressor average RMSE: 706.7090\n",
      "LGBMRegressor worst RMSE: 2102.4638\n",
      "Corresponding penalty value: 846.2845\n",
      "\u001b[32m[I 2025-03-31 13:37:20,919]\u001b[0m Trial 0 finished with value: 846.2845243615909 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.5700000000000001, 'feature_fraction': 0.32, 'min_gain_to_split': 0.87, 'reg_alpha': 8.67, 'reg_lambda': 6.01, 'linear_tree': True}. Best is trial 0 with value: 846.2845243615909.\u001b[0m\n",
      "3it [00:01,  2.14it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.8202\n",
      "2th fold: LGBMRegressor RMSE: 75.2689\n",
      "3th fold: LGBMRegressor RMSE: 128.5138\n",
      "\n",
      "LGBMRegressor average RMSE: 68.8676\n",
      "LGBMRegressor worst RMSE: 128.5138\n",
      "Corresponding penalty value: 74.8323\n",
      "\u001b[32m[I 2025-03-31 13:37:22,325]\u001b[0m Trial 1 finished with value: 74.83226403804555 and parameters: {'n_estimators': 2925, 'learning_rate': 0.08301, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.59, 'feature_fraction': 0.44, 'min_gain_to_split': 7.87, 'reg_alpha': 4.32, 'reg_lambda': 2.91, 'linear_tree': True}. Best is trial 1 with value: 74.83226403804555.\u001b[0m\n",
      "3it [00:00,  3.57it/s]\n",
      "1th fold: LGBMRegressor RMSE: 82.8784\n",
      "2th fold: LGBMRegressor RMSE: 2136.7934\n",
      "3th fold: LGBMRegressor RMSE: 1167.2819\n",
      "\n",
      "LGBMRegressor average RMSE: 1128.9846\n",
      "LGBMRegressor worst RMSE: 2136.7934\n",
      "Corresponding penalty value: 1229.7655\n",
      "\u001b[32m[I 2025-03-31 13:37:23,167]\u001b[0m Trial 2 finished with value: 1229.765469026957 and parameters: {'n_estimators': 1230, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.6, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 8.89, 'reg_alpha': 0.46, 'reg_lambda': 6.08, 'linear_tree': True}. Best is trial 1 with value: 74.83226403804555.\u001b[0m\n",
      "3it [00:01,  2.46it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6258\n",
      "2th fold: LGBMRegressor RMSE: 2.0559\n",
      "3th fold: LGBMRegressor RMSE: 3.8950\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8589\n",
      "LGBMRegressor worst RMSE: 3.8950\n",
      "Corresponding penalty value: 2.9625\n",
      "\u001b[32m[I 2025-03-31 13:37:24,390]\u001b[0m Trial 3 finished with value: 2.962506797710284 and parameters: {'n_estimators': 2873, 'learning_rate': 0.09601, 'max_depth': 11, 'num_leaves': 10, 'subsample': 0.54, 'feature_fraction': 0.75, 'min_gain_to_split': 6.6000000000000005, 'reg_alpha': 1.22, 'reg_lambda': 4.95, 'linear_tree': False}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:00,  5.06it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.8937\n",
      "2th fold: LGBMRegressor RMSE: 1873.1078\n",
      "3th fold: LGBMRegressor RMSE: 9.2442\n",
      "\n",
      "LGBMRegressor average RMSE: 628.4153\n",
      "LGBMRegressor worst RMSE: 1873.1078\n",
      "Corresponding penalty value: 752.8845\n",
      "\u001b[32m[I 2025-03-31 13:37:24,986]\u001b[0m Trial 4 finished with value: 752.8845256843975 and parameters: {'n_estimators': 1147, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.77, 'feature_fraction': 0.34, 'min_gain_to_split': 14.55, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'linear_tree': True}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:01,  1.87it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6054\n",
      "2th fold: LGBMRegressor RMSE: 2.3546\n",
      "3th fold: LGBMRegressor RMSE: 3.9147\n",
      "\n",
      "LGBMRegressor average RMSE: 2.9582\n",
      "LGBMRegressor worst RMSE: 3.9147\n",
      "Corresponding penalty value: 3.0539\n",
      "\u001b[32m[I 2025-03-31 13:37:26,593]\u001b[0m Trial 5 finished with value: 3.0538779493118158 and parameters: {'n_estimators': 2805, 'learning_rate': 0.00801, 'max_depth': 4, 'num_leaves': 3, 'subsample': 0.66, 'feature_fraction': 0.51, 'min_gain_to_split': 4.07, 'reg_alpha': 8.290000000000001, 'reg_lambda': 3.5700000000000003, 'linear_tree': False}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:00,  7.23it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6389\n",
      "2th fold: LGBMRegressor RMSE: 2.0467\n",
      "3th fold: LGBMRegressor RMSE: 4.0849\n",
      "\n",
      "LGBMRegressor average RMSE: 2.9235\n",
      "LGBMRegressor worst RMSE: 4.0849\n",
      "Corresponding penalty value: 3.0397\n",
      "\u001b[32m[I 2025-03-31 13:37:27,011]\u001b[0m Trial 6 finished with value: 3.03965164685765 and parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:00,  5.55it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.5156\n",
      "2th fold: LGBMRegressor RMSE: 1801.9217\n",
      "3th fold: LGBMRegressor RMSE: 42.3944\n",
      "\n",
      "LGBMRegressor average RMSE: 615.9439\n",
      "LGBMRegressor worst RMSE: 1801.9217\n",
      "Corresponding penalty value: 734.5417\n",
      "\u001b[32m[I 2025-03-31 13:37:27,554]\u001b[0m Trial 7 finished with value: 734.5416788043773 and parameters: {'n_estimators': 685, 'learning_rate': 0.035010000000000006, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.81, 'feature_fraction': 0.46, 'min_gain_to_split': 0.9500000000000001, 'reg_alpha': 3.11, 'reg_lambda': 3.25, 'linear_tree': True}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:01,  1.94it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6809\n",
      "2th fold: LGBMRegressor RMSE: 1986.3812\n",
      "3th fold: LGBMRegressor RMSE: 7.7094\n",
      "\n",
      "LGBMRegressor average RMSE: 665.5905\n",
      "LGBMRegressor worst RMSE: 1986.3812\n",
      "Corresponding penalty value: 797.6696\n",
      "\u001b[32m[I 2025-03-31 13:37:29,106]\u001b[0m Trial 8 finished with value: 797.6695944768672 and parameters: {'n_estimators': 2718, 'learning_rate': 0.04701, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.88, 'feature_fraction': 0.65, 'min_gain_to_split': 11.57, 'reg_alpha': 4.94, 'reg_lambda': 5.23, 'linear_tree': True}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:01,  1.57it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.2424\n",
      "2th fold: LGBMRegressor RMSE: 46.6062\n",
      "3th fold: LGBMRegressor RMSE: 17.6936\n",
      "\n",
      "LGBMRegressor average RMSE: 22.1807\n",
      "LGBMRegressor worst RMSE: 46.6062\n",
      "Corresponding penalty value: 24.6233\n",
      "\u001b[32m[I 2025-03-31 13:37:31,020]\u001b[0m Trial 9 finished with value: 24.623258581269013 and parameters: {'n_estimators': 769, 'learning_rate': 0.00301, 'max_depth': 9, 'num_leaves': 11, 'subsample': 0.75, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 3.74, 'reg_alpha': 4.1, 'reg_lambda': 7.5600000000000005, 'linear_tree': True}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:01,  2.80it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6330\n",
      "2th fold: LGBMRegressor RMSE: 2.0078\n",
      "3th fold: LGBMRegressor RMSE: 3.9350\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8586\n",
      "LGBMRegressor worst RMSE: 3.9350\n",
      "Corresponding penalty value: 2.9663\n",
      "\u001b[32m[I 2025-03-31 13:37:32,124]\u001b[0m Trial 10 finished with value: 2.966264730786662 and parameters: {'n_estimators': 2144, 'learning_rate': 0.06801, 'max_depth': 12, 'num_leaves': 12, 'subsample': 0.5, 'feature_fraction': 0.8300000000000001, 'min_gain_to_split': 5.42, 'reg_alpha': 0.11, 'reg_lambda': 0.97, 'linear_tree': False}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:01,  2.73it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6648\n",
      "2th fold: LGBMRegressor RMSE: 2.0163\n",
      "3th fold: LGBMRegressor RMSE: 3.9073\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8628\n",
      "LGBMRegressor worst RMSE: 3.9073\n",
      "Corresponding penalty value: 2.9673\n",
      "\u001b[32m[I 2025-03-31 13:37:33,259]\u001b[0m Trial 11 finished with value: 2.9672530639960346 and parameters: {'n_estimators': 2195, 'learning_rate': 0.06301, 'max_depth': 12, 'num_leaves': 13, 'subsample': 0.5, 'feature_fraction': 0.8300000000000001, 'min_gain_to_split': 5.8, 'reg_alpha': 0.04, 'reg_lambda': 0.15, 'linear_tree': False}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:00,  3.20it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6372\n",
      "2th fold: LGBMRegressor RMSE: 2.0316\n",
      "3th fold: LGBMRegressor RMSE: 3.9506\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8731\n",
      "LGBMRegressor worst RMSE: 3.9506\n",
      "Corresponding penalty value: 2.9809\n",
      "\u001b[32m[I 2025-03-31 13:37:34,231]\u001b[0m Trial 12 finished with value: 2.9808900342579294 and parameters: {'n_estimators': 2133, 'learning_rate': 0.09901, 'max_depth': 12, 'num_leaves': 9, 'subsample': 0.5, 'feature_fraction': 0.78, 'min_gain_to_split': 5.73, 'reg_alpha': 2.27, 'reg_lambda': 0.77, 'linear_tree': False}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:01,  2.47it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.7349\n",
      "2th fold: LGBMRegressor RMSE: 2.2804\n",
      "3th fold: LGBMRegressor RMSE: 3.9779\n",
      "\n",
      "LGBMRegressor average RMSE: 2.9977\n",
      "LGBMRegressor worst RMSE: 3.9779\n",
      "Corresponding penalty value: 3.0957\n",
      "\u001b[32m[I 2025-03-31 13:37:35,481]\u001b[0m Trial 13 finished with value: 3.0957159330125514 and parameters: {'n_estimators': 2313, 'learning_rate': 0.07001, 'max_depth': 10, 'num_leaves': 4, 'subsample': 0.66, 'feature_fraction': 1.0, 'min_gain_to_split': 10.33, 'reg_alpha': 1.57, 'reg_lambda': 1.85, 'linear_tree': False}. Best is trial 3 with value: 2.962506797710284.\u001b[0m\n",
      "3it [00:00,  3.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6158\n",
      "2th fold: LGBMRegressor RMSE: 2.0114\n",
      "3th fold: LGBMRegressor RMSE: 3.8766\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8346\n",
      "LGBMRegressor worst RMSE: 3.8766\n",
      "Corresponding penalty value: 2.9388\n",
      "\u001b[32m[I 2025-03-31 13:37:36,335]\u001b[0m Trial 14 finished with value: 2.9388258618677967 and parameters: {'n_estimators': 1786, 'learning_rate': 0.08101, 'max_depth': 11, 'num_leaves': 13, 'subsample': 0.67, 'feature_fraction': 0.75, 'min_gain_to_split': 5.93, 'reg_alpha': 1.47, 'reg_lambda': 4.32, 'linear_tree': False}. Best is trial 14 with value: 2.9388258618677967.\u001b[0m\n",
      "3it [00:00,  3.63it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5928\n",
      "2th fold: LGBMRegressor RMSE: 1.9892\n",
      "3th fold: LGBMRegressor RMSE: 3.8824\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8215\n",
      "LGBMRegressor worst RMSE: 3.8824\n",
      "Corresponding penalty value: 2.9276\n",
      "\u001b[32m[I 2025-03-31 13:37:37,199]\u001b[0m Trial 15 finished with value: 2.9275629342150187 and parameters: {'n_estimators': 1852, 'learning_rate': 0.08601, 'max_depth': 9, 'num_leaves': 15, 'subsample': 0.6799999999999999, 'feature_fraction': 0.71, 'min_gain_to_split': 9.52, 'reg_alpha': 6.26, 'reg_lambda': 4.41, 'linear_tree': False}. Best is trial 15 with value: 2.9275629342150187.\u001b[0m\n",
      "3it [00:00,  6.75it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5230\n",
      "2th fold: LGBMRegressor RMSE: 2.3053\n",
      "3th fold: LGBMRegressor RMSE: 4.4408\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0897\n",
      "LGBMRegressor worst RMSE: 4.4408\n",
      "Corresponding penalty value: 3.2248\n",
      "\u001b[32m[I 2025-03-31 13:37:37,682]\u001b[0m Trial 16 finished with value: 3.2248220777605914 and parameters: {'n_estimators': 1665, 'learning_rate': 0.08301, 'max_depth': 8, 'num_leaves': 15, 'subsample': 0.72, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 12.780000000000001, 'reg_alpha': 6.53, 'reg_lambda': 4.2, 'linear_tree': False}. Best is trial 15 with value: 2.9275629342150187.\u001b[0m\n",
      "3it [00:00,  3.47it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6047\n",
      "2th fold: LGBMRegressor RMSE: 2.0116\n",
      "3th fold: LGBMRegressor RMSE: 3.8284\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8149\n",
      "LGBMRegressor worst RMSE: 3.8284\n",
      "Corresponding penalty value: 2.9163\n",
      "\u001b[32m[I 2025-03-31 13:37:38,585]\u001b[0m Trial 17 finished with value: 2.916286745315835 and parameters: {'n_estimators': 1867, 'learning_rate': 0.05101000000000001, 'max_depth': 9, 'num_leaves': 21, 'subsample': 0.67, 'feature_fraction': 0.71, 'min_gain_to_split': 9.18, 'reg_alpha': 6.5600000000000005, 'reg_lambda': 2.19, 'linear_tree': False}. Best is trial 17 with value: 2.916286745315835.\u001b[0m\n",
      "3it [00:01,  2.89it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6255\n",
      "2th fold: LGBMRegressor RMSE: 1.8898\n",
      "3th fold: LGBMRegressor RMSE: 3.8538\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7897\n",
      "LGBMRegressor worst RMSE: 3.8538\n",
      "Corresponding penalty value: 2.8961\n",
      "\u001b[32m[I 2025-03-31 13:37:39,663]\u001b[0m Trial 18 finished with value: 2.896128406507814 and parameters: {'n_estimators': 1855, 'learning_rate': 0.01801, 'max_depth': 8, 'num_leaves': 20, 'subsample': 1.0, 'feature_fraction': 0.6799999999999999, 'min_gain_to_split': 9.36, 'reg_alpha': 6.33, 'reg_lambda': 2.16, 'linear_tree': False}. Best is trial 18 with value: 2.896128406507814.\u001b[0m\n",
      "3it [00:01,  2.58it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6377\n",
      "2th fold: LGBMRegressor RMSE: 1.8838\n",
      "3th fold: LGBMRegressor RMSE: 3.8915\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8043\n",
      "LGBMRegressor worst RMSE: 3.8915\n",
      "Corresponding penalty value: 2.9130\n",
      "\u001b[32m[I 2025-03-31 13:37:40,868]\u001b[0m Trial 19 finished with value: 2.9130466076594006 and parameters: {'n_estimators': 2480, 'learning_rate': 0.02101, 'max_depth': 7, 'num_leaves': 21, 'subsample': 1.0, 'feature_fraction': 0.54, 'min_gain_to_split': 11.24, 'reg_alpha': 9.82, 'reg_lambda': 2.13, 'linear_tree': False}. Best is trial 18 with value: 2.896128406507814.\u001b[0m\n",
      "3it [00:01,  2.60it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6255\n",
      "2th fold: LGBMRegressor RMSE: 1.8471\n",
      "3th fold: LGBMRegressor RMSE: 3.8938\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7888\n",
      "LGBMRegressor worst RMSE: 3.8938\n",
      "Corresponding penalty value: 2.8993\n",
      "\u001b[32m[I 2025-03-31 13:37:42,062]\u001b[0m Trial 20 finished with value: 2.8993078935797145 and parameters: {'n_estimators': 2330, 'learning_rate': 0.01801, 'max_depth': 7, 'num_leaves': 26, 'subsample': 1.0, 'feature_fraction': 0.54, 'min_gain_to_split': 12.47, 'reg_alpha': 9.82, 'reg_lambda': 1.8800000000000001, 'linear_tree': False}. Best is trial 18 with value: 2.896128406507814.\u001b[0m\n",
      "3it [00:01,  2.34it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6149\n",
      "2th fold: LGBMRegressor RMSE: 1.8412\n",
      "3th fold: LGBMRegressor RMSE: 3.8860\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7807\n",
      "LGBMRegressor worst RMSE: 3.8860\n",
      "Corresponding penalty value: 2.8912\n",
      "\u001b[32m[I 2025-03-31 13:37:43,387]\u001b[0m Trial 21 finished with value: 2.8912283354289894 and parameters: {'n_estimators': 2548, 'learning_rate': 0.01701, 'max_depth': 7, 'num_leaves': 25, 'subsample': 1.0, 'feature_fraction': 0.5800000000000001, 'min_gain_to_split': 12.82, 'reg_alpha': 9.57, 'reg_lambda': 1.8, 'linear_tree': False}. Best is trial 21 with value: 2.8912283354289894.\u001b[0m\n",
      "3it [00:01,  2.40it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6265\n",
      "2th fold: LGBMRegressor RMSE: 1.8329\n",
      "3th fold: LGBMRegressor RMSE: 3.9096\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7897\n",
      "LGBMRegressor worst RMSE: 3.9096\n",
      "Corresponding penalty value: 2.9017\n",
      "\u001b[32m[I 2025-03-31 13:37:44,678]\u001b[0m Trial 22 finished with value: 2.901670065048099 and parameters: {'n_estimators': 2435, 'learning_rate': 0.015009999999999999, 'max_depth': 6, 'num_leaves': 26, 'subsample': 0.98, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 14.72, 'reg_alpha': 10.0, 'reg_lambda': 1.26, 'linear_tree': False}. Best is trial 21 with value: 2.8912283354289894.\u001b[0m\n",
      "3it [00:01,  2.53it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6245\n",
      "2th fold: LGBMRegressor RMSE: 1.8368\n",
      "3th fold: LGBMRegressor RMSE: 3.8675\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7763\n",
      "LGBMRegressor worst RMSE: 3.8675\n",
      "Corresponding penalty value: 2.8854\n",
      "\u001b[32m[I 2025-03-31 13:37:45,906]\u001b[0m Trial 23 finished with value: 2.8853868465127293 and parameters: {'n_estimators': 2588, 'learning_rate': 0.02401, 'max_depth': 8, 'num_leaves': 30, 'subsample': 0.94, 'feature_fraction': 0.62, 'min_gain_to_split': 13.14, 'reg_alpha': 9.14, 'reg_lambda': 2.49, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.53it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6437\n",
      "2th fold: LGBMRegressor RMSE: 1.8698\n",
      "3th fold: LGBMRegressor RMSE: 3.8630\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7922\n",
      "LGBMRegressor worst RMSE: 3.8630\n",
      "Corresponding penalty value: 2.8992\n",
      "\u001b[32m[I 2025-03-31 13:37:47,134]\u001b[0m Trial 24 finished with value: 2.899237380852571 and parameters: {'n_estimators': 2615, 'learning_rate': 0.02901, 'max_depth': 8, 'num_leaves': 30, 'subsample': 0.94, 'feature_fraction': 0.65, 'min_gain_to_split': 12.71, 'reg_alpha': 7.24, 'reg_lambda': 2.7800000000000002, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.96it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6461\n",
      "2th fold: LGBMRegressor RMSE: 1.8367\n",
      "3th fold: LGBMRegressor RMSE: 3.8711\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7846\n",
      "LGBMRegressor worst RMSE: 3.8711\n",
      "Corresponding penalty value: 2.8933\n",
      "\u001b[32m[I 2025-03-31 13:37:48,192]\u001b[0m Trial 25 finished with value: 2.893277355536955 and parameters: {'n_estimators': 2086, 'learning_rate': 0.026010000000000002, 'max_depth': 6, 'num_leaves': 28, 'subsample': 0.9299999999999999, 'feature_fraction': 0.63, 'min_gain_to_split': 13.73, 'reg_alpha': 9.01, 'reg_lambda': 1.25, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  3.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5927\n",
      "2th fold: LGBMRegressor RMSE: 1.9531\n",
      "3th fold: LGBMRegressor RMSE: 4.0000\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8486\n",
      "LGBMRegressor worst RMSE: 4.0000\n",
      "Corresponding penalty value: 2.9638\n",
      "\u001b[32m[I 2025-03-31 13:37:49,236]\u001b[0m Trial 26 finished with value: 2.9637651338359836 and parameters: {'n_estimators': 2583, 'learning_rate': 0.02701, 'max_depth': 6, 'num_leaves': 28, 'subsample': 0.9199999999999999, 'feature_fraction': 0.46, 'min_gain_to_split': 13.75, 'reg_alpha': 8.74, 'reg_lambda': 0.35000000000000003, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  3.30it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6347\n",
      "2th fold: LGBMRegressor RMSE: 1.9174\n",
      "3th fold: LGBMRegressor RMSE: 3.8420\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7981\n",
      "LGBMRegressor worst RMSE: 3.8420\n",
      "Corresponding penalty value: 2.9025\n",
      "\u001b[32m[I 2025-03-31 13:37:50,190]\u001b[0m Trial 27 finished with value: 2.9024526028695035 and parameters: {'n_estimators': 2043, 'learning_rate': 0.042010000000000006, 'max_depth': 5, 'num_leaves': 25, 'subsample': 0.8400000000000001, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 13.85, 'reg_alpha': 9.06, 'reg_lambda': 1.31, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.57it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5705\n",
      "2th fold: LGBMRegressor RMSE: 1.9892\n",
      "3th fold: LGBMRegressor RMSE: 4.0294\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8630\n",
      "LGBMRegressor worst RMSE: 4.0294\n",
      "Corresponding penalty value: 2.9797\n",
      "\u001b[32m[I 2025-03-31 13:37:51,403]\u001b[0m Trial 28 finished with value: 2.979679052973495 and parameters: {'n_estimators': 2666, 'learning_rate': 0.01001, 'max_depth': 5, 'num_leaves': 23, 'subsample': 0.95, 'feature_fraction': 0.4, 'min_gain_to_split': 11.1, 'reg_alpha': 7.390000000000001, 'reg_lambda': 3.48, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  6.33it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.4866\n",
      "2th fold: LGBMRegressor RMSE: 2.2634\n",
      "3th fold: LGBMRegressor RMSE: 4.4569\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0689\n",
      "LGBMRegressor worst RMSE: 4.4569\n",
      "Corresponding penalty value: 3.2077\n",
      "\u001b[32m[I 2025-03-31 13:37:51,922]\u001b[0m Trial 29 finished with value: 3.2077287714006926 and parameters: {'n_estimators': 1527, 'learning_rate': 0.02501, 'max_depth': 6, 'num_leaves': 28, 'subsample': 0.89, 'feature_fraction': 0.24000000000000002, 'min_gain_to_split': 13.33, 'reg_alpha': 9.32, 'reg_lambda': 0.14, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:03,  1.30s/it]\n",
      "1th fold: LGBMRegressor RMSE: 2.5953\n",
      "2th fold: LGBMRegressor RMSE: 1.8239\n",
      "3th fold: LGBMRegressor RMSE: 4.0393\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8195\n",
      "LGBMRegressor worst RMSE: 4.0393\n",
      "Corresponding penalty value: 2.9415\n",
      "\u001b[32m[I 2025-03-31 13:37:55,860]\u001b[0m Trial 30 finished with value: 2.941489560023792 and parameters: {'n_estimators': 2045, 'learning_rate': 0.00101, 'max_depth': 7, 'num_leaves': 30, 'subsample': 0.8400000000000001, 'feature_fraction': 0.5, 'min_gain_to_split': 15.0, 'reg_alpha': 9.14, 'reg_lambda': 2.68, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.78it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6315\n",
      "2th fold: LGBMRegressor RMSE: 1.8305\n",
      "3th fold: LGBMRegressor RMSE: 3.8694\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7771\n",
      "LGBMRegressor worst RMSE: 3.8694\n",
      "Corresponding penalty value: 2.8864\n",
      "\u001b[32m[I 2025-03-31 13:37:56,985]\u001b[0m Trial 31 finished with value: 2.8863559781665358 and parameters: {'n_estimators': 1634, 'learning_rate': 0.011009999999999999, 'max_depth': 8, 'num_leaves': 19, 'subsample': 0.96, 'feature_fraction': 0.65, 'min_gain_to_split': 11.73, 'reg_alpha': 5.82, 'reg_lambda': 1.5, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  4.35it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6234\n",
      "2th fold: LGBMRegressor RMSE: 1.8836\n",
      "3th fold: LGBMRegressor RMSE: 3.8735\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7935\n",
      "LGBMRegressor worst RMSE: 3.8735\n",
      "Corresponding penalty value: 2.9015\n",
      "\u001b[32m[I 2025-03-31 13:37:57,720]\u001b[0m Trial 32 finished with value: 2.9014778192940573 and parameters: {'n_estimators': 1320, 'learning_rate': 0.033010000000000005, 'max_depth': 8, 'num_leaves': 18, 'subsample': 0.96, 'feature_fraction': 0.6000000000000001, 'min_gain_to_split': 11.67, 'reg_alpha': 5.5, 'reg_lambda': 1.6400000000000001, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  1.87it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6307\n",
      "2th fold: LGBMRegressor RMSE: 1.8324\n",
      "3th fold: LGBMRegressor RMSE: 3.8747\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7793\n",
      "LGBMRegressor worst RMSE: 3.8747\n",
      "Corresponding penalty value: 2.8888\n",
      "\u001b[32m[I 2025-03-31 13:37:59,368]\u001b[0m Trial 33 finished with value: 2.8888115278304163 and parameters: {'n_estimators': 2971, 'learning_rate': 0.011009999999999999, 'max_depth': 9, 'num_leaves': 24, 'subsample': 0.91, 'feature_fraction': 0.66, 'min_gain_to_split': 12.11, 'reg_alpha': 8.45, 'reg_lambda': 0.79, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:02,  1.42it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.4796\n",
      "2th fold: LGBMRegressor RMSE: 1940.5527\n",
      "3th fold: LGBMRegressor RMSE: 1538.5185\n",
      "\n",
      "LGBMRegressor average RMSE: 1160.5169\n",
      "LGBMRegressor worst RMSE: 1940.5527\n",
      "Corresponding penalty value: 1238.5205\n",
      "\u001b[32m[I 2025-03-31 13:38:01,532]\u001b[0m Trial 34 finished with value: 1238.5205093470872 and parameters: {'n_estimators': 2975, 'learning_rate': 0.011009999999999999, 'max_depth': 9, 'num_leaves': 23, 'subsample': 0.9, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 7.98, 'reg_alpha': 8.39, 'reg_lambda': 0.6900000000000001, 'linear_tree': True}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:02,  1.40it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6870\n",
      "2th fold: LGBMRegressor RMSE: 1.8961\n",
      "3th fold: LGBMRegressor RMSE: 3.8280\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8037\n",
      "LGBMRegressor worst RMSE: 3.8280\n",
      "Corresponding penalty value: 2.9061\n",
      "\u001b[32m[I 2025-03-31 13:38:03,728]\u001b[0m Trial 35 finished with value: 2.9061497969931858 and parameters: {'n_estimators': 2955, 'learning_rate': 0.00601, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.8500000000000001, 'feature_fraction': 0.8200000000000001, 'min_gain_to_split': 10.55, 'reg_alpha': 7.43, 'reg_lambda': 2.65, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  1.57it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.4677\n",
      "2th fold: LGBMRegressor RMSE: 1922.0347\n",
      "3th fold: LGBMRegressor RMSE: 1225.1365\n",
      "\n",
      "LGBMRegressor average RMSE: 1049.8797\n",
      "LGBMRegressor worst RMSE: 1922.0347\n",
      "Corresponding penalty value: 1137.0952\n",
      "\u001b[32m[I 2025-03-31 13:38:05,682]\u001b[0m Trial 36 finished with value: 1137.0951796878317 and parameters: {'n_estimators': 2802, 'learning_rate': 0.01201, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.97, 'feature_fraction': 0.69, 'min_gain_to_split': 12.25, 'reg_alpha': 7.930000000000001, 'reg_lambda': 0.72, 'linear_tree': True}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  3.38it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6502\n",
      "2th fold: LGBMRegressor RMSE: 1.9177\n",
      "3th fold: LGBMRegressor RMSE: 3.8654\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8111\n",
      "LGBMRegressor worst RMSE: 3.8654\n",
      "Corresponding penalty value: 2.9165\n",
      "\u001b[32m[I 2025-03-31 13:38:06,616]\u001b[0m Trial 37 finished with value: 2.9165392842516282 and parameters: {'n_estimators': 1512, 'learning_rate': 0.02101, 'max_depth': 9, 'num_leaves': 25, 'subsample': 0.9299999999999999, 'feature_fraction': 0.75, 'min_gain_to_split': 8.21, 'reg_alpha': 5.64, 'reg_lambda': 8.94, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  5.41it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6234\n",
      "2th fold: LGBMRegressor RMSE: 1.9849\n",
      "3th fold: LGBMRegressor RMSE: 3.9430\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8504\n",
      "LGBMRegressor worst RMSE: 3.9430\n",
      "Corresponding penalty value: 2.9597\n",
      "\u001b[32m[I 2025-03-31 13:38:07,217]\u001b[0m Trial 38 finished with value: 2.9597065897269763 and parameters: {'n_estimators': 1145, 'learning_rate': 0.041010000000000005, 'max_depth': 8, 'num_leaves': 18, 'subsample': 0.97, 'feature_fraction': 0.5, 'min_gain_to_split': 10.52, 'reg_alpha': 3.99, 'reg_lambda': 3.83, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:02,  1.22it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5157\n",
      "2th fold: LGBMRegressor RMSE: 2169.6303\n",
      "3th fold: LGBMRegressor RMSE: 1218.0819\n",
      "\n",
      "LGBMRegressor average RMSE: 1130.0760\n",
      "LGBMRegressor worst RMSE: 2169.6303\n",
      "Corresponding penalty value: 1234.0314\n",
      "\u001b[32m[I 2025-03-31 13:38:09,724]\u001b[0m Trial 39 finished with value: 1234.0313885031776 and parameters: {'n_estimators': 2801, 'learning_rate': 0.00601, 'max_depth': 10, 'num_leaves': 22, 'subsample': 0.81, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 12.11, 'reg_alpha': 8.53, 'reg_lambda': 5.6000000000000005, 'linear_tree': True}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:04,  1.59s/it]\n",
      "1th fold: LGBMRegressor RMSE: 4.2301\n",
      "2th fold: LGBMRegressor RMSE: 2.8417\n",
      "3th fold: LGBMRegressor RMSE: 5.4160\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1626\n",
      "LGBMRegressor worst RMSE: 5.4160\n",
      "Corresponding penalty value: 4.2880\n",
      "\u001b[32m[I 2025-03-31 13:38:14,532]\u001b[0m Trial 40 finished with value: 4.287955792455602 and parameters: {'n_estimators': 2451, 'learning_rate': 1e-05, 'max_depth': 11, 'num_leaves': 27, 'subsample': 0.87, 'feature_fraction': 0.41000000000000003, 'min_gain_to_split': 13.120000000000001, 'reg_alpha': 9.49, 'reg_lambda': 3.16, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.70it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6486\n",
      "2th fold: LGBMRegressor RMSE: 1.8419\n",
      "3th fold: LGBMRegressor RMSE: 3.8918\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7941\n",
      "LGBMRegressor worst RMSE: 3.8918\n",
      "Corresponding penalty value: 2.9039\n",
      "\u001b[32m[I 2025-03-31 13:38:15,693]\u001b[0m Trial 41 finished with value: 2.9038966602799263 and parameters: {'n_estimators': 2330, 'learning_rate': 0.02401, 'max_depth': 7, 'num_leaves': 29, 'subsample': 0.91, 'feature_fraction': 0.63, 'min_gain_to_split': 14.22, 'reg_alpha': 8.82, 'reg_lambda': 1.42, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  3.60it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6423\n",
      "2th fold: LGBMRegressor RMSE: 1.8901\n",
      "3th fold: LGBMRegressor RMSE: 3.8623\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7982\n",
      "LGBMRegressor worst RMSE: 3.8623\n",
      "Corresponding penalty value: 2.9047\n",
      "\u001b[32m[I 2025-03-31 13:38:16,576]\u001b[0m Trial 42 finished with value: 2.90465351801293 and parameters: {'n_estimators': 1670, 'learning_rate': 0.03101, 'max_depth': 6, 'num_leaves': 28, 'subsample': 0.94, 'feature_fraction': 0.65, 'min_gain_to_split': 13.75, 'reg_alpha': 8.14, 'reg_lambda': 1.08, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:00,  5.20it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6313\n",
      "2th fold: LGBMRegressor RMSE: 1.8712\n",
      "3th fold: LGBMRegressor RMSE: 3.8784\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7936\n",
      "LGBMRegressor worst RMSE: 3.8784\n",
      "Corresponding penalty value: 2.9021\n",
      "\u001b[32m[I 2025-03-31 13:38:17,203]\u001b[0m Trial 43 finished with value: 2.902112658419077 and parameters: {'n_estimators': 526, 'learning_rate': 0.015009999999999999, 'max_depth': 8, 'num_leaves': 26, 'subsample': 0.87, 'feature_fraction': 0.6799999999999999, 'min_gain_to_split': 11.870000000000001, 'reg_alpha': 7.05, 'reg_lambda': 2.37, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.76it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6447\n",
      "2th fold: LGBMRegressor RMSE: 1.9538\n",
      "3th fold: LGBMRegressor RMSE: 3.8581\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8189\n",
      "LGBMRegressor worst RMSE: 3.8581\n",
      "Corresponding penalty value: 2.9228\n",
      "\u001b[32m[I 2025-03-31 13:38:18,339]\u001b[0m Trial 44 finished with value: 2.9228154648730627 and parameters: {'n_estimators': 2549, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.91, 'feature_fraction': 0.54, 'min_gain_to_split': 13.27, 'reg_alpha': 3.23, 'reg_lambda': 1.6, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.41it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6428\n",
      "2th fold: LGBMRegressor RMSE: 1.9849\n",
      "3th fold: LGBMRegressor RMSE: 3.8266\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8181\n",
      "LGBMRegressor worst RMSE: 3.8266\n",
      "Corresponding penalty value: 2.9189\n",
      "\u001b[32m[I 2025-03-31 13:38:19,632]\u001b[0m Trial 45 finished with value: 2.9189255987206972 and parameters: {'n_estimators': 2857, 'learning_rate': 0.05301, 'max_depth': 5, 'num_leaves': 29, 'subsample': 0.79, 'feature_fraction': 0.74, 'min_gain_to_split': 9.93, 'reg_alpha': 9.46, 'reg_lambda': 0.49, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.13it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5399\n",
      "2th fold: LGBMRegressor RMSE: 1962.9554\n",
      "3th fold: LGBMRegressor RMSE: 1062.8739\n",
      "\n",
      "LGBMRegressor average RMSE: 1009.4564\n",
      "LGBMRegressor worst RMSE: 1962.9554\n",
      "Corresponding penalty value: 1104.8063\n",
      "\u001b[32m[I 2025-03-31 13:38:21,093]\u001b[0m Trial 46 finished with value: 1104.8063197715517 and parameters: {'n_estimators': 2011, 'learning_rate': 0.015009999999999999, 'max_depth': 9, 'num_leaves': 27, 'subsample': 0.98, 'feature_fraction': 0.63, 'min_gain_to_split': 14.31, 'reg_alpha': 7.86, 'reg_lambda': 1.07, 'linear_tree': True}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:01,  2.26it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.7079\n",
      "2th fold: LGBMRegressor RMSE: 1.9367\n",
      "3th fold: LGBMRegressor RMSE: 4.0196\n",
      "\n",
      "LGBMRegressor average RMSE: 2.8880\n",
      "LGBMRegressor worst RMSE: 4.0196\n",
      "Corresponding penalty value: 3.0012\n",
      "\u001b[32m[I 2025-03-31 13:38:22,471]\u001b[0m Trial 47 finished with value: 3.001199838608898 and parameters: {'n_estimators': 2710, 'learning_rate': 0.02201, 'max_depth': 3, 'num_leaves': 25, 'subsample': 0.61, 'feature_fraction': 0.8700000000000001, 'min_gain_to_split': 11.27, 'reg_alpha': 4.84, 'reg_lambda': 6.3, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:02,  1.29it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6366\n",
      "2th fold: LGBMRegressor RMSE: 1.8778\n",
      "3th fold: LGBMRegressor RMSE: 3.8368\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7837\n",
      "LGBMRegressor worst RMSE: 3.8368\n",
      "Corresponding penalty value: 2.8890\n",
      "\u001b[32m[I 2025-03-31 13:38:24,842]\u001b[0m Trial 48 finished with value: 2.889019538248424 and parameters: {'n_estimators': 2205, 'learning_rate': 0.00501, 'max_depth': 10, 'num_leaves': 23, 'subsample': 0.95, 'feature_fraction': 0.78, 'min_gain_to_split': 2.16, 'reg_alpha': 8.73, 'reg_lambda': 1.71, 'linear_tree': False}. Best is trial 23 with value: 2.8853868465127293.\u001b[0m\n",
      "3it [00:02,  1.48it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6367\n",
      "2th fold: LGBMRegressor RMSE: 1.8641\n",
      "3th fold: LGBMRegressor RMSE: 3.8288\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7765\n",
      "LGBMRegressor worst RMSE: 3.8288\n",
      "Corresponding penalty value: 2.8817\n",
      "\u001b[32m[I 2025-03-31 13:38:26,917]\u001b[0m Trial 49 finished with value: 2.881745121612493 and parameters: {'n_estimators': 2276, 'learning_rate': 0.00601, 'max_depth': 10, 'num_leaves': 16, 'subsample': 0.96, 'feature_fraction': 0.79, 'min_gain_to_split': 2.16, 'reg_alpha': 8.51, 'reg_lambda': 3.08, 'linear_tree': False}. Best is trial 49 with value: 2.881745121612493.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 2276, 'learning_rate': 0.00601, 'max_depth': 10, 'num_leaves': 16, 'subsample': 0.96, 'feature_fraction': 0.79, 'min_gain_to_split': 2.16, 'reg_alpha': 8.51, 'reg_lambda': 3.08, 'linear_tree': False}\n",
      "3it [00:02,  1.47it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.6364\n",
      "2th fold: LGBMRegressor RMSE: 1.8508\n",
      "3th fold: LGBMRegressor RMSE: 3.8144\n",
      "\n",
      "LGBMRegressor average RMSE: 2.7672\n",
      "LGBMRegressor worst RMSE: 3.8144\n",
      "Corresponding penalty value: 2.8719\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB4\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 2276, 'learning_rate': 0.00601, 'max_depth': 10, 'num_leaves': 16, 'subsample': 0.96, 'feature_fraction': 0.79, 'min_gain_to_split': 2.16, 'reg_alpha': 8.51, 'reg_lambda': 3.08, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.348\n",
      "RMSE_crossval: 2.767\n",
      "RMSE_test: 1.612\n",
      "MAE_test: 1.039\n",
      "Nash-Sutcliffe Test: 0.868\n",
      "Kling-Gupta Test: 0.659\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 71.3883 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:38:31,624]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB8\u001b[0m\n",
      "3it [00:00,  4.07it/s]\n",
      "1th fold: LGBMRegressor RMSE: 6.5224\n",
      "2th fold: LGBMRegressor RMSE: 10.4955\n",
      "3th fold: LGBMRegressor RMSE: 17.0133\n",
      "\n",
      "LGBMRegressor average RMSE: 11.3437\n",
      "LGBMRegressor worst RMSE: 17.0133\n",
      "Corresponding penalty value: 11.9107\n",
      "\u001b[32m[I 2025-03-31 13:38:32,364]\u001b[0m Trial 0 finished with value: 11.910704175772972 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.5700000000000001, 'feature_fraction': 0.32, 'min_gain_to_split': 0.87, 'reg_alpha': 8.67, 'reg_lambda': 6.01, 'linear_tree': True}. Best is trial 0 with value: 11.910704175772972.\u001b[0m\n",
      "3it [00:01,  2.14it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.7979\n",
      "2th fold: LGBMRegressor RMSE: 4.5346\n",
      "3th fold: LGBMRegressor RMSE: 48.3182\n",
      "\n",
      "LGBMRegressor average RMSE: 18.2169\n",
      "LGBMRegressor worst RMSE: 48.3182\n",
      "Corresponding penalty value: 21.2270\n",
      "\u001b[32m[I 2025-03-31 13:38:33,766]\u001b[0m Trial 1 finished with value: 21.22702680957609 and parameters: {'n_estimators': 2925, 'learning_rate': 0.08301, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.59, 'feature_fraction': 0.44, 'min_gain_to_split': 7.87, 'reg_alpha': 4.32, 'reg_lambda': 2.91, 'linear_tree': True}. Best is trial 0 with value: 11.910704175772972.\u001b[0m\n",
      "3it [00:00,  3.72it/s]\n",
      "1th fold: LGBMRegressor RMSE: 6.7688\n",
      "2th fold: LGBMRegressor RMSE: 11.5496\n",
      "3th fold: LGBMRegressor RMSE: 17.6839\n",
      "\n",
      "LGBMRegressor average RMSE: 12.0008\n",
      "LGBMRegressor worst RMSE: 17.6839\n",
      "Corresponding penalty value: 12.5691\n",
      "\u001b[32m[I 2025-03-31 13:38:34,574]\u001b[0m Trial 2 finished with value: 12.569069761882492 and parameters: {'n_estimators': 1230, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.6, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 8.89, 'reg_alpha': 0.46, 'reg_lambda': 6.08, 'linear_tree': True}. Best is trial 0 with value: 11.910704175772972.\u001b[0m\n",
      "3it [00:01,  2.49it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1362\n",
      "2th fold: LGBMRegressor RMSE: 2.4005\n",
      "3th fold: LGBMRegressor RMSE: 5.9678\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1682\n",
      "LGBMRegressor worst RMSE: 5.9678\n",
      "Corresponding penalty value: 3.4481\n",
      "\u001b[32m[I 2025-03-31 13:38:35,782]\u001b[0m Trial 3 finished with value: 3.448139007468413 and parameters: {'n_estimators': 2873, 'learning_rate': 0.09601, 'max_depth': 11, 'num_leaves': 10, 'subsample': 0.54, 'feature_fraction': 0.75, 'min_gain_to_split': 6.6000000000000005, 'reg_alpha': 1.22, 'reg_lambda': 4.95, 'linear_tree': False}. Best is trial 3 with value: 3.448139007468413.\u001b[0m\n",
      "3it [00:00,  5.16it/s]\n",
      "1th fold: LGBMRegressor RMSE: 10.3687\n",
      "2th fold: LGBMRegressor RMSE: 4.2244\n",
      "3th fold: LGBMRegressor RMSE: 7.2572\n",
      "\n",
      "LGBMRegressor average RMSE: 7.2834\n",
      "LGBMRegressor worst RMSE: 10.3687\n",
      "Corresponding penalty value: 7.5920\n",
      "\u001b[32m[I 2025-03-31 13:38:36,366]\u001b[0m Trial 4 finished with value: 7.591957280141392 and parameters: {'n_estimators': 1147, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.77, 'feature_fraction': 0.34, 'min_gain_to_split': 14.55, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'linear_tree': True}. Best is trial 3 with value: 3.448139007468413.\u001b[0m\n",
      "3it [00:01,  1.99it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0227\n",
      "2th fold: LGBMRegressor RMSE: 2.4487\n",
      "3th fold: LGBMRegressor RMSE: 5.9333\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1349\n",
      "LGBMRegressor worst RMSE: 5.9333\n",
      "Corresponding penalty value: 3.4148\n",
      "\u001b[32m[I 2025-03-31 13:38:37,875]\u001b[0m Trial 5 finished with value: 3.4147537427913752 and parameters: {'n_estimators': 2805, 'learning_rate': 0.00801, 'max_depth': 4, 'num_leaves': 3, 'subsample': 0.66, 'feature_fraction': 0.51, 'min_gain_to_split': 4.07, 'reg_alpha': 8.290000000000001, 'reg_lambda': 3.5700000000000003, 'linear_tree': False}. Best is trial 5 with value: 3.4147537427913752.\u001b[0m\n",
      "3it [00:00,  7.19it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0716\n",
      "2th fold: LGBMRegressor RMSE: 2.2445\n",
      "3th fold: LGBMRegressor RMSE: 5.9523\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0895\n",
      "LGBMRegressor worst RMSE: 5.9523\n",
      "Corresponding penalty value: 3.3758\n",
      "\u001b[32m[I 2025-03-31 13:38:38,294]\u001b[0m Trial 6 finished with value: 3.3757710219870822 and parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 6 with value: 3.3757710219870822.\u001b[0m\n",
      "3it [00:00,  5.78it/s]\n",
      "1th fold: LGBMRegressor RMSE: 25.2029\n",
      "2th fold: LGBMRegressor RMSE: 6.7805\n",
      "3th fold: LGBMRegressor RMSE: 125.0840\n",
      "\n",
      "LGBMRegressor average RMSE: 52.3558\n",
      "LGBMRegressor worst RMSE: 125.0840\n",
      "Corresponding penalty value: 59.6286\n",
      "\u001b[32m[I 2025-03-31 13:38:38,815]\u001b[0m Trial 7 finished with value: 59.62860750765556 and parameters: {'n_estimators': 685, 'learning_rate': 0.035010000000000006, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.81, 'feature_fraction': 0.46, 'min_gain_to_split': 0.9500000000000001, 'reg_alpha': 3.11, 'reg_lambda': 3.25, 'linear_tree': True}. Best is trial 6 with value: 3.3757710219870822.\u001b[0m\n",
      "3it [00:01,  1.91it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.9666\n",
      "2th fold: LGBMRegressor RMSE: 2.2541\n",
      "3th fold: LGBMRegressor RMSE: 25.8633\n",
      "\n",
      "LGBMRegressor average RMSE: 10.0280\n",
      "LGBMRegressor worst RMSE: 25.8633\n",
      "Corresponding penalty value: 11.6116\n",
      "\u001b[32m[I 2025-03-31 13:38:40,391]\u001b[0m Trial 8 finished with value: 11.611565004671045 and parameters: {'n_estimators': 2718, 'learning_rate': 0.04701, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.88, 'feature_fraction': 0.65, 'min_gain_to_split': 11.57, 'reg_alpha': 4.94, 'reg_lambda': 5.23, 'linear_tree': True}. Best is trial 6 with value: 3.3757710219870822.\u001b[0m\n",
      "3it [00:01,  1.71it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.5286\n",
      "2th fold: LGBMRegressor RMSE: 3.0400\n",
      "3th fold: LGBMRegressor RMSE: 6.0350\n",
      "\n",
      "LGBMRegressor average RMSE: 4.5345\n",
      "LGBMRegressor worst RMSE: 6.0350\n",
      "Corresponding penalty value: 4.6846\n",
      "\u001b[32m[I 2025-03-31 13:38:42,152]\u001b[0m Trial 9 finished with value: 4.684578454856167 and parameters: {'n_estimators': 769, 'learning_rate': 0.00301, 'max_depth': 9, 'num_leaves': 11, 'subsample': 0.75, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 3.74, 'reg_alpha': 4.1, 'reg_lambda': 7.5600000000000005, 'linear_tree': True}. Best is trial 6 with value: 3.3757710219870822.\u001b[0m\n",
      "3it [00:00,  5.66it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1442\n",
      "2th fold: LGBMRegressor RMSE: 2.1704\n",
      "3th fold: LGBMRegressor RMSE: 5.9192\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0779\n",
      "LGBMRegressor worst RMSE: 5.9192\n",
      "Corresponding penalty value: 3.3621\n",
      "\u001b[32m[I 2025-03-31 13:38:42,716]\u001b[0m Trial 10 finished with value: 3.362064510271342 and parameters: {'n_estimators': 2199, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.99, 'feature_fraction': 0.23, 'min_gain_to_split': 3.87, 'reg_alpha': 6.68, 'reg_lambda': 0.97, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  4.53it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1440\n",
      "2th fold: LGBMRegressor RMSE: 2.2174\n",
      "3th fold: LGBMRegressor RMSE: 5.9661\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1092\n",
      "LGBMRegressor worst RMSE: 5.9661\n",
      "Corresponding penalty value: 3.3949\n",
      "\u001b[32m[I 2025-03-31 13:38:43,414]\u001b[0m Trial 11 finished with value: 3.394863279449134 and parameters: {'n_estimators': 2079, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 30, 'subsample': 1.0, 'feature_fraction': 0.2, 'min_gain_to_split': 0.08, 'reg_alpha': 6.7700000000000005, 'reg_lambda': 0.16, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  5.84it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1400\n",
      "2th fold: LGBMRegressor RMSE: 2.2017\n",
      "3th fold: LGBMRegressor RMSE: 5.9185\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0867\n",
      "LGBMRegressor worst RMSE: 5.9185\n",
      "Corresponding penalty value: 3.3699\n",
      "\u001b[32m[I 2025-03-31 13:38:43,964]\u001b[0m Trial 12 finished with value: 3.3699146817029617 and parameters: {'n_estimators': 2117, 'learning_rate': 0.06801, 'max_depth': 3, 'num_leaves': 29, 'subsample': 1.0, 'feature_fraction': 0.22, 'min_gain_to_split': 3.7600000000000002, 'reg_alpha': 9.97, 'reg_lambda': 0.78, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  5.27it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1574\n",
      "2th fold: LGBMRegressor RMSE: 2.2863\n",
      "3th fold: LGBMRegressor RMSE: 5.9741\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1393\n",
      "LGBMRegressor worst RMSE: 5.9741\n",
      "Corresponding penalty value: 3.4228\n",
      "\u001b[32m[I 2025-03-31 13:38:44,571]\u001b[0m Trial 13 finished with value: 3.422751141682282 and parameters: {'n_estimators': 2186, 'learning_rate': 0.056010000000000004, 'max_depth': 8, 'num_leaves': 24, 'subsample': 1.0, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 4.25, 'reg_alpha': 9.66, 'reg_lambda': 0.17, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  5.17it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1384\n",
      "2th fold: LGBMRegressor RMSE: 2.1786\n",
      "3th fold: LGBMRegressor RMSE: 5.9925\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1032\n",
      "LGBMRegressor worst RMSE: 5.9925\n",
      "Corresponding penalty value: 3.3921\n",
      "\u001b[32m[I 2025-03-31 13:38:45,188]\u001b[0m Trial 14 finished with value: 3.3921104337586594 and parameters: {'n_estimators': 2224, 'learning_rate': 0.06501, 'max_depth': 6, 'num_leaves': 27, 'subsample': 0.9199999999999999, 'feature_fraction': 0.27, 'min_gain_to_split': 6.04, 'reg_alpha': 6.42, 'reg_lambda': 1.52, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.64it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1353\n",
      "2th fold: LGBMRegressor RMSE: 2.4215\n",
      "3th fold: LGBMRegressor RMSE: 5.9615\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1728\n",
      "LGBMRegressor worst RMSE: 5.9615\n",
      "Corresponding penalty value: 3.4516\n",
      "\u001b[32m[I 2025-03-31 13:38:46,048]\u001b[0m Trial 15 finished with value: 3.4516373298117604 and parameters: {'n_estimators': 1824, 'learning_rate': 0.08001, 'max_depth': 12, 'num_leaves': 20, 'subsample': 0.94, 'feature_fraction': 0.76, 'min_gain_to_split': 2.91, 'reg_alpha': 9.8, 'reg_lambda': 1.7, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.72it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0535\n",
      "2th fold: LGBMRegressor RMSE: 2.3746\n",
      "3th fold: LGBMRegressor RMSE: 5.9416\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1232\n",
      "LGBMRegressor worst RMSE: 5.9416\n",
      "Corresponding penalty value: 3.4050\n",
      "\u001b[32m[I 2025-03-31 13:38:46,891]\u001b[0m Trial 16 finished with value: 3.4050313856186705 and parameters: {'n_estimators': 2427, 'learning_rate': 0.042010000000000006, 'max_depth': 3, 'num_leaves': 26, 'subsample': 0.8400000000000001, 'feature_fraction': 0.4, 'min_gain_to_split': 9.99, 'reg_alpha': 6.2700000000000005, 'reg_lambda': 1.54, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.63it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0884\n",
      "2th fold: LGBMRegressor RMSE: 2.2574\n",
      "3th fold: LGBMRegressor RMSE: 5.9614\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1024\n",
      "LGBMRegressor worst RMSE: 5.9614\n",
      "Corresponding penalty value: 3.3883\n",
      "\u001b[32m[I 2025-03-31 13:38:47,754]\u001b[0m Trial 17 finished with value: 3.388306600816847 and parameters: {'n_estimators': 1858, 'learning_rate': 0.02701, 'max_depth': 5, 'num_leaves': 14, 'subsample': 0.95, 'feature_fraction': 0.53, 'min_gain_to_split': 2.36, 'reg_alpha': 1.87, 'reg_lambda': 2.36, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  6.54it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1295\n",
      "2th fold: LGBMRegressor RMSE: 2.2084\n",
      "3th fold: LGBMRegressor RMSE: 5.9940\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1107\n",
      "LGBMRegressor worst RMSE: 5.9940\n",
      "Corresponding penalty value: 3.3990\n",
      "\u001b[32m[I 2025-03-31 13:38:48,251]\u001b[0m Trial 18 finished with value: 3.398989216691604 and parameters: {'n_estimators': 1524, 'learning_rate': 0.056010000000000004, 'max_depth': 7, 'num_leaves': 29, 'subsample': 0.72, 'feature_fraction': 0.26, 'min_gain_to_split': 5.39, 'reg_alpha': 5.82, 'reg_lambda': 4.18, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:01,  2.33it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1540\n",
      "2th fold: LGBMRegressor RMSE: 2.5450\n",
      "3th fold: LGBMRegressor RMSE: 5.9538\n",
      "\n",
      "LGBMRegressor average RMSE: 3.2176\n",
      "LGBMRegressor worst RMSE: 5.9538\n",
      "Corresponding penalty value: 3.4912\n",
      "\u001b[32m[I 2025-03-31 13:38:49,576]\u001b[0m Trial 19 finished with value: 3.491214244043251 and parameters: {'n_estimators': 2480, 'learning_rate': 0.07300999999999999, 'max_depth': 5, 'num_leaves': 22, 'subsample': 1.0, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 2.08, 'reg_alpha': 7.19, 'reg_lambda': 0.92, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.36it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0701\n",
      "2th fold: LGBMRegressor RMSE: 2.3374\n",
      "3th fold: LGBMRegressor RMSE: 5.9813\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1296\n",
      "LGBMRegressor worst RMSE: 5.9813\n",
      "Corresponding penalty value: 3.4148\n",
      "\u001b[32m[I 2025-03-31 13:38:50,509]\u001b[0m Trial 20 finished with value: 3.4147606225566784 and parameters: {'n_estimators': 2559, 'learning_rate': 0.02001, 'max_depth': 6, 'num_leaves': 14, 'subsample': 0.86, 'feature_fraction': 0.31, 'min_gain_to_split': 4.99, 'reg_alpha': 9.14, 'reg_lambda': 2.35, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  4.37it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0312\n",
      "2th fold: LGBMRegressor RMSE: 2.2883\n",
      "3th fold: LGBMRegressor RMSE: 5.9726\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0974\n",
      "LGBMRegressor worst RMSE: 5.9726\n",
      "Corresponding penalty value: 3.3849\n",
      "\u001b[32m[I 2025-03-31 13:38:51,236]\u001b[0m Trial 21 finished with value: 3.384895766412162 and parameters: {'n_estimators': 2050, 'learning_rate': 0.08401, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.9, 'feature_fraction': 0.38, 'min_gain_to_split': 1.98, 'reg_alpha': 7.76, 'reg_lambda': 7.76, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  6.55it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1388\n",
      "2th fold: LGBMRegressor RMSE: 2.3267\n",
      "3th fold: LGBMRegressor RMSE: 5.9445\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1367\n",
      "LGBMRegressor worst RMSE: 5.9445\n",
      "Corresponding penalty value: 3.4175\n",
      "\u001b[32m[I 2025-03-31 13:38:51,734]\u001b[0m Trial 22 finished with value: 3.4174586747184605 and parameters: {'n_estimators': 1632, 'learning_rate': 0.05901000000000001, 'max_depth': 3, 'num_leaves': 27, 'subsample': 0.95, 'feature_fraction': 0.25, 'min_gain_to_split': 7.0200000000000005, 'reg_alpha': 10.0, 'reg_lambda': 7.16, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1700\n",
      "2th fold: LGBMRegressor RMSE: 2.1635\n",
      "3th fold: LGBMRegressor RMSE: 5.9707\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1014\n",
      "LGBMRegressor worst RMSE: 5.9707\n",
      "Corresponding penalty value: 3.3883\n",
      "\u001b[32m[I 2025-03-31 13:38:52,205]\u001b[0m Trial 23 finished with value: 3.38834921492625 and parameters: {'n_estimators': 1017, 'learning_rate': 0.07601, 'max_depth': 4, 'num_leaves': 24, 'subsample': 0.96, 'feature_fraction': 0.2, 'min_gain_to_split': 0.07, 'reg_alpha': 8.65, 'reg_lambda': 8.88, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  4.92it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0319\n",
      "2th fold: LGBMRegressor RMSE: 2.3255\n",
      "3th fold: LGBMRegressor RMSE: 5.9524\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1033\n",
      "LGBMRegressor worst RMSE: 5.9524\n",
      "Corresponding penalty value: 3.3882\n",
      "\u001b[32m[I 2025-03-31 13:38:52,856]\u001b[0m Trial 24 finished with value: 3.38818305358778 and parameters: {'n_estimators': 1895, 'learning_rate': 0.09401, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.81, 'feature_fraction': 0.37, 'min_gain_to_split': 3.04, 'reg_alpha': 7.62, 'reg_lambda': 6.65, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  4.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1079\n",
      "2th fold: LGBMRegressor RMSE: 2.2796\n",
      "3th fold: LGBMRegressor RMSE: 5.9952\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1275\n",
      "LGBMRegressor worst RMSE: 5.9952\n",
      "Corresponding penalty value: 3.4143\n",
      "\u001b[32m[I 2025-03-31 13:38:53,564]\u001b[0m Trial 25 finished with value: 3.4143036380486858 and parameters: {'n_estimators': 2300, 'learning_rate': 0.08601, 'max_depth': 5, 'num_leaves': 28, 'subsample': 0.9, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 1.36, 'reg_alpha': 9.06, 'reg_lambda': 8.77, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  8.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0787\n",
      "2th fold: LGBMRegressor RMSE: 2.2290\n",
      "3th fold: LGBMRegressor RMSE: 5.9717\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0931\n",
      "LGBMRegressor worst RMSE: 5.9717\n",
      "Corresponding penalty value: 3.3810\n",
      "\u001b[32m[I 2025-03-31 13:38:53,982]\u001b[0m Trial 26 finished with value: 3.380980776355323 and parameters: {'n_estimators': 867, 'learning_rate': 0.06201, 'max_depth': 4, 'num_leaves': 25, 'subsample': 0.96, 'feature_fraction': 0.44, 'min_gain_to_split': 4.82, 'reg_alpha': 8.11, 'reg_lambda': 4.43, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  5.55it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0748\n",
      "2th fold: LGBMRegressor RMSE: 2.3015\n",
      "3th fold: LGBMRegressor RMSE: 5.9666\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1143\n",
      "LGBMRegressor worst RMSE: 5.9666\n",
      "Corresponding penalty value: 3.3996\n",
      "\u001b[32m[I 2025-03-31 13:38:54,565]\u001b[0m Trial 27 finished with value: 3.3995635323013924 and parameters: {'n_estimators': 1308, 'learning_rate': 0.07400999999999999, 'max_depth': 3, 'num_leaves': 21, 'subsample': 0.8500000000000001, 'feature_fraction': 0.55, 'min_gain_to_split': 8.31, 'reg_alpha': 5.55, 'reg_lambda': 0.91, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  9.81it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0688\n",
      "2th fold: LGBMRegressor RMSE: 2.3413\n",
      "3th fold: LGBMRegressor RMSE: 5.9843\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1315\n",
      "LGBMRegressor worst RMSE: 5.9843\n",
      "Corresponding penalty value: 3.4168\n",
      "\u001b[32m[I 2025-03-31 13:38:54,915]\u001b[0m Trial 28 finished with value: 3.416751155660639 and parameters: {'n_estimators': 592, 'learning_rate': 0.049010000000000005, 'max_depth': 4, 'num_leaves': 18, 'subsample': 0.98, 'feature_fraction': 0.34, 'min_gain_to_split': 3.44, 'reg_alpha': 9.11, 'reg_lambda': 0.67, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.53it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1894\n",
      "2th fold: LGBMRegressor RMSE: 2.5736\n",
      "3th fold: LGBMRegressor RMSE: 5.9550\n",
      "\n",
      "LGBMRegressor average RMSE: 3.2393\n",
      "LGBMRegressor worst RMSE: 5.9550\n",
      "Corresponding penalty value: 3.5109\n",
      "\u001b[32m[I 2025-03-31 13:38:55,807]\u001b[0m Trial 29 finished with value: 3.5108897057234696 and parameters: {'n_estimators': 1632, 'learning_rate': 0.08900999999999999, 'max_depth': 9, 'num_leaves': 28, 'subsample': 0.91, 'feature_fraction': 1.0, 'min_gain_to_split': 1.22, 'reg_alpha': 7.2700000000000005, 'reg_lambda': 8.07, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  6.78it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0908\n",
      "2th fold: LGBMRegressor RMSE: 2.2760\n",
      "3th fold: LGBMRegressor RMSE: 5.9984\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1217\n",
      "LGBMRegressor worst RMSE: 5.9984\n",
      "Corresponding penalty value: 3.4094\n",
      "\u001b[32m[I 2025-03-31 13:38:56,294]\u001b[0m Trial 30 finished with value: 3.40937178115508 and parameters: {'n_estimators': 1405, 'learning_rate': 0.06901, 'max_depth': 5, 'num_leaves': 23, 'subsample': 0.5, 'feature_fraction': 0.30000000000000004, 'min_gain_to_split': 12.23, 'reg_alpha': 8.6, 'reg_lambda': 5.45, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.79it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0768\n",
      "2th fold: LGBMRegressor RMSE: 2.3375\n",
      "3th fold: LGBMRegressor RMSE: 5.9771\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1305\n",
      "LGBMRegressor worst RMSE: 5.9771\n",
      "Corresponding penalty value: 3.4151\n",
      "\u001b[32m[I 2025-03-31 13:38:56,724]\u001b[0m Trial 31 finished with value: 3.4151315563815094 and parameters: {'n_estimators': 890, 'learning_rate': 0.06001, 'max_depth': 4, 'num_leaves': 25, 'subsample': 0.97, 'feature_fraction': 0.44, 'min_gain_to_split': 5.24, 'reg_alpha': 8.370000000000001, 'reg_lambda': 4.29, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.77it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0446\n",
      "2th fold: LGBMRegressor RMSE: 2.2479\n",
      "3th fold: LGBMRegressor RMSE: 5.9649\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0858\n",
      "LGBMRegressor worst RMSE: 5.9649\n",
      "Corresponding penalty value: 3.3737\n",
      "\u001b[32m[I 2025-03-31 13:38:57,155]\u001b[0m Trial 32 finished with value: 3.373749652284559 and parameters: {'n_estimators': 983, 'learning_rate': 0.07901, 'max_depth': 3, 'num_leaves': 26, 'subsample': 0.9299999999999999, 'feature_fraction': 0.42000000000000004, 'min_gain_to_split': 4.61, 'reg_alpha': 8.120000000000001, 'reg_lambda': 6.33, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00, 13.29it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1502\n",
      "2th fold: LGBMRegressor RMSE: 2.3007\n",
      "3th fold: LGBMRegressor RMSE: 5.9501\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1337\n",
      "LGBMRegressor worst RMSE: 5.9501\n",
      "Corresponding penalty value: 3.4153\n",
      "\u001b[32m[I 2025-03-31 13:38:57,427]\u001b[0m Trial 33 finished with value: 3.415325157361565 and parameters: {'n_estimators': 551, 'learning_rate': 0.07901, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.9299999999999999, 'feature_fraction': 0.25, 'min_gain_to_split': 5.83, 'reg_alpha': 6.87, 'reg_lambda': 6.22, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  5.21it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3525\n",
      "2th fold: LGBMRegressor RMSE: 2.1700\n",
      "3th fold: LGBMRegressor RMSE: 67.3203\n",
      "\n",
      "LGBMRegressor average RMSE: 23.6143\n",
      "LGBMRegressor worst RMSE: 67.3203\n",
      "Corresponding penalty value: 27.9849\n",
      "\u001b[32m[I 2025-03-31 13:38:58,049]\u001b[0m Trial 34 finished with value: 27.984874364630482 and parameters: {'n_estimators': 1138, 'learning_rate': 0.08800999999999999, 'max_depth': 3, 'num_leaves': 26, 'subsample': 0.89, 'feature_fraction': 0.4, 'min_gain_to_split': 7.3, 'reg_alpha': 9.41, 'reg_lambda': 5.83, 'linear_tree': True}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.99it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0893\n",
      "2th fold: LGBMRegressor RMSE: 2.2536\n",
      "3th fold: LGBMRegressor RMSE: 5.9735\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1055\n",
      "LGBMRegressor worst RMSE: 5.9735\n",
      "Corresponding penalty value: 3.3923\n",
      "\u001b[32m[I 2025-03-31 13:38:58,848]\u001b[0m Trial 35 finished with value: 3.3922853940436712 and parameters: {'n_estimators': 2054, 'learning_rate': 0.09701, 'max_depth': 5, 'num_leaves': 28, 'subsample': 0.67, 'feature_fraction': 0.49, 'min_gain_to_split': 9.63, 'reg_alpha': 5.04, 'reg_lambda': 6.72, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  5.39it/s]\n",
      "1th fold: LGBMRegressor RMSE: 6.7391\n",
      "2th fold: LGBMRegressor RMSE: 3.2490\n",
      "3th fold: LGBMRegressor RMSE: 38.5370\n",
      "\n",
      "LGBMRegressor average RMSE: 16.1750\n",
      "LGBMRegressor worst RMSE: 38.5370\n",
      "Corresponding penalty value: 18.4112\n",
      "\u001b[32m[I 2025-03-31 13:38:59,451]\u001b[0m Trial 36 finished with value: 18.411245562276587 and parameters: {'n_estimators': 1039, 'learning_rate': 0.07101, 'max_depth': 4, 'num_leaves': 30, 'subsample': 0.8200000000000001, 'feature_fraction': 0.34, 'min_gain_to_split': 4.32, 'reg_alpha': 7.890000000000001, 'reg_lambda': 2.68, 'linear_tree': True}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:01,  2.76it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1037\n",
      "2th fold: LGBMRegressor RMSE: 2.4509\n",
      "3th fold: LGBMRegressor RMSE: 5.9674\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1740\n",
      "LGBMRegressor worst RMSE: 5.9674\n",
      "Corresponding penalty value: 3.4533\n",
      "\u001b[32m[I 2025-03-31 13:39:00,584]\u001b[0m Trial 37 finished with value: 3.453349770904155 and parameters: {'n_estimators': 2635, 'learning_rate': 0.07901, 'max_depth': 6, 'num_leaves': 7, 'subsample': 0.98, 'feature_fraction': 0.63, 'min_gain_to_split': 6.36, 'reg_alpha': 7.22, 'reg_lambda': 3.5, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.24it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0863\n",
      "2th fold: LGBMRegressor RMSE: 2.2560\n",
      "3th fold: LGBMRegressor RMSE: 5.9732\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1052\n",
      "LGBMRegressor worst RMSE: 5.9732\n",
      "Corresponding penalty value: 3.3920\n",
      "\u001b[32m[I 2025-03-31 13:39:01,559]\u001b[0m Trial 38 finished with value: 3.3919690982705655 and parameters: {'n_estimators': 2348, 'learning_rate': 0.09101, 'max_depth': 4, 'num_leaves': 26, 'subsample': 0.87, 'feature_fraction': 0.5700000000000001, 'min_gain_to_split': 2.46, 'reg_alpha': 6.2, 'reg_lambda': 9.76, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.83it/s]\n",
      "1th fold: LGBMRegressor RMSE: 48.8470\n",
      "2th fold: LGBMRegressor RMSE: 4.5814\n",
      "3th fold: LGBMRegressor RMSE: 14.5650\n",
      "\n",
      "LGBMRegressor average RMSE: 22.6645\n",
      "LGBMRegressor worst RMSE: 48.8470\n",
      "Corresponding penalty value: 25.2827\n",
      "\u001b[32m[I 2025-03-31 13:39:01,990]\u001b[0m Trial 39 finished with value: 25.28272337795334 and parameters: {'n_estimators': 736, 'learning_rate': 0.05201000000000001, 'max_depth': 7, 'num_leaves': 28, 'subsample': 0.77, 'feature_fraction': 0.23, 'min_gain_to_split': 7.82, 'reg_alpha': 4.0, 'reg_lambda': 4.7700000000000005, 'linear_tree': True}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  4.27it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0938\n",
      "2th fold: LGBMRegressor RMSE: 2.3246\n",
      "3th fold: LGBMRegressor RMSE: 5.9884\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1356\n",
      "LGBMRegressor worst RMSE: 5.9884\n",
      "Corresponding penalty value: 3.4209\n",
      "\u001b[32m[I 2025-03-31 13:39:02,741]\u001b[0m Trial 40 finished with value: 3.4208573989163464 and parameters: {'n_estimators': 1983, 'learning_rate': 0.08001, 'max_depth': 10, 'num_leaves': 20, 'subsample': 0.9299999999999999, 'feature_fraction': 0.36, 'min_gain_to_split': 0.63, 'reg_alpha': 0.18, 'reg_lambda': 6.99, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.66it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0622\n",
      "2th fold: LGBMRegressor RMSE: 2.2362\n",
      "3th fold: LGBMRegressor RMSE: 5.9739\n",
      "\n",
      "LGBMRegressor average RMSE: 3.0908\n",
      "LGBMRegressor worst RMSE: 5.9739\n",
      "Corresponding penalty value: 3.3791\n",
      "\u001b[32m[I 2025-03-31 13:39:03,181]\u001b[0m Trial 41 finished with value: 3.3790854100977694 and parameters: {'n_estimators': 899, 'learning_rate': 0.06401, 'max_depth': 3, 'num_leaves': 25, 'subsample': 0.97, 'feature_fraction': 0.46, 'min_gain_to_split': 4.69, 'reg_alpha': 8.0, 'reg_lambda': 6.0, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.50it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0703\n",
      "2th fold: LGBMRegressor RMSE: 2.2856\n",
      "3th fold: LGBMRegressor RMSE: 5.9826\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1128\n",
      "LGBMRegressor worst RMSE: 5.9826\n",
      "Corresponding penalty value: 3.3998\n",
      "\u001b[32m[I 2025-03-31 13:39:03,630]\u001b[0m Trial 42 finished with value: 3.3997978533612443 and parameters: {'n_estimators': 892, 'learning_rate': 0.06601, 'max_depth': 3, 'num_leaves': 25, 'subsample': 0.98, 'feature_fraction': 0.48000000000000004, 'min_gain_to_split': 3.71, 'reg_alpha': 8.83, 'reg_lambda': 6.1000000000000005, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  4.89it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0972\n",
      "2th fold: LGBMRegressor RMSE: 2.6286\n",
      "3th fold: LGBMRegressor RMSE: 5.9273\n",
      "\n",
      "LGBMRegressor average RMSE: 3.2177\n",
      "LGBMRegressor worst RMSE: 5.9273\n",
      "Corresponding penalty value: 3.4887\n",
      "\u001b[32m[I 2025-03-31 13:39:04,292]\u001b[0m Trial 43 finished with value: 3.488662962758964 and parameters: {'n_estimators': 1299, 'learning_rate': 0.07501, 'max_depth': 3, 'num_leaves': 3, 'subsample': 1.0, 'feature_fraction': 0.6799999999999999, 'min_gain_to_split': 4.63, 'reg_alpha': 8.370000000000001, 'reg_lambda': 8.11, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  6.95it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0652\n",
      "2th fold: LGBMRegressor RMSE: 2.3751\n",
      "3th fold: LGBMRegressor RMSE: 5.9705\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1369\n",
      "LGBMRegressor worst RMSE: 5.9705\n",
      "Corresponding penalty value: 3.4203\n",
      "\u001b[32m[I 2025-03-31 13:39:04,774]\u001b[0m Trial 44 finished with value: 3.42030459887809 and parameters: {'n_estimators': 1021, 'learning_rate': 0.06501, 'max_depth': 4, 'num_leaves': 23, 'subsample': 0.9199999999999999, 'feature_fraction': 0.42000000000000004, 'min_gain_to_split': 1.53, 'reg_alpha': 7.53, 'reg_lambda': 5.44, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.06it/s]\n",
      "1th fold: LGBMRegressor RMSE: 8.2920\n",
      "2th fold: LGBMRegressor RMSE: 47.1291\n",
      "3th fold: LGBMRegressor RMSE: 14.3507\n",
      "\n",
      "LGBMRegressor average RMSE: 23.2573\n",
      "LGBMRegressor worst RMSE: 47.1291\n",
      "Corresponding penalty value: 25.6445\n",
      "\u001b[32m[I 2025-03-31 13:39:05,248]\u001b[0m Trial 45 finished with value: 25.644454465779067 and parameters: {'n_estimators': 653, 'learning_rate': 0.04301000000000001, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.94, 'feature_fraction': 0.32, 'min_gain_to_split': 3.09, 'reg_alpha': 9.43, 'reg_lambda': 6.45, 'linear_tree': True}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  9.86it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0770\n",
      "2th fold: LGBMRegressor RMSE: 2.3483\n",
      "3th fold: LGBMRegressor RMSE: 5.9671\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1308\n",
      "LGBMRegressor worst RMSE: 5.9671\n",
      "Corresponding penalty value: 3.4144\n",
      "\u001b[32m[I 2025-03-31 13:39:05,603]\u001b[0m Trial 46 finished with value: 3.414426697328013 and parameters: {'n_estimators': 505, 'learning_rate': 0.05401, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.98, 'feature_fraction': 0.5900000000000001, 'min_gain_to_split': 6.7700000000000005, 'reg_alpha': 6.67, 'reg_lambda': 7.2700000000000005, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.48it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0855\n",
      "2th fold: LGBMRegressor RMSE: 2.2326\n",
      "3th fold: LGBMRegressor RMSE: 5.9913\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1031\n",
      "LGBMRegressor worst RMSE: 5.9913\n",
      "Corresponding penalty value: 3.3919\n",
      "\u001b[32m[I 2025-03-31 13:39:06,056]\u001b[0m Trial 47 finished with value: 3.3919353693777117 and parameters: {'n_estimators': 1152, 'learning_rate': 0.06901, 'max_depth': 5, 'num_leaves': 26, 'subsample': 0.59, 'feature_fraction': 0.28, 'min_gain_to_split': 5.6000000000000005, 'reg_alpha': 8.23, 'reg_lambda': 5.86, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  3.70it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.0859\n",
      "2th fold: LGBMRegressor RMSE: 2.3938\n",
      "3th fold: LGBMRegressor RMSE: 5.9728\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1508\n",
      "LGBMRegressor worst RMSE: 5.9728\n",
      "Corresponding penalty value: 3.4330\n",
      "\u001b[32m[I 2025-03-31 13:39:06,916]\u001b[0m Trial 48 finished with value: 3.4330291215985094 and parameters: {'n_estimators': 2172, 'learning_rate': 0.08401, 'max_depth': 12, 'num_leaves': 16, 'subsample': 0.88, 'feature_fraction': 0.48000000000000004, 'min_gain_to_split': 4.0, 'reg_alpha': 5.7, 'reg_lambda': 2.07, 'linear_tree': False}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "3it [00:00,  7.08it/s]\n",
      "1th fold: LGBMRegressor RMSE: 10.9967\n",
      "2th fold: LGBMRegressor RMSE: 3.7603\n",
      "3th fold: LGBMRegressor RMSE: 9.3026\n",
      "\n",
      "LGBMRegressor average RMSE: 8.0199\n",
      "LGBMRegressor worst RMSE: 10.9967\n",
      "Corresponding penalty value: 8.3176\n",
      "\u001b[32m[I 2025-03-31 13:39:07,391]\u001b[0m Trial 49 finished with value: 8.317571946612906 and parameters: {'n_estimators': 844, 'learning_rate': 0.06101, 'max_depth': 3, 'num_leaves': 30, 'subsample': 1.0, 'feature_fraction': 0.22, 'min_gain_to_split': 2.57, 'reg_alpha': 3.47, 'reg_lambda': 3.83, 'linear_tree': True}. Best is trial 10 with value: 3.362064510271342.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 2199, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.99, 'feature_fraction': 0.23, 'min_gain_to_split': 3.87, 'reg_alpha': 6.68, 'reg_lambda': 0.97, 'linear_tree': False}\n",
      "3it [00:00,  5.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.1244\n",
      "2th fold: LGBMRegressor RMSE: 2.3938\n",
      "3th fold: LGBMRegressor RMSE: 5.9551\n",
      "\n",
      "LGBMRegressor average RMSE: 3.1578\n",
      "LGBMRegressor worst RMSE: 5.9551\n",
      "Corresponding penalty value: 3.4375\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB8\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 2199, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.99, 'feature_fraction': 0.23, 'min_gain_to_split': 3.87, 'reg_alpha': 6.68, 'reg_lambda': 0.97, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.947\n",
      "RMSE_crossval: 3.158\n",
      "RMSE_test: 1.850\n",
      "MAE_test: 1.452\n",
      "Nash-Sutcliffe Test: -1.201\n",
      "Kling-Gupta Test: 0.007\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 37.2092 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:39:08,831]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB10\u001b[0m\n",
      "3it [00:00,  4.24it/s]\n",
      "1th fold: LGBMRegressor RMSE: 34.6027\n",
      "2th fold: LGBMRegressor RMSE: 50.7235\n",
      "3th fold: LGBMRegressor RMSE: 148.1344\n",
      "\n",
      "LGBMRegressor average RMSE: 77.8202\n",
      "LGBMRegressor worst RMSE: 148.1344\n",
      "Corresponding penalty value: 84.8516\n",
      "\u001b[32m[I 2025-03-31 13:39:09,541]\u001b[0m Trial 0 finished with value: 84.85162906589183 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.5700000000000001, 'feature_fraction': 0.32, 'min_gain_to_split': 0.87, 'reg_alpha': 8.67, 'reg_lambda': 6.01, 'linear_tree': True}. Best is trial 0 with value: 84.85162906589183.\u001b[0m\n",
      "3it [00:01,  2.12it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.0271\n",
      "2th fold: LGBMRegressor RMSE: 57.8251\n",
      "3th fold: LGBMRegressor RMSE: 186.6594\n",
      "\n",
      "LGBMRegressor average RMSE: 82.1705\n",
      "LGBMRegressor worst RMSE: 186.6594\n",
      "Corresponding penalty value: 92.6194\n",
      "\u001b[32m[I 2025-03-31 13:39:10,957]\u001b[0m Trial 1 finished with value: 92.61943739412081 and parameters: {'n_estimators': 2925, 'learning_rate': 0.08301, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.59, 'feature_fraction': 0.44, 'min_gain_to_split': 7.87, 'reg_alpha': 4.32, 'reg_lambda': 2.91, 'linear_tree': True}. Best is trial 0 with value: 84.85162906589183.\u001b[0m\n",
      "3it [00:00,  3.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.2549\n",
      "2th fold: LGBMRegressor RMSE: 36.2308\n",
      "3th fold: LGBMRegressor RMSE: 189.4736\n",
      "\n",
      "LGBMRegressor average RMSE: 75.9864\n",
      "LGBMRegressor worst RMSE: 189.4736\n",
      "Corresponding penalty value: 87.3351\n",
      "\u001b[32m[I 2025-03-31 13:39:11,813]\u001b[0m Trial 2 finished with value: 87.33513514994073 and parameters: {'n_estimators': 1230, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.6, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 8.89, 'reg_alpha': 0.46, 'reg_lambda': 6.08, 'linear_tree': True}. Best is trial 0 with value: 84.85162906589183.\u001b[0m\n",
      "3it [00:01,  2.45it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.7219\n",
      "2th fold: LGBMRegressor RMSE: 2.5968\n",
      "3th fold: LGBMRegressor RMSE: 1.3965\n",
      "\n",
      "LGBMRegressor average RMSE: 1.9051\n",
      "LGBMRegressor worst RMSE: 2.5968\n",
      "Corresponding penalty value: 1.9742\n",
      "\u001b[32m[I 2025-03-31 13:39:13,038]\u001b[0m Trial 3 finished with value: 1.9742379536259074 and parameters: {'n_estimators': 2873, 'learning_rate': 0.09601, 'max_depth': 11, 'num_leaves': 10, 'subsample': 0.54, 'feature_fraction': 0.75, 'min_gain_to_split': 6.6000000000000005, 'reg_alpha': 1.22, 'reg_lambda': 4.95, 'linear_tree': False}. Best is trial 3 with value: 1.9742379536259074.\u001b[0m\n",
      "3it [00:00,  5.15it/s]\n",
      "1th fold: LGBMRegressor RMSE: 30.7925\n",
      "2th fold: LGBMRegressor RMSE: 67.8254\n",
      "3th fold: LGBMRegressor RMSE: 32.7172\n",
      "\n",
      "LGBMRegressor average RMSE: 43.7784\n",
      "LGBMRegressor worst RMSE: 67.8254\n",
      "Corresponding penalty value: 46.1831\n",
      "\u001b[32m[I 2025-03-31 13:39:13,622]\u001b[0m Trial 4 finished with value: 46.18307210838256 and parameters: {'n_estimators': 1147, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.77, 'feature_fraction': 0.34, 'min_gain_to_split': 14.55, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'linear_tree': True}. Best is trial 3 with value: 1.9742379536259074.\u001b[0m\n",
      "3it [00:01,  1.75it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.6983\n",
      "2th fold: LGBMRegressor RMSE: 4.1678\n",
      "3th fold: LGBMRegressor RMSE: 1.5944\n",
      "\n",
      "LGBMRegressor average RMSE: 2.4868\n",
      "LGBMRegressor worst RMSE: 4.1678\n",
      "Corresponding penalty value: 2.6549\n",
      "\u001b[32m[I 2025-03-31 13:39:15,342]\u001b[0m Trial 5 finished with value: 2.6548960157812145 and parameters: {'n_estimators': 2805, 'learning_rate': 0.00801, 'max_depth': 4, 'num_leaves': 3, 'subsample': 0.66, 'feature_fraction': 0.51, 'min_gain_to_split': 4.07, 'reg_alpha': 8.290000000000001, 'reg_lambda': 3.5700000000000003, 'linear_tree': False}. Best is trial 3 with value: 1.9742379536259074.\u001b[0m\n",
      "3it [00:00,  6.42it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4256\n",
      "2th fold: LGBMRegressor RMSE: 2.3248\n",
      "3th fold: LGBMRegressor RMSE: 1.4780\n",
      "\n",
      "LGBMRegressor average RMSE: 1.7428\n",
      "LGBMRegressor worst RMSE: 2.3248\n",
      "Corresponding penalty value: 1.8010\n",
      "\u001b[32m[I 2025-03-31 13:39:15,811]\u001b[0m Trial 6 finished with value: 1.800983324172357 and parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 6 with value: 1.800983324172357.\u001b[0m\n",
      "3it [00:00,  5.15it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.6432\n",
      "2th fold: LGBMRegressor RMSE: 411.9338\n",
      "3th fold: LGBMRegressor RMSE: 356.3100\n",
      "\n",
      "LGBMRegressor average RMSE: 257.9623\n",
      "LGBMRegressor worst RMSE: 411.9338\n",
      "Corresponding penalty value: 273.3595\n",
      "\u001b[32m[I 2025-03-31 13:39:16,396]\u001b[0m Trial 7 finished with value: 273.35946825912043 and parameters: {'n_estimators': 685, 'learning_rate': 0.035010000000000006, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.81, 'feature_fraction': 0.46, 'min_gain_to_split': 0.9500000000000001, 'reg_alpha': 3.11, 'reg_lambda': 3.25, 'linear_tree': True}. Best is trial 6 with value: 1.800983324172357.\u001b[0m\n",
      "3it [00:01,  1.89it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.5317\n",
      "2th fold: LGBMRegressor RMSE: 77.9589\n",
      "3th fold: LGBMRegressor RMSE: 67.1342\n",
      "\n",
      "LGBMRegressor average RMSE: 49.2083\n",
      "LGBMRegressor worst RMSE: 77.9589\n",
      "Corresponding penalty value: 52.0833\n",
      "\u001b[32m[I 2025-03-31 13:39:17,982]\u001b[0m Trial 8 finished with value: 52.083313837550456 and parameters: {'n_estimators': 2718, 'learning_rate': 0.04701, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.88, 'feature_fraction': 0.65, 'min_gain_to_split': 11.57, 'reg_alpha': 4.94, 'reg_lambda': 5.23, 'linear_tree': True}. Best is trial 6 with value: 1.800983324172357.\u001b[0m\n",
      "3it [00:01,  1.62it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.8216\n",
      "2th fold: LGBMRegressor RMSE: 29.0447\n",
      "3th fold: LGBMRegressor RMSE: 67.9865\n",
      "\n",
      "LGBMRegressor average RMSE: 32.9510\n",
      "LGBMRegressor worst RMSE: 67.9865\n",
      "Corresponding penalty value: 36.4545\n",
      "\u001b[32m[I 2025-03-31 13:39:19,839]\u001b[0m Trial 9 finished with value: 36.45450976547043 and parameters: {'n_estimators': 769, 'learning_rate': 0.00301, 'max_depth': 9, 'num_leaves': 11, 'subsample': 0.75, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 3.74, 'reg_alpha': 4.1, 'reg_lambda': 7.5600000000000005, 'linear_tree': True}. Best is trial 6 with value: 1.800983324172357.\u001b[0m\n",
      "3it [00:00,  5.37it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3558\n",
      "2th fold: LGBMRegressor RMSE: 2.4930\n",
      "3th fold: LGBMRegressor RMSE: 1.2729\n",
      "\n",
      "LGBMRegressor average RMSE: 1.7072\n",
      "LGBMRegressor worst RMSE: 2.4930\n",
      "Corresponding penalty value: 1.7858\n",
      "\u001b[32m[I 2025-03-31 13:39:20,432]\u001b[0m Trial 10 finished with value: 1.7858096763141857 and parameters: {'n_estimators': 2199, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.99, 'feature_fraction': 0.23, 'min_gain_to_split': 3.87, 'reg_alpha': 6.68, 'reg_lambda': 0.97, 'linear_tree': False}. Best is trial 10 with value: 1.7858096763141857.\u001b[0m\n",
      "3it [00:00,  3.94it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3584\n",
      "2th fold: LGBMRegressor RMSE: 2.1029\n",
      "3th fold: LGBMRegressor RMSE: 1.3200\n",
      "\n",
      "LGBMRegressor average RMSE: 1.5938\n",
      "LGBMRegressor worst RMSE: 2.1029\n",
      "Corresponding penalty value: 1.6447\n",
      "\u001b[32m[I 2025-03-31 13:39:21,229]\u001b[0m Trial 11 finished with value: 1.6446748352074068 and parameters: {'n_estimators': 2079, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 30, 'subsample': 1.0, 'feature_fraction': 0.2, 'min_gain_to_split': 0.08, 'reg_alpha': 6.7700000000000005, 'reg_lambda': 0.16, 'linear_tree': False}. Best is trial 11 with value: 1.6446748352074068.\u001b[0m\n",
      "3it [00:00,  5.32it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3556\n",
      "2th fold: LGBMRegressor RMSE: 2.5140\n",
      "3th fold: LGBMRegressor RMSE: 1.2425\n",
      "\n",
      "LGBMRegressor average RMSE: 1.7040\n",
      "LGBMRegressor worst RMSE: 2.5140\n",
      "Corresponding penalty value: 1.7850\n",
      "\u001b[32m[I 2025-03-31 13:39:21,829]\u001b[0m Trial 12 finished with value: 1.78501078157469 and parameters: {'n_estimators': 2159, 'learning_rate': 0.06801, 'max_depth': 3, 'num_leaves': 29, 'subsample': 1.0, 'feature_fraction': 0.22, 'min_gain_to_split': 3.98, 'reg_alpha': 6.53, 'reg_lambda': 0.43, 'linear_tree': False}. Best is trial 11 with value: 1.6446748352074068.\u001b[0m\n",
      "3it [00:00,  5.02it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2661\n",
      "2th fold: LGBMRegressor RMSE: 1.4929\n",
      "3th fold: LGBMRegressor RMSE: 0.9700\n",
      "\n",
      "LGBMRegressor average RMSE: 1.2430\n",
      "LGBMRegressor worst RMSE: 1.4929\n",
      "Corresponding penalty value: 1.2680\n",
      "\u001b[32m[I 2025-03-31 13:39:22,463]\u001b[0m Trial 13 finished with value: 1.2679949668904578 and parameters: {'n_estimators': 2093, 'learning_rate': 0.056010000000000004, 'max_depth': 8, 'num_leaves': 25, 'subsample': 1.0, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 2.5500000000000003, 'reg_alpha': 5.78, 'reg_lambda': 0.25, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  5.52it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2817\n",
      "2th fold: LGBMRegressor RMSE: 1.5417\n",
      "3th fold: LGBMRegressor RMSE: 0.9658\n",
      "\n",
      "LGBMRegressor average RMSE: 1.2631\n",
      "LGBMRegressor worst RMSE: 1.5417\n",
      "Corresponding penalty value: 1.2910\n",
      "\u001b[32m[I 2025-03-31 13:39:23,044]\u001b[0m Trial 14 finished with value: 1.2909686645901362 and parameters: {'n_estimators': 1952, 'learning_rate': 0.05301, 'max_depth': 8, 'num_leaves': 24, 'subsample': 0.9199999999999999, 'feature_fraction': 0.22, 'min_gain_to_split': 2.9, 'reg_alpha': 9.700000000000001, 'reg_lambda': 1.43, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.29it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.7228\n",
      "2th fold: LGBMRegressor RMSE: 2.0371\n",
      "3th fold: LGBMRegressor RMSE: 1.4457\n",
      "\n",
      "LGBMRegressor average RMSE: 1.7352\n",
      "LGBMRegressor worst RMSE: 2.0371\n",
      "Corresponding penalty value: 1.7654\n",
      "\u001b[32m[I 2025-03-31 13:39:23,994]\u001b[0m Trial 15 finished with value: 1.76539124073229 and parameters: {'n_estimators': 1751, 'learning_rate': 0.049010000000000005, 'max_depth': 9, 'num_leaves': 23, 'subsample': 0.9199999999999999, 'feature_fraction': 0.8700000000000001, 'min_gain_to_split': 5.84, 'reg_alpha': 9.8, 'reg_lambda': 1.7, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.14it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4109\n",
      "2th fold: LGBMRegressor RMSE: 1.8291\n",
      "3th fold: LGBMRegressor RMSE: 1.0186\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4196\n",
      "LGBMRegressor worst RMSE: 1.8291\n",
      "Corresponding penalty value: 1.4605\n",
      "\u001b[32m[I 2025-03-31 13:39:24,988]\u001b[0m Trial 16 finished with value: 1.460522367065079 and parameters: {'n_estimators': 2436, 'learning_rate': 0.02001, 'max_depth': 8, 'num_leaves': 19, 'subsample': 0.9299999999999999, 'feature_fraction': 0.30000000000000004, 'min_gain_to_split': 2.8000000000000003, 'reg_alpha': 2.56, 'reg_lambda': 2.18, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.88it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.5243\n",
      "2th fold: LGBMRegressor RMSE: 1.8381\n",
      "3th fold: LGBMRegressor RMSE: 1.1994\n",
      "\n",
      "LGBMRegressor average RMSE: 1.5206\n",
      "LGBMRegressor worst RMSE: 1.8381\n",
      "Corresponding penalty value: 1.5523\n",
      "\u001b[32m[I 2025-03-31 13:39:25,799]\u001b[0m Trial 17 finished with value: 1.5523183382202372 and parameters: {'n_estimators': 1771, 'learning_rate': 0.058010000000000006, 'max_depth': 12, 'num_leaves': 25, 'subsample': 0.8500000000000001, 'feature_fraction': 0.51, 'min_gain_to_split': 2.15, 'reg_alpha': 9.59, 'reg_lambda': 1.6400000000000001, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.95it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4669\n",
      "2th fold: LGBMRegressor RMSE: 2.2686\n",
      "3th fold: LGBMRegressor RMSE: 1.2068\n",
      "\n",
      "LGBMRegressor average RMSE: 1.6474\n",
      "LGBMRegressor worst RMSE: 2.2686\n",
      "Corresponding penalty value: 1.7095\n",
      "\u001b[32m[I 2025-03-31 13:39:26,595]\u001b[0m Trial 18 finished with value: 1.7095443705181035 and parameters: {'n_estimators': 1927, 'learning_rate': 0.03701, 'max_depth': 7, 'num_leaves': 13, 'subsample': 0.69, 'feature_fraction': 0.4, 'min_gain_to_split': 5.49, 'reg_alpha': 5.82, 'reg_lambda': 4.07, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:01,  2.50it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.6799\n",
      "2th fold: LGBMRegressor RMSE: 2.0777\n",
      "3th fold: LGBMRegressor RMSE: 1.2033\n",
      "\n",
      "LGBMRegressor average RMSE: 1.6537\n",
      "LGBMRegressor worst RMSE: 2.0777\n",
      "Corresponding penalty value: 1.6961\n",
      "\u001b[32m[I 2025-03-31 13:39:27,837]\u001b[0m Trial 19 finished with value: 1.6960630068587272 and parameters: {'n_estimators': 2472, 'learning_rate': 0.02501, 'max_depth': 8, 'num_leaves': 21, 'subsample': 0.95, 'feature_fraction': 0.71, 'min_gain_to_split': 9.290000000000001, 'reg_alpha': 2.7800000000000002, 'reg_lambda': 2.31, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  6.29it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4211\n",
      "2th fold: LGBMRegressor RMSE: 1.7175\n",
      "3th fold: LGBMRegressor RMSE: 1.1313\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4233\n",
      "LGBMRegressor worst RMSE: 1.7175\n",
      "Corresponding penalty value: 1.4527\n",
      "\u001b[32m[I 2025-03-31 13:39:28,355]\u001b[0m Trial 20 finished with value: 1.4527022812172614 and parameters: {'n_estimators': 1497, 'learning_rate': 0.05901000000000001, 'max_depth': 6, 'num_leaves': 26, 'subsample': 0.8300000000000001, 'feature_fraction': 0.26, 'min_gain_to_split': 2.2, 'reg_alpha': 5.63, 'reg_lambda': 1.01, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  6.22it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4094\n",
      "2th fold: LGBMRegressor RMSE: 1.7398\n",
      "3th fold: LGBMRegressor RMSE: 1.0912\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4135\n",
      "LGBMRegressor worst RMSE: 1.7398\n",
      "Corresponding penalty value: 1.4461\n",
      "\u001b[32m[I 2025-03-31 13:39:28,878]\u001b[0m Trial 21 finished with value: 1.446106703750129 and parameters: {'n_estimators': 1484, 'learning_rate': 0.058010000000000006, 'max_depth': 6, 'num_leaves': 26, 'subsample': 0.8400000000000001, 'feature_fraction': 0.27, 'min_gain_to_split': 1.98, 'reg_alpha': 5.7, 'reg_lambda': 1.06, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  5.41it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4046\n",
      "2th fold: LGBMRegressor RMSE: 1.6299\n",
      "3th fold: LGBMRegressor RMSE: 1.0528\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3624\n",
      "LGBMRegressor worst RMSE: 1.6299\n",
      "Corresponding penalty value: 1.3892\n",
      "\u001b[32m[I 2025-03-31 13:39:29,474]\u001b[0m Trial 22 finished with value: 1.3891524190931734 and parameters: {'n_estimators': 1502, 'learning_rate': 0.05301, 'max_depth': 6, 'num_leaves': 27, 'subsample': 0.94, 'feature_fraction': 0.28, 'min_gain_to_split': 1.94, 'reg_alpha': 7.34, 'reg_lambda': 0.06, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  4.74it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3646\n",
      "2th fold: LGBMRegressor RMSE: 1.5194\n",
      "3th fold: LGBMRegressor RMSE: 1.0857\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3232\n",
      "LGBMRegressor worst RMSE: 1.5194\n",
      "Corresponding penalty value: 1.3429\n",
      "\u001b[32m[I 2025-03-31 13:39:30,147]\u001b[0m Trial 23 finished with value: 1.3428624125127973 and parameters: {'n_estimators': 2386, 'learning_rate': 0.04401, 'max_depth': 9, 'num_leaves': 21, 'subsample': 0.95, 'feature_fraction': 0.2, 'min_gain_to_split': 5.11, 'reg_alpha': 7.45, 'reg_lambda': 0.34, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  4.70it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3619\n",
      "2th fold: LGBMRegressor RMSE: 1.6579\n",
      "3th fold: LGBMRegressor RMSE: 1.0917\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3705\n",
      "LGBMRegressor worst RMSE: 1.6579\n",
      "Corresponding penalty value: 1.3992\n",
      "\u001b[32m[I 2025-03-31 13:39:30,829]\u001b[0m Trial 24 finished with value: 1.3992351238394782 and parameters: {'n_estimators': 2455, 'learning_rate': 0.04301000000000001, 'max_depth': 9, 'num_leaves': 15, 'subsample': 0.96, 'feature_fraction': 0.2, 'min_gain_to_split': 5.21, 'reg_alpha': 8.82, 'reg_lambda': 2.5, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.32it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4869\n",
      "2th fold: LGBMRegressor RMSE: 1.8923\n",
      "3th fold: LGBMRegressor RMSE: 1.0798\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4863\n",
      "LGBMRegressor worst RMSE: 1.8923\n",
      "Corresponding penalty value: 1.5269\n",
      "\u001b[32m[I 2025-03-31 13:39:31,774]\u001b[0m Trial 25 finished with value: 1.5269192105373368 and parameters: {'n_estimators': 2280, 'learning_rate': 0.02501, 'max_depth': 10, 'num_leaves': 20, 'subsample': 0.89, 'feature_fraction': 0.4, 'min_gain_to_split': 7.04, 'reg_alpha': 9.13, 'reg_lambda': 1.41, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  4.47it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4934\n",
      "2th fold: LGBMRegressor RMSE: 1.7765\n",
      "3th fold: LGBMRegressor RMSE: 1.1453\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4717\n",
      "LGBMRegressor worst RMSE: 1.7765\n",
      "Corresponding penalty value: 1.5022\n",
      "\u001b[32m[I 2025-03-31 13:39:32,489]\u001b[0m Trial 26 finished with value: 1.5022021248727455 and parameters: {'n_estimators': 2008, 'learning_rate': 0.07901, 'max_depth': 8, 'num_leaves': 17, 'subsample': 0.8, 'feature_fraction': 0.35, 'min_gain_to_split': 4.87, 'reg_alpha': 9.94, 'reg_lambda': 0.55, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.62it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4020\n",
      "2th fold: LGBMRegressor RMSE: 1.7943\n",
      "3th fold: LGBMRegressor RMSE: 1.0010\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3991\n",
      "LGBMRegressor worst RMSE: 1.7943\n",
      "Corresponding penalty value: 1.4386\n",
      "\u001b[32m[I 2025-03-31 13:39:33,360]\u001b[0m Trial 27 finished with value: 1.4386412267565292 and parameters: {'n_estimators': 2597, 'learning_rate': 0.040010000000000004, 'max_depth': 10, 'num_leaves': 23, 'subsample': 0.97, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 2.95, 'reg_alpha': 7.74, 'reg_lambda': 3.97, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.5783\n",
      "2th fold: LGBMRegressor RMSE: 1.9326\n",
      "3th fold: LGBMRegressor RMSE: 1.1411\n",
      "\n",
      "LGBMRegressor average RMSE: 1.5507\n",
      "LGBMRegressor worst RMSE: 1.9326\n",
      "Corresponding penalty value: 1.5889\n",
      "\u001b[32m[I 2025-03-31 13:39:34,221]\u001b[0m Trial 28 finished with value: 1.5888592904047207 and parameters: {'n_estimators': 1880, 'learning_rate': 0.03101, 'max_depth': 7, 'num_leaves': 21, 'subsample': 0.91, 'feature_fraction': 0.53, 'min_gain_to_split': 10.93, 'reg_alpha': 7.21, 'reg_lambda': 1.86, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:01,  2.61it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.7670\n",
      "2th fold: LGBMRegressor RMSE: 2.2565\n",
      "3th fold: LGBMRegressor RMSE: 1.4395\n",
      "\n",
      "LGBMRegressor average RMSE: 1.8210\n",
      "LGBMRegressor worst RMSE: 2.2565\n",
      "Corresponding penalty value: 1.8646\n",
      "\u001b[32m[I 2025-03-31 13:39:35,412]\u001b[0m Trial 29 finished with value: 1.8645709156073862 and parameters: {'n_estimators': 2314, 'learning_rate': 0.08800999999999999, 'max_depth': 11, 'num_leaves': 19, 'subsample': 0.87, 'feature_fraction': 1.0, 'min_gain_to_split': 1.02, 'reg_alpha': 8.88, 'reg_lambda': 0.09, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  5.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4706\n",
      "2th fold: LGBMRegressor RMSE: 1.9745\n",
      "3th fold: LGBMRegressor RMSE: 1.1662\n",
      "\n",
      "LGBMRegressor average RMSE: 1.5371\n",
      "LGBMRegressor worst RMSE: 1.9745\n",
      "Corresponding penalty value: 1.5809\n",
      "\u001b[32m[I 2025-03-31 13:39:36,057]\u001b[0m Trial 30 finished with value: 1.5808595489489667 and parameters: {'n_estimators': 1659, 'learning_rate': 0.05301, 'max_depth': 9, 'num_leaves': 16, 'subsample': 0.5, 'feature_fraction': 0.33, 'min_gain_to_split': 3.0500000000000003, 'reg_alpha': 6.09, 'reg_lambda': 2.68, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  6.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4292\n",
      "2th fold: LGBMRegressor RMSE: 1.5824\n",
      "3th fold: LGBMRegressor RMSE: 1.0792\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3636\n",
      "LGBMRegressor worst RMSE: 1.5824\n",
      "Corresponding penalty value: 1.3855\n",
      "\u001b[32m[I 2025-03-31 13:39:36,552]\u001b[0m Trial 31 finished with value: 1.385465704926095 and parameters: {'n_estimators': 1192, 'learning_rate': 0.05201000000000001, 'max_depth': 8, 'num_leaves': 26, 'subsample': 0.94, 'feature_fraction': 0.26, 'min_gain_to_split': 1.54, 'reg_alpha': 7.37, 'reg_lambda': 0.05, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  6.18it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4322\n",
      "2th fold: LGBMRegressor RMSE: 1.5764\n",
      "3th fold: LGBMRegressor RMSE: 1.0984\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3690\n",
      "LGBMRegressor worst RMSE: 1.5764\n",
      "Corresponding penalty value: 1.3898\n",
      "\u001b[32m[I 2025-03-31 13:39:37,083]\u001b[0m Trial 32 finished with value: 1.3897510326768294 and parameters: {'n_estimators': 1039, 'learning_rate': 0.04701, 'max_depth': 8, 'num_leaves': 24, 'subsample': 0.97, 'feature_fraction': 0.25, 'min_gain_to_split': 1.27, 'reg_alpha': 5.01, 'reg_lambda': 0.93, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  7.25it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3526\n",
      "2th fold: LGBMRegressor RMSE: 1.4325\n",
      "3th fold: LGBMRegressor RMSE: 1.1105\n",
      "\n",
      "LGBMRegressor average RMSE: 1.2985\n",
      "LGBMRegressor worst RMSE: 1.4325\n",
      "Corresponding penalty value: 1.3119\n",
      "\u001b[32m[I 2025-03-31 13:39:37,542]\u001b[0m Trial 33 finished with value: 1.3119260444844318 and parameters: {'n_estimators': 1308, 'learning_rate': 0.06201, 'max_depth': 7, 'num_leaves': 28, 'subsample': 0.9199999999999999, 'feature_fraction': 0.2, 'min_gain_to_split': 4.5600000000000005, 'reg_alpha': 8.32, 'reg_lambda': 0.74, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  9.30it/s]\n",
      "1th fold: LGBMRegressor RMSE: 37.2852\n",
      "2th fold: LGBMRegressor RMSE: 20.4514\n",
      "3th fold: LGBMRegressor RMSE: 17.6870\n",
      "\n",
      "LGBMRegressor average RMSE: 25.1412\n",
      "LGBMRegressor worst RMSE: 37.2852\n",
      "Corresponding penalty value: 26.3556\n",
      "\u001b[32m[I 2025-03-31 13:39:37,910]\u001b[0m Trial 34 finished with value: 26.355589788861753 and parameters: {'n_estimators': 510, 'learning_rate': 0.06301, 'max_depth': 7, 'num_leaves': 28, 'subsample': 0.9, 'feature_fraction': 0.2, 'min_gain_to_split': 7.98, 'reg_alpha': 8.21, 'reg_lambda': 1.36, 'linear_tree': True}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  5.40it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.5387\n",
      "2th fold: LGBMRegressor RMSE: 1.6140\n",
      "3th fold: LGBMRegressor RMSE: 1.1211\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4246\n",
      "LGBMRegressor worst RMSE: 1.6140\n",
      "Corresponding penalty value: 1.4435\n",
      "\u001b[32m[I 2025-03-31 13:39:38,511]\u001b[0m Trial 35 finished with value: 1.4435284127894503 and parameters: {'n_estimators': 1361, 'learning_rate': 0.07201, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.74, 'feature_fraction': 0.44, 'min_gain_to_split': 6.34, 'reg_alpha': 9.32, 'reg_lambda': 1.96, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 13.1879\n",
      "2th fold: LGBMRegressor RMSE: 94.2034\n",
      "3th fold: LGBMRegressor RMSE: 50.7269\n",
      "\n",
      "LGBMRegressor average RMSE: 52.7061\n",
      "LGBMRegressor worst RMSE: 94.2034\n",
      "Corresponding penalty value: 56.8558\n",
      "\u001b[32m[I 2025-03-31 13:39:39,411]\u001b[0m Trial 36 finished with value: 56.855808152512445 and parameters: {'n_estimators': 1879, 'learning_rate': 0.07501, 'max_depth': 5, 'num_leaves': 22, 'subsample': 0.97, 'feature_fraction': 0.32, 'min_gain_to_split': 4.7700000000000005, 'reg_alpha': 8.46, 'reg_lambda': 0.78, 'linear_tree': True}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  5.50it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4600\n",
      "2th fold: LGBMRegressor RMSE: 1.8985\n",
      "3th fold: LGBMRegressor RMSE: 1.0418\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4668\n",
      "LGBMRegressor worst RMSE: 1.8985\n",
      "Corresponding penalty value: 1.5099\n",
      "\u001b[32m[I 2025-03-31 13:39:40,003]\u001b[0m Trial 37 finished with value: 1.5099306739207714 and parameters: {'n_estimators': 1346, 'learning_rate': 0.06201, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.86, 'feature_fraction': 0.39, 'min_gain_to_split': 4.42, 'reg_alpha': 7.95, 'reg_lambda': 8.94, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  6.52it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3813\n",
      "2th fold: LGBMRegressor RMSE: 3.1506\n",
      "3th fold: LGBMRegressor RMSE: 1.2872\n",
      "\n",
      "LGBMRegressor average RMSE: 1.9397\n",
      "LGBMRegressor worst RMSE: 3.1506\n",
      "Corresponding penalty value: 2.0608\n",
      "\u001b[32m[I 2025-03-31 13:39:40,510]\u001b[0m Trial 38 finished with value: 2.0607722160352675 and parameters: {'n_estimators': 1649, 'learning_rate': 0.04301000000000001, 'max_depth': 9, 'num_leaves': 5, 'subsample': 0.9199999999999999, 'feature_fraction': 0.24000000000000002, 'min_gain_to_split': 14.64, 'reg_alpha': 4.01, 'reg_lambda': 3.11, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:01,  1.69it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.9513\n",
      "2th fold: LGBMRegressor RMSE: 34.9951\n",
      "3th fold: LGBMRegressor RMSE: 174.6151\n",
      "\n",
      "LGBMRegressor average RMSE: 70.5205\n",
      "LGBMRegressor worst RMSE: 174.6151\n",
      "Corresponding penalty value: 80.9300\n",
      "\u001b[32m[I 2025-03-31 13:39:42,334]\u001b[0m Trial 39 finished with value: 80.92997077562293 and parameters: {'n_estimators': 2977, 'learning_rate': 0.08701, 'max_depth': 5, 'num_leaves': 28, 'subsample': 0.78, 'feature_fraction': 0.81, 'min_gain_to_split': 8.06, 'reg_alpha': 5.03, 'reg_lambda': 4.42, 'linear_tree': True}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:01,  2.50it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.6069\n",
      "2th fold: LGBMRegressor RMSE: 1.9332\n",
      "3th fold: LGBMRegressor RMSE: 1.1715\n",
      "\n",
      "LGBMRegressor average RMSE: 1.5705\n",
      "LGBMRegressor worst RMSE: 1.9332\n",
      "Corresponding penalty value: 1.6068\n",
      "\u001b[32m[I 2025-03-31 13:39:43,581]\u001b[0m Trial 40 finished with value: 1.6067740331082538 and parameters: {'n_estimators': 2623, 'learning_rate': 0.03101, 'max_depth': 11, 'num_leaves': 24, 'subsample': 0.63, 'feature_fraction': 0.5900000000000001, 'min_gain_to_split': 3.08, 'reg_alpha': 0.18, 'reg_lambda': 5.21, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  6.75it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4379\n",
      "2th fold: LGBMRegressor RMSE: 1.6337\n",
      "3th fold: LGBMRegressor RMSE: 1.0851\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3855\n",
      "LGBMRegressor worst RMSE: 1.6337\n",
      "Corresponding penalty value: 1.4104\n",
      "\u001b[32m[I 2025-03-31 13:39:44,073]\u001b[0m Trial 41 finished with value: 1.4103556593019182 and parameters: {'n_estimators': 1162, 'learning_rate': 0.05301, 'max_depth': 8, 'num_leaves': 26, 'subsample': 0.94, 'feature_fraction': 0.25, 'min_gain_to_split': 3.5, 'reg_alpha': 7.44, 'reg_lambda': 0.49, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  7.15it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4097\n",
      "2th fold: LGBMRegressor RMSE: 1.8366\n",
      "3th fold: LGBMRegressor RMSE: 1.0053\n",
      "\n",
      "LGBMRegressor average RMSE: 1.4172\n",
      "LGBMRegressor worst RMSE: 1.8366\n",
      "Corresponding penalty value: 1.4591\n",
      "\u001b[32m[I 2025-03-31 13:39:44,541]\u001b[0m Trial 42 finished with value: 1.4591317106828046 and parameters: {'n_estimators': 906, 'learning_rate': 0.05401, 'max_depth': 8, 'num_leaves': 25, 'subsample': 0.98, 'feature_fraction': 0.30000000000000004, 'min_gain_to_split': 1.57, 'reg_alpha': 7.01, 'reg_lambda': 0.52, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  5.05it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.5110\n",
      "2th fold: LGBMRegressor RMSE: 1.4589\n",
      "3th fold: LGBMRegressor RMSE: 1.0925\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3541\n",
      "LGBMRegressor worst RMSE: 1.5110\n",
      "Corresponding penalty value: 1.3698\n",
      "\u001b[32m[I 2025-03-31 13:39:45,185]\u001b[0m Trial 43 finished with value: 1.3698052469027697 and parameters: {'n_estimators': 1031, 'learning_rate': 0.04601, 'max_depth': 7, 'num_leaves': 28, 'subsample': 1.0, 'feature_fraction': 0.37, 'min_gain_to_split': 0.55, 'reg_alpha': 6.36, 'reg_lambda': 0.05, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  4.09it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4819\n",
      "2th fold: LGBMRegressor RMSE: 1.4276\n",
      "3th fold: LGBMRegressor RMSE: 1.1127\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3408\n",
      "LGBMRegressor worst RMSE: 1.4819\n",
      "Corresponding penalty value: 1.3549\n",
      "\u001b[32m[I 2025-03-31 13:39:45,968]\u001b[0m Trial 44 finished with value: 1.3548730072852604 and parameters: {'n_estimators': 970, 'learning_rate': 0.04501, 'max_depth': 7, 'num_leaves': 28, 'subsample': 1.0, 'feature_fraction': 0.35, 'min_gain_to_split': 0.06, 'reg_alpha': 6.28, 'reg_lambda': 1.3, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  5.37it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2807\n",
      "2th fold: LGBMRegressor RMSE: 1.5049\n",
      "3th fold: LGBMRegressor RMSE: 0.9408\n",
      "\n",
      "LGBMRegressor average RMSE: 1.2421\n",
      "LGBMRegressor worst RMSE: 1.5049\n",
      "Corresponding penalty value: 1.2684\n",
      "\u001b[32m[I 2025-03-31 13:39:46,577]\u001b[0m Trial 45 finished with value: 1.2683940136395866 and parameters: {'n_estimators': 2073, 'learning_rate': 0.06501, 'max_depth': 9, 'num_leaves': 30, 'subsample': 0.96, 'feature_fraction': 0.22, 'min_gain_to_split': 6.32, 'reg_alpha': 8.56, 'reg_lambda': 1.35, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  3.55it/s]\n",
      "1th fold: LGBMRegressor RMSE: 207.7493\n",
      "2th fold: LGBMRegressor RMSE: 19.7668\n",
      "3th fold: LGBMRegressor RMSE: 131.9488\n",
      "\n",
      "LGBMRegressor average RMSE: 119.8216\n",
      "LGBMRegressor worst RMSE: 207.7493\n",
      "Corresponding penalty value: 128.6144\n",
      "\u001b[32m[I 2025-03-31 13:39:47,471]\u001b[0m Trial 46 finished with value: 128.61441002350242 and parameters: {'n_estimators': 2135, 'learning_rate': 0.06501, 'max_depth': 10, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 6.19, 'reg_alpha': 8.57, 'reg_lambda': 2.9, 'linear_tree': True}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  4.64it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.4801\n",
      "2th fold: LGBMRegressor RMSE: 1.5435\n",
      "3th fold: LGBMRegressor RMSE: 1.0563\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3600\n",
      "LGBMRegressor worst RMSE: 1.5435\n",
      "Corresponding penalty value: 1.3783\n",
      "\u001b[32m[I 2025-03-31 13:39:48,169]\u001b[0m Trial 47 finished with value: 1.3783163059509975 and parameters: {'n_estimators': 2042, 'learning_rate': 0.07300999999999999, 'max_depth': 9, 'num_leaves': 30, 'subsample': 0.72, 'feature_fraction': 0.31, 'min_gain_to_split': 7.05, 'reg_alpha': 9.41, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  4.94it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.2922\n",
      "2th fold: LGBMRegressor RMSE: 1.6777\n",
      "3th fold: LGBMRegressor RMSE: 0.9834\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3178\n",
      "LGBMRegressor worst RMSE: 1.6777\n",
      "Corresponding penalty value: 1.3538\n",
      "\u001b[32m[I 2025-03-31 13:39:48,827]\u001b[0m Trial 48 finished with value: 1.3537695636811302 and parameters: {'n_estimators': 2296, 'learning_rate': 0.057010000000000005, 'max_depth': 9, 'num_leaves': 22, 'subsample': 0.91, 'feature_fraction': 0.23, 'min_gain_to_split': 5.64, 'reg_alpha': 7.88, 'reg_lambda': 3.49, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "3it [00:00,  6.28it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3854\n",
      "2th fold: LGBMRegressor RMSE: 1.4680\n",
      "3th fold: LGBMRegressor RMSE: 1.0979\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3171\n",
      "LGBMRegressor worst RMSE: 1.4680\n",
      "Corresponding penalty value: 1.3322\n",
      "\u001b[32m[I 2025-03-31 13:39:49,355]\u001b[0m Trial 49 finished with value: 1.3321667888889581 and parameters: {'n_estimators': 1627, 'learning_rate': 0.06201, 'max_depth': 9, 'num_leaves': 29, 'subsample': 0.8200000000000001, 'feature_fraction': 0.2, 'min_gain_to_split': 4.64, 'reg_alpha': 1.12, 'reg_lambda': 1.6600000000000001, 'linear_tree': False}. Best is trial 13 with value: 1.2679949668904578.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 2093, 'learning_rate': 0.056010000000000004, 'max_depth': 8, 'num_leaves': 25, 'subsample': 1.0, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 2.5500000000000003, 'reg_alpha': 5.78, 'reg_lambda': 0.25, 'linear_tree': False}\n",
      "3it [00:00,  4.97it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1.3313\n",
      "2th fold: LGBMRegressor RMSE: 1.6347\n",
      "3th fold: LGBMRegressor RMSE: 0.9555\n",
      "\n",
      "LGBMRegressor average RMSE: 1.3072\n",
      "LGBMRegressor worst RMSE: 1.6347\n",
      "Corresponding penalty value: 1.3400\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB10\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 2093, 'learning_rate': 0.056010000000000004, 'max_depth': 8, 'num_leaves': 25, 'subsample': 1.0, 'feature_fraction': 0.21000000000000002, 'min_gain_to_split': 2.5500000000000003, 'reg_alpha': 5.78, 'reg_lambda': 0.25, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.291\n",
      "RMSE_crossval: 1.307\n",
      "RMSE_test: 1.303\n",
      "MAE_test: 1.057\n",
      "Nash-Sutcliffe Test: -0.013\n",
      "Kling-Gupta Test: 0.187\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 42.0386 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:39:50,877]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB18\u001b[0m\n",
      "3it [00:00,  4.26it/s]\n",
      "1th fold: LGBMRegressor RMSE: 74.5952\n",
      "2th fold: LGBMRegressor RMSE: 65.0695\n",
      "3th fold: LGBMRegressor RMSE: 125.6618\n",
      "\n",
      "LGBMRegressor average RMSE: 88.4422\n",
      "LGBMRegressor worst RMSE: 125.6618\n",
      "Corresponding penalty value: 92.1641\n",
      "\u001b[32m[I 2025-03-31 13:39:51,584]\u001b[0m Trial 0 finished with value: 92.16413128079594 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 10, 'num_leaves': 19, 'subsample': 0.5700000000000001, 'feature_fraction': 0.32, 'min_gain_to_split': 0.87, 'reg_alpha': 8.67, 'reg_lambda': 6.01, 'linear_tree': True}. Best is trial 0 with value: 92.16413128079594.\u001b[0m\n",
      "3it [00:01,  2.01it/s]\n",
      "1th fold: LGBMRegressor RMSE: 146.1233\n",
      "2th fold: LGBMRegressor RMSE: 14.3621\n",
      "3th fold: LGBMRegressor RMSE: 272.6814\n",
      "\n",
      "LGBMRegressor average RMSE: 144.3889\n",
      "LGBMRegressor worst RMSE: 272.6814\n",
      "Corresponding penalty value: 157.2182\n",
      "\u001b[32m[I 2025-03-31 13:39:53,078]\u001b[0m Trial 1 finished with value: 157.21816291760786 and parameters: {'n_estimators': 2925, 'learning_rate': 0.08301, 'max_depth': 5, 'num_leaves': 7, 'subsample': 0.59, 'feature_fraction': 0.44, 'min_gain_to_split': 7.87, 'reg_alpha': 4.32, 'reg_lambda': 2.91, 'linear_tree': True}. Best is trial 0 with value: 92.16413128079594.\u001b[0m\n",
      "3it [00:00,  3.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 74.0174\n",
      "2th fold: LGBMRegressor RMSE: 111.4651\n",
      "3th fold: LGBMRegressor RMSE: 181.2641\n",
      "\n",
      "LGBMRegressor average RMSE: 122.2489\n",
      "LGBMRegressor worst RMSE: 181.2641\n",
      "Corresponding penalty value: 128.1504\n",
      "\u001b[32m[I 2025-03-31 13:39:53,934]\u001b[0m Trial 2 finished with value: 128.15041829006543 and parameters: {'n_estimators': 1230, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'num_leaves': 24, 'subsample': 0.6, 'feature_fraction': 0.6100000000000001, 'min_gain_to_split': 8.89, 'reg_alpha': 0.46, 'reg_lambda': 6.08, 'linear_tree': True}. Best is trial 0 with value: 92.16413128079594.\u001b[0m\n",
      "3it [00:01,  2.46it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.9846\n",
      "2th fold: LGBMRegressor RMSE: 1.5895\n",
      "3th fold: LGBMRegressor RMSE: 5.5716\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0486\n",
      "LGBMRegressor worst RMSE: 5.5716\n",
      "Corresponding penalty value: 4.2009\n",
      "\u001b[32m[I 2025-03-31 13:39:55,154]\u001b[0m Trial 3 finished with value: 4.200865057890305 and parameters: {'n_estimators': 2873, 'learning_rate': 0.09601, 'max_depth': 11, 'num_leaves': 10, 'subsample': 0.54, 'feature_fraction': 0.75, 'min_gain_to_split': 6.6000000000000005, 'reg_alpha': 1.22, 'reg_lambda': 4.95, 'linear_tree': False}. Best is trial 3 with value: 4.200865057890305.\u001b[0m\n",
      "3it [00:00,  5.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.1558\n",
      "2th fold: LGBMRegressor RMSE: 242.3691\n",
      "3th fold: LGBMRegressor RMSE: 31.4024\n",
      "\n",
      "LGBMRegressor average RMSE: 91.9758\n",
      "LGBMRegressor worst RMSE: 242.3691\n",
      "Corresponding penalty value: 107.0151\n",
      "\u001b[32m[I 2025-03-31 13:39:55,757]\u001b[0m Trial 4 finished with value: 107.01510304236467 and parameters: {'n_estimators': 1147, 'learning_rate': 0.06601, 'max_depth': 6, 'num_leaves': 17, 'subsample': 0.77, 'feature_fraction': 0.34, 'min_gain_to_split': 14.55, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'linear_tree': True}. Best is trial 3 with value: 4.200865057890305.\u001b[0m\n",
      "3it [00:01,  1.81it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.2365\n",
      "2th fold: LGBMRegressor RMSE: 1.9849\n",
      "3th fold: LGBMRegressor RMSE: 5.1591\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1268\n",
      "LGBMRegressor worst RMSE: 5.2365\n",
      "Corresponding penalty value: 4.2378\n",
      "\u001b[32m[I 2025-03-31 13:39:57,416]\u001b[0m Trial 5 finished with value: 4.237787898562407 and parameters: {'n_estimators': 2805, 'learning_rate': 0.00801, 'max_depth': 4, 'num_leaves': 3, 'subsample': 0.66, 'feature_fraction': 0.51, 'min_gain_to_split': 4.07, 'reg_alpha': 8.290000000000001, 'reg_lambda': 3.5700000000000003, 'linear_tree': False}. Best is trial 3 with value: 4.200865057890305.\u001b[0m\n",
      "3it [00:00,  6.45it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.6367\n",
      "2th fold: LGBMRegressor RMSE: 1.8377\n",
      "3th fold: LGBMRegressor RMSE: 5.1082\n",
      "\n",
      "LGBMRegressor average RMSE: 3.8609\n",
      "LGBMRegressor worst RMSE: 5.1082\n",
      "Corresponding penalty value: 3.9856\n",
      "\u001b[32m[I 2025-03-31 13:39:57,883]\u001b[0m Trial 6 finished with value: 3.9856396917694705 and parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  5.47it/s]\n",
      "1th fold: LGBMRegressor RMSE: 113.7716\n",
      "2th fold: LGBMRegressor RMSE: 4219.4131\n",
      "3th fold: LGBMRegressor RMSE: 3972.3563\n",
      "\n",
      "LGBMRegressor average RMSE: 2768.5137\n",
      "LGBMRegressor worst RMSE: 4219.4131\n",
      "Corresponding penalty value: 2913.6036\n",
      "\u001b[32m[I 2025-03-31 13:39:58,434]\u001b[0m Trial 7 finished with value: 2913.603596425394 and parameters: {'n_estimators': 685, 'learning_rate': 0.035010000000000006, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.81, 'feature_fraction': 0.46, 'min_gain_to_split': 0.9500000000000001, 'reg_alpha': 3.11, 'reg_lambda': 3.25, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  1.94it/s]\n",
      "1th fold: LGBMRegressor RMSE: 35.2899\n",
      "2th fold: LGBMRegressor RMSE: 95.5030\n",
      "3th fold: LGBMRegressor RMSE: 58.9682\n",
      "\n",
      "LGBMRegressor average RMSE: 63.2537\n",
      "LGBMRegressor worst RMSE: 95.5030\n",
      "Corresponding penalty value: 66.4786\n",
      "\u001b[32m[I 2025-03-31 13:39:59,984]\u001b[0m Trial 8 finished with value: 66.47861360446136 and parameters: {'n_estimators': 2718, 'learning_rate': 0.04701, 'max_depth': 4, 'num_leaves': 22, 'subsample': 0.88, 'feature_fraction': 0.65, 'min_gain_to_split': 11.57, 'reg_alpha': 4.94, 'reg_lambda': 5.23, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  1.59it/s]\n",
      "1th fold: LGBMRegressor RMSE: 61.4605\n",
      "2th fold: LGBMRegressor RMSE: 79.4743\n",
      "3th fold: LGBMRegressor RMSE: 91.0353\n",
      "\n",
      "LGBMRegressor average RMSE: 77.3234\n",
      "LGBMRegressor worst RMSE: 91.0353\n",
      "Corresponding penalty value: 78.6946\n",
      "\u001b[32m[I 2025-03-31 13:40:01,872]\u001b[0m Trial 9 finished with value: 78.69456488555805 and parameters: {'n_estimators': 769, 'learning_rate': 0.00301, 'max_depth': 9, 'num_leaves': 11, 'subsample': 0.75, 'feature_fraction': 0.9299999999999999, 'min_gain_to_split': 3.74, 'reg_alpha': 4.1, 'reg_lambda': 7.5600000000000005, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  5.42it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.8225\n",
      "2th fold: LGBMRegressor RMSE: 1.9238\n",
      "3th fold: LGBMRegressor RMSE: 4.9539\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9001\n",
      "LGBMRegressor worst RMSE: 4.9539\n",
      "Corresponding penalty value: 4.0055\n",
      "\u001b[32m[I 2025-03-31 13:40:02,460]\u001b[0m Trial 10 finished with value: 4.005460623305989 and parameters: {'n_estimators': 2199, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.99, 'feature_fraction': 0.23, 'min_gain_to_split': 3.87, 'reg_alpha': 6.68, 'reg_lambda': 0.97, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.56it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.3385\n",
      "2th fold: LGBMRegressor RMSE: 1.8658\n",
      "3th fold: LGBMRegressor RMSE: 4.9913\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0652\n",
      "LGBMRegressor worst RMSE: 5.3385\n",
      "Corresponding penalty value: 4.1925\n",
      "\u001b[32m[I 2025-03-31 13:40:03,154]\u001b[0m Trial 11 finished with value: 4.192526134506544 and parameters: {'n_estimators': 2079, 'learning_rate': 0.06901, 'max_depth': 3, 'num_leaves': 30, 'subsample': 1.0, 'feature_fraction': 0.2, 'min_gain_to_split': 0.08, 'reg_alpha': 6.7700000000000005, 'reg_lambda': 0.16, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  5.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.9754\n",
      "2th fold: LGBMRegressor RMSE: 1.9598\n",
      "3th fold: LGBMRegressor RMSE: 4.9995\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9782\n",
      "LGBMRegressor worst RMSE: 4.9995\n",
      "Corresponding penalty value: 4.0803\n",
      "\u001b[32m[I 2025-03-31 13:40:03,719]\u001b[0m Trial 12 finished with value: 4.080322446772968 and parameters: {'n_estimators': 2117, 'learning_rate': 0.06801, 'max_depth': 3, 'num_leaves': 29, 'subsample': 1.0, 'feature_fraction': 0.22, 'min_gain_to_split': 3.7600000000000002, 'reg_alpha': 9.97, 'reg_lambda': 0.78, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.71it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.9080\n",
      "2th fold: LGBMRegressor RMSE: 2.3943\n",
      "3th fold: LGBMRegressor RMSE: 5.3390\n",
      "\n",
      "LGBMRegressor average RMSE: 4.2138\n",
      "LGBMRegressor worst RMSE: 5.3390\n",
      "Corresponding penalty value: 4.3263\n",
      "\u001b[32m[I 2025-03-31 13:40:04,393]\u001b[0m Trial 13 finished with value: 4.326304749138029 and parameters: {'n_estimators': 1927, 'learning_rate': 0.08001, 'max_depth': 8, 'num_leaves': 25, 'subsample': 0.91, 'feature_fraction': 0.33, 'min_gain_to_split': 2.48, 'reg_alpha': 6.62, 'reg_lambda': 8.26, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.14it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1165\n",
      "2th fold: LGBMRegressor RMSE: 2.2225\n",
      "3th fold: LGBMRegressor RMSE: 5.3152\n",
      "\n",
      "LGBMRegressor average RMSE: 4.2181\n",
      "LGBMRegressor worst RMSE: 5.3152\n",
      "Corresponding penalty value: 4.3278\n",
      "\u001b[32m[I 2025-03-31 13:40:05,155]\u001b[0m Trial 14 finished with value: 4.3277630270077 and parameters: {'n_estimators': 2445, 'learning_rate': 0.05301, 'max_depth': 6, 'num_leaves': 21, 'subsample': 0.91, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 6.140000000000001, 'reg_alpha': 6.3, 'reg_lambda': 2.11, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.96it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.8394\n",
      "2th fold: LGBMRegressor RMSE: 2.0465\n",
      "3th fold: LGBMRegressor RMSE: 5.3627\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0829\n",
      "LGBMRegressor worst RMSE: 5.3627\n",
      "Corresponding penalty value: 4.2108\n",
      "\u001b[32m[I 2025-03-31 13:40:05,797]\u001b[0m Trial 15 finished with value: 4.2108486177104325 and parameters: {'n_estimators': 1621, 'learning_rate': 0.08201, 'max_depth': 12, 'num_leaves': 30, 'subsample': 0.8500000000000001, 'feature_fraction': 0.42000000000000004, 'min_gain_to_split': 2.43, 'reg_alpha': 9.8, 'reg_lambda': 7.48, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  2.84it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.3136\n",
      "2th fold: LGBMRegressor RMSE: 1.6073\n",
      "3th fold: LGBMRegressor RMSE: 5.4979\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1396\n",
      "LGBMRegressor worst RMSE: 5.4979\n",
      "Corresponding penalty value: 4.2754\n",
      "\u001b[32m[I 2025-03-31 13:40:06,890]\u001b[0m Trial 16 finished with value: 4.275409178390252 and parameters: {'n_estimators': 2336, 'learning_rate': 0.05501, 'max_depth': 3, 'num_leaves': 13, 'subsample': 0.95, 'feature_fraction': 0.76, 'min_gain_to_split': 5.34, 'reg_alpha': 5.93, 'reg_lambda': 9.81, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.77it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1573\n",
      "2th fold: LGBMRegressor RMSE: 1.7797\n",
      "3th fold: LGBMRegressor RMSE: 5.5795\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1721\n",
      "LGBMRegressor worst RMSE: 5.5795\n",
      "Corresponding penalty value: 4.3129\n",
      "\u001b[32m[I 2025-03-31 13:40:07,724]\u001b[0m Trial 17 finished with value: 4.31286395132002 and parameters: {'n_estimators': 977, 'learning_rate': 0.01701, 'max_depth': 5, 'num_leaves': 26, 'subsample': 0.69, 'feature_fraction': 0.55, 'min_gain_to_split': 1.97, 'reg_alpha': 7.46, 'reg_lambda': 1.27, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  7.10it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.7058\n",
      "2th fold: LGBMRegressor RMSE: 2.0578\n",
      "3th fold: LGBMRegressor RMSE: 5.2457\n",
      "\n",
      "LGBMRegressor average RMSE: 4.3364\n",
      "LGBMRegressor worst RMSE: 5.7058\n",
      "Corresponding penalty value: 4.4734\n",
      "\u001b[32m[I 2025-03-31 13:40:08,184]\u001b[0m Trial 18 finished with value: 4.47336597476369 and parameters: {'n_estimators': 1593, 'learning_rate': 0.07501, 'max_depth': 7, 'num_leaves': 15, 'subsample': 0.95, 'feature_fraction': 0.26, 'min_gain_to_split': 10.620000000000001, 'reg_alpha': 8.93, 'reg_lambda': 4.54, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.69it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.5828\n",
      "2th fold: LGBMRegressor RMSE: 2.0269\n",
      "3th fold: LGBMRegressor RMSE: 5.3090\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9729\n",
      "LGBMRegressor worst RMSE: 5.3090\n",
      "Corresponding penalty value: 4.1065\n",
      "\u001b[32m[I 2025-03-31 13:40:08,863]\u001b[0m Trial 19 finished with value: 4.1065309172320905 and parameters: {'n_estimators': 1793, 'learning_rate': 0.058010000000000006, 'max_depth': 5, 'num_leaves': 22, 'subsample': 0.8300000000000001, 'feature_fraction': 0.39, 'min_gain_to_split': 4.79, 'reg_alpha': 2.7800000000000002, 'reg_lambda': 6.7700000000000005, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00, 12.36it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.5642\n",
      "2th fold: LGBMRegressor RMSE: 2.0043\n",
      "3th fold: LGBMRegressor RMSE: 5.0765\n",
      "\n",
      "LGBMRegressor average RMSE: 4.2150\n",
      "LGBMRegressor worst RMSE: 5.5642\n",
      "Corresponding penalty value: 4.3499\n",
      "\u001b[32m[I 2025-03-31 13:40:09,145]\u001b[0m Trial 20 finished with value: 4.349909927004111 and parameters: {'n_estimators': 566, 'learning_rate': 0.08900999999999999, 'max_depth': 6, 'num_leaves': 27, 'subsample': 0.94, 'feature_fraction': 0.2, 'min_gain_to_split': 2.48, 'reg_alpha': 5.63, 'reg_lambda': 8.63, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  5.21it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.7620\n",
      "2th fold: LGBMRegressor RMSE: 1.8967\n",
      "3th fold: LGBMRegressor RMSE: 5.1780\n",
      "\n",
      "LGBMRegressor average RMSE: 4.2789\n",
      "LGBMRegressor worst RMSE: 5.7620\n",
      "Corresponding penalty value: 4.4272\n",
      "\u001b[32m[I 2025-03-31 13:40:09,761]\u001b[0m Trial 21 finished with value: 4.427194881513436 and parameters: {'n_estimators': 2207, 'learning_rate': 0.06601, 'max_depth': 3, 'num_leaves': 30, 'subsample': 1.0, 'feature_fraction': 0.25, 'min_gain_to_split': 3.9, 'reg_alpha': 9.78, 'reg_lambda': 0.49, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.86it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.6823\n",
      "2th fold: LGBMRegressor RMSE: 1.8999\n",
      "3th fold: LGBMRegressor RMSE: 5.1379\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9067\n",
      "LGBMRegressor worst RMSE: 5.1379\n",
      "Corresponding penalty value: 4.0298\n",
      "\u001b[32m[I 2025-03-31 13:40:10,579]\u001b[0m Trial 22 finished with value: 4.029816643244708 and parameters: {'n_estimators': 2524, 'learning_rate': 0.07201, 'max_depth': 3, 'num_leaves': 28, 'subsample': 0.98, 'feature_fraction': 0.37, 'min_gain_to_split': 8.25, 'reg_alpha': 10.0, 'reg_lambda': 1.72, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.81it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.7650\n",
      "2th fold: LGBMRegressor RMSE: 1.8982\n",
      "3th fold: LGBMRegressor RMSE: 5.2691\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9774\n",
      "LGBMRegressor worst RMSE: 5.2691\n",
      "Corresponding penalty value: 4.1066\n",
      "\u001b[32m[I 2025-03-31 13:40:11,408]\u001b[0m Trial 23 finished with value: 4.106602635431612 and parameters: {'n_estimators': 2561, 'learning_rate': 0.07601, 'max_depth': 4, 'num_leaves': 24, 'subsample': 0.88, 'feature_fraction': 0.37, 'min_gain_to_split': 8.790000000000001, 'reg_alpha': 7.68, 'reg_lambda': 1.9000000000000001, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.11it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1008\n",
      "2th fold: LGBMRegressor RMSE: 1.8516\n",
      "3th fold: LGBMRegressor RMSE: 5.2549\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0691\n",
      "LGBMRegressor worst RMSE: 5.2549\n",
      "Corresponding penalty value: 4.1877\n",
      "\u001b[32m[I 2025-03-31 13:40:12,414]\u001b[0m Trial 24 finished with value: 4.1876713714789915 and parameters: {'n_estimators': 2573, 'learning_rate': 0.04401, 'max_depth': 3, 'num_leaves': 27, 'subsample': 0.95, 'feature_fraction': 0.5, 'min_gain_to_split': 10.83, 'reg_alpha': 9.02, 'reg_lambda': 2.24, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  5.17it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.0487\n",
      "2th fold: LGBMRegressor RMSE: 2.3277\n",
      "3th fold: LGBMRegressor RMSE: 5.2744\n",
      "\n",
      "LGBMRegressor average RMSE: 4.2169\n",
      "LGBMRegressor worst RMSE: 5.2744\n",
      "Corresponding penalty value: 4.3227\n",
      "\u001b[32m[I 2025-03-31 13:40:13,038]\u001b[0m Trial 25 finished with value: 4.3226868751297705 and parameters: {'n_estimators': 1965, 'learning_rate': 0.08601, 'max_depth': 5, 'num_leaves': 28, 'subsample': 0.91, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 7.11, 'reg_alpha': 7.28, 'reg_lambda': 3.96, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  2.81it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.3541\n",
      "2th fold: LGBMRegressor RMSE: 1.7980\n",
      "3th fold: LGBMRegressor RMSE: 5.8098\n",
      "\n",
      "LGBMRegressor average RMSE: 4.3206\n",
      "LGBMRegressor worst RMSE: 5.8098\n",
      "Corresponding penalty value: 4.4695\n",
      "\u001b[32m[I 2025-03-31 13:40:14,147]\u001b[0m Trial 26 finished with value: 4.469537588881067 and parameters: {'n_estimators': 2229, 'learning_rate': 0.06101, 'max_depth': 4, 'num_leaves': 20, 'subsample': 0.79, 'feature_fraction': 0.96, 'min_gain_to_split': 12.48, 'reg_alpha': 8.31, 'reg_lambda': 1.3800000000000001, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.84it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.6934\n",
      "2th fold: LGBMRegressor RMSE: 1.8611\n",
      "3th fold: LGBMRegressor RMSE: 5.2026\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9190\n",
      "LGBMRegressor worst RMSE: 5.2026\n",
      "Corresponding penalty value: 4.0474\n",
      "\u001b[32m[I 2025-03-31 13:40:14,972]\u001b[0m Trial 27 finished with value: 4.047402525824752 and parameters: {'n_estimators': 2379, 'learning_rate': 0.07400999999999999, 'max_depth': 3, 'num_leaves': 23, 'subsample': 0.98, 'feature_fraction': 0.38, 'min_gain_to_split': 9.72, 'reg_alpha': 9.05, 'reg_lambda': 0.1, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  2.71it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1150\n",
      "2th fold: LGBMRegressor RMSE: 1.7546\n",
      "3th fold: LGBMRegressor RMSE: 5.5777\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1491\n",
      "LGBMRegressor worst RMSE: 5.5777\n",
      "Corresponding penalty value: 4.2919\n",
      "\u001b[32m[I 2025-03-31 13:40:16,123]\u001b[0m Trial 28 finished with value: 4.291935632180416 and parameters: {'n_estimators': 2636, 'learning_rate': 0.08900999999999999, 'max_depth': 4, 'num_leaves': 18, 'subsample': 0.86, 'feature_fraction': 0.67, 'min_gain_to_split': 7.78, 'reg_alpha': 5.28, 'reg_lambda': 2.61, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.21it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.9021\n",
      "2th fold: LGBMRegressor RMSE: 2.3893\n",
      "3th fold: LGBMRegressor RMSE: 5.3752\n",
      "\n",
      "LGBMRegressor average RMSE: 4.2222\n",
      "LGBMRegressor worst RMSE: 5.3752\n",
      "Corresponding penalty value: 4.3375\n",
      "\u001b[32m[I 2025-03-31 13:40:16,879]\u001b[0m Trial 29 finished with value: 4.33749371413686 and parameters: {'n_estimators': 1527, 'learning_rate': 0.09701, 'max_depth': 9, 'num_leaves': 28, 'subsample': 0.97, 'feature_fraction': 0.31, 'min_gain_to_split': 0.01, 'reg_alpha': 8.22, 'reg_lambda': 5.83, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.90it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.9220\n",
      "2th fold: LGBMRegressor RMSE: 1.9267\n",
      "3th fold: LGBMRegressor RMSE: 5.4008\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0832\n",
      "LGBMRegressor worst RMSE: 5.4008\n",
      "Corresponding penalty value: 4.2149\n",
      "\u001b[32m[I 2025-03-31 13:40:17,536]\u001b[0m Trial 30 finished with value: 4.214917783334513 and parameters: {'n_estimators': 1341, 'learning_rate': 0.06101, 'max_depth': 5, 'num_leaves': 25, 'subsample': 0.71, 'feature_fraction': 0.48000000000000004, 'min_gain_to_split': 1.11, 'reg_alpha': 6.98, 'reg_lambda': 4.04, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.73it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.5598\n",
      "2th fold: LGBMRegressor RMSE: 1.8602\n",
      "3th fold: LGBMRegressor RMSE: 5.2032\n",
      "\n",
      "LGBMRegressor average RMSE: 3.8744\n",
      "LGBMRegressor worst RMSE: 5.2032\n",
      "Corresponding penalty value: 4.0073\n",
      "\u001b[32m[I 2025-03-31 13:40:18,384]\u001b[0m Trial 31 finished with value: 4.007282825573477 and parameters: {'n_estimators': 2469, 'learning_rate': 0.07300999999999999, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.97, 'feature_fraction': 0.38, 'min_gain_to_split': 9.18, 'reg_alpha': 9.15, 'reg_lambda': 0.03, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.71it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.8158\n",
      "2th fold: LGBMRegressor RMSE: 1.8076\n",
      "3th fold: LGBMRegressor RMSE: 5.0926\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9053\n",
      "LGBMRegressor worst RMSE: 5.0926\n",
      "Corresponding penalty value: 4.0240\n",
      "\u001b[32m[I 2025-03-31 13:40:19,239]\u001b[0m Trial 32 finished with value: 4.024026880064416 and parameters: {'n_estimators': 2422, 'learning_rate': 0.07400999999999999, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.9199999999999999, 'feature_fraction': 0.42000000000000004, 'min_gain_to_split': 8.73, 'reg_alpha': 9.27, 'reg_lambda': 1.29, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.01it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.9060\n",
      "2th fold: LGBMRegressor RMSE: 1.9314\n",
      "3th fold: LGBMRegressor RMSE: 5.2694\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0356\n",
      "LGBMRegressor worst RMSE: 5.2694\n",
      "Corresponding penalty value: 4.1590\n",
      "\u001b[32m[I 2025-03-31 13:40:20,281]\u001b[0m Trial 33 finished with value: 4.159003857087326 and parameters: {'n_estimators': 2992, 'learning_rate': 0.08001, 'max_depth': 4, 'num_leaves': 30, 'subsample': 0.9299999999999999, 'feature_fraction': 0.43000000000000005, 'min_gain_to_split': 9.71, 'reg_alpha': 9.15, 'reg_lambda': 0.88, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 82.0490\n",
      "2th fold: LGBMRegressor RMSE: 34.2475\n",
      "3th fold: LGBMRegressor RMSE: 120.4173\n",
      "\n",
      "LGBMRegressor average RMSE: 78.9046\n",
      "LGBMRegressor worst RMSE: 120.4173\n",
      "Corresponding penalty value: 83.0559\n",
      "\u001b[32m[I 2025-03-31 13:40:21,326]\u001b[0m Trial 34 finished with value: 83.0559009393412 and parameters: {'n_estimators': 1893, 'learning_rate': 0.09000999999999999, 'max_depth': 3, 'num_leaves': 26, 'subsample': 0.89, 'feature_fraction': 0.54, 'min_gain_to_split': 5.95, 'reg_alpha': 8.47, 'reg_lambda': 1.1, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  5.03it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.6655\n",
      "2th fold: LGBMRegressor RMSE: 1.9376\n",
      "3th fold: LGBMRegressor RMSE: 5.2290\n",
      "\n",
      "LGBMRegressor average RMSE: 4.2774\n",
      "LGBMRegressor worst RMSE: 5.6655\n",
      "Corresponding penalty value: 4.4162\n",
      "\u001b[32m[I 2025-03-31 13:40:21,969]\u001b[0m Trial 35 finished with value: 4.416164022482835 and parameters: {'n_estimators': 2320, 'learning_rate': 0.041010000000000005, 'max_depth': 5, 'num_leaves': 24, 'subsample': 0.86, 'feature_fraction': 0.25, 'min_gain_to_split': 12.86, 'reg_alpha': 7.88, 'reg_lambda': 2.75, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  2.44it/s]\n",
      "1th fold: LGBMRegressor RMSE: 8.0978\n",
      "2th fold: LGBMRegressor RMSE: 6.1272\n",
      "3th fold: LGBMRegressor RMSE: 189.0190\n",
      "\n",
      "LGBMRegressor average RMSE: 67.7480\n",
      "LGBMRegressor worst RMSE: 189.0190\n",
      "Corresponding penalty value: 79.8751\n",
      "\u001b[32m[I 2025-03-31 13:40:23,244]\u001b[0m Trial 36 finished with value: 79.87509334319756 and parameters: {'n_estimators': 2759, 'learning_rate': 0.06401, 'max_depth': 6, 'num_leaves': 7, 'subsample': 0.9299999999999999, 'feature_fraction': 0.34, 'min_gain_to_split': 7.37, 'reg_alpha': 8.88, 'reg_lambda': 0.02, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  7.10it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.7619\n",
      "2th fold: LGBMRegressor RMSE: 1.9772\n",
      "3th fold: LGBMRegressor RMSE: 5.2896\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0096\n",
      "LGBMRegressor worst RMSE: 5.2896\n",
      "Corresponding penalty value: 4.1376\n",
      "\u001b[32m[I 2025-03-31 13:40:23,713]\u001b[0m Trial 37 finished with value: 4.137559854558588 and parameters: {'n_estimators': 1008, 'learning_rate': 0.09901, 'max_depth': 4, 'num_leaves': 29, 'subsample': 0.8300000000000001, 'feature_fraction': 0.42000000000000004, 'min_gain_to_split': 9.07, 'reg_alpha': 9.24, 'reg_lambda': 5.53, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.51it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1764\n",
      "2th fold: LGBMRegressor RMSE: 1.7383\n",
      "3th fold: LGBMRegressor RMSE: 5.6091\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1746\n",
      "LGBMRegressor worst RMSE: 5.6091\n",
      "Corresponding penalty value: 4.3181\n",
      "\u001b[32m[I 2025-03-31 13:40:24,614]\u001b[0m Trial 38 finished with value: 4.318052305315658 and parameters: {'n_estimators': 1733, 'learning_rate': 0.02501, 'max_depth': 7, 'num_leaves': 26, 'subsample': 0.53, 'feature_fraction': 0.5800000000000001, 'min_gain_to_split': 14.64, 'reg_alpha': 7.92, 'reg_lambda': 6.46, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  2.21it/s]\n",
      "1th fold: LGBMRegressor RMSE: 151.9930\n",
      "2th fold: LGBMRegressor RMSE: 997.0968\n",
      "3th fold: LGBMRegressor RMSE: 464.3022\n",
      "\n",
      "LGBMRegressor average RMSE: 537.7974\n",
      "LGBMRegressor worst RMSE: 997.0968\n",
      "Corresponding penalty value: 583.7273\n",
      "\u001b[32m[I 2025-03-31 13:40:26,019]\u001b[0m Trial 39 finished with value: 583.7272999907116 and parameters: {'n_estimators': 2882, 'learning_rate': 0.09201, 'max_depth': 11, 'num_leaves': 28, 'subsample': 0.97, 'feature_fraction': 0.47000000000000003, 'min_gain_to_split': 4.8, 'reg_alpha': 7.24, 'reg_lambda': 0.64, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  2.78it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.2231\n",
      "2th fold: LGBMRegressor RMSE: 1.5811\n",
      "3th fold: LGBMRegressor RMSE: 5.6333\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1458\n",
      "LGBMRegressor worst RMSE: 5.6333\n",
      "Corresponding penalty value: 4.2946\n",
      "\u001b[32m[I 2025-03-31 13:40:27,146]\u001b[0m Trial 40 finished with value: 4.2945545394473 and parameters: {'n_estimators': 2115, 'learning_rate': 0.050010000000000006, 'max_depth': 4, 'num_leaves': 7, 'subsample': 0.63, 'feature_fraction': 0.8300000000000001, 'min_gain_to_split': 7.04, 'reg_alpha': 0.18, 'reg_lambda': 1.51, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.90it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.7261\n",
      "2th fold: LGBMRegressor RMSE: 1.8694\n",
      "3th fold: LGBMRegressor RMSE: 5.1191\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9049\n",
      "LGBMRegressor worst RMSE: 5.1191\n",
      "Corresponding penalty value: 4.0263\n",
      "\u001b[32m[I 2025-03-31 13:40:27,963]\u001b[0m Trial 41 finished with value: 4.026297901597007 and parameters: {'n_estimators': 2488, 'learning_rate': 0.07101, 'max_depth': 3, 'num_leaves': 28, 'subsample': 0.97, 'feature_fraction': 0.36, 'min_gain_to_split': 8.290000000000001, 'reg_alpha': 9.52, 'reg_lambda': 1.79, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.7929\n",
      "2th fold: LGBMRegressor RMSE: 2.0091\n",
      "3th fold: LGBMRegressor RMSE: 5.1122\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9714\n",
      "LGBMRegressor worst RMSE: 5.1122\n",
      "Corresponding penalty value: 4.0855\n",
      "\u001b[32m[I 2025-03-31 13:40:28,831]\u001b[0m Trial 42 finished with value: 4.085467928647526 and parameters: {'n_estimators': 2707, 'learning_rate': 0.07801, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.9, 'feature_fraction': 0.33, 'min_gain_to_split': 8.4, 'reg_alpha': 9.39, 'reg_lambda': 3.16, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.31it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1502\n",
      "2th fold: LGBMRegressor RMSE: 2.0954\n",
      "3th fold: LGBMRegressor RMSE: 5.0331\n",
      "\n",
      "LGBMRegressor average RMSE: 4.0929\n",
      "LGBMRegressor worst RMSE: 5.1502\n",
      "Corresponding penalty value: 4.1986\n",
      "\u001b[32m[I 2025-03-31 13:40:29,577]\u001b[0m Trial 43 finished with value: 4.198586807466 and parameters: {'n_estimators': 2452, 'learning_rate': 0.07001, 'max_depth': 3, 'num_leaves': 3, 'subsample': 1.0, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 9.4, 'reg_alpha': 8.51, 'reg_lambda': 2.35, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.07it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.6473\n",
      "2th fold: LGBMRegressor RMSE: 1.9270\n",
      "3th fold: LGBMRegressor RMSE: 5.2813\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9519\n",
      "LGBMRegressor worst RMSE: 5.2813\n",
      "Corresponding penalty value: 4.0848\n",
      "\u001b[32m[I 2025-03-31 13:40:30,365]\u001b[0m Trial 44 finished with value: 4.084815386288804 and parameters: {'n_estimators': 2230, 'learning_rate': 0.08401, 'max_depth': 4, 'num_leaves': 30, 'subsample': 0.97, 'feature_fraction': 0.4, 'min_gain_to_split': 10.05, 'reg_alpha': 9.5, 'reg_lambda': 0.56, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.11it/s]\n",
      "1th fold: LGBMRegressor RMSE: 131.0000\n",
      "2th fold: LGBMRegressor RMSE: 11.4411\n",
      "3th fold: LGBMRegressor RMSE: 90.7181\n",
      "\n",
      "LGBMRegressor average RMSE: 77.7197\n",
      "LGBMRegressor worst RMSE: 131.0000\n",
      "Corresponding penalty value: 83.0478\n",
      "\u001b[32m[I 2025-03-31 13:40:31,380]\u001b[0m Trial 45 finished with value: 83.04777101755356 and parameters: {'n_estimators': 1995, 'learning_rate': 0.07101, 'max_depth': 3, 'num_leaves': 25, 'subsample': 0.9299999999999999, 'feature_fraction': 0.46, 'min_gain_to_split': 6.48, 'reg_alpha': 4.28, 'reg_lambda': 1.1300000000000001, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  3.92it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.6889\n",
      "2th fold: LGBMRegressor RMSE: 1.8758\n",
      "3th fold: LGBMRegressor RMSE: 5.3048\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9565\n",
      "LGBMRegressor worst RMSE: 5.3048\n",
      "Corresponding penalty value: 4.0913\n",
      "\u001b[32m[I 2025-03-31 13:40:32,195]\u001b[0m Trial 46 finished with value: 4.091325294269477 and parameters: {'n_estimators': 2446, 'learning_rate': 0.06301, 'max_depth': 4, 'num_leaves': 27, 'subsample': 0.91, 'feature_fraction': 0.35, 'min_gain_to_split': 11.620000000000001, 'reg_alpha': 6.42, 'reg_lambda': 4.74, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.86it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.0187\n",
      "2th fold: LGBMRegressor RMSE: 1.9609\n",
      "3th fold: LGBMRegressor RMSE: 4.9101\n",
      "\n",
      "LGBMRegressor average RMSE: 3.9632\n",
      "LGBMRegressor worst RMSE: 5.0187\n",
      "Corresponding penalty value: 4.0687\n",
      "\u001b[32m[I 2025-03-31 13:40:32,866]\u001b[0m Trial 47 finished with value: 4.068741570556238 and parameters: {'n_estimators': 2644, 'learning_rate': 0.08401, 'max_depth': 3, 'num_leaves': 29, 'subsample': 0.5700000000000001, 'feature_fraction': 0.23, 'min_gain_to_split': 8.03, 'reg_alpha': 8.59, 'reg_lambda': 1.71, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:00,  4.50it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.2453\n",
      "2th fold: LGBMRegressor RMSE: 1.7353\n",
      "3th fold: LGBMRegressor RMSE: 5.5492\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1766\n",
      "LGBMRegressor worst RMSE: 5.5492\n",
      "Corresponding penalty value: 4.3139\n",
      "\u001b[32m[I 2025-03-31 13:40:33,583]\u001b[0m Trial 48 finished with value: 4.3138695422319175 and parameters: {'n_estimators': 1269, 'learning_rate': 0.05501, 'max_depth': 4, 'num_leaves': 23, 'subsample': 0.88, 'feature_fraction': 0.64, 'min_gain_to_split': 1.34, 'reg_alpha': 7.92, 'reg_lambda': 7.79, 'linear_tree': False}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "3it [00:01,  2.53it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.7499\n",
      "2th fold: LGBMRegressor RMSE: 31.6582\n",
      "3th fold: LGBMRegressor RMSE: 164.9423\n",
      "\n",
      "LGBMRegressor average RMSE: 67.4501\n",
      "LGBMRegressor worst RMSE: 164.9423\n",
      "Corresponding penalty value: 77.1994\n",
      "\u001b[32m[I 2025-03-31 13:40:34,820]\u001b[0m Trial 49 finished with value: 77.19936166862063 and parameters: {'n_estimators': 2831, 'learning_rate': 0.07801, 'max_depth': 3, 'num_leaves': 16, 'subsample': 0.96, 'feature_fraction': 0.29000000000000004, 'min_gain_to_split': 3.23, 'reg_alpha': 1.12, 'reg_lambda': 8.84, 'linear_tree': True}. Best is trial 6 with value: 3.9856396917694705.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}\n",
      "3it [00:00,  6.30it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1592\n",
      "2th fold: LGBMRegressor RMSE: 2.1366\n",
      "3th fold: LGBMRegressor RMSE: 5.1237\n",
      "\n",
      "LGBMRegressor average RMSE: 4.1398\n",
      "LGBMRegressor worst RMSE: 5.1592\n",
      "Corresponding penalty value: 4.2418\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB18\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 852, 'learning_rate': 0.08001, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.89, 'feature_fraction': 0.36, 'min_gain_to_split': 0.08, 'reg_alpha': 8.16, 'reg_lambda': 7.07, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.878\n",
      "RMSE_crossval: 4.140\n",
      "RMSE_test: 4.027\n",
      "MAE_test: 3.286\n",
      "Nash-Sutcliffe Test: -0.008\n",
      "Kling-Gupta Test: -0.153\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 45.4577 seconds\n",
      "\n",
      "Total elapsed time: 348.7003 seconds\n",
      "\n",
      "Output saved to LightGBM_tuning_31_3_pen_01.txt\n"
     ]
    }
   ],
   "source": [
    "!python ./models/LightGBM_tuning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c953144f-b001-4106-b9eb-e293f4096a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-03-31 13:40:37,568]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV1\u001b[0m\n",
      "3it [00:01,  1.79it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5351\n",
      "2th fold: XGBRegressor RMSE: 0.3437\n",
      "3th fold: XGBRegressor RMSE: 0.9327\n",
      "\n",
      "XGBRegressor average RMSE: 0.6039\n",
      "XGBRegressor worst RMSE: 0.9327\n",
      "Corresponding penalty value: 0.6367\n",
      "\u001b[32m[I 2025-03-31 13:40:39,245]\u001b[0m Trial 0 finished with value: 0.636746521612897 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.5700000000000001, 'reg_alpha': 0.58, 'reg_lambda': 8.67, 'gamma': 3.0100000000000002}. Best is trial 0 with value: 0.636746521612897.\u001b[0m\n",
      "3it [00:05,  1.96s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.4392\n",
      "2th fold: XGBRegressor RMSE: 0.3032\n",
      "3th fold: XGBRegressor RMSE: 0.9417\n",
      "\n",
      "XGBRegressor average RMSE: 0.5613\n",
      "XGBRegressor worst RMSE: 0.9417\n",
      "Corresponding penalty value: 0.5994\n",
      "\u001b[32m[I 2025-03-31 13:40:45,133]\u001b[0m Trial 1 finished with value: 0.5993786319982106 and parameters: {'n_estimators': 2270, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 1.83, 'reg_lambda': 3.04, 'gamma': 2.62}. Best is trial 1 with value: 0.5993786319982106.\u001b[0m\n",
      "3it [00:01,  1.58it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4912\n",
      "2th fold: XGBRegressor RMSE: 0.3071\n",
      "3th fold: XGBRegressor RMSE: 0.7667\n",
      "\n",
      "XGBRegressor average RMSE: 0.5217\n",
      "XGBRegressor worst RMSE: 0.7667\n",
      "Corresponding penalty value: 0.5462\n",
      "\u001b[32m[I 2025-03-31 13:40:47,040]\u001b[0m Trial 2 finished with value: 0.5461753881050426 and parameters: {'n_estimators': 1580, 'learning_rate': 0.02901, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.64, 'subsample': 0.6799999999999999, 'reg_alpha': 4.5600000000000005, 'reg_lambda': 7.8500000000000005, 'gamma': 1.0}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:01,  1.54it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6115\n",
      "2th fold: XGBRegressor RMSE: 0.3307\n",
      "3th fold: XGBRegressor RMSE: 0.7706\n",
      "\n",
      "XGBRegressor average RMSE: 0.5709\n",
      "XGBRegressor worst RMSE: 0.7706\n",
      "Corresponding penalty value: 0.5909\n",
      "\u001b[32m[I 2025-03-31 13:40:48,987]\u001b[0m Trial 3 finished with value: 0.5909020305364078 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05901000000000001, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.53, 'reg_alpha': 9.49, 'reg_lambda': 9.66, 'gamma': 4.05}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:02,  1.35it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4262\n",
      "2th fold: XGBRegressor RMSE: 0.3232\n",
      "3th fold: XGBRegressor RMSE: 0.9121\n",
      "\n",
      "XGBRegressor average RMSE: 0.5539\n",
      "XGBRegressor worst RMSE: 0.9121\n",
      "Corresponding penalty value: 0.5897\n",
      "\u001b[32m[I 2025-03-31 13:40:51,215]\u001b[0m Trial 4 finished with value: 0.5896864501781738 and parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:02,  1.21it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4815\n",
      "2th fold: XGBRegressor RMSE: 0.3061\n",
      "3th fold: XGBRegressor RMSE: 0.9629\n",
      "\n",
      "XGBRegressor average RMSE: 0.5835\n",
      "XGBRegressor worst RMSE: 0.9629\n",
      "Corresponding penalty value: 0.6214\n",
      "\u001b[32m[I 2025-03-31 13:40:53,695]\u001b[0m Trial 5 finished with value: 0.6214409521692704 and parameters: {'n_estimators': 2156, 'learning_rate': 0.03101, 'max_depth': 6, 'max_leaves': 17, 'colsample_bytree': 0.59, 'subsample': 0.99, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'gamma': 4.48}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:02,  1.44it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8115\n",
      "2th fold: XGBRegressor RMSE: 0.3135\n",
      "3th fold: XGBRegressor RMSE: 0.8169\n",
      "\n",
      "XGBRegressor average RMSE: 0.6473\n",
      "XGBRegressor worst RMSE: 0.8169\n",
      "Corresponding penalty value: 0.6643\n",
      "\u001b[32m[I 2025-03-31 13:40:55,777]\u001b[0m Trial 6 finished with value: 0.6642656132059696 and parameters: {'n_estimators': 1995, 'learning_rate': 0.09201, 'max_depth': 1, 'max_leaves': 7, 'colsample_bytree': 0.52, 'subsample': 0.66, 'reg_alpha': 3.89, 'reg_lambda': 2.71, 'gamma': 4.15}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:01,  1.71it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5084\n",
      "2th fold: XGBRegressor RMSE: 0.2686\n",
      "3th fold: XGBRegressor RMSE: 0.8275\n",
      "\n",
      "XGBRegressor average RMSE: 0.5349\n",
      "XGBRegressor worst RMSE: 0.8275\n",
      "Corresponding penalty value: 0.5641\n",
      "\u001b[32m[I 2025-03-31 13:40:57,536]\u001b[0m Trial 7 finished with value: 0.564130664870432 and parameters: {'n_estimators': 1392, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.9, 'subsample': 0.53, 'reg_alpha': 9.870000000000001, 'reg_lambda': 7.73, 'gamma': 0.99}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:00,  4.07it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4574\n",
      "2th fold: XGBRegressor RMSE: 0.2858\n",
      "3th fold: XGBRegressor RMSE: 0.9577\n",
      "\n",
      "XGBRegressor average RMSE: 0.5670\n",
      "XGBRegressor worst RMSE: 0.9577\n",
      "Corresponding penalty value: 0.6060\n",
      "\u001b[32m[I 2025-03-31 13:40:58,275]\u001b[0m Trial 8 finished with value: 0.606044512079797 and parameters: {'n_estimators': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'max_leaves': 23, 'colsample_bytree': 0.89, 'subsample': 0.53, 'reg_alpha': 3.58, 'reg_lambda': 1.1500000000000001, 'gamma': 4.32}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:02,  1.35it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5621\n",
      "2th fold: XGBRegressor RMSE: 0.3536\n",
      "3th fold: XGBRegressor RMSE: 0.6931\n",
      "\n",
      "XGBRegressor average RMSE: 0.5363\n",
      "XGBRegressor worst RMSE: 0.6931\n",
      "Corresponding penalty value: 0.5519\n",
      "\u001b[32m[I 2025-03-31 13:41:00,504]\u001b[0m Trial 9 finished with value: 0.5519344180076441 and parameters: {'n_estimators': 2058, 'learning_rate': 0.033010000000000005, 'max_depth': 1, 'max_leaves': 11, 'colsample_bytree': 0.66, 'subsample': 0.87, 'reg_alpha': 6.38, 'reg_lambda': 8.88, 'gamma': 2.36}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6353\n",
      "2th fold: XGBRegressor RMSE: 0.3666\n",
      "3th fold: XGBRegressor RMSE: 0.7266\n",
      "\n",
      "XGBRegressor average RMSE: 0.5762\n",
      "XGBRegressor worst RMSE: 0.7266\n",
      "Corresponding penalty value: 0.5912\n",
      "\u001b[32m[I 2025-03-31 13:41:03,628]\u001b[0m Trial 10 finished with value: 0.5912031027278315 and parameters: {'n_estimators': 2863, 'learning_rate': 0.056010000000000004, 'max_depth': 4, 'max_leaves': 2, 'colsample_bytree': 0.75, 'subsample': 0.76, 'reg_alpha': 5.5200000000000005, 'reg_lambda': 6.24, 'gamma': 0.2}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:02,  1.02it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4524\n",
      "2th fold: XGBRegressor RMSE: 0.3464\n",
      "3th fold: XGBRegressor RMSE: 0.8914\n",
      "\n",
      "XGBRegressor average RMSE: 0.5634\n",
      "XGBRegressor worst RMSE: 0.8914\n",
      "Corresponding penalty value: 0.5962\n",
      "\u001b[32m[I 2025-03-31 13:41:06,613]\u001b[0m Trial 11 finished with value: 0.596153174328851 and parameters: {'n_estimators': 2625, 'learning_rate': 0.034010000000000006, 'max_depth': 4, 'max_leaves': 11, 'colsample_bytree': 0.72, 'subsample': 0.9, 'reg_alpha': 6.2, 'reg_lambda': 6.76, 'gamma': 1.32}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:01,  2.40it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4806\n",
      "2th fold: XGBRegressor RMSE: 0.2794\n",
      "3th fold: XGBRegressor RMSE: 0.9025\n",
      "\n",
      "XGBRegressor average RMSE: 0.5542\n",
      "XGBRegressor worst RMSE: 0.9025\n",
      "Corresponding penalty value: 0.5890\n",
      "\u001b[32m[I 2025-03-31 13:41:07,916]\u001b[0m Trial 12 finished with value: 0.5890024561581102 and parameters: {'n_estimators': 891, 'learning_rate': 0.02001, 'max_depth': 3, 'max_leaves': 10, 'colsample_bytree': 0.7, 'subsample': 0.8300000000000001, 'reg_alpha': 7.01, 'reg_lambda': 5.1000000000000005, 'gamma': 1.96}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:02,  1.17it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6370\n",
      "2th fold: XGBRegressor RMSE: 0.3359\n",
      "3th fold: XGBRegressor RMSE: 0.7234\n",
      "\n",
      "XGBRegressor average RMSE: 0.5654\n",
      "XGBRegressor worst RMSE: 0.7234\n",
      "Corresponding penalty value: 0.5812\n",
      "\u001b[32m[I 2025-03-31 13:41:10,540]\u001b[0m Trial 13 finished with value: 0.5812278422512964 and parameters: {'n_estimators': 2458, 'learning_rate': 0.05101000000000001, 'max_depth': 10, 'max_leaves': 2, 'colsample_bytree': 0.67, 'subsample': 0.69, 'reg_alpha': 4.41, 'reg_lambda': 7.36, 'gamma': 3.22}. Best is trial 2 with value: 0.5461753881050426.\u001b[0m\n",
      "3it [00:02,  1.42it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4670\n",
      "2th fold: XGBRegressor RMSE: 0.2357\n",
      "3th fold: XGBRegressor RMSE: 0.7994\n",
      "\n",
      "XGBRegressor average RMSE: 0.5007\n",
      "XGBRegressor worst RMSE: 0.7994\n",
      "Corresponding penalty value: 0.5305\n",
      "\u001b[32m[I 2025-03-31 13:41:12,701]\u001b[0m Trial 14 finished with value: 0.53053102839007 and parameters: {'n_estimators': 1826, 'learning_rate': 0.040010000000000004, 'max_depth': 2, 'max_leaves': 12, 'colsample_bytree': 0.8200000000000001, 'subsample': 0.88, 'reg_alpha': 2.38, 'reg_lambda': 5.0200000000000005, 'gamma': 0.25}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:01,  1.58it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4835\n",
      "2th fold: XGBRegressor RMSE: 0.2785\n",
      "3th fold: XGBRegressor RMSE: 0.7885\n",
      "\n",
      "XGBRegressor average RMSE: 0.5168\n",
      "XGBRegressor worst RMSE: 0.7885\n",
      "Corresponding penalty value: 0.5440\n",
      "\u001b[32m[I 2025-03-31 13:41:14,651]\u001b[0m Trial 15 finished with value: 0.5439827162417155 and parameters: {'n_estimators': 1673, 'learning_rate': 0.06601, 'max_depth': 3, 'max_leaves': 7, 'colsample_bytree': 0.8200000000000001, 'subsample': 0.98, 'reg_alpha': 2.32, 'reg_lambda': 4.07, 'gamma': 0.22}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:02,  1.43it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4590\n",
      "2th fold: XGBRegressor RMSE: 0.2961\n",
      "3th fold: XGBRegressor RMSE: 0.9317\n",
      "\n",
      "XGBRegressor average RMSE: 0.5623\n",
      "XGBRegressor worst RMSE: 0.9317\n",
      "Corresponding penalty value: 0.5992\n",
      "\u001b[32m[I 2025-03-31 13:41:16,806]\u001b[0m Trial 16 finished with value: 0.5991966658884184 and parameters: {'n_estimators': 1806, 'learning_rate': 0.07001, 'max_depth': 3, 'max_leaves': 30, 'colsample_bytree': 0.81, 'subsample': 0.99, 'reg_alpha': 2.2800000000000002, 'reg_lambda': 3.98, 'gamma': 0.06}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:01,  2.29it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4596\n",
      "2th fold: XGBRegressor RMSE: 0.2678\n",
      "3th fold: XGBRegressor RMSE: 0.9220\n",
      "\n",
      "XGBRegressor average RMSE: 0.5498\n",
      "XGBRegressor worst RMSE: 0.9220\n",
      "Corresponding penalty value: 0.5870\n",
      "\u001b[32m[I 2025-03-31 13:41:18,171]\u001b[0m Trial 17 finished with value: 0.5870305742213241 and parameters: {'n_estimators': 1033, 'learning_rate': 0.07101, 'max_depth': 3, 'max_leaves': 13, 'colsample_bytree': 0.8200000000000001, 'subsample': 0.9199999999999999, 'reg_alpha': 2.49, 'reg_lambda': 5.23, 'gamma': 0.63}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:01,  2.29it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4901\n",
      "2th fold: XGBRegressor RMSE: 0.2523\n",
      "3th fold: XGBRegressor RMSE: 0.8112\n",
      "\n",
      "XGBRegressor average RMSE: 0.5179\n",
      "XGBRegressor worst RMSE: 0.8112\n",
      "Corresponding penalty value: 0.5472\n",
      "\u001b[32m[I 2025-03-31 13:41:19,536]\u001b[0m Trial 18 finished with value: 0.5472331003721685 and parameters: {'n_estimators': 1093, 'learning_rate': 0.04501, 'max_depth': 2, 'max_leaves': 8, 'colsample_bytree': 0.96, 'subsample': 0.94, 'reg_alpha': 1.3800000000000001, 'reg_lambda': 0.9, 'gamma': 2.0}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:00,  3.01it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4856\n",
      "2th fold: XGBRegressor RMSE: 0.3315\n",
      "3th fold: XGBRegressor RMSE: 0.9555\n",
      "\n",
      "XGBRegressor average RMSE: 0.5909\n",
      "XGBRegressor worst RMSE: 0.9555\n",
      "Corresponding penalty value: 0.6273\n",
      "\u001b[32m[I 2025-03-31 13:41:20,588]\u001b[0m Trial 19 finished with value: 0.6273465460299712 and parameters: {'n_estimators': 673, 'learning_rate': 0.04401, 'max_depth': 4, 'max_leaves': 16, 'colsample_bytree': 0.81, 'subsample': 0.8200000000000001, 'reg_alpha': 3.2, 'reg_lambda': 3.86, 'gamma': 0.52}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:01,  1.69it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4939\n",
      "2th fold: XGBRegressor RMSE: 0.2397\n",
      "3th fold: XGBRegressor RMSE: 0.8331\n",
      "\n",
      "XGBRegressor average RMSE: 0.5222\n",
      "XGBRegressor worst RMSE: 0.8331\n",
      "Corresponding penalty value: 0.5533\n",
      "\u001b[32m[I 2025-03-31 13:41:22,425]\u001b[0m Trial 20 finished with value: 0.5533212069775252 and parameters: {'n_estimators': 1610, 'learning_rate': 0.06601, 'max_depth': 2, 'max_leaves': 4, 'colsample_bytree': 1.0, 'subsample': 0.96, 'reg_alpha': 1.1500000000000001, 'reg_lambda': 1.8, 'gamma': 4.97}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:02,  1.31it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4966\n",
      "2th fold: XGBRegressor RMSE: 0.2719\n",
      "3th fold: XGBRegressor RMSE: 0.8013\n",
      "\n",
      "XGBRegressor average RMSE: 0.5233\n",
      "XGBRegressor worst RMSE: 0.8013\n",
      "Corresponding penalty value: 0.5511\n",
      "\u001b[32m[I 2025-03-31 13:41:24,794]\u001b[0m Trial 21 finished with value: 0.5510921305179838 and parameters: {'n_estimators': 1592, 'learning_rate': 0.02001, 'max_depth': 5, 'max_leaves': 6, 'colsample_bytree': 0.87, 'subsample': 0.66, 'reg_alpha': 5.05, 'reg_lambda': 5.7, 'gamma': 0.8300000000000001}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:02,  1.40it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4779\n",
      "2th fold: XGBRegressor RMSE: 0.3506\n",
      "3th fold: XGBRegressor RMSE: 0.9100\n",
      "\n",
      "XGBRegressor average RMSE: 0.5795\n",
      "XGBRegressor worst RMSE: 0.9100\n",
      "Corresponding penalty value: 0.6125\n",
      "\u001b[32m[I 2025-03-31 13:41:26,997]\u001b[0m Trial 22 finished with value: 0.6125484301459927 and parameters: {'n_estimators': 1812, 'learning_rate': 0.041010000000000005, 'max_depth': 8, 'max_leaves': 9, 'colsample_bytree': 0.77, 'subsample': 0.8300000000000001, 'reg_alpha': 2.85, 'reg_lambda': 4.3500000000000005, 'gamma': 1.53}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:01,  1.52it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4936\n",
      "2th fold: XGBRegressor RMSE: 0.2997\n",
      "3th fold: XGBRegressor RMSE: 0.7982\n",
      "\n",
      "XGBRegressor average RMSE: 0.5305\n",
      "XGBRegressor worst RMSE: 0.7982\n",
      "Corresponding penalty value: 0.5573\n",
      "\u001b[32m[I 2025-03-31 13:41:29,038]\u001b[0m Trial 23 finished with value: 0.5572993897461372 and parameters: {'n_estimators': 1455, 'learning_rate': 0.01901, 'max_depth': 5, 'max_leaves': 5, 'colsample_bytree': 0.8400000000000001, 'subsample': 0.71, 'reg_alpha': 4.37, 'reg_lambda': 0.14, 'gamma': 0.35000000000000003}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:02,  1.46it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5680\n",
      "2th fold: XGBRegressor RMSE: 0.2236\n",
      "3th fold: XGBRegressor RMSE: 0.8167\n",
      "\n",
      "XGBRegressor average RMSE: 0.5361\n",
      "XGBRegressor worst RMSE: 0.8167\n",
      "Corresponding penalty value: 0.5641\n",
      "\u001b[32m[I 2025-03-31 13:41:31,151]\u001b[0m Trial 24 finished with value: 0.5641391725015993 and parameters: {'n_estimators': 1877, 'learning_rate': 0.08001, 'max_depth': 2, 'max_leaves': 13, 'colsample_bytree': 0.77, 'subsample': 0.88, 'reg_alpha': 2.0, 'reg_lambda': 2.7, 'gamma': 0.8300000000000001}. Best is trial 14 with value: 0.53053102839007.\u001b[0m\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.4506\n",
      "2th fold: XGBRegressor RMSE: 0.2426\n",
      "3th fold: XGBRegressor RMSE: 0.8054\n",
      "\n",
      "XGBRegressor average RMSE: 0.4995\n",
      "XGBRegressor worst RMSE: 0.8054\n",
      "Corresponding penalty value: 0.5301\n",
      "\u001b[32m[I 2025-03-31 13:41:34,885]\u001b[0m Trial 25 finished with value: 0.5300927214851631 and parameters: {'n_estimators': 2320, 'learning_rate': 0.05101000000000001, 'max_depth': 7, 'max_leaves': 4, 'colsample_bytree': 0.65, 'subsample': 0.79, 'reg_alpha': 3.23, 'reg_lambda': 7.8, 'gamma': 0.0}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:02,  1.04it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4789\n",
      "2th fold: XGBRegressor RMSE: 0.2392\n",
      "3th fold: XGBRegressor RMSE: 0.8542\n",
      "\n",
      "XGBRegressor average RMSE: 0.5241\n",
      "XGBRegressor worst RMSE: 0.8542\n",
      "Corresponding penalty value: 0.5571\n",
      "\u001b[32m[I 2025-03-31 13:41:37,845]\u001b[0m Trial 26 finished with value: 0.5571144656425953 and parameters: {'n_estimators': 2466, 'learning_rate': 0.05501, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.9199999999999999, 'subsample': 0.79, 'reg_alpha': 3.15, 'reg_lambda': 6.5200000000000005, 'gamma': 0.07}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5052\n",
      "2th fold: XGBRegressor RMSE: 0.3503\n",
      "3th fold: XGBRegressor RMSE: 0.8723\n",
      "\n",
      "XGBRegressor average RMSE: 0.5760\n",
      "XGBRegressor worst RMSE: 0.8723\n",
      "Corresponding penalty value: 0.6056\n",
      "\u001b[32m[I 2025-03-31 13:41:40,577]\u001b[0m Trial 27 finished with value: 0.605593161294634 and parameters: {'n_estimators': 2309, 'learning_rate': 0.040010000000000004, 'max_depth': 5, 'max_leaves': 9, 'colsample_bytree': 0.72, 'subsample': 0.86, 'reg_alpha': 0.78, 'reg_lambda': 4.49, 'gamma': 0.42}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:03,  1.04s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6970\n",
      "2th fold: XGBRegressor RMSE: 0.3345\n",
      "3th fold: XGBRegressor RMSE: 0.6550\n",
      "\n",
      "XGBRegressor average RMSE: 0.5621\n",
      "XGBRegressor worst RMSE: 0.6970\n",
      "Corresponding penalty value: 0.5756\n",
      "\u001b[32m[I 2025-03-31 13:41:43,773]\u001b[0m Trial 28 finished with value: 0.5756250825210704 and parameters: {'n_estimators': 2964, 'learning_rate': 0.06201, 'max_depth': 7, 'max_leaves': 2, 'colsample_bytree': 0.86, 'subsample': 0.95, 'reg_alpha': 1.78, 'reg_lambda': 3.31, 'gamma': 1.61}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5044\n",
      "2th fold: XGBRegressor RMSE: 0.2309\n",
      "3th fold: XGBRegressor RMSE: 0.8214\n",
      "\n",
      "XGBRegressor average RMSE: 0.5189\n",
      "XGBRegressor worst RMSE: 0.8214\n",
      "Corresponding penalty value: 0.5492\n",
      "\u001b[32m[I 2025-03-31 13:41:46,600]\u001b[0m Trial 29 finished with value: 0.5491520551194952 and parameters: {'n_estimators': 2624, 'learning_rate': 0.07901, 'max_depth': 2, 'max_leaves': 15, 'colsample_bytree': 0.79, 'subsample': 1.0, 'reg_alpha': 0.18, 'reg_lambda': 8.4, 'gamma': 3.27}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:02,  1.30it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4529\n",
      "2th fold: XGBRegressor RMSE: 0.3337\n",
      "3th fold: XGBRegressor RMSE: 0.9207\n",
      "\n",
      "XGBRegressor average RMSE: 0.5691\n",
      "XGBRegressor worst RMSE: 0.9207\n",
      "Corresponding penalty value: 0.6042\n",
      "\u001b[32m[I 2025-03-31 13:41:48,977]\u001b[0m Trial 30 finished with value: 0.6042411099559012 and parameters: {'n_estimators': 2005, 'learning_rate': 0.09601, 'max_depth': 3, 'max_leaves': 19, 'colsample_bytree': 0.9299999999999999, 'subsample': 0.91, 'reg_alpha': 3.89, 'reg_lambda': 5.82, 'gamma': 0.04}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:01,  1.63it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5156\n",
      "2th fold: XGBRegressor RMSE: 0.2888\n",
      "3th fold: XGBRegressor RMSE: 0.7986\n",
      "\n",
      "XGBRegressor average RMSE: 0.5343\n",
      "XGBRegressor worst RMSE: 0.7986\n",
      "Corresponding penalty value: 0.5607\n",
      "\u001b[32m[I 2025-03-31 13:41:50,880]\u001b[0m Trial 31 finished with value: 0.560748596111809 and parameters: {'n_estimators': 1557, 'learning_rate': 0.049010000000000005, 'max_depth': 7, 'max_leaves': 7, 'colsample_bytree': 0.65, 'subsample': 0.6, 'reg_alpha': 4.66, 'reg_lambda': 8.3, 'gamma': 1.11}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:01,  1.86it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4961\n",
      "2th fold: XGBRegressor RMSE: 0.2435\n",
      "3th fold: XGBRegressor RMSE: 0.7776\n",
      "\n",
      "XGBRegressor average RMSE: 0.5057\n",
      "XGBRegressor worst RMSE: 0.7776\n",
      "Corresponding penalty value: 0.5329\n",
      "\u001b[32m[I 2025-03-31 13:41:52,556]\u001b[0m Trial 32 finished with value: 0.5329142345381376 and parameters: {'n_estimators': 1305, 'learning_rate': 0.02501, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.62, 'subsample': 0.79, 'reg_alpha': 2.61, 'reg_lambda': 7.3500000000000005, 'gamma': 0.64}. Best is trial 25 with value: 0.5300927214851631.\u001b[0m\n",
      "3it [00:01,  1.73it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4463\n",
      "2th fold: XGBRegressor RMSE: 0.2420\n",
      "3th fold: XGBRegressor RMSE: 0.7773\n",
      "\n",
      "XGBRegressor average RMSE: 0.4885\n",
      "XGBRegressor worst RMSE: 0.7773\n",
      "Corresponding penalty value: 0.5174\n",
      "\u001b[32m[I 2025-03-31 13:41:54,357]\u001b[0m Trial 33 finished with value: 0.5173917121430776 and parameters: {'n_estimators': 1219, 'learning_rate': 0.011009999999999999, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.62, 'subsample': 0.79, 'reg_alpha': 2.47, 'reg_lambda': 9.99, 'gamma': 0.63}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:02,  1.48it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4991\n",
      "2th fold: XGBRegressor RMSE: 0.3323\n",
      "3th fold: XGBRegressor RMSE: 1.0643\n",
      "\n",
      "XGBRegressor average RMSE: 0.6319\n",
      "XGBRegressor worst RMSE: 1.0643\n",
      "Corresponding penalty value: 0.6751\n",
      "\u001b[32m[I 2025-03-31 13:41:56,448]\u001b[0m Trial 34 finished with value: 0.6751467002882474 and parameters: {'n_estimators': 1239, 'learning_rate': 0.00201, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.61, 'subsample': 0.76, 'reg_alpha': 1.51, 'reg_lambda': 7.01, 'gamma': 0.61}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.69it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4562\n",
      "2th fold: XGBRegressor RMSE: 0.3542\n",
      "3th fold: XGBRegressor RMSE: 0.9621\n",
      "\n",
      "XGBRegressor average RMSE: 0.5908\n",
      "XGBRegressor worst RMSE: 0.9621\n",
      "Corresponding penalty value: 0.6280\n",
      "\u001b[32m[I 2025-03-31 13:41:58,293]\u001b[0m Trial 35 finished with value: 0.6279581888585676 and parameters: {'n_estimators': 861, 'learning_rate': 0.01201, 'max_depth': 10, 'max_leaves': 21, 'colsample_bytree': 0.55, 'subsample': 0.79, 'reg_alpha': 2.86, 'reg_lambda': 9.790000000000001, 'gamma': 0.71}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.95it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4890\n",
      "2th fold: XGBRegressor RMSE: 0.2467\n",
      "3th fold: XGBRegressor RMSE: 0.7959\n",
      "\n",
      "XGBRegressor average RMSE: 0.5105\n",
      "XGBRegressor worst RMSE: 0.7959\n",
      "Corresponding penalty value: 0.5391\n",
      "\u001b[32m[I 2025-03-31 13:41:59,900]\u001b[0m Trial 36 finished with value: 0.5390527705903473 and parameters: {'n_estimators': 1273, 'learning_rate': 0.02501, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.61, 'subsample': 0.74, 'reg_alpha': 3.35, 'reg_lambda': 7.98, 'gamma': 2.67}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.4296\n",
      "2th fold: XGBRegressor RMSE: 0.3457\n",
      "3th fold: XGBRegressor RMSE: 0.8860\n",
      "\n",
      "XGBRegressor average RMSE: 0.5538\n",
      "XGBRegressor worst RMSE: 0.8860\n",
      "Corresponding penalty value: 0.5870\n",
      "\u001b[32m[I 2025-03-31 13:42:03,021]\u001b[0m Trial 37 finished with value: 0.5869748579167451 and parameters: {'n_estimators': 2227, 'learning_rate': 0.00901, 'max_depth': 8, 'max_leaves': 11, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 1.06, 'reg_lambda': 8.74, 'gamma': 1.2}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.73it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6239\n",
      "2th fold: XGBRegressor RMSE: 0.3399\n",
      "3th fold: XGBRegressor RMSE: 0.7792\n",
      "\n",
      "XGBRegressor average RMSE: 0.5810\n",
      "XGBRegressor worst RMSE: 0.7792\n",
      "Corresponding penalty value: 0.6008\n",
      "\u001b[32m[I 2025-03-31 13:42:04,821]\u001b[0m Trial 38 finished with value: 0.6008154934232857 and parameters: {'n_estimators': 1419, 'learning_rate': 0.03701, 'max_depth': 9, 'max_leaves': 3, 'colsample_bytree': 0.69, 'subsample': 0.73, 'reg_alpha': 2.57, 'reg_lambda': 7.45, 'gamma': 0.37}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:02,  1.45it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8127\n",
      "2th fold: XGBRegressor RMSE: 0.8862\n",
      "3th fold: XGBRegressor RMSE: 1.8196\n",
      "\n",
      "XGBRegressor average RMSE: 1.1728\n",
      "XGBRegressor worst RMSE: 1.8196\n",
      "Corresponding penalty value: 1.2375\n",
      "\u001b[32m[I 2025-03-31 13:42:06,959]\u001b[0m Trial 39 finished with value: 1.2375085433262916 and parameters: {'n_estimators': 1023, 'learning_rate': 0.00101, 'max_depth': 6, 'max_leaves': 5, 'colsample_bytree': 0.54, 'subsample': 0.86, 'reg_alpha': 1.83, 'reg_lambda': 9.950000000000001, 'gamma': 1.59}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.86it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4641\n",
      "2th fold: XGBRegressor RMSE: 0.2992\n",
      "3th fold: XGBRegressor RMSE: 0.9299\n",
      "\n",
      "XGBRegressor average RMSE: 0.5644\n",
      "XGBRegressor worst RMSE: 0.9299\n",
      "Corresponding penalty value: 0.6009\n",
      "\u001b[32m[I 2025-03-31 13:42:08,645]\u001b[0m Trial 40 finished with value: 0.6009454020142443 and parameters: {'n_estimators': 1198, 'learning_rate': 0.02301, 'max_depth': 8, 'max_leaves': 24, 'colsample_bytree': 0.63, 'subsample': 0.77, 'reg_alpha': 3.72, 'reg_lambda': 8.950000000000001, 'gamma': 3.63}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.92it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4846\n",
      "2th fold: XGBRegressor RMSE: 0.3256\n",
      "3th fold: XGBRegressor RMSE: 0.7974\n",
      "\n",
      "XGBRegressor average RMSE: 0.5359\n",
      "XGBRegressor worst RMSE: 0.7974\n",
      "Corresponding penalty value: 0.5620\n",
      "\u001b[32m[I 2025-03-31 13:42:10,277]\u001b[0m Trial 41 finished with value: 0.5620053413407454 and parameters: {'n_estimators': 1255, 'learning_rate': 0.02701, 'max_depth': 9, 'max_leaves': 5, 'colsample_bytree': 0.61, 'subsample': 0.74, 'reg_alpha': 3.63, 'reg_lambda': 7.94, 'gamma': 2.65}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.77it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5853\n",
      "2th fold: XGBRegressor RMSE: 0.3556\n",
      "3th fold: XGBRegressor RMSE: 0.7962\n",
      "\n",
      "XGBRegressor average RMSE: 0.5790\n",
      "XGBRegressor worst RMSE: 0.7962\n",
      "Corresponding penalty value: 0.6008\n",
      "\u001b[32m[I 2025-03-31 13:42:12,047]\u001b[0m Trial 42 finished with value: 0.6007531501120248 and parameters: {'n_estimators': 1351, 'learning_rate': 0.01401, 'max_depth': 9, 'max_leaves': 3, 'colsample_bytree': 0.58, 'subsample': 0.81, 'reg_alpha': 3.21, 'reg_lambda': 8.17, 'gamma': 2.5500000000000003}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  2.64it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4884\n",
      "2th fold: XGBRegressor RMSE: 0.3261\n",
      "3th fold: XGBRegressor RMSE: 0.9063\n",
      "\n",
      "XGBRegressor average RMSE: 0.5736\n",
      "XGBRegressor worst RMSE: 0.9063\n",
      "Corresponding penalty value: 0.6069\n",
      "\u001b[32m[I 2025-03-31 13:42:13,255]\u001b[0m Trial 43 finished with value: 0.6068732593149633 and parameters: {'n_estimators': 811, 'learning_rate': 0.02701, 'max_depth': 10, 'max_leaves': 8, 'colsample_bytree': 0.61, 'subsample': 0.66, 'reg_alpha': 5.21, 'reg_lambda': 9.28, 'gamma': 2.94}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.80it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6138\n",
      "2th fold: XGBRegressor RMSE: 0.3723\n",
      "3th fold: XGBRegressor RMSE: 0.7718\n",
      "\n",
      "XGBRegressor average RMSE: 0.5860\n",
      "XGBRegressor worst RMSE: 0.7718\n",
      "Corresponding penalty value: 0.6045\n",
      "\u001b[32m[I 2025-03-31 13:42:14,996]\u001b[0m Trial 44 finished with value: 0.6045438808189593 and parameters: {'n_estimators': 1111, 'learning_rate': 0.00701, 'max_depth': 7, 'max_leaves': 3, 'colsample_bytree': 0.63, 'subsample': 0.72, 'reg_alpha': 8.61, 'reg_lambda': 7.3100000000000005, 'gamma': 2.1}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:02,  1.49it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4814\n",
      "2th fold: XGBRegressor RMSE: 0.3004\n",
      "3th fold: XGBRegressor RMSE: 0.7911\n",
      "\n",
      "XGBRegressor average RMSE: 0.5243\n",
      "XGBRegressor worst RMSE: 0.7911\n",
      "Corresponding penalty value: 0.5510\n",
      "\u001b[32m[I 2025-03-31 13:42:17,080]\u001b[0m Trial 45 finished with value: 0.5509960184510498 and parameters: {'n_estimators': 1479, 'learning_rate': 0.01601, 'max_depth': 8, 'max_leaves': 7, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.8500000000000001, 'reg_alpha': 4.1, 'reg_lambda': 6.19, 'gamma': 0.96}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:02,  1.45it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4785\n",
      "2th fold: XGBRegressor RMSE: 0.2885\n",
      "3th fold: XGBRegressor RMSE: 0.9381\n",
      "\n",
      "XGBRegressor average RMSE: 0.5684\n",
      "XGBRegressor worst RMSE: 0.9381\n",
      "Corresponding penalty value: 0.6053\n",
      "\u001b[32m[I 2025-03-31 13:42:19,220]\u001b[0m Trial 46 finished with value: 0.6053324320918462 and parameters: {'n_estimators': 1692, 'learning_rate': 0.033010000000000005, 'max_depth': 9, 'max_leaves': 17, 'colsample_bytree': 0.6799999999999999, 'subsample': 0.7, 'reg_alpha': 0.72, 'reg_lambda': 9.47, 'gamma': 3.68}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:02,  1.20it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4972\n",
      "2th fold: XGBRegressor RMSE: 0.2878\n",
      "3th fold: XGBRegressor RMSE: 0.8076\n",
      "\n",
      "XGBRegressor average RMSE: 0.5309\n",
      "XGBRegressor worst RMSE: 0.8076\n",
      "Corresponding penalty value: 0.5586\n",
      "\u001b[32m[I 2025-03-31 13:42:21,791]\u001b[0m Trial 47 finished with value: 0.5585543530527466 and parameters: {'n_estimators': 2127, 'learning_rate': 0.02301, 'max_depth': 10, 'max_leaves': 6, 'colsample_bytree': 0.73, 'subsample': 0.77, 'reg_alpha': 2.84, 'reg_lambda': 7.74, 'gamma': 2.2800000000000002}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:02,  1.33it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4744\n",
      "2th fold: XGBRegressor RMSE: 0.3402\n",
      "3th fold: XGBRegressor RMSE: 0.8951\n",
      "\n",
      "XGBRegressor average RMSE: 0.5699\n",
      "XGBRegressor worst RMSE: 0.8951\n",
      "Corresponding penalty value: 0.6024\n",
      "\u001b[32m[I 2025-03-31 13:42:24,129]\u001b[0m Trial 48 finished with value: 0.6024284839522378 and parameters: {'n_estimators': 1947, 'learning_rate': 0.03701, 'max_depth': 8, 'max_leaves': 12, 'colsample_bytree': 0.59, 'subsample': 0.8400000000000001, 'reg_alpha': 5.75, 'reg_lambda': 7.0600000000000005, 'gamma': 2.83}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "3it [00:01,  1.86it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5249\n",
      "2th fold: XGBRegressor RMSE: 0.3577\n",
      "3th fold: XGBRegressor RMSE: 0.6963\n",
      "\n",
      "XGBRegressor average RMSE: 0.5263\n",
      "XGBRegressor worst RMSE: 0.6963\n",
      "Corresponding penalty value: 0.5433\n",
      "\u001b[32m[I 2025-03-31 13:42:25,815]\u001b[0m Trial 49 finished with value: 0.5433068023191281 and parameters: {'n_estimators': 1367, 'learning_rate': 0.048010000000000004, 'max_depth': 6, 'max_leaves': 2, 'colsample_bytree': 0.64, 'subsample': 0.61, 'reg_alpha': 2.25, 'reg_lambda': 8.55, 'gamma': 0.26}. Best is trial 33 with value: 0.5173917121430776.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1219, 'learning_rate': 0.011009999999999999, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.62, 'subsample': 0.79, 'reg_alpha': 2.47, 'reg_lambda': 9.99, 'gamma': 0.63}\n",
      "3it [00:01,  1.75it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4557\n",
      "2th fold: XGBRegressor RMSE: 0.2345\n",
      "3th fold: XGBRegressor RMSE: 0.7833\n",
      "\n",
      "XGBRegressor average RMSE: 0.4912\n",
      "XGBRegressor worst RMSE: 0.7833\n",
      "Corresponding penalty value: 0.5204\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV1\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1219, 'learning_rate': 0.011009999999999999, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.62, 'subsample': 0.79, 'reg_alpha': 2.47, 'reg_lambda': 9.99, 'gamma': 0.63}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.099\n",
      "RMSE_crossval: 0.491\n",
      "RMSE_test: 0.354\n",
      "MAE_test: 0.264\n",
      "Nash-Sutcliffe Test: 0.988\n",
      "Kling-Gupta Test: 0.939\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 111.3476 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:42:28,941]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV3\u001b[0m\n",
      "3it [00:01,  1.80it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7546\n",
      "2th fold: XGBRegressor RMSE: 0.3310\n",
      "3th fold: XGBRegressor RMSE: 1.2566\n",
      "\n",
      "XGBRegressor average RMSE: 0.7807\n",
      "XGBRegressor worst RMSE: 1.2566\n",
      "Corresponding penalty value: 0.8283\n",
      "\u001b[32m[I 2025-03-31 13:42:30,615]\u001b[0m Trial 0 finished with value: 0.8283156000723437 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.5700000000000001, 'reg_alpha': 0.58, 'reg_lambda': 8.67, 'gamma': 3.0100000000000002}. Best is trial 0 with value: 0.8283156000723437.\u001b[0m\n",
      "3it [00:06,  2.16s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.7229\n",
      "2th fold: XGBRegressor RMSE: 0.2262\n",
      "3th fold: XGBRegressor RMSE: 1.3434\n",
      "\n",
      "XGBRegressor average RMSE: 0.7642\n",
      "XGBRegressor worst RMSE: 1.3434\n",
      "Corresponding penalty value: 0.8221\n",
      "\u001b[32m[I 2025-03-31 13:42:37,110]\u001b[0m Trial 1 finished with value: 0.8221060437768632 and parameters: {'n_estimators': 2270, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 1.83, 'reg_lambda': 3.04, 'gamma': 2.62}. Best is trial 1 with value: 0.8221060437768632.\u001b[0m\n",
      "3it [00:01,  1.54it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7286\n",
      "2th fold: XGBRegressor RMSE: 0.2412\n",
      "3th fold: XGBRegressor RMSE: 1.4553\n",
      "\n",
      "XGBRegressor average RMSE: 0.8084\n",
      "XGBRegressor worst RMSE: 1.4553\n",
      "Corresponding penalty value: 0.8731\n",
      "\u001b[32m[I 2025-03-31 13:42:39,063]\u001b[0m Trial 2 finished with value: 0.8730570633462293 and parameters: {'n_estimators': 1580, 'learning_rate': 0.02901, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.64, 'subsample': 0.6799999999999999, 'reg_alpha': 4.5600000000000005, 'reg_lambda': 7.8500000000000005, 'gamma': 1.0}. Best is trial 1 with value: 0.8221060437768632.\u001b[0m\n",
      "3it [00:01,  1.52it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9161\n",
      "2th fold: XGBRegressor RMSE: 0.3475\n",
      "3th fold: XGBRegressor RMSE: 1.3578\n",
      "\n",
      "XGBRegressor average RMSE: 0.8738\n",
      "XGBRegressor worst RMSE: 1.3578\n",
      "Corresponding penalty value: 0.9222\n",
      "\u001b[32m[I 2025-03-31 13:42:41,044]\u001b[0m Trial 3 finished with value: 0.9222137319902911 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05901000000000001, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.53, 'reg_alpha': 9.49, 'reg_lambda': 9.66, 'gamma': 4.05}. Best is trial 1 with value: 0.8221060437768632.\u001b[0m\n",
      "3it [00:02,  1.27it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6970\n",
      "2th fold: XGBRegressor RMSE: 0.2512\n",
      "3th fold: XGBRegressor RMSE: 1.3092\n",
      "\n",
      "XGBRegressor average RMSE: 0.7525\n",
      "XGBRegressor worst RMSE: 1.3092\n",
      "Corresponding penalty value: 0.8082\n",
      "\u001b[32m[I 2025-03-31 13:42:43,408]\u001b[0m Trial 4 finished with value: 0.8081614510471792 and parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}. Best is trial 4 with value: 0.8081614510471792.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6151\n",
      "2th fold: XGBRegressor RMSE: 0.2691\n",
      "3th fold: XGBRegressor RMSE: 1.3114\n",
      "\n",
      "XGBRegressor average RMSE: 0.7319\n",
      "XGBRegressor worst RMSE: 1.3114\n",
      "Corresponding penalty value: 0.7898\n",
      "\u001b[32m[I 2025-03-31 13:42:45,945]\u001b[0m Trial 5 finished with value: 0.7898236934364438 and parameters: {'n_estimators': 2156, 'learning_rate': 0.03101, 'max_depth': 6, 'max_leaves': 17, 'colsample_bytree': 0.59, 'subsample': 0.99, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'gamma': 4.48}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:02,  1.42it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8620\n",
      "2th fold: XGBRegressor RMSE: 0.3752\n",
      "3th fold: XGBRegressor RMSE: 1.3757\n",
      "\n",
      "XGBRegressor average RMSE: 0.8709\n",
      "XGBRegressor worst RMSE: 1.3757\n",
      "Corresponding penalty value: 0.9214\n",
      "\u001b[32m[I 2025-03-31 13:42:48,063]\u001b[0m Trial 6 finished with value: 0.9213998912050246 and parameters: {'n_estimators': 1995, 'learning_rate': 0.09201, 'max_depth': 1, 'max_leaves': 7, 'colsample_bytree': 0.52, 'subsample': 0.66, 'reg_alpha': 3.89, 'reg_lambda': 2.71, 'gamma': 4.15}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:01,  1.65it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9330\n",
      "2th fold: XGBRegressor RMSE: 0.2297\n",
      "3th fold: XGBRegressor RMSE: 1.4869\n",
      "\n",
      "XGBRegressor average RMSE: 0.8832\n",
      "XGBRegressor worst RMSE: 1.4869\n",
      "Corresponding penalty value: 0.9436\n",
      "\u001b[32m[I 2025-03-31 13:42:49,882]\u001b[0m Trial 7 finished with value: 0.9435707879593533 and parameters: {'n_estimators': 1392, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.9, 'subsample': 0.53, 'reg_alpha': 9.870000000000001, 'reg_lambda': 7.73, 'gamma': 0.99}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:00,  3.93it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8007\n",
      "2th fold: XGBRegressor RMSE: 0.1927\n",
      "3th fold: XGBRegressor RMSE: 1.3230\n",
      "\n",
      "XGBRegressor average RMSE: 0.7721\n",
      "XGBRegressor worst RMSE: 1.3230\n",
      "Corresponding penalty value: 0.8272\n",
      "\u001b[32m[I 2025-03-31 13:42:50,649]\u001b[0m Trial 8 finished with value: 0.8271964486500403 and parameters: {'n_estimators': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'max_leaves': 23, 'colsample_bytree': 0.89, 'subsample': 0.53, 'reg_alpha': 3.58, 'reg_lambda': 1.1500000000000001, 'gamma': 4.32}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:02,  1.34it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7018\n",
      "2th fold: XGBRegressor RMSE: 0.3258\n",
      "3th fold: XGBRegressor RMSE: 1.4034\n",
      "\n",
      "XGBRegressor average RMSE: 0.8103\n",
      "XGBRegressor worst RMSE: 1.4034\n",
      "Corresponding penalty value: 0.8696\n",
      "\u001b[32m[I 2025-03-31 13:42:52,895]\u001b[0m Trial 9 finished with value: 0.8696343592163217 and parameters: {'n_estimators': 2058, 'learning_rate': 0.033010000000000005, 'max_depth': 1, 'max_leaves': 11, 'colsample_bytree': 0.66, 'subsample': 0.87, 'reg_alpha': 6.38, 'reg_lambda': 8.88, 'gamma': 2.36}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:03,  1.06s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.7037\n",
      "2th fold: XGBRegressor RMSE: 0.2332\n",
      "3th fold: XGBRegressor RMSE: 1.3212\n",
      "\n",
      "XGBRegressor average RMSE: 0.7527\n",
      "XGBRegressor worst RMSE: 1.3212\n",
      "Corresponding penalty value: 0.8096\n",
      "\u001b[32m[I 2025-03-31 13:42:56,133]\u001b[0m Trial 10 finished with value: 0.809568505216648 and parameters: {'n_estimators': 2907, 'learning_rate': 0.058010000000000006, 'max_depth': 4, 'max_leaves': 29, 'colsample_bytree': 0.76, 'subsample': 0.96, 'reg_alpha': 7.3100000000000005, 'reg_lambda': 6.0600000000000005, 'gamma': 4.8500000000000005}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:02,  1.34it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7732\n",
      "2th fold: XGBRegressor RMSE: 0.3789\n",
      "3th fold: XGBRegressor RMSE: 1.5572\n",
      "\n",
      "XGBRegressor average RMSE: 0.9031\n",
      "XGBRegressor worst RMSE: 1.5572\n",
      "Corresponding penalty value: 0.9685\n",
      "\u001b[32m[I 2025-03-31 13:42:58,431]\u001b[0m Trial 11 finished with value: 0.9685243166798994 and parameters: {'n_estimators': 814, 'learning_rate': 0.00301, 'max_depth': 4, 'max_leaves': 13, 'colsample_bytree': 0.75, 'subsample': 0.78, 'reg_alpha': 7.23, 'reg_lambda': 6.07, 'gamma': 0.15}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:03,  1.03s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6392\n",
      "2th fold: XGBRegressor RMSE: 0.2737\n",
      "3th fold: XGBRegressor RMSE: 1.3075\n",
      "\n",
      "XGBRegressor average RMSE: 0.7401\n",
      "XGBRegressor worst RMSE: 1.3075\n",
      "Corresponding penalty value: 0.7969\n",
      "\u001b[32m[I 2025-03-31 13:43:01,582]\u001b[0m Trial 12 finished with value: 0.7968594807384639 and parameters: {'n_estimators': 2556, 'learning_rate': 0.01701, 'max_depth': 4, 'max_leaves': 15, 'colsample_bytree': 0.51, 'subsample': 0.81, 'reg_alpha': 2.1, 'reg_lambda': 9.94, 'gamma': 1.69}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6381\n",
      "2th fold: XGBRegressor RMSE: 0.3042\n",
      "3th fold: XGBRegressor RMSE: 1.2929\n",
      "\n",
      "XGBRegressor average RMSE: 0.7450\n",
      "XGBRegressor worst RMSE: 1.2929\n",
      "Corresponding penalty value: 0.7998\n",
      "\u001b[32m[I 2025-03-31 13:43:04,552]\u001b[0m Trial 13 finished with value: 0.7998287729018206 and parameters: {'n_estimators': 2665, 'learning_rate': 0.041010000000000005, 'max_depth': 4, 'max_leaves': 18, 'colsample_bytree': 0.5, 'subsample': 0.95, 'reg_alpha': 2.41, 'reg_lambda': 9.98, 'gamma': 1.9000000000000001}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7125\n",
      "2th fold: XGBRegressor RMSE: 0.2696\n",
      "3th fold: XGBRegressor RMSE: 1.3950\n",
      "\n",
      "XGBRegressor average RMSE: 0.7924\n",
      "XGBRegressor worst RMSE: 1.3950\n",
      "Corresponding penalty value: 0.8526\n",
      "\u001b[32m[I 2025-03-31 13:43:07,367]\u001b[0m Trial 14 finished with value: 0.8526260415215411 and parameters: {'n_estimators': 2514, 'learning_rate': 0.015009999999999999, 'max_depth': 3, 'max_leaves': 2, 'colsample_bytree': 0.71, 'subsample': 0.88, 'reg_alpha': 5.59, 'reg_lambda': 6.78, 'gamma': 3.5300000000000002}. Best is trial 5 with value: 0.7898236934364438.\u001b[0m\n",
      "3it [00:02,  1.01it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6387\n",
      "2th fold: XGBRegressor RMSE: 0.2287\n",
      "3th fold: XGBRegressor RMSE: 1.3030\n",
      "\n",
      "XGBRegressor average RMSE: 0.7235\n",
      "XGBRegressor worst RMSE: 1.3030\n",
      "Corresponding penalty value: 0.7814\n",
      "\u001b[32m[I 2025-03-31 13:43:10,403]\u001b[0m Trial 15 finished with value: 0.7814432271228748 and parameters: {'n_estimators': 2396, 'learning_rate': 0.01901, 'max_depth': 5, 'max_leaves': 21, 'colsample_bytree': 0.8200000000000001, 'subsample': 1.0, 'reg_alpha': 8.63, 'reg_lambda': 7.61, 'gamma': 1.68}. Best is trial 15 with value: 0.7814432271228748.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6611\n",
      "2th fold: XGBRegressor RMSE: 0.2513\n",
      "3th fold: XGBRegressor RMSE: 1.3740\n",
      "\n",
      "XGBRegressor average RMSE: 0.7621\n",
      "XGBRegressor worst RMSE: 1.3740\n",
      "Corresponding penalty value: 0.8233\n",
      "\u001b[32m[I 2025-03-31 13:43:13,207]\u001b[0m Trial 16 finished with value: 0.8233281434397536 and parameters: {'n_estimators': 2265, 'learning_rate': 0.049010000000000005, 'max_depth': 6, 'max_leaves': 22, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.99, 'reg_alpha': 8.21, 'reg_lambda': 4.73, 'gamma': 0.06}. Best is trial 15 with value: 0.7814432271228748.\u001b[0m\n",
      "3it [00:03,  1.18s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.7128\n",
      "2th fold: XGBRegressor RMSE: 0.2347\n",
      "3th fold: XGBRegressor RMSE: 1.3083\n",
      "\n",
      "XGBRegressor average RMSE: 0.7519\n",
      "XGBRegressor worst RMSE: 1.3083\n",
      "Corresponding penalty value: 0.8075\n",
      "\u001b[32m[I 2025-03-31 13:43:16,814]\u001b[0m Trial 17 finished with value: 0.8075463933985948 and parameters: {'n_estimators': 2938, 'learning_rate': 0.02201, 'max_depth': 10, 'max_leaves': 23, 'colsample_bytree': 0.8200000000000001, 'subsample': 0.9, 'reg_alpha': 8.47, 'reg_lambda': 7.23, 'gamma': 3.29}. Best is trial 15 with value: 0.7814432271228748.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6797\n",
      "2th fold: XGBRegressor RMSE: 0.2229\n",
      "3th fold: XGBRegressor RMSE: 1.3346\n",
      "\n",
      "XGBRegressor average RMSE: 0.7457\n",
      "XGBRegressor worst RMSE: 1.3346\n",
      "Corresponding penalty value: 0.8046\n",
      "\u001b[32m[I 2025-03-31 13:43:19,405]\u001b[0m Trial 18 finished with value: 0.8046359702330345 and parameters: {'n_estimators': 2222, 'learning_rate': 0.04401, 'max_depth': 5, 'max_leaves': 28, 'colsample_bytree': 0.8300000000000001, 'subsample': 1.0, 'reg_alpha': 8.71, 'reg_lambda': 4.68, 'gamma': 2.34}. Best is trial 15 with value: 0.7814432271228748.\u001b[0m\n",
      "3it [00:02,  1.43it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7389\n",
      "2th fold: XGBRegressor RMSE: 0.2577\n",
      "3th fold: XGBRegressor RMSE: 1.3265\n",
      "\n",
      "XGBRegressor average RMSE: 0.7744\n",
      "XGBRegressor worst RMSE: 1.3265\n",
      "Corresponding penalty value: 0.8296\n",
      "\u001b[32m[I 2025-03-31 13:43:21,565]\u001b[0m Trial 19 finished with value: 0.8295841401025874 and parameters: {'n_estimators': 1797, 'learning_rate': 0.07001, 'max_depth': 3, 'max_leaves': 10, 'colsample_bytree': 0.98, 'subsample': 0.9199999999999999, 'reg_alpha': 6.33, 'reg_lambda': 8.1, 'gamma': 0.63}. Best is trial 15 with value: 0.7814432271228748.\u001b[0m\n",
      "3it [00:02,  1.01it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7573\n",
      "2th fold: XGBRegressor RMSE: 0.2763\n",
      "3th fold: XGBRegressor RMSE: 1.3362\n",
      "\n",
      "XGBRegressor average RMSE: 0.7899\n",
      "XGBRegressor worst RMSE: 1.3362\n",
      "Corresponding penalty value: 0.8445\n",
      "\u001b[32m[I 2025-03-31 13:43:24,593]\u001b[0m Trial 20 finished with value: 0.844534583208204 and parameters: {'n_estimators': 2430, 'learning_rate': 0.03801, 'max_depth': 8, 'max_leaves': 17, 'colsample_bytree': 1.0, 'subsample': 0.8400000000000001, 'reg_alpha': 7.58, 'reg_lambda': 6.42, 'gamma': 4.97}. Best is trial 15 with value: 0.7814432271228748.\u001b[0m\n",
      "3it [00:03,  1.13s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6363\n",
      "2th fold: XGBRegressor RMSE: 0.2179\n",
      "3th fold: XGBRegressor RMSE: 1.2927\n",
      "\n",
      "XGBRegressor average RMSE: 0.7156\n",
      "XGBRegressor worst RMSE: 1.2927\n",
      "Corresponding penalty value: 0.7733\n",
      "\u001b[32m[I 2025-03-31 13:43:28,035]\u001b[0m Trial 21 finished with value: 0.7733205658448832 and parameters: {'n_estimators': 2673, 'learning_rate': 0.01701, 'max_depth': 5, 'max_leaves': 15, 'colsample_bytree': 0.64, 'subsample': 0.8200000000000001, 'reg_alpha': 2.0300000000000002, 'reg_lambda': 9.81, 'gamma': 1.62}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:03,  1.08s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6852\n",
      "2th fold: XGBRegressor RMSE: 0.2301\n",
      "3th fold: XGBRegressor RMSE: 1.2868\n",
      "\n",
      "XGBRegressor average RMSE: 0.7341\n",
      "XGBRegressor worst RMSE: 1.2868\n",
      "Corresponding penalty value: 0.7893\n",
      "\u001b[32m[I 2025-03-31 13:43:31,346]\u001b[0m Trial 22 finished with value: 0.7893301000907016 and parameters: {'n_estimators': 2657, 'learning_rate': 0.02201, 'max_depth': 5, 'max_leaves': 21, 'colsample_bytree': 0.6799999999999999, 'subsample': 0.73, 'reg_alpha': 5.79, 'reg_lambda': 8.870000000000001, 'gamma': 1.8}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:03,  1.20s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6854\n",
      "2th fold: XGBRegressor RMSE: 0.2021\n",
      "3th fold: XGBRegressor RMSE: 1.2829\n",
      "\n",
      "XGBRegressor average RMSE: 0.7235\n",
      "XGBRegressor worst RMSE: 1.2829\n",
      "Corresponding penalty value: 0.7794\n",
      "\u001b[32m[I 2025-03-31 13:43:35,000]\u001b[0m Trial 23 finished with value: 0.7794127650023606 and parameters: {'n_estimators': 2751, 'learning_rate': 0.01301, 'max_depth': 5, 'max_leaves': 21, 'colsample_bytree': 0.7, 'subsample': 0.73, 'reg_alpha': 3.04, 'reg_lambda': 8.42, 'gamma': 1.75}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:03,  1.14s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.7432\n",
      "2th fold: XGBRegressor RMSE: 0.2445\n",
      "3th fold: XGBRegressor RMSE: 1.3427\n",
      "\n",
      "XGBRegressor average RMSE: 0.7768\n",
      "XGBRegressor worst RMSE: 1.3427\n",
      "Corresponding penalty value: 0.8334\n",
      "\u001b[32m[I 2025-03-31 13:43:38,495]\u001b[0m Trial 24 finished with value: 0.8333807061710568 and parameters: {'n_estimators': 2770, 'learning_rate': 0.01201, 'max_depth': 3, 'max_leaves': 25, 'colsample_bytree': 0.72, 'subsample': 0.69, 'reg_alpha': 3.17, 'reg_lambda': 8.32, 'gamma': 1.43}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:09,  3.27s/it]\n",
      "1th fold: XGBRegressor RMSE: 2.1607\n",
      "2th fold: XGBRegressor RMSE: 2.8347\n",
      "3th fold: XGBRegressor RMSE: 4.5317\n",
      "\n",
      "XGBRegressor average RMSE: 3.1757\n",
      "XGBRegressor worst RMSE: 4.5317\n",
      "Corresponding penalty value: 3.3113\n",
      "\u001b[32m[I 2025-03-31 13:43:48,378]\u001b[0m Trial 25 finished with value: 3.3112827600254198 and parameters: {'n_estimators': 2998, 'learning_rate': 1e-05, 'max_depth': 5, 'max_leaves': 20, 'colsample_bytree': 0.79, 'subsample': 0.64, 'reg_alpha': 1.6400000000000001, 'reg_lambda': 5.42, 'gamma': 2.04}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:03,  1.31s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6564\n",
      "2th fold: XGBRegressor RMSE: 0.2185\n",
      "3th fold: XGBRegressor RMSE: 1.2846\n",
      "\n",
      "XGBRegressor average RMSE: 0.7198\n",
      "XGBRegressor worst RMSE: 1.2846\n",
      "Corresponding penalty value: 0.7763\n",
      "\u001b[32m[I 2025-03-31 13:43:52,360]\u001b[0m Trial 26 finished with value: 0.7763167442515292 and parameters: {'n_estimators': 2748, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 26, 'colsample_bytree': 0.64, 'subsample': 0.73, 'reg_alpha': 2.89, 'reg_lambda': 7.38, 'gamma': 2.74}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:03,  1.33s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6578\n",
      "2th fold: XGBRegressor RMSE: 0.2176\n",
      "3th fold: XGBRegressor RMSE: 1.2907\n",
      "\n",
      "XGBRegressor average RMSE: 0.7220\n",
      "XGBRegressor worst RMSE: 1.2907\n",
      "Corresponding penalty value: 0.7789\n",
      "\u001b[32m[I 2025-03-31 13:43:56,400]\u001b[0m Trial 27 finished with value: 0.7789194766414739 and parameters: {'n_estimators': 2719, 'learning_rate': 0.00801, 'max_depth': 7, 'max_leaves': 26, 'colsample_bytree': 0.62, 'subsample': 0.73, 'reg_alpha': 2.7600000000000002, 'reg_lambda': 7.26, 'gamma': 2.89}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:04,  1.43s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.7171\n",
      "2th fold: XGBRegressor RMSE: 0.2077\n",
      "3th fold: XGBRegressor RMSE: 1.3260\n",
      "\n",
      "XGBRegressor average RMSE: 0.7503\n",
      "XGBRegressor worst RMSE: 1.3260\n",
      "Corresponding penalty value: 0.8078\n",
      "\u001b[32m[I 2025-03-31 13:44:00,757]\u001b[0m Trial 28 finished with value: 0.8078475739816456 and parameters: {'n_estimators': 2782, 'learning_rate': 0.00701, 'max_depth': 9, 'max_leaves': 26, 'colsample_bytree': 0.62, 'subsample': 0.8200000000000001, 'reg_alpha': 1.11, 'reg_lambda': 4.0, 'gamma': 2.8000000000000003}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:02,  1.22it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7116\n",
      "2th fold: XGBRegressor RMSE: 0.2582\n",
      "3th fold: XGBRegressor RMSE: 1.2930\n",
      "\n",
      "XGBRegressor average RMSE: 0.7543\n",
      "XGBRegressor worst RMSE: 1.2930\n",
      "Corresponding penalty value: 0.8081\n",
      "\u001b[32m[I 2025-03-31 13:44:03,278]\u001b[0m Trial 29 finished with value: 0.8081379257611562 and parameters: {'n_estimators': 1968, 'learning_rate': 0.02501, 'max_depth': 7, 'max_leaves': 30, 'colsample_bytree': 0.55, 'subsample': 0.62, 'reg_alpha': 0.91, 'reg_lambda': 7.0200000000000005, 'gamma': 3.13}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7133\n",
      "2th fold: XGBRegressor RMSE: 0.2098\n",
      "3th fold: XGBRegressor RMSE: 1.3288\n",
      "\n",
      "XGBRegressor average RMSE: 0.7506\n",
      "XGBRegressor worst RMSE: 1.3288\n",
      "Corresponding penalty value: 0.8084\n",
      "\u001b[32m[I 2025-03-31 13:44:05,896]\u001b[0m Trial 30 finished with value: 0.8084261004955997 and parameters: {'n_estimators': 1128, 'learning_rate': 0.00701, 'max_depth': 9, 'max_leaves': 27, 'colsample_bytree': 0.64, 'subsample': 0.78, 'reg_alpha': 0.03, 'reg_lambda': 5.49, 'gamma': 3.6}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:03,  1.19s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6831\n",
      "2th fold: XGBRegressor RMSE: 0.2028\n",
      "3th fold: XGBRegressor RMSE: 1.2914\n",
      "\n",
      "XGBRegressor average RMSE: 0.7258\n",
      "XGBRegressor worst RMSE: 1.2914\n",
      "Corresponding penalty value: 0.7823\n",
      "\u001b[32m[I 2025-03-31 13:44:09,537]\u001b[0m Trial 31 finished with value: 0.7823424811217002 and parameters: {'n_estimators': 2771, 'learning_rate': 0.01401, 'max_depth': 8, 'max_leaves': 25, 'colsample_bytree': 0.6799999999999999, 'subsample': 0.74, 'reg_alpha': 2.7600000000000002, 'reg_lambda': 8.53, 'gamma': 2.86}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:08,  2.78s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.8317\n",
      "2th fold: XGBRegressor RMSE: 0.3671\n",
      "3th fold: XGBRegressor RMSE: 1.5630\n",
      "\n",
      "XGBRegressor average RMSE: 0.9206\n",
      "XGBRegressor worst RMSE: 1.5630\n",
      "Corresponding penalty value: 0.9848\n",
      "\u001b[32m[I 2025-03-31 13:44:17,937]\u001b[0m Trial 32 finished with value: 0.9848128419785194 and parameters: {'n_estimators': 2397, 'learning_rate': 0.00101, 'max_depth': 7, 'max_leaves': 24, 'colsample_bytree': 0.71, 'subsample': 0.71, 'reg_alpha': 4.29, 'reg_lambda': 0.05, 'gamma': 2.22}. Best is trial 21 with value: 0.7733205658448832.\u001b[0m\n",
      "3it [00:04,  1.44s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6354\n",
      "2th fold: XGBRegressor RMSE: 0.2132\n",
      "3th fold: XGBRegressor RMSE: 1.2942\n",
      "\n",
      "XGBRegressor average RMSE: 0.7143\n",
      "XGBRegressor worst RMSE: 1.2942\n",
      "Corresponding penalty value: 0.7723\n",
      "\u001b[32m[I 2025-03-31 13:44:22,323]\u001b[0m Trial 33 finished with value: 0.7722662967781624 and parameters: {'n_estimators': 2627, 'learning_rate': 0.00601, 'max_depth': 6, 'max_leaves': 27, 'colsample_bytree': 0.62, 'subsample': 0.77, 'reg_alpha': 2.98, 'reg_lambda': 8.38, 'gamma': 2.6}. Best is trial 33 with value: 0.7722662967781624.\u001b[0m\n",
      "3it [00:04,  1.38s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6798\n",
      "2th fold: XGBRegressor RMSE: 0.2177\n",
      "3th fold: XGBRegressor RMSE: 1.3201\n",
      "\n",
      "XGBRegressor average RMSE: 0.7392\n",
      "XGBRegressor worst RMSE: 1.3201\n",
      "Corresponding penalty value: 0.7973\n",
      "\u001b[32m[I 2025-03-31 13:44:26,541]\u001b[0m Trial 34 finished with value: 0.7972920986038495 and parameters: {'n_estimators': 2580, 'learning_rate': 0.00701, 'max_depth': 7, 'max_leaves': 30, 'colsample_bytree': 0.61, 'subsample': 0.79, 'reg_alpha': 1.5, 'reg_lambda': 7.36, 'gamma': 2.6}. Best is trial 33 with value: 0.7722662967781624.\u001b[0m\n",
      "3it [00:04,  1.57s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6065\n",
      "2th fold: XGBRegressor RMSE: 0.2248\n",
      "3th fold: XGBRegressor RMSE: 1.2989\n",
      "\n",
      "XGBRegressor average RMSE: 0.7101\n",
      "XGBRegressor worst RMSE: 1.2989\n",
      "Corresponding penalty value: 0.7689\n",
      "\u001b[32m[I 2025-03-31 13:44:31,306]\u001b[0m Trial 35 finished with value: 0.7689485676759104 and parameters: {'n_estimators': 2857, 'learning_rate': 0.00501, 'max_depth': 6, 'max_leaves': 27, 'colsample_bytree': 0.64, 'subsample': 0.8400000000000001, 'reg_alpha': 4.62, 'reg_lambda': 9.24, 'gamma': 3.48}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:09,  3.32s/it]\n",
      "1th fold: XGBRegressor RMSE: 2.1568\n",
      "2th fold: XGBRegressor RMSE: 2.8345\n",
      "3th fold: XGBRegressor RMSE: 4.5347\n",
      "\n",
      "XGBRegressor average RMSE: 3.1753\n",
      "XGBRegressor worst RMSE: 4.5347\n",
      "Corresponding penalty value: 3.3113\n",
      "\u001b[32m[I 2025-03-31 13:44:41,329]\u001b[0m Trial 36 finished with value: 3.311265854214204 and parameters: {'n_estimators': 2894, 'learning_rate': 1e-05, 'max_depth': 6, 'max_leaves': 28, 'colsample_bytree': 0.56, 'subsample': 0.8500000000000001, 'reg_alpha': 4.9, 'reg_lambda': 9.21, 'gamma': 3.2800000000000002}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6417\n",
      "2th fold: XGBRegressor RMSE: 0.2135\n",
      "3th fold: XGBRegressor RMSE: 1.3482\n",
      "\n",
      "XGBRegressor average RMSE: 0.7345\n",
      "XGBRegressor worst RMSE: 1.3482\n",
      "Corresponding penalty value: 0.7958\n",
      "\u001b[32m[I 2025-03-31 13:44:44,317]\u001b[0m Trial 37 finished with value: 0.795829889601032 and parameters: {'n_estimators': 2382, 'learning_rate': 0.01901, 'max_depth': 6, 'max_leaves': 11, 'colsample_bytree': 0.65, 'subsample': 0.76, 'reg_alpha': 3.79, 'reg_lambda': 9.65, 'gamma': 3.69}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6266\n",
      "2th fold: XGBRegressor RMSE: 0.2449\n",
      "3th fold: XGBRegressor RMSE: 1.3071\n",
      "\n",
      "XGBRegressor average RMSE: 0.7262\n",
      "XGBRegressor worst RMSE: 1.3071\n",
      "Corresponding penalty value: 0.7843\n",
      "\u001b[32m[I 2025-03-31 13:44:46,922]\u001b[0m Trial 38 finished with value: 0.7842787233791042 and parameters: {'n_estimators': 1639, 'learning_rate': 0.011009999999999999, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.8200000000000001, 'reg_alpha': 4.63, 'reg_lambda': 9.08, 'gamma': 3.93}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:03,  1.06s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6799\n",
      "2th fold: XGBRegressor RMSE: 0.2955\n",
      "3th fold: XGBRegressor RMSE: 1.3122\n",
      "\n",
      "XGBRegressor average RMSE: 0.7626\n",
      "XGBRegressor worst RMSE: 1.3122\n",
      "Corresponding penalty value: 0.8175\n",
      "\u001b[32m[I 2025-03-31 13:44:50,176]\u001b[0m Trial 39 finished with value: 0.8175221013852285 and parameters: {'n_estimators': 2851, 'learning_rate': 0.035010000000000006, 'max_depth': 6, 'max_leaves': 28, 'colsample_bytree': 0.54, 'subsample': 0.69, 'reg_alpha': 2.13, 'reg_lambda': 8.13, 'gamma': 2.66}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:02,  1.02it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7728\n",
      "2th fold: XGBRegressor RMSE: 0.2155\n",
      "3th fold: XGBRegressor RMSE: 1.5485\n",
      "\n",
      "XGBRegressor average RMSE: 0.8456\n",
      "XGBRegressor worst RMSE: 1.5485\n",
      "Corresponding penalty value: 0.9159\n",
      "\u001b[32m[I 2025-03-31 13:44:53,193]\u001b[0m Trial 40 finished with value: 0.9158913555224213 and parameters: {'n_estimators': 2540, 'learning_rate': 0.026010000000000002, 'max_depth': 2, 'max_leaves': 13, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 4.22, 'reg_lambda': 9.36, 'gamma': 1.08}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:04,  1.44s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6410\n",
      "2th fold: XGBRegressor RMSE: 0.2068\n",
      "3th fold: XGBRegressor RMSE: 1.3023\n",
      "\n",
      "XGBRegressor average RMSE: 0.7167\n",
      "XGBRegressor worst RMSE: 1.3023\n",
      "Corresponding penalty value: 0.7753\n",
      "\u001b[32m[I 2025-03-31 13:44:57,586]\u001b[0m Trial 41 finished with value: 0.7752746616418111 and parameters: {'n_estimators': 2657, 'learning_rate': 0.00601, 'max_depth': 7, 'max_leaves': 26, 'colsample_bytree': 0.62, 'subsample': 0.76, 'reg_alpha': 2.7, 'reg_lambda': 7.63, 'gamma': 2.9}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:04,  1.45s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6399\n",
      "2th fold: XGBRegressor RMSE: 0.2074\n",
      "3th fold: XGBRegressor RMSE: 1.2980\n",
      "\n",
      "XGBRegressor average RMSE: 0.7151\n",
      "XGBRegressor worst RMSE: 1.2980\n",
      "Corresponding penalty value: 0.7734\n",
      "\u001b[32m[I 2025-03-31 13:45:01,996]\u001b[0m Trial 42 finished with value: 0.7733776019113608 and parameters: {'n_estimators': 2636, 'learning_rate': 0.00601, 'max_depth': 7, 'max_leaves': 24, 'colsample_bytree': 0.67, 'subsample': 0.77, 'reg_alpha': 3.48, 'reg_lambda': 7.72, 'gamma': 2.48}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:05,  1.69s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6291\n",
      "2th fold: XGBRegressor RMSE: 0.2266\n",
      "3th fold: XGBRegressor RMSE: 1.3051\n",
      "\n",
      "XGBRegressor average RMSE: 0.7203\n",
      "XGBRegressor worst RMSE: 1.3051\n",
      "Corresponding penalty value: 0.7787\n",
      "\u001b[32m[I 2025-03-31 13:45:07,146]\u001b[0m Trial 43 finished with value: 0.778742248677006 and parameters: {'n_estimators': 2112, 'learning_rate': 0.00301, 'max_depth': 9, 'max_leaves': 24, 'colsample_bytree': 0.59, 'subsample': 0.77, 'reg_alpha': 3.52, 'reg_lambda': 8.83, 'gamma': 3.1}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:04,  1.42s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6285\n",
      "2th fold: XGBRegressor RMSE: 0.2163\n",
      "3th fold: XGBRegressor RMSE: 1.2930\n",
      "\n",
      "XGBRegressor average RMSE: 0.7126\n",
      "XGBRegressor worst RMSE: 1.2930\n",
      "Corresponding penalty value: 0.7706\n",
      "\u001b[32m[I 2025-03-31 13:45:11,490]\u001b[0m Trial 44 finished with value: 0.7706253993031661 and parameters: {'n_estimators': 2597, 'learning_rate': 0.00601, 'max_depth': 7, 'max_leaves': 29, 'colsample_bytree': 0.67, 'subsample': 0.8, 'reg_alpha': 5.4, 'reg_lambda': 7.87, 'gamma': 2.2}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:03,  1.25s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6585\n",
      "2th fold: XGBRegressor RMSE: 0.2103\n",
      "3th fold: XGBRegressor RMSE: 1.2952\n",
      "\n",
      "XGBRegressor average RMSE: 0.7213\n",
      "XGBRegressor worst RMSE: 1.2952\n",
      "Corresponding penalty value: 0.7787\n",
      "\u001b[32m[I 2025-03-31 13:45:15,299]\u001b[0m Trial 45 finished with value: 0.7787250504304325 and parameters: {'n_estimators': 3000, 'learning_rate': 0.01601, 'max_depth': 6, 'max_leaves': 29, 'colsample_bytree': 0.6799999999999999, 'subsample': 0.8, 'reg_alpha': 5.2, 'reg_lambda': 9.6, 'gamma': 2.1}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6793\n",
      "2th fold: XGBRegressor RMSE: 0.2732\n",
      "3th fold: XGBRegressor RMSE: 1.2784\n",
      "\n",
      "XGBRegressor average RMSE: 0.7437\n",
      "XGBRegressor worst RMSE: 1.2784\n",
      "Corresponding penalty value: 0.7971\n",
      "\u001b[32m[I 2025-03-31 13:45:17,964]\u001b[0m Trial 46 finished with value: 0.7971375189884313 and parameters: {'n_estimators': 2296, 'learning_rate': 0.09301, 'max_depth': 8, 'max_leaves': 15, 'colsample_bytree': 0.73, 'subsample': 0.8500000000000001, 'reg_alpha': 5.38, 'reg_lambda': 2.7, 'gamma': 2.49}. Best is trial 35 with value: 0.7689485676759104.\u001b[0m\n",
      "3it [00:04,  1.63s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6157\n",
      "2th fold: XGBRegressor RMSE: 0.2094\n",
      "3th fold: XGBRegressor RMSE: 1.2971\n",
      "\n",
      "XGBRegressor average RMSE: 0.7074\n",
      "XGBRegressor worst RMSE: 1.2971\n",
      "Corresponding penalty value: 0.7664\n",
      "\u001b[32m[I 2025-03-31 13:45:22,940]\u001b[0m Trial 47 finished with value: 0.7663822788871183 and parameters: {'n_estimators': 2464, 'learning_rate': 0.00401, 'max_depth': 5, 'max_leaves': 30, 'colsample_bytree': 0.66, 'subsample': 0.8300000000000001, 'reg_alpha': 6.24, 'reg_lambda': 7.95, 'gamma': 1.31}. Best is trial 47 with value: 0.7663822788871183.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6824\n",
      "2th fold: XGBRegressor RMSE: 0.2806\n",
      "3th fold: XGBRegressor RMSE: 1.3052\n",
      "\n",
      "XGBRegressor average RMSE: 0.7561\n",
      "XGBRegressor worst RMSE: 1.3052\n",
      "Corresponding penalty value: 0.8110\n",
      "\u001b[32m[I 2025-03-31 13:45:26,080]\u001b[0m Trial 48 finished with value: 0.8109690587275232 and parameters: {'n_estimators': 2505, 'learning_rate': 0.08701, 'max_depth': 4, 'max_leaves': 30, 'colsample_bytree': 0.75, 'subsample': 0.88, 'reg_alpha': 6.8100000000000005, 'reg_lambda': 6.5, 'gamma': 1.47}. Best is trial 47 with value: 0.7663822788871183.\u001b[0m\n",
      "3it [00:02,  1.40it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6934\n",
      "2th fold: XGBRegressor RMSE: 0.2852\n",
      "3th fold: XGBRegressor RMSE: 1.2772\n",
      "\n",
      "XGBRegressor average RMSE: 0.7519\n",
      "XGBRegressor worst RMSE: 1.2772\n",
      "Corresponding penalty value: 0.8044\n",
      "\u001b[32m[I 2025-03-31 13:45:28,295]\u001b[0m Trial 49 finished with value: 0.8044491978067531 and parameters: {'n_estimators': 1838, 'learning_rate': 0.06001, 'max_depth': 5, 'max_leaves': 29, 'colsample_bytree': 0.64, 'subsample': 0.8300000000000001, 'reg_alpha': 6.0200000000000005, 'reg_lambda': 8.76, 'gamma': 0.8200000000000001}. Best is trial 47 with value: 0.7663822788871183.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 2464, 'learning_rate': 0.00401, 'max_depth': 5, 'max_leaves': 30, 'colsample_bytree': 0.66, 'subsample': 0.8300000000000001, 'reg_alpha': 6.24, 'reg_lambda': 7.95, 'gamma': 1.31}\n",
      "3it [00:04,  1.62s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.6119\n",
      "2th fold: XGBRegressor RMSE: 0.2093\n",
      "3th fold: XGBRegressor RMSE: 1.2953\n",
      "\n",
      "XGBRegressor average RMSE: 0.7055\n",
      "XGBRegressor worst RMSE: 1.2953\n",
      "Corresponding penalty value: 0.7645\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV3\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 2464, 'learning_rate': 0.00401, 'max_depth': 5, 'max_leaves': 30, 'colsample_bytree': 0.66, 'subsample': 0.8300000000000001, 'reg_alpha': 6.24, 'reg_lambda': 7.95, 'gamma': 1.31}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.087\n",
      "RMSE_crossval: 0.706\n",
      "RMSE_test: 0.703\n",
      "MAE_test: 0.458\n",
      "Nash-Sutcliffe Test: 0.970\n",
      "Kling-Gupta Test: 0.897\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 187.1201 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:45:36,064]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV51\u001b[0m\n",
      "3it [00:01,  1.76it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0102\n",
      "2th fold: XGBRegressor RMSE: 0.3813\n",
      "3th fold: XGBRegressor RMSE: 1.1455\n",
      "\n",
      "XGBRegressor average RMSE: 0.8456\n",
      "XGBRegressor worst RMSE: 1.1455\n",
      "Corresponding penalty value: 0.8756\n",
      "\u001b[32m[I 2025-03-31 13:45:37,767]\u001b[0m Trial 0 finished with value: 0.8756156390525504 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.5700000000000001, 'reg_alpha': 0.58, 'reg_lambda': 8.67, 'gamma': 3.0100000000000002}. Best is trial 0 with value: 0.8756156390525504.\u001b[0m\n",
      "3it [00:06,  2.27s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.8926\n",
      "2th fold: XGBRegressor RMSE: 0.3834\n",
      "3th fold: XGBRegressor RMSE: 1.1158\n",
      "\n",
      "XGBRegressor average RMSE: 0.7973\n",
      "XGBRegressor worst RMSE: 1.1158\n",
      "Corresponding penalty value: 0.8291\n",
      "\u001b[32m[I 2025-03-31 13:45:44,567]\u001b[0m Trial 1 finished with value: 0.8291234881639072 and parameters: {'n_estimators': 2270, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 1.83, 'reg_lambda': 3.04, 'gamma': 2.62}. Best is trial 1 with value: 0.8291234881639072.\u001b[0m\n",
      "3it [00:01,  1.51it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8396\n",
      "2th fold: XGBRegressor RMSE: 0.3253\n",
      "3th fold: XGBRegressor RMSE: 1.0661\n",
      "\n",
      "XGBRegressor average RMSE: 0.7437\n",
      "XGBRegressor worst RMSE: 1.0661\n",
      "Corresponding penalty value: 0.7759\n",
      "\u001b[32m[I 2025-03-31 13:45:46,559]\u001b[0m Trial 2 finished with value: 0.7759206093726211 and parameters: {'n_estimators': 1580, 'learning_rate': 0.02901, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.64, 'subsample': 0.6799999999999999, 'reg_alpha': 4.5600000000000005, 'reg_lambda': 7.8500000000000005, 'gamma': 1.0}. Best is trial 2 with value: 0.7759206093726211.\u001b[0m\n",
      "3it [00:02,  1.46it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.0485\n",
      "2th fold: XGBRegressor RMSE: 0.4605\n",
      "3th fold: XGBRegressor RMSE: 1.0383\n",
      "\n",
      "XGBRegressor average RMSE: 1.1824\n",
      "XGBRegressor worst RMSE: 2.0485\n",
      "Corresponding penalty value: 1.2690\n",
      "\u001b[32m[I 2025-03-31 13:45:48,615]\u001b[0m Trial 3 finished with value: 1.2690379126773164 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05901000000000001, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.53, 'reg_alpha': 9.49, 'reg_lambda': 9.66, 'gamma': 4.05}. Best is trial 2 with value: 0.7759206093726211.\u001b[0m\n",
      "3it [00:02,  1.23it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0003\n",
      "2th fold: XGBRegressor RMSE: 0.3697\n",
      "3th fold: XGBRegressor RMSE: 1.1272\n",
      "\n",
      "XGBRegressor average RMSE: 0.8324\n",
      "XGBRegressor worst RMSE: 1.1272\n",
      "Corresponding penalty value: 0.8619\n",
      "\u001b[32m[I 2025-03-31 13:45:51,066]\u001b[0m Trial 4 finished with value: 0.8619172444750369 and parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}. Best is trial 2 with value: 0.7759206093726211.\u001b[0m\n",
      "3it [00:02,  1.17it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9787\n",
      "2th fold: XGBRegressor RMSE: 0.3993\n",
      "3th fold: XGBRegressor RMSE: 1.1326\n",
      "\n",
      "XGBRegressor average RMSE: 0.8368\n",
      "XGBRegressor worst RMSE: 1.1326\n",
      "Corresponding penalty value: 0.8664\n",
      "\u001b[32m[I 2025-03-31 13:45:53,638]\u001b[0m Trial 5 finished with value: 0.8663986077568439 and parameters: {'n_estimators': 2156, 'learning_rate': 0.03101, 'max_depth': 6, 'max_leaves': 17, 'colsample_bytree': 0.59, 'subsample': 0.99, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'gamma': 4.48}. Best is trial 2 with value: 0.7759206093726211.\u001b[0m\n",
      "3it [00:02,  1.39it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5849\n",
      "2th fold: XGBRegressor RMSE: 0.6373\n",
      "3th fold: XGBRegressor RMSE: 1.0015\n",
      "\n",
      "XGBRegressor average RMSE: 1.0745\n",
      "XGBRegressor worst RMSE: 1.5849\n",
      "Corresponding penalty value: 1.1256\n",
      "\u001b[32m[I 2025-03-31 13:45:55,798]\u001b[0m Trial 6 finished with value: 1.1255863651495333 and parameters: {'n_estimators': 1995, 'learning_rate': 0.09201, 'max_depth': 1, 'max_leaves': 7, 'colsample_bytree': 0.52, 'subsample': 0.66, 'reg_alpha': 3.89, 'reg_lambda': 2.71, 'gamma': 4.15}. Best is trial 2 with value: 0.7759206093726211.\u001b[0m\n",
      "3it [00:01,  1.63it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5194\n",
      "2th fold: XGBRegressor RMSE: 0.3506\n",
      "3th fold: XGBRegressor RMSE: 1.0520\n",
      "\n",
      "XGBRegressor average RMSE: 0.6407\n",
      "XGBRegressor worst RMSE: 1.0520\n",
      "Corresponding penalty value: 0.6818\n",
      "\u001b[32m[I 2025-03-31 13:45:57,645]\u001b[0m Trial 7 finished with value: 0.6818118819702528 and parameters: {'n_estimators': 1392, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.9, 'subsample': 0.53, 'reg_alpha': 9.870000000000001, 'reg_lambda': 7.73, 'gamma': 0.99}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:00,  3.81it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7106\n",
      "2th fold: XGBRegressor RMSE: 0.3359\n",
      "3th fold: XGBRegressor RMSE: 1.1189\n",
      "\n",
      "XGBRegressor average RMSE: 0.7218\n",
      "XGBRegressor worst RMSE: 1.1189\n",
      "Corresponding penalty value: 0.7615\n",
      "\u001b[32m[I 2025-03-31 13:45:58,435]\u001b[0m Trial 8 finished with value: 0.7615164337100229 and parameters: {'n_estimators': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'max_leaves': 23, 'colsample_bytree': 0.89, 'subsample': 0.53, 'reg_alpha': 3.58, 'reg_lambda': 1.1500000000000001, 'gamma': 4.32}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:02,  1.32it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5878\n",
      "2th fold: XGBRegressor RMSE: 0.3355\n",
      "3th fold: XGBRegressor RMSE: 0.9192\n",
      "\n",
      "XGBRegressor average RMSE: 0.9475\n",
      "XGBRegressor worst RMSE: 1.5878\n",
      "Corresponding penalty value: 1.0115\n",
      "\u001b[32m[I 2025-03-31 13:46:00,710]\u001b[0m Trial 9 finished with value: 1.0115311302634167 and parameters: {'n_estimators': 2058, 'learning_rate': 0.033010000000000005, 'max_depth': 1, 'max_leaves': 11, 'colsample_bytree': 0.66, 'subsample': 0.87, 'reg_alpha': 6.38, 'reg_lambda': 8.88, 'gamma': 2.36}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:03,  1.05s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.2756\n",
      "2th fold: XGBRegressor RMSE: 0.3550\n",
      "3th fold: XGBRegressor RMSE: 0.8991\n",
      "\n",
      "XGBRegressor average RMSE: 0.8432\n",
      "XGBRegressor worst RMSE: 1.2756\n",
      "Corresponding penalty value: 0.8865\n",
      "\u001b[32m[I 2025-03-31 13:46:03,902]\u001b[0m Trial 10 finished with value: 0.8864516872529072 and parameters: {'n_estimators': 2863, 'learning_rate': 0.056010000000000004, 'max_depth': 4, 'max_leaves': 2, 'colsample_bytree': 1.0, 'subsample': 0.8500000000000001, 'reg_alpha': 9.74, 'reg_lambda': 6.24, 'gamma': 0.19}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:00,  3.94it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8794\n",
      "2th fold: XGBRegressor RMSE: 0.4313\n",
      "3th fold: XGBRegressor RMSE: 1.1531\n",
      "\n",
      "XGBRegressor average RMSE: 0.8213\n",
      "XGBRegressor worst RMSE: 1.1531\n",
      "Corresponding penalty value: 0.8544\n",
      "\u001b[32m[I 2025-03-31 13:46:04,715]\u001b[0m Trial 11 finished with value: 0.8544498287604833 and parameters: {'n_estimators': 512, 'learning_rate': 0.07501, 'max_depth': 4, 'max_leaves': 26, 'colsample_bytree': 0.9, 'subsample': 0.51, 'reg_alpha': 2.98, 'reg_lambda': 0.74, 'gamma': 5.0}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:00,  3.61it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8255\n",
      "2th fold: XGBRegressor RMSE: 0.3713\n",
      "3th fold: XGBRegressor RMSE: 1.1378\n",
      "\n",
      "XGBRegressor average RMSE: 0.7782\n",
      "XGBRegressor worst RMSE: 1.1378\n",
      "Corresponding penalty value: 0.8142\n",
      "\u001b[32m[I 2025-03-31 13:46:05,599]\u001b[0m Trial 12 finished with value: 0.8141734177324248 and parameters: {'n_estimators': 529, 'learning_rate': 0.07400999999999999, 'max_depth': 10, 'max_leaves': 30, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.64, 'reg_alpha': 6.28, 'reg_lambda': 5.63, 'gamma': 1.71}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  2.38it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6952\n",
      "2th fold: XGBRegressor RMSE: 0.3941\n",
      "3th fold: XGBRegressor RMSE: 1.1271\n",
      "\n",
      "XGBRegressor average RMSE: 0.7388\n",
      "XGBRegressor worst RMSE: 1.1271\n",
      "Corresponding penalty value: 0.7776\n",
      "\u001b[32m[I 2025-03-31 13:46:06,915]\u001b[0m Trial 13 finished with value: 0.7776442234415327 and parameters: {'n_estimators': 938, 'learning_rate': 0.04601, 'max_depth': 4, 'max_leaves': 23, 'colsample_bytree': 0.8, 'subsample': 0.51, 'reg_alpha': 6.57, 'reg_lambda': 3.71, 'gamma': 3.43}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:02,  1.48it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0335\n",
      "2th fold: XGBRegressor RMSE: 0.3215\n",
      "3th fold: XGBRegressor RMSE: 1.0978\n",
      "\n",
      "XGBRegressor average RMSE: 0.8176\n",
      "XGBRegressor worst RMSE: 1.0978\n",
      "Corresponding penalty value: 0.8456\n",
      "\u001b[32m[I 2025-03-31 13:46:08,993]\u001b[0m Trial 14 finished with value: 0.8456307721727929 and parameters: {'n_estimators': 1033, 'learning_rate': 0.01601, 'max_depth': 8, 'max_leaves': 12, 'colsample_bytree': 0.9299999999999999, 'subsample': 0.77, 'reg_alpha': 2.35, 'reg_lambda': 1.2, 'gamma': 0.26}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:00,  3.11it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6473\n",
      "2th fold: XGBRegressor RMSE: 0.4262\n",
      "3th fold: XGBRegressor RMSE: 0.9734\n",
      "\n",
      "XGBRegressor average RMSE: 1.0156\n",
      "XGBRegressor worst RMSE: 1.6473\n",
      "Corresponding penalty value: 1.0788\n",
      "\u001b[32m[I 2025-03-31 13:46:10,012]\u001b[0m Trial 15 finished with value: 1.0788074743254104 and parameters: {'n_estimators': 793, 'learning_rate': 0.07801, 'max_depth': 5, 'max_leaves': 2, 'colsample_bytree': 0.74, 'subsample': 0.6, 'reg_alpha': 8.63, 'reg_lambda': 6.71, 'gamma': 1.9100000000000001}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:03,  1.05s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.9131\n",
      "2th fold: XGBRegressor RMSE: 0.3645\n",
      "3th fold: XGBRegressor RMSE: 1.1640\n",
      "\n",
      "XGBRegressor average RMSE: 0.8139\n",
      "XGBRegressor worst RMSE: 1.1640\n",
      "Corresponding penalty value: 0.8489\n",
      "\u001b[32m[I 2025-03-31 13:46:13,217]\u001b[0m Trial 16 finished with value: 0.8489112091722728 and parameters: {'n_estimators': 2666, 'learning_rate': 0.04601, 'max_depth': 9, 'max_leaves': 22, 'colsample_bytree': 0.9, 'subsample': 0.6799999999999999, 'reg_alpha': 5.23, 'reg_lambda': 4.5, 'gamma': 0.86}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.80it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8743\n",
      "2th fold: XGBRegressor RMSE: 0.3615\n",
      "3th fold: XGBRegressor RMSE: 1.0998\n",
      "\n",
      "XGBRegressor average RMSE: 0.7785\n",
      "XGBRegressor worst RMSE: 1.0998\n",
      "Corresponding penalty value: 0.8107\n",
      "\u001b[32m[I 2025-03-31 13:46:14,939]\u001b[0m Trial 17 finished with value: 0.8106686867306733 and parameters: {'n_estimators': 1190, 'learning_rate': 0.02201, 'max_depth': 6, 'max_leaves': 8, 'colsample_bytree': 0.97, 'subsample': 0.74, 'reg_alpha': 3.65, 'reg_lambda': 7.36, 'gamma': 3.36}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.52it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6929\n",
      "2th fold: XGBRegressor RMSE: 0.3572\n",
      "3th fold: XGBRegressor RMSE: 1.0944\n",
      "\n",
      "XGBRegressor average RMSE: 0.7148\n",
      "XGBRegressor worst RMSE: 1.0944\n",
      "Corresponding penalty value: 0.7528\n",
      "\u001b[32m[I 2025-03-31 13:46:16,972]\u001b[0m Trial 18 finished with value: 0.7527767971599216 and parameters: {'n_estimators': 1698, 'learning_rate': 0.06601, 'max_depth': 3, 'max_leaves': 29, 'colsample_bytree': 0.8400000000000001, 'subsample': 0.55, 'reg_alpha': 7.9, 'reg_lambda': 1.79, 'gamma': 2.15}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.53it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6953\n",
      "2th fold: XGBRegressor RMSE: 0.3792\n",
      "3th fold: XGBRegressor RMSE: 1.1640\n",
      "\n",
      "XGBRegressor average RMSE: 0.7461\n",
      "XGBRegressor worst RMSE: 1.1640\n",
      "Corresponding penalty value: 0.7879\n",
      "\u001b[32m[I 2025-03-31 13:46:18,994]\u001b[0m Trial 19 finished with value: 0.7879267471245613 and parameters: {'n_estimators': 1688, 'learning_rate': 0.06601, 'max_depth': 3, 'max_leaves': 30, 'colsample_bytree': 0.75, 'subsample': 0.61, 'reg_alpha': 8.11, 'reg_lambda': 2.23, 'gamma': 1.92}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:02,  1.04it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7717\n",
      "2th fold: XGBRegressor RMSE: 0.3835\n",
      "3th fold: XGBRegressor RMSE: 1.0943\n",
      "\n",
      "XGBRegressor average RMSE: 0.7498\n",
      "XGBRegressor worst RMSE: 1.0943\n",
      "Corresponding penalty value: 0.7843\n",
      "\u001b[32m[I 2025-03-31 13:46:21,948]\u001b[0m Trial 20 finished with value: 0.7842832491611522 and parameters: {'n_estimators': 2480, 'learning_rate': 0.040010000000000004, 'max_depth': 3, 'max_leaves': 10, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.56, 'reg_alpha': 7.3500000000000005, 'reg_lambda': 0.11, 'gamma': 0.63}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.66it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7273\n",
      "2th fold: XGBRegressor RMSE: 0.3578\n",
      "3th fold: XGBRegressor RMSE: 1.1417\n",
      "\n",
      "XGBRegressor average RMSE: 0.7423\n",
      "XGBRegressor worst RMSE: 1.1417\n",
      "Corresponding penalty value: 0.7822\n",
      "\u001b[32m[I 2025-03-31 13:46:23,819]\u001b[0m Trial 21 finished with value: 0.7822465395887533 and parameters: {'n_estimators': 1453, 'learning_rate': 0.06501, 'max_depth': 7, 'max_leaves': 26, 'colsample_bytree': 0.87, 'subsample': 0.5, 'reg_alpha': 8.950000000000001, 'reg_lambda': 1.29, 'gamma': 2.52}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:02,  1.40it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7447\n",
      "2th fold: XGBRegressor RMSE: 0.3954\n",
      "3th fold: XGBRegressor RMSE: 1.1656\n",
      "\n",
      "XGBRegressor average RMSE: 0.7686\n",
      "XGBRegressor worst RMSE: 1.1656\n",
      "Corresponding penalty value: 0.8083\n",
      "\u001b[32m[I 2025-03-31 13:46:26,029]\u001b[0m Trial 22 finished with value: 0.8082893561515214 and parameters: {'n_estimators': 1836, 'learning_rate': 0.08401, 'max_depth': 5, 'max_leaves': 23, 'colsample_bytree': 0.79, 'subsample': 0.55, 'reg_alpha': 5.46, 'reg_lambda': 4.63, 'gamma': 1.43}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  2.87it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6849\n",
      "2th fold: XGBRegressor RMSE: 0.3600\n",
      "3th fold: XGBRegressor RMSE: 1.1359\n",
      "\n",
      "XGBRegressor average RMSE: 0.7269\n",
      "XGBRegressor worst RMSE: 1.1359\n",
      "Corresponding penalty value: 0.7678\n",
      "\u001b[32m[I 2025-03-31 13:46:27,134]\u001b[0m Trial 23 finished with value: 0.7678152762706602 and parameters: {'n_estimators': 780, 'learning_rate': 0.08800999999999999, 'max_depth': 8, 'max_leaves': 28, 'colsample_bytree': 0.95, 'subsample': 0.64, 'reg_alpha': 9.97, 'reg_lambda': 1.82, 'gamma': 3.5300000000000002}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  2.00it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4679\n",
      "2th fold: XGBRegressor RMSE: 0.4536\n",
      "3th fold: XGBRegressor RMSE: 1.0748\n",
      "\n",
      "XGBRegressor average RMSE: 0.6654\n",
      "XGBRegressor worst RMSE: 1.0748\n",
      "Corresponding penalty value: 0.7064\n",
      "\u001b[32m[I 2025-03-31 13:46:28,697]\u001b[0m Trial 24 finished with value: 0.7063753388723666 and parameters: {'n_estimators': 1297, 'learning_rate': 0.09901, 'max_depth': 2, 'max_leaves': 20, 'colsample_bytree': 0.87, 'subsample': 0.55, 'reg_alpha': 8.84, 'reg_lambda': 3.68, 'gamma': 2.29}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.94it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5413\n",
      "2th fold: XGBRegressor RMSE: 0.4073\n",
      "3th fold: XGBRegressor RMSE: 1.0944\n",
      "\n",
      "XGBRegressor average RMSE: 0.6810\n",
      "XGBRegressor worst RMSE: 1.0944\n",
      "Corresponding penalty value: 0.7224\n",
      "\u001b[32m[I 2025-03-31 13:46:30,305]\u001b[0m Trial 25 finished with value: 0.7223666868568239 and parameters: {'n_estimators': 1330, 'learning_rate': 0.05201000000000001, 'max_depth': 2, 'max_leaves': 15, 'colsample_bytree': 0.71, 'subsample': 0.62, 'reg_alpha': 8.73, 'reg_lambda': 3.64, 'gamma': 2.21}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.84it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6269\n",
      "2th fold: XGBRegressor RMSE: 0.4112\n",
      "3th fold: XGBRegressor RMSE: 1.0836\n",
      "\n",
      "XGBRegressor average RMSE: 0.7073\n",
      "XGBRegressor worst RMSE: 1.0836\n",
      "Corresponding penalty value: 0.7449\n",
      "\u001b[32m[I 2025-03-31 13:46:32,002]\u001b[0m Trial 26 finished with value: 0.7448976625332256 and parameters: {'n_estimators': 1297, 'learning_rate': 0.01901, 'max_depth': 2, 'max_leaves': 15, 'colsample_bytree': 0.71, 'subsample': 0.71, 'reg_alpha': 8.93, 'reg_lambda': 3.73, 'gamma': 2.87}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  2.28it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5149\n",
      "2th fold: XGBRegressor RMSE: 0.3651\n",
      "3th fold: XGBRegressor RMSE: 1.0829\n",
      "\n",
      "XGBRegressor average RMSE: 0.6543\n",
      "XGBRegressor worst RMSE: 1.0829\n",
      "Corresponding penalty value: 0.6972\n",
      "\u001b[32m[I 2025-03-31 13:46:33,381]\u001b[0m Trial 27 finished with value: 0.6971811383415365 and parameters: {'n_estimators': 1071, 'learning_rate': 0.03901, 'max_depth': 2, 'max_leaves': 5, 'colsample_bytree': 0.69, 'subsample': 0.61, 'reg_alpha': 7.15, 'reg_lambda': 5.15, 'gamma': 1.46}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  2.28it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6526\n",
      "2th fold: XGBRegressor RMSE: 0.4068\n",
      "3th fold: XGBRegressor RMSE: 1.0958\n",
      "\n",
      "XGBRegressor average RMSE: 0.7184\n",
      "XGBRegressor worst RMSE: 1.0958\n",
      "Corresponding penalty value: 0.7561\n",
      "\u001b[32m[I 2025-03-31 13:46:34,760]\u001b[0m Trial 28 finished with value: 0.7561242819459056 and parameters: {'n_estimators': 1075, 'learning_rate': 0.040010000000000004, 'max_depth': 2, 'max_leaves': 5, 'colsample_bytree': 0.66, 'subsample': 0.58, 'reg_alpha': 7.36, 'reg_lambda': 5.61, 'gamma': 1.48}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.78it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4583\n",
      "2th fold: XGBRegressor RMSE: 0.4297\n",
      "3th fold: XGBRegressor RMSE: 1.0586\n",
      "\n",
      "XGBRegressor average RMSE: 0.6489\n",
      "XGBRegressor worst RMSE: 1.0586\n",
      "Corresponding penalty value: 0.6898\n",
      "\u001b[32m[I 2025-03-31 13:46:36,514]\u001b[0m Trial 29 finished with value: 0.6898468634122407 and parameters: {'n_estimators': 1489, 'learning_rate': 0.09701, 'max_depth': 5, 'max_leaves': 4, 'colsample_bytree': 0.78, 'subsample': 0.79, 'reg_alpha': 7.09, 'reg_lambda': 7.83, 'gamma': 0.59}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.58it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5034\n",
      "2th fold: XGBRegressor RMSE: 0.4078\n",
      "3th fold: XGBRegressor RMSE: 1.0872\n",
      "\n",
      "XGBRegressor average RMSE: 0.6662\n",
      "XGBRegressor worst RMSE: 1.0872\n",
      "Corresponding penalty value: 0.7083\n",
      "\u001b[32m[I 2025-03-31 13:46:38,474]\u001b[0m Trial 30 finished with value: 0.7082622819166958 and parameters: {'n_estimators': 1500, 'learning_rate': 0.02501, 'max_depth': 5, 'max_leaves': 4, 'colsample_bytree': 0.78, 'subsample': 0.8200000000000001, 'reg_alpha': 5.88, 'reg_lambda': 8.17, 'gamma': 0.39}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  2.70it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8251\n",
      "2th fold: XGBRegressor RMSE: 0.3502\n",
      "3th fold: XGBRegressor RMSE: 1.0959\n",
      "\n",
      "XGBRegressor average RMSE: 0.7571\n",
      "XGBRegressor worst RMSE: 1.0959\n",
      "Corresponding penalty value: 0.7910\n",
      "\u001b[32m[I 2025-03-31 13:46:39,651]\u001b[0m Trial 31 finished with value: 0.790956680629175 and parameters: {'n_estimators': 882, 'learning_rate': 0.09401, 'max_depth': 6, 'max_leaves': 9, 'colsample_bytree': 0.86, 'subsample': 0.9299999999999999, 'reg_alpha': 7.19, 'reg_lambda': 6.9, 'gamma': 1.04}. Best is trial 7 with value: 0.6818118819702528.\u001b[0m\n",
      "3it [00:01,  1.82it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4764\n",
      "2th fold: XGBRegressor RMSE: 0.3921\n",
      "3th fold: XGBRegressor RMSE: 1.0420\n",
      "\n",
      "XGBRegressor average RMSE: 0.6368\n",
      "XGBRegressor worst RMSE: 1.0420\n",
      "Corresponding penalty value: 0.6773\n",
      "\u001b[32m[I 2025-03-31 13:46:41,366]\u001b[0m Trial 32 finished with value: 0.6773450549815123 and parameters: {'n_estimators': 1139, 'learning_rate': 0.09501, 'max_depth': 2, 'max_leaves': 4, 'colsample_bytree': 0.7, 'subsample': 0.79, 'reg_alpha': 9.26, 'reg_lambda': 8.0, 'gamma': 0.01}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  1.77it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6184\n",
      "2th fold: XGBRegressor RMSE: 0.4120\n",
      "3th fold: XGBRegressor RMSE: 1.0981\n",
      "\n",
      "XGBRegressor average RMSE: 0.7095\n",
      "XGBRegressor worst RMSE: 1.0981\n",
      "Corresponding penalty value: 0.7484\n",
      "\u001b[32m[I 2025-03-31 13:46:43,131]\u001b[0m Trial 33 finished with value: 0.7483506337730825 and parameters: {'n_estimators': 1102, 'learning_rate': 0.09901, 'max_depth': 3, 'max_leaves': 4, 'colsample_bytree': 0.7, 'subsample': 0.79, 'reg_alpha': 9.42, 'reg_lambda': 8.13, 'gamma': 0.0}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  1.61it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7182\n",
      "2th fold: XGBRegressor RMSE: 0.3258\n",
      "3th fold: XGBRegressor RMSE: 1.0938\n",
      "\n",
      "XGBRegressor average RMSE: 0.7126\n",
      "XGBRegressor worst RMSE: 1.0938\n",
      "Corresponding penalty value: 0.7507\n",
      "\u001b[32m[I 2025-03-31 13:46:45,067]\u001b[0m Trial 34 finished with value: 0.7507251210896371 and parameters: {'n_estimators': 1499, 'learning_rate': 0.03901, 'max_depth': 4, 'max_leaves': 6, 'colsample_bytree': 0.66, 'subsample': 0.72, 'reg_alpha': 4.58, 'reg_lambda': 7.57, 'gamma': 0.5700000000000001}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  2.54it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0230\n",
      "2th fold: XGBRegressor RMSE: 0.3529\n",
      "3th fold: XGBRegressor RMSE: 1.1481\n",
      "\n",
      "XGBRegressor average RMSE: 0.8414\n",
      "XGBRegressor worst RMSE: 1.1481\n",
      "Corresponding penalty value: 0.8720\n",
      "\u001b[32m[I 2025-03-31 13:46:46,318]\u001b[0m Trial 35 finished with value: 0.87203133873625 and parameters: {'n_estimators': 715, 'learning_rate': 0.00801, 'max_depth': 7, 'max_leaves': 3, 'colsample_bytree': 0.64, 'subsample': 0.8, 'reg_alpha': 8.14, 'reg_lambda': 9.82, 'gamma': 0.81}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  1.64it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7039\n",
      "2th fold: XGBRegressor RMSE: 0.3556\n",
      "3th fold: XGBRegressor RMSE: 1.0941\n",
      "\n",
      "XGBRegressor average RMSE: 0.7179\n",
      "XGBRegressor worst RMSE: 1.0941\n",
      "Corresponding penalty value: 0.7555\n",
      "\u001b[32m[I 2025-03-31 13:46:48,221]\u001b[0m Trial 36 finished with value: 0.755519300423412 and parameters: {'n_estimators': 1612, 'learning_rate': 0.08601, 'max_depth': 6, 'max_leaves': 7, 'colsample_bytree': 0.69, 'subsample': 0.89, 'reg_alpha': 6.8500000000000005, 'reg_lambda': 8.290000000000001, 'gamma': 1.23}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:02,  1.39it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7151\n",
      "2th fold: XGBRegressor RMSE: 0.3661\n",
      "3th fold: XGBRegressor RMSE: 0.8897\n",
      "\n",
      "XGBRegressor average RMSE: 0.9903\n",
      "XGBRegressor worst RMSE: 1.7151\n",
      "Corresponding penalty value: 1.0628\n",
      "\u001b[32m[I 2025-03-31 13:46:50,454]\u001b[0m Trial 37 finished with value: 1.0627710277252238 and parameters: {'n_estimators': 1840, 'learning_rate': 0.03101, 'max_depth': 1, 'max_leaves': 5, 'colsample_bytree': 0.62, 'subsample': 0.8300000000000001, 'reg_alpha': 1.06, 'reg_lambda': 8.700000000000001, 'gamma': 0.02}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  2.10it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0662\n",
      "2th fold: XGBRegressor RMSE: 0.4388\n",
      "3th fold: XGBRegressor RMSE: 1.1873\n",
      "\n",
      "XGBRegressor average RMSE: 0.8974\n",
      "XGBRegressor worst RMSE: 1.1873\n",
      "Corresponding penalty value: 0.9264\n",
      "\u001b[32m[I 2025-03-31 13:46:51,950]\u001b[0m Trial 38 finished with value: 0.9264025777726519 and parameters: {'n_estimators': 1192, 'learning_rate': 0.09201, 'max_depth': 5, 'max_leaves': 13, 'colsample_bytree': 0.76, 'subsample': 0.9199999999999999, 'reg_alpha': 9.200000000000001, 'reg_lambda': 6.140000000000001, 'gamma': 0.59}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  1.91it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8907\n",
      "2th fold: XGBRegressor RMSE: 0.3410\n",
      "3th fold: XGBRegressor RMSE: 1.1466\n",
      "\n",
      "XGBRegressor average RMSE: 0.7928\n",
      "XGBRegressor worst RMSE: 1.1466\n",
      "Corresponding penalty value: 0.8282\n",
      "\u001b[32m[I 2025-03-31 13:46:53,591]\u001b[0m Trial 39 finished with value: 0.8281568925881757 and parameters: {'n_estimators': 960, 'learning_rate': 0.01301, 'max_depth': 7, 'max_leaves': 8, 'colsample_bytree': 0.54, 'subsample': 0.77, 'reg_alpha': 8.44, 'reg_lambda': 7.21, 'gamma': 1.1}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  1.92it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.4009\n",
      "2th fold: XGBRegressor RMSE: 0.4018\n",
      "3th fold: XGBRegressor RMSE: 0.9536\n",
      "\n",
      "XGBRegressor average RMSE: 0.9188\n",
      "XGBRegressor worst RMSE: 1.4009\n",
      "Corresponding penalty value: 0.9670\n",
      "\u001b[32m[I 2025-03-31 13:46:55,224]\u001b[0m Trial 40 finished with value: 0.9670041535234049 and parameters: {'n_estimators': 1371, 'learning_rate': 0.035010000000000006, 'max_depth': 1, 'max_leaves': 6, 'colsample_bytree': 0.73, 'subsample': 0.69, 'reg_alpha': 9.55, 'reg_lambda': 9.120000000000001, 'gamma': 1.6}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  2.06it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5503\n",
      "2th fold: XGBRegressor RMSE: 0.4794\n",
      "3th fold: XGBRegressor RMSE: 1.0275\n",
      "\n",
      "XGBRegressor average RMSE: 0.6857\n",
      "XGBRegressor worst RMSE: 1.0275\n",
      "Corresponding penalty value: 0.7199\n",
      "\u001b[32m[I 2025-03-31 13:46:56,750]\u001b[0m Trial 41 finished with value: 0.7199159698433365 and parameters: {'n_estimators': 1244, 'learning_rate': 0.09901, 'max_depth': 2, 'max_leaves': 19, 'colsample_bytree': 0.8, 'subsample': 0.58, 'reg_alpha': 9.98, 'reg_lambda': 3.0300000000000002, 'gamma': 0.41000000000000003}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  1.86it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5275\n",
      "2th fold: XGBRegressor RMSE: 0.4328\n",
      "3th fold: XGBRegressor RMSE: 1.0532\n",
      "\n",
      "XGBRegressor average RMSE: 0.6712\n",
      "XGBRegressor worst RMSE: 1.0532\n",
      "Corresponding penalty value: 0.7094\n",
      "\u001b[32m[I 2025-03-31 13:46:58,434]\u001b[0m Trial 42 finished with value: 0.7093651909649881 and parameters: {'n_estimators': 1408, 'learning_rate': 0.09000999999999999, 'max_depth': 2, 'max_leaves': 18, 'colsample_bytree': 0.9199999999999999, 'subsample': 0.53, 'reg_alpha': 7.65, 'reg_lambda': 4.95, 'gamma': 0.84}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  1.70it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9655\n",
      "2th fold: XGBRegressor RMSE: 0.3146\n",
      "3th fold: XGBRegressor RMSE: 1.1774\n",
      "\n",
      "XGBRegressor average RMSE: 0.8192\n",
      "XGBRegressor worst RMSE: 1.1774\n",
      "Corresponding penalty value: 0.8550\n",
      "\u001b[32m[I 2025-03-31 13:47:00,275]\u001b[0m Trial 43 finished with value: 0.8549997138826015 and parameters: {'n_estimators': 1570, 'learning_rate': 0.08201, 'max_depth': 3, 'max_leaves': 3, 'colsample_bytree': 0.6799999999999999, 'subsample': 0.76, 'reg_alpha': 8.22, 'reg_lambda': 6.34, 'gamma': 2.77}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  2.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9574\n",
      "2th fold: XGBRegressor RMSE: 1.6043\n",
      "3th fold: XGBRegressor RMSE: 3.1243\n",
      "\n",
      "XGBRegressor average RMSE: 1.8953\n",
      "XGBRegressor worst RMSE: 3.1243\n",
      "Corresponding penalty value: 2.0182\n",
      "\u001b[32m[I 2025-03-31 13:47:01,721]\u001b[0m Trial 44 finished with value: 2.018228170745469 and parameters: {'n_estimators': 1131, 'learning_rate': 0.00101, 'max_depth': 1, 'max_leaves': 10, 'colsample_bytree': 0.77, 'subsample': 0.8, 'reg_alpha': 9.200000000000001, 'reg_lambda': 7.65, 'gamma': 1.86}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:00,  3.14it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4920\n",
      "2th fold: XGBRegressor RMSE: 0.4278\n",
      "3th fold: XGBRegressor RMSE: 1.0307\n",
      "\n",
      "XGBRegressor average RMSE: 0.6502\n",
      "XGBRegressor worst RMSE: 1.0307\n",
      "Corresponding penalty value: 0.6882\n",
      "\u001b[32m[I 2025-03-31 13:47:02,751]\u001b[0m Trial 45 finished with value: 0.6882241322337136 and parameters: {'n_estimators': 643, 'learning_rate': 0.026010000000000002, 'max_depth': 2, 'max_leaves': 20, 'colsample_bytree': 0.87, 'subsample': 0.53, 'reg_alpha': 8.56, 'reg_lambda': 5.54, 'gamma': 1.25}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:00,  3.62it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.9534\n",
      "2th fold: XGBRegressor RMSE: 0.3819\n",
      "3th fold: XGBRegressor RMSE: 0.9631\n",
      "\n",
      "XGBRegressor average RMSE: 1.0995\n",
      "XGBRegressor worst RMSE: 1.9534\n",
      "Corresponding penalty value: 1.1848\n",
      "\u001b[32m[I 2025-03-31 13:47:03,654]\u001b[0m Trial 46 finished with value: 1.1848427291336647 and parameters: {'n_estimators': 643, 'learning_rate': 0.02501, 'max_depth': 4, 'max_leaves': 2, 'colsample_bytree': 0.61, 'subsample': 0.73, 'reg_alpha': 6.890000000000001, 'reg_lambda': 5.91, 'gamma': 1.28}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:02,  1.32it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5378\n",
      "2th fold: XGBRegressor RMSE: 0.4394\n",
      "3th fold: XGBRegressor RMSE: 0.9308\n",
      "\n",
      "XGBRegressor average RMSE: 0.9693\n",
      "XGBRegressor worst RMSE: 1.5378\n",
      "Corresponding penalty value: 1.0262\n",
      "\u001b[32m[I 2025-03-31 13:47:06,001]\u001b[0m Trial 47 finished with value: 1.026181015090076 and parameters: {'n_estimators': 1974, 'learning_rate': 0.02701, 'max_depth': 1, 'max_leaves': 21, 'colsample_bytree': 0.8200000000000001, 'subsample': 0.53, 'reg_alpha': 5.89, 'reg_lambda': 5.21, 'gamma': 0.22}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  2.48it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9282\n",
      "2th fold: XGBRegressor RMSE: 0.3850\n",
      "3th fold: XGBRegressor RMSE: 1.1528\n",
      "\n",
      "XGBRegressor average RMSE: 0.8220\n",
      "XGBRegressor worst RMSE: 1.1528\n",
      "Corresponding penalty value: 0.8551\n",
      "\u001b[32m[I 2025-03-31 13:47:07,288]\u001b[0m Trial 48 finished with value: 0.8550923576960636 and parameters: {'n_estimators': 864, 'learning_rate': 0.04701, 'max_depth': 4, 'max_leaves': 17, 'colsample_bytree': 0.99, 'subsample': 0.8500000000000001, 'reg_alpha': 7.55, 'reg_lambda': 9.31, 'gamma': 0.71}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "3it [00:01,  3.00it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.7681\n",
      "2th fold: XGBRegressor RMSE: 0.3496\n",
      "3th fold: XGBRegressor RMSE: 1.0663\n",
      "\n",
      "XGBRegressor average RMSE: 0.7280\n",
      "XGBRegressor worst RMSE: 1.0663\n",
      "Corresponding penalty value: 0.7618\n",
      "\u001b[32m[I 2025-03-31 13:47:08,364]\u001b[0m Trial 49 finished with value: 0.7618234878430837 and parameters: {'n_estimators': 656, 'learning_rate': 0.03601000000000001, 'max_depth': 9, 'max_leaves': 7, 'colsample_bytree': 0.9199999999999999, 'subsample': 0.65, 'reg_alpha': 9.56, 'reg_lambda': 6.53, 'gamma': 1.05}. Best is trial 32 with value: 0.6773450549815123.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1139, 'learning_rate': 0.09501, 'max_depth': 2, 'max_leaves': 4, 'colsample_bytree': 0.7, 'subsample': 0.79, 'reg_alpha': 9.26, 'reg_lambda': 8.0, 'gamma': 0.01}\n",
      "3it [00:01,  1.84it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5210\n",
      "2th fold: XGBRegressor RMSE: 0.3939\n",
      "3th fold: XGBRegressor RMSE: 0.9732\n",
      "\n",
      "XGBRegressor average RMSE: 0.6294\n",
      "XGBRegressor worst RMSE: 0.9732\n",
      "Corresponding penalty value: 0.6638\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV51\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1139, 'learning_rate': 0.09501, 'max_depth': 2, 'max_leaves': 4, 'colsample_bytree': 0.7, 'subsample': 0.79, 'reg_alpha': 9.26, 'reg_lambda': 8.0, 'gamma': 0.01}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.106\n",
      "RMSE_crossval: 0.629\n",
      "RMSE_test: 0.427\n",
      "MAE_test: 0.338\n",
      "Nash-Sutcliffe Test: 0.990\n",
      "Kling-Gupta Test: 0.922\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 95.3735 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:47:11,432]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB4\u001b[0m\n",
      "3it [00:01,  1.81it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4186\n",
      "2th fold: XGBRegressor RMSE: 1.9769\n",
      "3th fold: XGBRegressor RMSE: 3.9400\n",
      "\n",
      "XGBRegressor average RMSE: 3.1118\n",
      "XGBRegressor worst RMSE: 3.9400\n",
      "Corresponding penalty value: 3.1947\n",
      "\u001b[32m[I 2025-03-31 13:47:13,088]\u001b[0m Trial 0 finished with value: 3.1946562100897324 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.5700000000000001, 'reg_alpha': 0.58, 'reg_lambda': 8.67, 'gamma': 3.0100000000000002}. Best is trial 0 with value: 3.1946562100897324.\u001b[0m\n",
      "3it [00:07,  2.38s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.4039\n",
      "2th fold: XGBRegressor RMSE: 1.8094\n",
      "3th fold: XGBRegressor RMSE: 3.9976\n",
      "\n",
      "XGBRegressor average RMSE: 3.0703\n",
      "XGBRegressor worst RMSE: 3.9976\n",
      "Corresponding penalty value: 3.1630\n",
      "\u001b[32m[I 2025-03-31 13:47:20,243]\u001b[0m Trial 1 finished with value: 3.163010333576416 and parameters: {'n_estimators': 2270, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 1.83, 'reg_lambda': 3.04, 'gamma': 2.62}. Best is trial 1 with value: 3.163010333576416.\u001b[0m\n",
      "3it [00:02,  1.41it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5159\n",
      "2th fold: XGBRegressor RMSE: 1.9572\n",
      "3th fold: XGBRegressor RMSE: 4.0093\n",
      "\n",
      "XGBRegressor average RMSE: 3.1608\n",
      "XGBRegressor worst RMSE: 4.0093\n",
      "Corresponding penalty value: 3.2457\n",
      "\u001b[32m[I 2025-03-31 13:47:22,367]\u001b[0m Trial 2 finished with value: 3.2456545064098306 and parameters: {'n_estimators': 1580, 'learning_rate': 0.02901, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.64, 'subsample': 0.6799999999999999, 'reg_alpha': 4.5600000000000005, 'reg_lambda': 7.8500000000000005, 'gamma': 1.0}. Best is trial 1 with value: 3.163010333576416.\u001b[0m\n",
      "3it [00:02,  1.47it/s]\n",
      "1th fold: XGBRegressor RMSE: 4.1647\n",
      "2th fold: XGBRegressor RMSE: 2.8467\n",
      "3th fold: XGBRegressor RMSE: 4.1798\n",
      "\n",
      "XGBRegressor average RMSE: 3.7304\n",
      "XGBRegressor worst RMSE: 4.1798\n",
      "Corresponding penalty value: 3.7753\n",
      "\u001b[32m[I 2025-03-31 13:47:24,405]\u001b[0m Trial 3 finished with value: 3.7753259307580174 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05901000000000001, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.53, 'reg_alpha': 9.49, 'reg_lambda': 9.66, 'gamma': 4.05}. Best is trial 1 with value: 3.163010333576416.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1798\n",
      "2th fold: XGBRegressor RMSE: 1.9006\n",
      "3th fold: XGBRegressor RMSE: 3.8642\n",
      "\n",
      "XGBRegressor average RMSE: 2.9815\n",
      "XGBRegressor worst RMSE: 3.8642\n",
      "Corresponding penalty value: 3.0698\n",
      "\u001b[32m[I 2025-03-31 13:47:27,329]\u001b[0m Trial 4 finished with value: 3.0698098591885654 and parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.19it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4318\n",
      "2th fold: XGBRegressor RMSE: 1.9613\n",
      "3th fold: XGBRegressor RMSE: 3.9119\n",
      "\n",
      "XGBRegressor average RMSE: 3.1017\n",
      "XGBRegressor worst RMSE: 3.9119\n",
      "Corresponding penalty value: 3.1827\n",
      "\u001b[32m[I 2025-03-31 13:47:29,857]\u001b[0m Trial 5 finished with value: 3.1826768267845513 and parameters: {'n_estimators': 2156, 'learning_rate': 0.03101, 'max_depth': 6, 'max_leaves': 17, 'colsample_bytree': 0.59, 'subsample': 0.99, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'gamma': 4.48}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.37it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.9369\n",
      "2th fold: XGBRegressor RMSE: 2.9339\n",
      "3th fold: XGBRegressor RMSE: 4.3229\n",
      "\n",
      "XGBRegressor average RMSE: 3.7312\n",
      "XGBRegressor worst RMSE: 4.3229\n",
      "Corresponding penalty value: 3.7904\n",
      "\u001b[32m[I 2025-03-31 13:47:32,044]\u001b[0m Trial 6 finished with value: 3.790393588924214 and parameters: {'n_estimators': 1995, 'learning_rate': 0.09201, 'max_depth': 1, 'max_leaves': 7, 'colsample_bytree': 0.52, 'subsample': 0.66, 'reg_alpha': 3.89, 'reg_lambda': 2.71, 'gamma': 4.15}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  1.54it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4044\n",
      "2th fold: XGBRegressor RMSE: 2.2213\n",
      "3th fold: XGBRegressor RMSE: 4.0484\n",
      "\n",
      "XGBRegressor average RMSE: 3.2247\n",
      "XGBRegressor worst RMSE: 4.0484\n",
      "Corresponding penalty value: 3.3070\n",
      "\u001b[32m[I 2025-03-31 13:47:33,995]\u001b[0m Trial 7 finished with value: 3.307037092243447 and parameters: {'n_estimators': 1392, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.9, 'subsample': 0.53, 'reg_alpha': 9.870000000000001, 'reg_lambda': 7.73, 'gamma': 0.99}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:00,  3.88it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5750\n",
      "2th fold: XGBRegressor RMSE: 2.1810\n",
      "3th fold: XGBRegressor RMSE: 3.9883\n",
      "\n",
      "XGBRegressor average RMSE: 3.2481\n",
      "XGBRegressor worst RMSE: 3.9883\n",
      "Corresponding penalty value: 3.3221\n",
      "\u001b[32m[I 2025-03-31 13:47:34,771]\u001b[0m Trial 8 finished with value: 3.3221095844583077 and parameters: {'n_estimators': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'max_leaves': 23, 'colsample_bytree': 0.89, 'subsample': 0.53, 'reg_alpha': 3.58, 'reg_lambda': 1.1500000000000001, 'gamma': 4.32}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.27it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.9945\n",
      "2th fold: XGBRegressor RMSE: 2.8667\n",
      "3th fold: XGBRegressor RMSE: 4.1363\n",
      "\n",
      "XGBRegressor average RMSE: 3.6658\n",
      "XGBRegressor worst RMSE: 4.1363\n",
      "Corresponding penalty value: 3.7129\n",
      "\u001b[32m[I 2025-03-31 13:47:37,130]\u001b[0m Trial 9 finished with value: 3.7128647039489007 and parameters: {'n_estimators': 2058, 'learning_rate': 0.033010000000000005, 'max_depth': 1, 'max_leaves': 11, 'colsample_bytree': 0.66, 'subsample': 0.87, 'reg_alpha': 6.38, 'reg_lambda': 8.88, 'gamma': 2.36}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:07,  2.48s/it]\n",
      "1th fold: XGBRegressor RMSE: 4.1710\n",
      "2th fold: XGBRegressor RMSE: 2.8242\n",
      "3th fold: XGBRegressor RMSE: 5.4279\n",
      "\n",
      "XGBRegressor average RMSE: 4.1410\n",
      "XGBRegressor worst RMSE: 5.4279\n",
      "Corresponding penalty value: 4.2697\n",
      "\u001b[32m[I 2025-03-31 13:47:44,620]\u001b[0m Trial 10 finished with value: 4.269719940728683 and parameters: {'n_estimators': 2863, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 12, 'colsample_bytree': 0.77, 'subsample': 0.81, 'reg_alpha': 0.15, 'reg_lambda': 6.140000000000001, 'gamma': 0.23}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:03,  1.10s/it]\n",
      "1th fold: XGBRegressor RMSE: 2.4765\n",
      "2th fold: XGBRegressor RMSE: 1.8754\n",
      "3th fold: XGBRegressor RMSE: 4.5244\n",
      "\n",
      "XGBRegressor average RMSE: 2.9588\n",
      "XGBRegressor worst RMSE: 4.5244\n",
      "Corresponding penalty value: 3.1153\n",
      "\u001b[32m[I 2025-03-31 13:47:47,970]\u001b[0m Trial 11 finished with value: 3.115341517206988 and parameters: {'n_estimators': 814, 'learning_rate': 0.00101, 'max_depth': 10, 'max_leaves': 28, 'colsample_bytree': 0.73, 'subsample': 0.6799999999999999, 'reg_alpha': 1.99, 'reg_lambda': 4.2700000000000005, 'gamma': 2.2800000000000002}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  1.61it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5365\n",
      "2th fold: XGBRegressor RMSE: 1.9481\n",
      "3th fold: XGBRegressor RMSE: 4.0554\n",
      "\n",
      "XGBRegressor average RMSE: 3.1800\n",
      "XGBRegressor worst RMSE: 4.0554\n",
      "Corresponding penalty value: 3.2676\n",
      "\u001b[32m[I 2025-03-31 13:47:49,884]\u001b[0m Trial 12 finished with value: 3.267565898794334 and parameters: {'n_estimators': 830, 'learning_rate': 0.01401, 'max_depth': 10, 'max_leaves': 30, 'colsample_bytree': 0.78, 'subsample': 0.75, 'reg_alpha': 2.35, 'reg_lambda': 5.2, 'gamma': 1.69}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.29it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.6504\n",
      "2th fold: XGBRegressor RMSE: 1.8336\n",
      "3th fold: XGBRegressor RMSE: 3.7894\n",
      "\n",
      "XGBRegressor average RMSE: 3.0911\n",
      "XGBRegressor worst RMSE: 3.7894\n",
      "Corresponding penalty value: 3.1610\n",
      "\u001b[32m[I 2025-03-31 13:47:51,246]\u001b[0m Trial 13 finished with value: 3.160962930195626 and parameters: {'n_estimators': 987, 'learning_rate': 0.05501, 'max_depth': 4, 'max_leaves': 13, 'colsample_bytree': 0.71, 'subsample': 0.7, 'reg_alpha': 1.99, 'reg_lambda': 3.79, 'gamma': 1.86}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.33it/s]\n",
      "1th fold: XGBRegressor RMSE: 4.1196\n",
      "2th fold: XGBRegressor RMSE: 2.6418\n",
      "3th fold: XGBRegressor RMSE: 4.2166\n",
      "\n",
      "XGBRegressor average RMSE: 3.6594\n",
      "XGBRegressor worst RMSE: 4.2166\n",
      "Corresponding penalty value: 3.7151\n",
      "\u001b[32m[I 2025-03-31 13:47:52,588]\u001b[0m Trial 14 finished with value: 3.715086895474089 and parameters: {'n_estimators': 1088, 'learning_rate': 0.015009999999999999, 'max_depth': 9, 'max_leaves': 2, 'colsample_bytree': 1.0, 'subsample': 0.8500000000000001, 'reg_alpha': 0.74, 'reg_lambda': 6.32, 'gamma': 3.39}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.25it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.8338\n",
      "2th fold: XGBRegressor RMSE: 2.0269\n",
      "3th fold: XGBRegressor RMSE: 3.7859\n",
      "\n",
      "XGBRegressor average RMSE: 3.2155\n",
      "XGBRegressor worst RMSE: 3.8338\n",
      "Corresponding penalty value: 3.2773\n",
      "\u001b[32m[I 2025-03-31 13:47:53,977]\u001b[0m Trial 15 finished with value: 3.277343450710315 and parameters: {'n_estimators': 550, 'learning_rate': 0.01401, 'max_depth': 4, 'max_leaves': 24, 'colsample_bytree': 0.8200000000000001, 'subsample': 0.76, 'reg_alpha': 2.85, 'reg_lambda': 0.15, 'gamma': 1.27}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.50it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.6811\n",
      "2th fold: XGBRegressor RMSE: 1.8088\n",
      "3th fold: XGBRegressor RMSE: 4.0306\n",
      "\n",
      "XGBRegressor average RMSE: 3.1735\n",
      "XGBRegressor worst RMSE: 4.0306\n",
      "Corresponding penalty value: 3.2592\n",
      "\u001b[32m[I 2025-03-31 13:47:56,035]\u001b[0m Trial 16 finished with value: 3.2591821644814774 and parameters: {'n_estimators': 1254, 'learning_rate': 0.041010000000000005, 'max_depth': 8, 'max_leaves': 30, 'colsample_bytree': 0.5, 'subsample': 0.63, 'reg_alpha': 5.7700000000000005, 'reg_lambda': 4.15, 'gamma': 0.06}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.80it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5759\n",
      "2th fold: XGBRegressor RMSE: 1.9916\n",
      "3th fold: XGBRegressor RMSE: 3.9283\n",
      "\n",
      "XGBRegressor average RMSE: 3.1653\n",
      "XGBRegressor worst RMSE: 3.9283\n",
      "Corresponding penalty value: 3.2416\n",
      "\u001b[32m[I 2025-03-31 13:47:57,164]\u001b[0m Trial 17 finished with value: 3.2415861326089526 and parameters: {'n_estimators': 799, 'learning_rate': 0.07101, 'max_depth': 9, 'max_leaves': 21, 'colsample_bytree': 0.7, 'subsample': 0.95, 'reg_alpha': 1.26, 'reg_lambda': 6.43, 'gamma': 2.16}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:04,  1.40s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.4895\n",
      "2th fold: XGBRegressor RMSE: 2.1317\n",
      "3th fold: XGBRegressor RMSE: 4.1679\n",
      "\n",
      "XGBRegressor average RMSE: 3.2630\n",
      "XGBRegressor worst RMSE: 4.1679\n",
      "Corresponding penalty value: 3.3535\n",
      "\u001b[32m[I 2025-03-31 13:48:01,417]\u001b[0m Trial 18 finished with value: 3.3535212273427906 and parameters: {'n_estimators': 2599, 'learning_rate': 0.00801, 'max_depth': 3, 'max_leaves': 15, 'colsample_bytree': 0.8500000000000001, 'subsample': 0.74, 'reg_alpha': 0.07, 'reg_lambda': 1.74, 'gamma': 0.68}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  1.59it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.3501\n",
      "2th fold: XGBRegressor RMSE: 2.2064\n",
      "3th fold: XGBRegressor RMSE: 4.0060\n",
      "\n",
      "XGBRegressor average RMSE: 3.1875\n",
      "XGBRegressor worst RMSE: 4.0060\n",
      "Corresponding penalty value: 3.2693\n",
      "\u001b[32m[I 2025-03-31 13:48:03,365]\u001b[0m Trial 19 finished with value: 3.269347028748055 and parameters: {'n_estimators': 1183, 'learning_rate': 0.02001, 'max_depth': 7, 'max_leaves': 26, 'colsample_bytree': 0.97, 'subsample': 0.8200000000000001, 'reg_alpha': 3.47, 'reg_lambda': 4.88, 'gamma': 3.44}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.82it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.3311\n",
      "2th fold: XGBRegressor RMSE: 1.9168\n",
      "3th fold: XGBRegressor RMSE: 4.1169\n",
      "\n",
      "XGBRegressor average RMSE: 3.1216\n",
      "XGBRegressor worst RMSE: 4.1169\n",
      "Corresponding penalty value: 3.2211\n",
      "\u001b[32m[I 2025-03-31 13:48:04,487]\u001b[0m Trial 20 finished with value: 3.22113091403268 and parameters: {'n_estimators': 758, 'learning_rate': 0.04401, 'max_depth': 5, 'max_leaves': 9, 'colsample_bytree': 0.7, 'subsample': 0.9, 'reg_alpha': 1.3800000000000001, 'reg_lambda': 7.01, 'gamma': 4.97}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.37it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.7531\n",
      "2th fold: XGBRegressor RMSE: 2.0272\n",
      "3th fold: XGBRegressor RMSE: 4.1784\n",
      "\n",
      "XGBRegressor average RMSE: 3.3196\n",
      "XGBRegressor worst RMSE: 4.1784\n",
      "Corresponding penalty value: 3.4055\n",
      "\u001b[32m[I 2025-03-31 13:48:05,810]\u001b[0m Trial 21 finished with value: 3.405467535870672 and parameters: {'n_estimators': 987, 'learning_rate': 0.05501, 'max_depth': 3, 'max_leaves': 14, 'colsample_bytree': 0.71, 'subsample': 0.71, 'reg_alpha': 2.33, 'reg_lambda': 3.8200000000000003, 'gamma': 1.72}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.37it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.6514\n",
      "2th fold: XGBRegressor RMSE: 1.9737\n",
      "3th fold: XGBRegressor RMSE: 3.8017\n",
      "\n",
      "XGBRegressor average RMSE: 3.1423\n",
      "XGBRegressor worst RMSE: 3.8017\n",
      "Corresponding penalty value: 3.2082\n",
      "\u001b[32m[I 2025-03-31 13:48:07,133]\u001b[0m Trial 22 finished with value: 3.208235025709917 and parameters: {'n_estimators': 971, 'learning_rate': 0.06501, 'max_depth': 5, 'max_leaves': 13, 'colsample_bytree': 0.73, 'subsample': 0.62, 'reg_alpha': 1.58, 'reg_lambda': 5.21, 'gamma': 1.8}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.48it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5850\n",
      "2th fold: XGBRegressor RMSE: 2.0120\n",
      "3th fold: XGBRegressor RMSE: 4.1373\n",
      "\n",
      "XGBRegressor average RMSE: 3.2448\n",
      "XGBRegressor worst RMSE: 4.1373\n",
      "Corresponding penalty value: 3.3340\n",
      "\u001b[32m[I 2025-03-31 13:48:09,221]\u001b[0m Trial 23 finished with value: 3.3340150427961732 and parameters: {'n_estimators': 1728, 'learning_rate': 0.04401, 'max_depth': 3, 'max_leaves': 16, 'colsample_bytree': 0.65, 'subsample': 0.7, 'reg_alpha': 4.47, 'reg_lambda': 4.23, 'gamma': 2.81}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  1.96it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4559\n",
      "2th fold: XGBRegressor RMSE: 1.9205\n",
      "3th fold: XGBRegressor RMSE: 4.0549\n",
      "\n",
      "XGBRegressor average RMSE: 3.1438\n",
      "XGBRegressor worst RMSE: 4.0549\n",
      "Corresponding penalty value: 3.2349\n",
      "\u001b[32m[I 2025-03-31 13:48:10,815]\u001b[0m Trial 24 finished with value: 3.234909143654991 and parameters: {'n_estimators': 1302, 'learning_rate': 0.07701, 'max_depth': 7, 'max_leaves': 9, 'colsample_bytree': 0.54, 'subsample': 0.77, 'reg_alpha': 2.95, 'reg_lambda': 2.7, 'gamma': 1.99}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.94it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.8041\n",
      "2th fold: XGBRegressor RMSE: 2.0063\n",
      "3th fold: XGBRegressor RMSE: 3.7662\n",
      "\n",
      "XGBRegressor average RMSE: 3.1922\n",
      "XGBRegressor worst RMSE: 3.8041\n",
      "Corresponding penalty value: 3.2534\n",
      "\u001b[32m[I 2025-03-31 13:48:11,901]\u001b[0m Trial 25 finished with value: 3.2534084424753953 and parameters: {'n_estimators': 689, 'learning_rate': 0.050010000000000006, 'max_depth': 4, 'max_leaves': 18, 'colsample_bytree': 0.8, 'subsample': 0.65, 'reg_alpha': 0.9, 'reg_lambda': 1.74, 'gamma': 1.35}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5365\n",
      "2th fold: XGBRegressor RMSE: 1.8648\n",
      "3th fold: XGBRegressor RMSE: 4.0090\n",
      "\n",
      "XGBRegressor average RMSE: 3.1368\n",
      "XGBRegressor worst RMSE: 4.0090\n",
      "Corresponding penalty value: 3.2240\n",
      "\u001b[32m[I 2025-03-31 13:48:14,514]\u001b[0m Trial 26 finished with value: 3.2239794770510932 and parameters: {'n_estimators': 981, 'learning_rate': 0.00601, 'max_depth': 9, 'max_leaves': 11, 'colsample_bytree': 0.63, 'subsample': 0.7, 'reg_alpha': 2.15, 'reg_lambda': 3.29, 'gamma': 0.67}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.37it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.7944\n",
      "2th fold: XGBRegressor RMSE: 2.6652\n",
      "3th fold: XGBRegressor RMSE: 3.8780\n",
      "\n",
      "XGBRegressor average RMSE: 3.1125\n",
      "XGBRegressor worst RMSE: 3.8780\n",
      "Corresponding penalty value: 3.1891\n",
      "\u001b[32m[I 2025-03-31 13:48:16,771]\u001b[0m Trial 27 finished with value: 3.189080524830448 and parameters: {'n_estimators': 1542, 'learning_rate': 0.02301, 'max_depth': 6, 'max_leaves': 3, 'colsample_bytree': 0.75, 'subsample': 0.79, 'reg_alpha': 2.81, 'reg_lambda': 5.63, 'gamma': 1.42}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  2.02it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1086\n",
      "2th fold: XGBRegressor RMSE: 2.4118\n",
      "3th fold: XGBRegressor RMSE: 4.1003\n",
      "\n",
      "XGBRegressor average RMSE: 3.2069\n",
      "XGBRegressor worst RMSE: 4.1003\n",
      "Corresponding penalty value: 3.2962\n",
      "\u001b[32m[I 2025-03-31 13:48:18,320]\u001b[0m Trial 28 finished with value: 3.2962170284569163 and parameters: {'n_estimators': 1161, 'learning_rate': 0.03801, 'max_depth': 2, 'max_leaves': 21, 'colsample_bytree': 0.67, 'subsample': 0.72, 'reg_alpha': 5.24, 'reg_lambda': 4.5, 'gamma': 2.34}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  1.71it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4896\n",
      "2th fold: XGBRegressor RMSE: 1.8799\n",
      "3th fold: XGBRegressor RMSE: 3.8628\n",
      "\n",
      "XGBRegressor average RMSE: 3.0775\n",
      "XGBRegressor worst RMSE: 3.8628\n",
      "Corresponding penalty value: 3.1560\n",
      "\u001b[32m[I 2025-03-31 13:48:20,137]\u001b[0m Trial 29 finished with value: 3.15599709815502 and parameters: {'n_estimators': 1458, 'learning_rate': 0.06101, 'max_depth': 10, 'max_leaves': 15, 'colsample_bytree': 0.55, 'subsample': 0.59, 'reg_alpha': 0.44, 'reg_lambda': 7.55, 'gamma': 3.0}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  1.78it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5855\n",
      "2th fold: XGBRegressor RMSE: 2.0190\n",
      "3th fold: XGBRegressor RMSE: 4.0193\n",
      "\n",
      "XGBRegressor average RMSE: 3.2079\n",
      "XGBRegressor worst RMSE: 4.0193\n",
      "Corresponding penalty value: 3.2891\n",
      "\u001b[32m[I 2025-03-31 13:48:21,888]\u001b[0m Trial 30 finished with value: 3.2890540338870364 and parameters: {'n_estimators': 1472, 'learning_rate': 0.08501, 'max_depth': 10, 'max_leaves': 20, 'colsample_bytree': 0.54, 'subsample': 0.58, 'reg_alpha': 0.01, 'reg_lambda': 8.2, 'gamma': 3.35}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.50it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4352\n",
      "2th fold: XGBRegressor RMSE: 1.8990\n",
      "3th fold: XGBRegressor RMSE: 3.8696\n",
      "\n",
      "XGBRegressor average RMSE: 3.0679\n",
      "XGBRegressor worst RMSE: 3.8696\n",
      "Corresponding penalty value: 3.1481\n",
      "\u001b[32m[I 2025-03-31 13:48:23,955]\u001b[0m Trial 31 finished with value: 3.1480911652070507 and parameters: {'n_estimators': 1654, 'learning_rate': 0.06101, 'max_depth': 9, 'max_leaves': 15, 'colsample_bytree': 0.55, 'subsample': 0.6, 'reg_alpha': 0.65, 'reg_lambda': 8.53, 'gamma': 3.0}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.47it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4693\n",
      "2th fold: XGBRegressor RMSE: 1.9760\n",
      "3th fold: XGBRegressor RMSE: 3.8801\n",
      "\n",
      "XGBRegressor average RMSE: 3.1085\n",
      "XGBRegressor worst RMSE: 3.8801\n",
      "Corresponding penalty value: 3.1856\n",
      "\u001b[32m[I 2025-03-31 13:48:26,059]\u001b[0m Trial 32 finished with value: 3.1856246734515903 and parameters: {'n_estimators': 1727, 'learning_rate': 0.06301, 'max_depth': 10, 'max_leaves': 16, 'colsample_bytree': 0.55, 'subsample': 0.61, 'reg_alpha': 0.68, 'reg_lambda': 8.85, 'gamma': 3.0100000000000002}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:01,  1.86it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.7302\n",
      "2th fold: XGBRegressor RMSE: 2.0555\n",
      "3th fold: XGBRegressor RMSE: 3.8894\n",
      "\n",
      "XGBRegressor average RMSE: 3.2250\n",
      "XGBRegressor worst RMSE: 3.8894\n",
      "Corresponding penalty value: 3.2915\n",
      "\u001b[32m[I 2025-03-31 13:48:27,739]\u001b[0m Trial 33 finished with value: 3.291471121109402 and parameters: {'n_estimators': 1357, 'learning_rate': 0.07101, 'max_depth': 8, 'max_leaves': 15, 'colsample_bytree': 0.6, 'subsample': 0.5700000000000001, 'reg_alpha': 1.2, 'reg_lambda': 9.99, 'gamma': 2.71}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.46it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4533\n",
      "2th fold: XGBRegressor RMSE: 1.9197\n",
      "3th fold: XGBRegressor RMSE: 3.9453\n",
      "\n",
      "XGBRegressor average RMSE: 3.1061\n",
      "XGBRegressor worst RMSE: 3.9453\n",
      "Corresponding penalty value: 3.1900\n",
      "\u001b[32m[I 2025-03-31 13:48:29,862]\u001b[0m Trial 34 finished with value: 3.190043919355792 and parameters: {'n_estimators': 1852, 'learning_rate': 0.09901, 'max_depth': 9, 'max_leaves': 18, 'colsample_bytree': 0.56, 'subsample': 0.65, 'reg_alpha': 0.59, 'reg_lambda': 7.28, 'gamma': 3.74}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:03,  1.12s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1926\n",
      "2th fold: XGBRegressor RMSE: 1.7880\n",
      "3th fold: XGBRegressor RMSE: 3.9904\n",
      "\n",
      "XGBRegressor average RMSE: 2.9903\n",
      "XGBRegressor worst RMSE: 3.9904\n",
      "Corresponding penalty value: 3.0903\n",
      "\u001b[32m[I 2025-03-31 13:48:33,287]\u001b[0m Trial 35 finished with value: 3.0903387376507374 and parameters: {'n_estimators': 1625, 'learning_rate': 0.00601, 'max_depth': 10, 'max_leaves': 27, 'colsample_bytree': 0.5, 'subsample': 0.51, 'reg_alpha': 1.6, 'reg_lambda': 8.32, 'gamma': 2.56}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:04,  1.36s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1969\n",
      "2th fold: XGBRegressor RMSE: 1.7853\n",
      "3th fold: XGBRegressor RMSE: 3.9921\n",
      "\n",
      "XGBRegressor average RMSE: 2.9914\n",
      "XGBRegressor worst RMSE: 3.9921\n",
      "Corresponding penalty value: 3.0915\n",
      "\u001b[32m[I 2025-03-31 13:48:37,425]\u001b[0m Trial 36 finished with value: 3.091515707926292 and parameters: {'n_estimators': 2384, 'learning_rate': 0.00601, 'max_depth': 8, 'max_leaves': 26, 'colsample_bytree': 0.5, 'subsample': 0.51, 'reg_alpha': 1.71, 'reg_lambda': 8.290000000000001, 'gamma': 2.48}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:03,  1.30s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1818\n",
      "2th fold: XGBRegressor RMSE: 1.7936\n",
      "3th fold: XGBRegressor RMSE: 3.9608\n",
      "\n",
      "XGBRegressor average RMSE: 2.9787\n",
      "XGBRegressor worst RMSE: 3.9608\n",
      "Corresponding penalty value: 3.0769\n",
      "\u001b[32m[I 2025-03-31 13:48:41,406]\u001b[0m Trial 37 finished with value: 3.0769262933795942 and parameters: {'n_estimators': 2307, 'learning_rate': 0.00601, 'max_depth': 7, 'max_leaves': 28, 'colsample_bytree': 0.5, 'subsample': 0.51, 'reg_alpha': 7.5, 'reg_lambda': 9.51, 'gamma': 2.58}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:04,  1.34s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1752\n",
      "2th fold: XGBRegressor RMSE: 1.7831\n",
      "3th fold: XGBRegressor RMSE: 3.9702\n",
      "\n",
      "XGBRegressor average RMSE: 2.9762\n",
      "XGBRegressor worst RMSE: 3.9702\n",
      "Corresponding penalty value: 3.0756\n",
      "\u001b[32m[I 2025-03-31 13:48:45,482]\u001b[0m Trial 38 finished with value: 3.075576396746011 and parameters: {'n_estimators': 2375, 'learning_rate': 0.00601, 'max_depth': 7, 'max_leaves': 26, 'colsample_bytree': 0.5, 'subsample': 0.5, 'reg_alpha': 8.11, 'reg_lambda': 8.99, 'gamma': 2.61}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.01it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5858\n",
      "2th fold: XGBRegressor RMSE: 1.9004\n",
      "3th fold: XGBRegressor RMSE: 3.9578\n",
      "\n",
      "XGBRegressor average RMSE: 3.1480\n",
      "XGBRegressor worst RMSE: 3.9578\n",
      "Corresponding penalty value: 3.2290\n",
      "\u001b[32m[I 2025-03-31 13:48:48,513]\u001b[0m Trial 39 finished with value: 3.22895563543038 and parameters: {'n_estimators': 2370, 'learning_rate': 0.02201, 'max_depth': 7, 'max_leaves': 28, 'colsample_bytree': 0.6, 'subsample': 0.5, 'reg_alpha': 7.66, 'reg_lambda': 9.33, 'gamma': 2.64}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2798\n",
      "2th fold: XGBRegressor RMSE: 1.8533\n",
      "3th fold: XGBRegressor RMSE: 3.9354\n",
      "\n",
      "XGBRegressor average RMSE: 3.0228\n",
      "XGBRegressor worst RMSE: 3.9354\n",
      "Corresponding penalty value: 3.1141\n",
      "\u001b[32m[I 2025-03-31 13:48:52,231]\u001b[0m Trial 40 finished with value: 3.1140925066956537 and parameters: {'n_estimators': 2800, 'learning_rate': 0.011009999999999999, 'max_depth': 7, 'max_leaves': 24, 'colsample_bytree': 0.52, 'subsample': 0.53, 'reg_alpha': 8.620000000000001, 'reg_lambda': 9.34, 'gamma': 3.63}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:03,  1.28s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1725\n",
      "2th fold: XGBRegressor RMSE: 1.7847\n",
      "3th fold: XGBRegressor RMSE: 3.9760\n",
      "\n",
      "XGBRegressor average RMSE: 2.9777\n",
      "XGBRegressor worst RMSE: 3.9760\n",
      "Corresponding penalty value: 3.0775\n",
      "\u001b[32m[I 2025-03-31 13:48:56,148]\u001b[0m Trial 41 finished with value: 3.0775389098141512 and parameters: {'n_estimators': 2309, 'learning_rate': 0.00601, 'max_depth': 6, 'max_leaves': 27, 'colsample_bytree': 0.5, 'subsample': 0.5, 'reg_alpha': 8.13, 'reg_lambda': 8.34, 'gamma': 2.56}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:04,  1.40s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2580\n",
      "2th fold: XGBRegressor RMSE: 1.8354\n",
      "3th fold: XGBRegressor RMSE: 3.9843\n",
      "\n",
      "XGBRegressor average RMSE: 3.0259\n",
      "XGBRegressor worst RMSE: 3.9843\n",
      "Corresponding penalty value: 3.1217\n",
      "\u001b[32m[I 2025-03-31 13:49:00,409]\u001b[0m Trial 42 finished with value: 3.121710752293085 and parameters: {'n_estimators': 2563, 'learning_rate': 0.00601, 'max_depth': 6, 'max_leaves': 28, 'colsample_bytree': 0.52, 'subsample': 0.56, 'reg_alpha': 7.57, 'reg_lambda': 9.91, 'gamma': 2.5500000000000003}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4357\n",
      "2th fold: XGBRegressor RMSE: 1.8039\n",
      "3th fold: XGBRegressor RMSE: 4.0014\n",
      "\n",
      "XGBRegressor average RMSE: 3.0803\n",
      "XGBRegressor worst RMSE: 4.0014\n",
      "Corresponding penalty value: 3.1724\n",
      "\u001b[32m[I 2025-03-31 13:49:03,191]\u001b[0m Trial 43 finished with value: 3.172443093743644 and parameters: {'n_estimators': 2169, 'learning_rate': 0.01901, 'max_depth': 6, 'max_leaves': 23, 'colsample_bytree': 0.5, 'subsample': 0.55, 'reg_alpha': 6.91, 'reg_lambda': 9.08, 'gamma': 3.19}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:05,  1.90s/it]\n",
      "1th fold: XGBRegressor RMSE: 4.2145\n",
      "2th fold: XGBRegressor RMSE: 2.8496\n",
      "3th fold: XGBRegressor RMSE: 5.4261\n",
      "\n",
      "XGBRegressor average RMSE: 4.1634\n",
      "XGBRegressor worst RMSE: 5.4261\n",
      "Corresponding penalty value: 4.2897\n",
      "\u001b[32m[I 2025-03-31 13:49:08,954]\u001b[0m Trial 44 finished with value: 4.289678047737816 and parameters: {'n_estimators': 1974, 'learning_rate': 1e-05, 'max_depth': 5, 'max_leaves': 27, 'colsample_bytree': 0.58, 'subsample': 0.5, 'reg_alpha': 8.61, 'reg_lambda': 7.99, 'gamma': 2.0}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:03,  1.01s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.5354\n",
      "2th fold: XGBRegressor RMSE: 1.9291\n",
      "3th fold: XGBRegressor RMSE: 3.9464\n",
      "\n",
      "XGBRegressor average RMSE: 3.1370\n",
      "XGBRegressor worst RMSE: 3.9464\n",
      "Corresponding penalty value: 3.2179\n",
      "\u001b[32m[I 2025-03-31 13:49:12,045]\u001b[0m Trial 45 finished with value: 3.217911690665328 and parameters: {'n_estimators': 2544, 'learning_rate': 0.02801, 'max_depth': 7, 'max_leaves': 30, 'colsample_bytree': 0.62, 'subsample': 0.55, 'reg_alpha': 8.620000000000001, 'reg_lambda': 9.58, 'gamma': 2.84}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.2909\n",
      "2th fold: XGBRegressor RMSE: 1.8463\n",
      "3th fold: XGBRegressor RMSE: 3.9417\n",
      "\n",
      "XGBRegressor average RMSE: 3.0263\n",
      "XGBRegressor worst RMSE: 3.9417\n",
      "Corresponding penalty value: 3.1178\n",
      "\u001b[32m[I 2025-03-31 13:49:15,041]\u001b[0m Trial 46 finished with value: 3.117815324134111 and parameters: {'n_estimators': 1872, 'learning_rate': 0.01001, 'max_depth': 8, 'max_leaves': 24, 'colsample_bytree': 0.52, 'subsample': 0.52, 'reg_alpha': 9.42, 'reg_lambda': 8.77, 'gamma': 2.31}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:05,  1.83s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2733\n",
      "2th fold: XGBRegressor RMSE: 1.8137\n",
      "3th fold: XGBRegressor RMSE: 3.9935\n",
      "\n",
      "XGBRegressor average RMSE: 3.0268\n",
      "XGBRegressor worst RMSE: 3.9935\n",
      "Corresponding penalty value: 3.1235\n",
      "\u001b[32m[I 2025-03-31 13:49:20,620]\u001b[0m Trial 47 finished with value: 3.123472300777729 and parameters: {'n_estimators': 2982, 'learning_rate': 0.00401, 'max_depth': 6, 'max_leaves': 29, 'colsample_bytree': 0.58, 'subsample': 0.54, 'reg_alpha': 7.22, 'reg_lambda': 7.140000000000001, 'gamma': 2.1}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4050\n",
      "2th fold: XGBRegressor RMSE: 1.7803\n",
      "3th fold: XGBRegressor RMSE: 3.9587\n",
      "\n",
      "XGBRegressor average RMSE: 3.0480\n",
      "XGBRegressor worst RMSE: 3.9587\n",
      "Corresponding penalty value: 3.1391\n",
      "\u001b[32m[I 2025-03-31 13:49:23,605]\u001b[0m Trial 48 finished with value: 3.139075412051108 and parameters: {'n_estimators': 2216, 'learning_rate': 0.01701, 'max_depth': 7, 'max_leaves': 25, 'colsample_bytree': 0.5, 'subsample': 0.5, 'reg_alpha': 8.26, 'reg_lambda': 7.8500000000000005, 'gamma': 1.55}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "3it [00:03,  1.08s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1285\n",
      "2th fold: XGBRegressor RMSE: 1.9023\n",
      "3th fold: XGBRegressor RMSE: 3.9483\n",
      "\n",
      "XGBRegressor average RMSE: 2.9931\n",
      "XGBRegressor worst RMSE: 3.9483\n",
      "Corresponding penalty value: 3.0886\n",
      "\u001b[32m[I 2025-03-31 13:49:26,922]\u001b[0m Trial 49 finished with value: 3.0885801325455433 and parameters: {'n_estimators': 2324, 'learning_rate': 0.01201, 'max_depth': 5, 'max_leaves': 27, 'colsample_bytree': 0.53, 'subsample': 0.95, 'reg_alpha': 9.4, 'reg_lambda': 8.45, 'gamma': 1.1300000000000001}. Best is trial 4 with value: 3.0698098591885654.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}\n",
      "3it [00:02,  1.15it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1759\n",
      "2th fold: XGBRegressor RMSE: 1.8949\n",
      "3th fold: XGBRegressor RMSE: 3.8596\n",
      "\n",
      "XGBRegressor average RMSE: 2.9768\n",
      "XGBRegressor worst RMSE: 3.8596\n",
      "Corresponding penalty value: 3.0651\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB4\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.328\n",
      "RMSE_crossval: 2.977\n",
      "RMSE_test: 1.640\n",
      "MAE_test: 1.047\n",
      "Nash-Sutcliffe Test: 0.864\n",
      "Kling-Gupta Test: 0.611\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 140.4603 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:49:31,891]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB8\u001b[0m\n",
      "3it [00:01,  1.79it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1100\n",
      "2th fold: XGBRegressor RMSE: 2.4200\n",
      "3th fold: XGBRegressor RMSE: 5.9558\n",
      "\n",
      "XGBRegressor average RMSE: 3.1619\n",
      "XGBRegressor worst RMSE: 5.9558\n",
      "Corresponding penalty value: 3.4413\n",
      "\u001b[32m[I 2025-03-31 13:49:33,566]\u001b[0m Trial 0 finished with value: 3.4413201876314234 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.5700000000000001, 'reg_alpha': 0.58, 'reg_lambda': 8.67, 'gamma': 3.0100000000000002}. Best is trial 0 with value: 3.4413201876314234.\u001b[0m\n",
      "3it [00:06,  2.25s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0820\n",
      "2th fold: XGBRegressor RMSE: 2.3818\n",
      "3th fold: XGBRegressor RMSE: 5.9531\n",
      "\n",
      "XGBRegressor average RMSE: 3.1389\n",
      "XGBRegressor worst RMSE: 5.9531\n",
      "Corresponding penalty value: 3.4204\n",
      "\u001b[32m[I 2025-03-31 13:49:40,319]\u001b[0m Trial 1 finished with value: 3.4203586514761977 and parameters: {'n_estimators': 2270, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 1.83, 'reg_lambda': 3.04, 'gamma': 2.62}. Best is trial 1 with value: 3.4203586514761977.\u001b[0m\n",
      "3it [00:02,  1.46it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0887\n",
      "2th fold: XGBRegressor RMSE: 2.5005\n",
      "3th fold: XGBRegressor RMSE: 5.9493\n",
      "\n",
      "XGBRegressor average RMSE: 3.1795\n",
      "XGBRegressor worst RMSE: 5.9493\n",
      "Corresponding penalty value: 3.4565\n",
      "\u001b[32m[I 2025-03-31 13:49:42,381]\u001b[0m Trial 2 finished with value: 3.456476517800988 and parameters: {'n_estimators': 1580, 'learning_rate': 0.02901, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.64, 'subsample': 0.6799999999999999, 'reg_alpha': 4.5600000000000005, 'reg_lambda': 7.8500000000000005, 'gamma': 1.0}. Best is trial 1 with value: 3.4203586514761977.\u001b[0m\n",
      "3it [00:02,  1.50it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0819\n",
      "2th fold: XGBRegressor RMSE: 3.3527\n",
      "3th fold: XGBRegressor RMSE: 5.9641\n",
      "\n",
      "XGBRegressor average RMSE: 3.4662\n",
      "XGBRegressor worst RMSE: 5.9641\n",
      "Corresponding penalty value: 3.7160\n",
      "\u001b[32m[I 2025-03-31 13:49:44,390]\u001b[0m Trial 3 finished with value: 3.71601045781043 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05901000000000001, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.53, 'reg_alpha': 9.49, 'reg_lambda': 9.66, 'gamma': 4.05}. Best is trial 1 with value: 3.4203586514761977.\u001b[0m\n",
      "3it [00:02,  1.23it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1022\n",
      "2th fold: XGBRegressor RMSE: 2.3276\n",
      "3th fold: XGBRegressor RMSE: 5.9703\n",
      "\n",
      "XGBRegressor average RMSE: 3.1334\n",
      "XGBRegressor worst RMSE: 5.9703\n",
      "Corresponding penalty value: 3.4171\n",
      "\u001b[32m[I 2025-03-31 13:49:46,825]\u001b[0m Trial 4 finished with value: 3.4170520810560534 and parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}. Best is trial 4 with value: 3.4170520810560534.\u001b[0m\n",
      "3it [00:02,  1.22it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0987\n",
      "2th fold: XGBRegressor RMSE: 2.4192\n",
      "3th fold: XGBRegressor RMSE: 5.9496\n",
      "\n",
      "XGBRegressor average RMSE: 3.1558\n",
      "XGBRegressor worst RMSE: 5.9496\n",
      "Corresponding penalty value: 3.4352\n",
      "\u001b[32m[I 2025-03-31 13:49:49,291]\u001b[0m Trial 5 finished with value: 3.435195651511281 and parameters: {'n_estimators': 2156, 'learning_rate': 0.03101, 'max_depth': 6, 'max_leaves': 17, 'colsample_bytree': 0.59, 'subsample': 0.99, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'gamma': 4.48}. Best is trial 4 with value: 3.4170520810560534.\u001b[0m\n",
      "3it [00:02,  1.35it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0920\n",
      "2th fold: XGBRegressor RMSE: 3.4470\n",
      "3th fold: XGBRegressor RMSE: 5.9701\n",
      "\n",
      "XGBRegressor average RMSE: 3.5031\n",
      "XGBRegressor worst RMSE: 5.9701\n",
      "Corresponding penalty value: 3.7498\n",
      "\u001b[32m[I 2025-03-31 13:49:51,513]\u001b[0m Trial 6 finished with value: 3.749761228655127 and parameters: {'n_estimators': 1995, 'learning_rate': 0.09201, 'max_depth': 1, 'max_leaves': 7, 'colsample_bytree': 0.52, 'subsample': 0.66, 'reg_alpha': 3.89, 'reg_lambda': 2.71, 'gamma': 4.15}. Best is trial 4 with value: 3.4170520810560534.\u001b[0m\n",
      "3it [00:01,  1.62it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1481\n",
      "2th fold: XGBRegressor RMSE: 2.4003\n",
      "3th fold: XGBRegressor RMSE: 5.9536\n",
      "\n",
      "XGBRegressor average RMSE: 3.1673\n",
      "XGBRegressor worst RMSE: 5.9536\n",
      "Corresponding penalty value: 3.4460\n",
      "\u001b[32m[I 2025-03-31 13:49:53,372]\u001b[0m Trial 7 finished with value: 3.4459626334224116 and parameters: {'n_estimators': 1392, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.9, 'subsample': 0.53, 'reg_alpha': 9.870000000000001, 'reg_lambda': 7.73, 'gamma': 0.99}. Best is trial 4 with value: 3.4170520810560534.\u001b[0m\n",
      "3it [00:00,  3.98it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1633\n",
      "2th fold: XGBRegressor RMSE: 2.5575\n",
      "3th fold: XGBRegressor RMSE: 5.9560\n",
      "\n",
      "XGBRegressor average RMSE: 3.2256\n",
      "XGBRegressor worst RMSE: 5.9560\n",
      "Corresponding penalty value: 3.4987\n",
      "\u001b[32m[I 2025-03-31 13:49:54,129]\u001b[0m Trial 8 finished with value: 3.498661049853436 and parameters: {'n_estimators': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'max_leaves': 23, 'colsample_bytree': 0.89, 'subsample': 0.53, 'reg_alpha': 3.58, 'reg_lambda': 1.1500000000000001, 'gamma': 4.32}. Best is trial 4 with value: 3.4170520810560534.\u001b[0m\n",
      "3it [00:02,  1.29it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0688\n",
      "2th fold: XGBRegressor RMSE: 3.3953\n",
      "3th fold: XGBRegressor RMSE: 5.9733\n",
      "\n",
      "XGBRegressor average RMSE: 3.4791\n",
      "XGBRegressor worst RMSE: 5.9733\n",
      "Corresponding penalty value: 3.7286\n",
      "\u001b[32m[I 2025-03-31 13:49:56,453]\u001b[0m Trial 9 finished with value: 3.728559981190086 and parameters: {'n_estimators': 2058, 'learning_rate': 0.033010000000000005, 'max_depth': 1, 'max_leaves': 11, 'colsample_bytree': 0.66, 'subsample': 0.87, 'reg_alpha': 6.38, 'reg_lambda': 8.88, 'gamma': 2.36}. Best is trial 4 with value: 3.4170520810560534.\u001b[0m\n",
      "3it [00:07,  2.58s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3218\n",
      "2th fold: XGBRegressor RMSE: 1.8110\n",
      "3th fold: XGBRegressor RMSE: 6.0355\n",
      "\n",
      "XGBRegressor average RMSE: 3.0561\n",
      "XGBRegressor worst RMSE: 6.0355\n",
      "Corresponding penalty value: 3.3541\n",
      "\u001b[32m[I 2025-03-31 13:50:04,233]\u001b[0m Trial 10 finished with value: 3.354052755848235 and parameters: {'n_estimators': 2863, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 12, 'colsample_bytree': 0.77, 'subsample': 0.81, 'reg_alpha': 0.15, 'reg_lambda': 6.140000000000001, 'gamma': 0.23}. Best is trial 10 with value: 3.354052755848235.\u001b[0m\n",
      "3it [00:08,  2.69s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3213\n",
      "2th fold: XGBRegressor RMSE: 1.8117\n",
      "3th fold: XGBRegressor RMSE: 6.0353\n",
      "\n",
      "XGBRegressor average RMSE: 3.0561\n",
      "XGBRegressor worst RMSE: 6.0353\n",
      "Corresponding penalty value: 3.3540\n",
      "\u001b[32m[I 2025-03-31 13:50:12,359]\u001b[0m Trial 11 finished with value: 3.354020118374294 and parameters: {'n_estimators': 2990, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 12, 'colsample_bytree': 0.77, 'subsample': 0.8300000000000001, 'reg_alpha': 0.11, 'reg_lambda': 5.89, 'gamma': 0.02}. Best is trial 11 with value: 3.354020118374294.\u001b[0m\n",
      "3it [00:07,  2.62s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3215\n",
      "2th fold: XGBRegressor RMSE: 1.8108\n",
      "3th fold: XGBRegressor RMSE: 6.0354\n",
      "\n",
      "XGBRegressor average RMSE: 3.0559\n",
      "XGBRegressor worst RMSE: 6.0354\n",
      "Corresponding penalty value: 3.3539\n",
      "\u001b[32m[I 2025-03-31 13:50:20,268]\u001b[0m Trial 12 finished with value: 3.353871582613388 and parameters: {'n_estimators': 2918, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 11, 'colsample_bytree': 0.77, 'subsample': 0.86, 'reg_alpha': 2.11, 'reg_lambda': 5.36, 'gamma': 0.01}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.14s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1184\n",
      "2th fold: XGBRegressor RMSE: 3.3312\n",
      "3th fold: XGBRegressor RMSE: 5.9757\n",
      "\n",
      "XGBRegressor average RMSE: 3.4751\n",
      "XGBRegressor worst RMSE: 5.9757\n",
      "Corresponding penalty value: 3.7252\n",
      "\u001b[32m[I 2025-03-31 13:50:23,744]\u001b[0m Trial 13 finished with value: 3.725163920914436 and parameters: {'n_estimators': 2991, 'learning_rate': 0.01601, 'max_depth': 4, 'max_leaves': 2, 'colsample_bytree': 0.78, 'subsample': 0.91, 'reg_alpha': 2.41, 'reg_lambda': 5.45, 'gamma': 0.09}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.07it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1906\n",
      "2th fold: XGBRegressor RMSE: 2.3352\n",
      "3th fold: XGBRegressor RMSE: 5.9287\n",
      "\n",
      "XGBRegressor average RMSE: 3.1515\n",
      "XGBRegressor worst RMSE: 5.9287\n",
      "Corresponding penalty value: 3.4292\n",
      "\u001b[32m[I 2025-03-31 13:50:26,612]\u001b[0m Trial 14 finished with value: 3.4292496181099628 and parameters: {'n_estimators': 2551, 'learning_rate': 0.05201000000000001, 'max_depth': 3, 'max_leaves': 30, 'colsample_bytree': 1.0, 'subsample': 0.81, 'reg_alpha': 1.82, 'reg_lambda': 4.0, 'gamma': 1.71}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.08s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0961\n",
      "2th fold: XGBRegressor RMSE: 2.3419\n",
      "3th fold: XGBRegressor RMSE: 5.9310\n",
      "\n",
      "XGBRegressor average RMSE: 3.1230\n",
      "XGBRegressor worst RMSE: 5.9310\n",
      "Corresponding penalty value: 3.4038\n",
      "\u001b[32m[I 2025-03-31 13:50:29,914]\u001b[0m Trial 15 finished with value: 3.40380298736066 and parameters: {'n_estimators': 2620, 'learning_rate': 0.01901, 'max_depth': 3, 'max_leaves': 10, 'colsample_bytree': 0.71, 'subsample': 0.94, 'reg_alpha': 2.86, 'reg_lambda': 6.5, 'gamma': 0.52}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.05it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1039\n",
      "2th fold: XGBRegressor RMSE: 3.5654\n",
      "3th fold: XGBRegressor RMSE: 5.9792\n",
      "\n",
      "XGBRegressor average RMSE: 3.5495\n",
      "XGBRegressor worst RMSE: 5.9792\n",
      "Corresponding penalty value: 3.7925\n",
      "\u001b[32m[I 2025-03-31 13:50:32,836]\u001b[0m Trial 16 finished with value: 3.7924704199017967 and parameters: {'n_estimators': 2569, 'learning_rate': 0.04301000000000001, 'max_depth': 4, 'max_leaves': 2, 'colsample_bytree': 0.8400000000000001, 'subsample': 0.8200000000000001, 'reg_alpha': 5.61, 'reg_lambda': 4.58, 'gamma': 1.79}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:01,  1.61it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0957\n",
      "2th fold: XGBRegressor RMSE: 2.3880\n",
      "3th fold: XGBRegressor RMSE: 5.9400\n",
      "\n",
      "XGBRegressor average RMSE: 3.1412\n",
      "XGBRegressor worst RMSE: 5.9400\n",
      "Corresponding penalty value: 3.4211\n",
      "\u001b[32m[I 2025-03-31 13:50:34,758]\u001b[0m Trial 17 finished with value: 3.421113756829941 and parameters: {'n_estimators': 1033, 'learning_rate': 0.01201, 'max_depth': 3, 'max_leaves': 15, 'colsample_bytree': 0.72, 'subsample': 0.75, 'reg_alpha': 1.28, 'reg_lambda': 6.88, 'gamma': 0.64}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.09s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1151\n",
      "2th fold: XGBRegressor RMSE: 2.4592\n",
      "3th fold: XGBRegressor RMSE: 5.9349\n",
      "\n",
      "XGBRegressor average RMSE: 3.1697\n",
      "XGBRegressor worst RMSE: 5.9349\n",
      "Corresponding penalty value: 3.4462\n",
      "\u001b[32m[I 2025-03-31 13:50:38,087]\u001b[0m Trial 18 finished with value: 3.4462435908748676 and parameters: {'n_estimators': 2796, 'learning_rate': 0.06601, 'max_depth': 5, 'max_leaves': 8, 'colsample_bytree': 0.8200000000000001, 'subsample': 0.88, 'reg_alpha': 3.23, 'reg_lambda': 0.9, 'gamma': 0.06}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1554\n",
      "2th fold: XGBRegressor RMSE: 2.7192\n",
      "3th fold: XGBRegressor RMSE: 5.9132\n",
      "\n",
      "XGBRegressor average RMSE: 3.2626\n",
      "XGBRegressor worst RMSE: 5.9132\n",
      "Corresponding penalty value: 3.5277\n",
      "\u001b[32m[I 2025-03-31 13:50:40,735]\u001b[0m Trial 19 finished with value: 3.5276623982712962 and parameters: {'n_estimators': 2357, 'learning_rate': 0.042010000000000006, 'max_depth': 2, 'max_leaves': 21, 'colsample_bytree': 0.95, 'subsample': 1.0, 'reg_alpha': 1.01, 'reg_lambda': 5.17, 'gamma': 3.13}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.06s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0825\n",
      "2th fold: XGBRegressor RMSE: 2.3616\n",
      "3th fold: XGBRegressor RMSE: 5.9657\n",
      "\n",
      "XGBRegressor average RMSE: 3.1366\n",
      "XGBRegressor worst RMSE: 5.9657\n",
      "Corresponding penalty value: 3.4195\n",
      "\u001b[32m[I 2025-03-31 13:50:43,966]\u001b[0m Trial 20 finished with value: 3.4195123744078892 and parameters: {'n_estimators': 2728, 'learning_rate': 0.02201, 'max_depth': 5, 'max_leaves': 13, 'colsample_bytree': 0.7, 'subsample': 0.7, 'reg_alpha': 1.99, 'reg_lambda': 3.5, 'gamma': 4.97}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:07,  2.64s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1012\n",
      "2th fold: XGBRegressor RMSE: 2.3491\n",
      "3th fold: XGBRegressor RMSE: 5.9523\n",
      "\n",
      "XGBRegressor average RMSE: 3.1342\n",
      "XGBRegressor worst RMSE: 5.9523\n",
      "Corresponding penalty value: 3.4160\n",
      "\u001b[32m[I 2025-03-31 13:50:51,932]\u001b[0m Trial 21 finished with value: 3.4160077878334016 and parameters: {'n_estimators': 2931, 'learning_rate': 0.00101, 'max_depth': 4, 'max_leaves': 11, 'colsample_bytree': 0.78, 'subsample': 0.8200000000000001, 'reg_alpha': 0.08, 'reg_lambda': 6.140000000000001, 'gamma': 0.02}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:07,  2.60s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0953\n",
      "2th fold: XGBRegressor RMSE: 2.3129\n",
      "3th fold: XGBRegressor RMSE: 5.9547\n",
      "\n",
      "XGBRegressor average RMSE: 3.1210\n",
      "XGBRegressor worst RMSE: 5.9547\n",
      "Corresponding penalty value: 3.4043\n",
      "\u001b[32m[I 2025-03-31 13:50:59,785]\u001b[0m Trial 22 finished with value: 3.4043304519049657 and parameters: {'n_estimators': 2963, 'learning_rate': 0.00101, 'max_depth': 4, 'max_leaves': 13, 'colsample_bytree': 0.77, 'subsample': 0.8, 'reg_alpha': 1.36, 'reg_lambda': 5.5, 'gamma': 0.56}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.17s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1304\n",
      "2th fold: XGBRegressor RMSE: 2.6094\n",
      "3th fold: XGBRegressor RMSE: 5.9122\n",
      "\n",
      "XGBRegressor average RMSE: 3.2173\n",
      "XGBRegressor worst RMSE: 5.9122\n",
      "Corresponding penalty value: 3.4868\n",
      "\u001b[32m[I 2025-03-31 13:51:03,347]\u001b[0m Trial 23 finished with value: 3.486791925613723 and parameters: {'n_estimators': 2434, 'learning_rate': 0.00901, 'max_depth': 2, 'max_leaves': 9, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.86, 'reg_alpha': 0.05, 'reg_lambda': 7.58, 'gamma': 0.48}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:04,  1.38s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0934\n",
      "2th fold: XGBRegressor RMSE: 2.3724\n",
      "3th fold: XGBRegressor RMSE: 5.9694\n",
      "\n",
      "XGBRegressor average RMSE: 3.1451\n",
      "XGBRegressor worst RMSE: 5.9694\n",
      "Corresponding penalty value: 3.4275\n",
      "\u001b[32m[I 2025-03-31 13:51:07,551]\u001b[0m Trial 24 finished with value: 3.4275048638419126 and parameters: {'n_estimators': 2834, 'learning_rate': 0.00801, 'max_depth': 5, 'max_leaves': 17, 'colsample_bytree': 0.73, 'subsample': 0.76, 'reg_alpha': 1.26, 'reg_lambda': 4.42, 'gamma': 1.36}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:04,  1.45s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3227\n",
      "2th fold: XGBRegressor RMSE: 1.8112\n",
      "3th fold: XGBRegressor RMSE: 6.0355\n",
      "\n",
      "XGBRegressor average RMSE: 3.0564\n",
      "XGBRegressor worst RMSE: 6.0355\n",
      "Corresponding penalty value: 3.3543\n",
      "\u001b[32m[I 2025-03-31 13:51:11,978]\u001b[0m Trial 25 finished with value: 3.35434046365817 and parameters: {'n_estimators': 2691, 'learning_rate': 1e-05, 'max_depth': 3, 'max_leaves': 4, 'colsample_bytree': 0.86, 'subsample': 0.9299999999999999, 'reg_alpha': 2.62, 'reg_lambda': 5.99, 'gamma': 0.93}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1054\n",
      "2th fold: XGBRegressor RMSE: 2.5625\n",
      "3th fold: XGBRegressor RMSE: 5.9145\n",
      "\n",
      "XGBRegressor average RMSE: 3.1942\n",
      "XGBRegressor worst RMSE: 5.9145\n",
      "Corresponding penalty value: 3.4662\n",
      "\u001b[32m[I 2025-03-31 13:51:14,629]\u001b[0m Trial 26 finished with value: 3.4661928964644235 and parameters: {'n_estimators': 1868, 'learning_rate': 0.02101, 'max_depth': 2, 'max_leaves': 11, 'colsample_bytree': 0.67, 'subsample': 0.78, 'reg_alpha': 0.9, 'reg_lambda': 7.2, 'gamma': 0.3}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.08s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1073\n",
      "2th fold: XGBRegressor RMSE: 2.3767\n",
      "3th fold: XGBRegressor RMSE: 5.9824\n",
      "\n",
      "XGBRegressor average RMSE: 3.1555\n",
      "XGBRegressor worst RMSE: 5.9824\n",
      "Corresponding penalty value: 3.4382\n",
      "\u001b[32m[I 2025-03-31 13:51:17,943]\u001b[0m Trial 27 finished with value: 3.438160846934449 and parameters: {'n_estimators': 2462, 'learning_rate': 0.01201, 'max_depth': 5, 'max_leaves': 13, 'colsample_bytree': 0.79, 'subsample': 0.72, 'reg_alpha': 4.76, 'reg_lambda': 1.77, 'gamma': 2.0300000000000002}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:04,  1.50s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1074\n",
      "2th fold: XGBRegressor RMSE: 2.3778\n",
      "3th fold: XGBRegressor RMSE: 5.9880\n",
      "\n",
      "XGBRegressor average RMSE: 3.1577\n",
      "XGBRegressor worst RMSE: 5.9880\n",
      "Corresponding penalty value: 3.4408\n",
      "\u001b[32m[I 2025-03-31 13:51:22,504]\u001b[0m Trial 28 finished with value: 3.4407640792693237 and parameters: {'n_estimators': 2784, 'learning_rate': 0.00701, 'max_depth': 6, 'max_leaves': 16, 'colsample_bytree': 0.76, 'subsample': 0.8500000000000001, 'reg_alpha': 0.12, 'reg_lambda': 4.7700000000000005, 'gamma': 0.8}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.21it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1033\n",
      "2th fold: XGBRegressor RMSE: 2.4361\n",
      "3th fold: XGBRegressor RMSE: 5.9725\n",
      "\n",
      "XGBRegressor average RMSE: 3.1706\n",
      "XGBRegressor worst RMSE: 5.9725\n",
      "Corresponding penalty value: 3.4508\n",
      "\u001b[32m[I 2025-03-31 13:51:25,049]\u001b[0m Trial 29 finished with value: 3.450819469431827 and parameters: {'n_estimators': 2236, 'learning_rate': 0.06901, 'max_depth': 4, 'max_leaves': 18, 'colsample_bytree': 0.81, 'subsample': 0.62, 'reg_alpha': 0.89, 'reg_lambda': 8.4, 'gamma': 3.2800000000000002}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:01,  2.06it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0996\n",
      "2th fold: XGBRegressor RMSE: 2.4041\n",
      "3th fold: XGBRegressor RMSE: 5.9601\n",
      "\n",
      "XGBRegressor average RMSE: 3.1546\n",
      "XGBRegressor worst RMSE: 5.9601\n",
      "Corresponding penalty value: 3.4352\n",
      "\u001b[32m[I 2025-03-31 13:51:26,569]\u001b[0m Trial 30 finished with value: 3.4351560026712264 and parameters: {'n_estimators': 1020, 'learning_rate': 0.03901, 'max_depth': 7, 'max_leaves': 20, 'colsample_bytree': 0.74, 'subsample': 0.91, 'reg_alpha': 7.29, 'reg_lambda': 6.0, 'gamma': 1.34}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:05,  1.86s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1374\n",
      "2th fold: XGBRegressor RMSE: 2.4605\n",
      "3th fold: XGBRegressor RMSE: 5.9391\n",
      "\n",
      "XGBRegressor average RMSE: 3.1790\n",
      "XGBRegressor worst RMSE: 5.9391\n",
      "Corresponding penalty value: 3.4550\n",
      "\u001b[32m[I 2025-03-31 13:51:32,214]\u001b[0m Trial 31 finished with value: 3.4550265225994874 and parameters: {'n_estimators': 2691, 'learning_rate': 0.00301, 'max_depth': 3, 'max_leaves': 5, 'colsample_bytree': 0.86, 'subsample': 0.95, 'reg_alpha': 2.61, 'reg_lambda': 6.22, 'gamma': 0.23}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:05,  1.98s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1297\n",
      "2th fold: XGBRegressor RMSE: 2.4253\n",
      "3th fold: XGBRegressor RMSE: 5.9409\n",
      "\n",
      "XGBRegressor average RMSE: 3.1653\n",
      "XGBRegressor worst RMSE: 5.9409\n",
      "Corresponding penalty value: 3.4429\n",
      "\u001b[32m[I 2025-03-31 13:51:38,220]\u001b[0m Trial 32 finished with value: 3.4428547011301833 and parameters: {'n_estimators': 2995, 'learning_rate': 0.00201, 'max_depth': 3, 'max_leaves': 5, 'colsample_bytree': 0.87, 'subsample': 0.91, 'reg_alpha': 2.06, 'reg_lambda': 5.63, 'gamma': 0.8300000000000001}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.27s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1454\n",
      "2th fold: XGBRegressor RMSE: 2.7368\n",
      "3th fold: XGBRegressor RMSE: 5.9039\n",
      "\n",
      "XGBRegressor average RMSE: 3.2620\n",
      "XGBRegressor worst RMSE: 5.9039\n",
      "Corresponding penalty value: 3.5262\n",
      "\u001b[32m[I 2025-03-31 13:51:42,095]\u001b[0m Trial 33 finished with value: 3.5262243425784208 and parameters: {'n_estimators': 2811, 'learning_rate': 0.015009999999999999, 'max_depth': 10, 'max_leaves': 4, 'colsample_bytree': 0.9, 'subsample': 0.8400000000000001, 'reg_alpha': 4.12, 'reg_lambda': 6.86, 'gamma': 0.41000000000000003}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.08s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1556\n",
      "2th fold: XGBRegressor RMSE: 2.6886\n",
      "3th fold: XGBRegressor RMSE: 5.9127\n",
      "\n",
      "XGBRegressor average RMSE: 3.2523\n",
      "XGBRegressor worst RMSE: 5.9127\n",
      "Corresponding penalty value: 3.5183\n",
      "\u001b[32m[I 2025-03-31 13:51:45,416]\u001b[0m Trial 34 finished with value: 3.5183283988823844 and parameters: {'n_estimators': 2681, 'learning_rate': 0.02401, 'max_depth': 2, 'max_leaves': 9, 'colsample_bytree': 0.94, 'subsample': 0.95, 'reg_alpha': 0.64, 'reg_lambda': 4.26, 'gamma': 1.12}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.19s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0810\n",
      "2th fold: XGBRegressor RMSE: 2.3316\n",
      "3th fold: XGBRegressor RMSE: 5.9788\n",
      "\n",
      "XGBRegressor average RMSE: 3.1305\n",
      "XGBRegressor worst RMSE: 5.9788\n",
      "Corresponding penalty value: 3.4153\n",
      "\u001b[32m[I 2025-03-31 13:51:49,041]\u001b[0m Trial 35 finished with value: 3.415324604565825 and parameters: {'n_estimators': 2349, 'learning_rate': 0.00601, 'max_depth': 4, 'max_leaves': 12, 'colsample_bytree': 0.6799999999999999, 'subsample': 0.89, 'reg_alpha': 1.55, 'reg_lambda': 8.24, 'gamma': 3.58}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:05,  1.82s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3228\n",
      "2th fold: XGBRegressor RMSE: 1.8093\n",
      "3th fold: XGBRegressor RMSE: 6.0360\n",
      "\n",
      "XGBRegressor average RMSE: 3.0560\n",
      "XGBRegressor worst RMSE: 6.0360\n",
      "Corresponding penalty value: 3.3540\n",
      "\u001b[32m[I 2025-03-31 13:51:54,581]\u001b[0m Trial 36 finished with value: 3.3540208486012166 and parameters: {'n_estimators': 2502, 'learning_rate': 1e-05, 'max_depth': 5, 'max_leaves': 8, 'colsample_bytree': 0.81, 'subsample': 0.97, 'reg_alpha': 2.77, 'reg_lambda': 3.5700000000000003, 'gamma': 0.02}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:04,  1.53s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1134\n",
      "2th fold: XGBRegressor RMSE: 2.3365\n",
      "3th fold: XGBRegressor RMSE: 5.9751\n",
      "\n",
      "XGBRegressor average RMSE: 3.1417\n",
      "XGBRegressor worst RMSE: 5.9751\n",
      "Corresponding penalty value: 3.4250\n",
      "\u001b[32m[I 2025-03-31 13:51:59,235]\u001b[0m Trial 37 finished with value: 3.4250301658209334 and parameters: {'n_estimators': 2506, 'learning_rate': 0.015009999999999999, 'max_depth': 8, 'max_leaves': 15, 'colsample_bytree': 0.63, 'subsample': 0.77, 'reg_alpha': 5.42, 'reg_lambda': 2.46, 'gamma': 0.02}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.10s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1088\n",
      "2th fold: XGBRegressor RMSE: 2.3442\n",
      "3th fold: XGBRegressor RMSE: 5.9310\n",
      "\n",
      "XGBRegressor average RMSE: 3.1280\n",
      "XGBRegressor worst RMSE: 5.9310\n",
      "Corresponding penalty value: 3.4083\n",
      "\u001b[32m[I 2025-03-31 13:52:02,589]\u001b[0m Trial 38 finished with value: 3.408286407700424 and parameters: {'n_estimators': 1639, 'learning_rate': 0.00601, 'max_depth': 9, 'max_leaves': 7, 'colsample_bytree': 0.81, 'subsample': 0.8400000000000001, 'reg_alpha': 4.19, 'reg_lambda': 3.7800000000000002, 'gamma': 0.35000000000000003}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.08s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0855\n",
      "2th fold: XGBRegressor RMSE: 2.3719\n",
      "3th fold: XGBRegressor RMSE: 5.9709\n",
      "\n",
      "XGBRegressor average RMSE: 3.1427\n",
      "XGBRegressor worst RMSE: 5.9709\n",
      "Corresponding penalty value: 3.4256\n",
      "\u001b[32m[I 2025-03-31 13:52:05,893]\u001b[0m Trial 39 finished with value: 3.425555828388897 and parameters: {'n_estimators': 2866, 'learning_rate': 0.026010000000000002, 'max_depth': 6, 'max_leaves': 8, 'colsample_bytree': 0.63, 'subsample': 0.97, 'reg_alpha': 3.4, 'reg_lambda': 3.08, 'gamma': 2.62}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1017\n",
      "2th fold: XGBRegressor RMSE: 2.4615\n",
      "3th fold: XGBRegressor RMSE: 5.9701\n",
      "\n",
      "XGBRegressor average RMSE: 3.1778\n",
      "XGBRegressor worst RMSE: 5.9701\n",
      "Corresponding penalty value: 3.4570\n",
      "\u001b[32m[I 2025-03-31 13:52:08,635]\u001b[0m Trial 40 finished with value: 3.4570089764251333 and parameters: {'n_estimators': 2216, 'learning_rate': 0.034010000000000006, 'max_depth': 5, 'max_leaves': 14, 'colsample_bytree': 0.75, 'subsample': 0.72, 'reg_alpha': 0.61, 'reg_lambda': 4.9, 'gamma': 0.72}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:04,  1.44s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3228\n",
      "2th fold: XGBRegressor RMSE: 1.8110\n",
      "3th fold: XGBRegressor RMSE: 6.0355\n",
      "\n",
      "XGBRegressor average RMSE: 3.0564\n",
      "XGBRegressor worst RMSE: 6.0355\n",
      "Corresponding penalty value: 3.3543\n",
      "\u001b[32m[I 2025-03-31 13:52:13,024]\u001b[0m Trial 41 finished with value: 3.3543284913941465 and parameters: {'n_estimators': 2657, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 4, 'colsample_bytree': 0.8500000000000001, 'subsample': 0.9299999999999999, 'reg_alpha': 2.38, 'reg_lambda': 0.14, 'gamma': 0.27}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:07,  2.63s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3215\n",
      "2th fold: XGBRegressor RMSE: 1.8113\n",
      "3th fold: XGBRegressor RMSE: 6.0354\n",
      "\n",
      "XGBRegressor average RMSE: 3.0561\n",
      "XGBRegressor worst RMSE: 6.0354\n",
      "Corresponding penalty value: 3.3540\n",
      "\u001b[32m[I 2025-03-31 13:52:20,994]\u001b[0m Trial 42 finished with value: 3.3539913736894973 and parameters: {'n_estimators': 2882, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 10, 'colsample_bytree': 0.8, 'subsample': 0.98, 'reg_alpha': 3.0700000000000003, 'reg_lambda': 0.43, 'gamma': 0.2}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.29s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0896\n",
      "2th fold: XGBRegressor RMSE: 2.4360\n",
      "3th fold: XGBRegressor RMSE: 5.9775\n",
      "\n",
      "XGBRegressor average RMSE: 3.1677\n",
      "XGBRegressor worst RMSE: 5.9775\n",
      "Corresponding penalty value: 3.4487\n",
      "\u001b[32m[I 2025-03-31 13:52:24,927]\u001b[0m Trial 43 finished with value: 3.448698452878731 and parameters: {'n_estimators': 2873, 'learning_rate': 0.011009999999999999, 'max_depth': 5, 'max_leaves': 10, 'colsample_bytree': 0.75, 'subsample': 0.98, 'reg_alpha': 2.93, 'reg_lambda': 1.92, 'gamma': 1.11}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:07,  2.41s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1103\n",
      "2th fold: XGBRegressor RMSE: 2.3686\n",
      "3th fold: XGBRegressor RMSE: 5.9823\n",
      "\n",
      "XGBRegressor average RMSE: 3.1537\n",
      "XGBRegressor worst RMSE: 5.9823\n",
      "Corresponding penalty value: 3.4366\n",
      "\u001b[32m[I 2025-03-31 13:52:32,225]\u001b[0m Trial 44 finished with value: 3.4365628885973365 and parameters: {'n_estimators': 2888, 'learning_rate': 0.00601, 'max_depth': 6, 'max_leaves': 9, 'colsample_bytree': 0.8, 'subsample': 0.79, 'reg_alpha': 8.61, 'reg_lambda': 0.61, 'gamma': 0.0}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.31s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1057\n",
      "2th fold: XGBRegressor RMSE: 2.3510\n",
      "3th fold: XGBRegressor RMSE: 5.9905\n",
      "\n",
      "XGBRegressor average RMSE: 3.1491\n",
      "XGBRegressor worst RMSE: 5.9905\n",
      "Corresponding penalty value: 3.4332\n",
      "\u001b[32m[I 2025-03-31 13:52:36,236]\u001b[0m Trial 45 finished with value: 3.4332182235589177 and parameters: {'n_estimators': 3000, 'learning_rate': 0.01701, 'max_depth': 4, 'max_leaves': 12, 'colsample_bytree': 0.79, 'subsample': 0.97, 'reg_alpha': 1.6400000000000001, 'reg_lambda': 3.37, 'gamma': 0.27}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1108\n",
      "2th fold: XGBRegressor RMSE: 2.2522\n",
      "3th fold: XGBRegressor RMSE: 5.9818\n",
      "\n",
      "XGBRegressor average RMSE: 3.1149\n",
      "XGBRegressor worst RMSE: 5.9818\n",
      "Corresponding penalty value: 3.4016\n",
      "\u001b[32m[I 2025-03-31 13:52:39,018]\u001b[0m Trial 46 finished with value: 3.4016159250902467 and parameters: {'n_estimators': 2616, 'learning_rate': 0.09301, 'max_depth': 5, 'max_leaves': 7, 'colsample_bytree': 0.51, 'subsample': 1.0, 'reg_alpha': 3.5, 'reg_lambda': 5.26, 'gamma': 0.58}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:04,  1.41s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.0942\n",
      "2th fold: XGBRegressor RMSE: 2.3885\n",
      "3th fold: XGBRegressor RMSE: 5.9790\n",
      "\n",
      "XGBRegressor average RMSE: 3.1539\n",
      "XGBRegressor worst RMSE: 5.9790\n",
      "Corresponding penalty value: 3.4364\n",
      "\u001b[32m[I 2025-03-31 13:52:43,322]\u001b[0m Trial 47 finished with value: 3.4364128611550875 and parameters: {'n_estimators': 2354, 'learning_rate': 0.00501, 'max_depth': 6, 'max_leaves': 10, 'colsample_bytree': 0.77, 'subsample': 0.89, 'reg_alpha': 2.24, 'reg_lambda': 1.73, 'gamma': 1.6}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:02,  1.23it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.1038\n",
      "2th fold: XGBRegressor RMSE: 2.3092\n",
      "3th fold: XGBRegressor RMSE: 5.9709\n",
      "\n",
      "XGBRegressor average RMSE: 3.1280\n",
      "XGBRegressor worst RMSE: 5.9709\n",
      "Corresponding penalty value: 3.4123\n",
      "\u001b[32m[I 2025-03-31 13:52:45,841]\u001b[0m Trial 48 finished with value: 3.41225705951138 and parameters: {'n_estimators': 2120, 'learning_rate': 0.08701, 'max_depth': 4, 'max_leaves': 12, 'colsample_bytree': 0.69, 'subsample': 0.65, 'reg_alpha': 0.56, 'reg_lambda': 7.26, 'gamma': 0.7000000000000001}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "3it [00:03,  1.24s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.1043\n",
      "2th fold: XGBRegressor RMSE: 2.3920\n",
      "3th fold: XGBRegressor RMSE: 5.9340\n",
      "\n",
      "XGBRegressor average RMSE: 3.1434\n",
      "XGBRegressor worst RMSE: 5.9340\n",
      "Corresponding penalty value: 3.4225\n",
      "\u001b[32m[I 2025-03-31 13:52:49,636]\u001b[0m Trial 49 finished with value: 3.422494507688879 and parameters: {'n_estimators': 2548, 'learning_rate': 0.01201, 'max_depth': 3, 'max_leaves': 26, 'colsample_bytree': 0.72, 'subsample': 0.8300000000000001, 'reg_alpha': 3.84, 'reg_lambda': 6.61, 'gamma': 0.23}. Best is trial 12 with value: 3.353871582613388.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 2918, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 11, 'colsample_bytree': 0.77, 'subsample': 0.86, 'reg_alpha': 2.11, 'reg_lambda': 5.36, 'gamma': 0.01}\n",
      "3it [00:07,  2.63s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.3215\n",
      "2th fold: XGBRegressor RMSE: 1.8108\n",
      "3th fold: XGBRegressor RMSE: 6.0354\n",
      "\n",
      "XGBRegressor average RMSE: 3.0559\n",
      "XGBRegressor worst RMSE: 6.0354\n",
      "Corresponding penalty value: 3.3539\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB8\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 2918, 'learning_rate': 1e-05, 'max_depth': 4, 'max_leaves': 11, 'colsample_bytree': 0.77, 'subsample': 0.86, 'reg_alpha': 2.11, 'reg_lambda': 5.36, 'gamma': 0.01}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 3.155\n",
      "RMSE_crossval: 3.056\n",
      "RMSE_test: 1.250\n",
      "MAE_test: 1.044\n",
      "Nash-Sutcliffe Test: -0.005\n",
      "Kling-Gupta Test: -0.276\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 209.5137 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:53:01,424]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB10\u001b[0m\n",
      "3it [00:01,  1.79it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.4436\n",
      "2th fold: XGBRegressor RMSE: 2.2314\n",
      "3th fold: XGBRegressor RMSE: 1.0884\n",
      "\n",
      "XGBRegressor average RMSE: 1.5878\n",
      "XGBRegressor worst RMSE: 2.2314\n",
      "Corresponding penalty value: 1.6522\n",
      "\u001b[32m[I 2025-03-31 13:53:03,102]\u001b[0m Trial 0 finished with value: 1.6521747254735386 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.5700000000000001, 'reg_alpha': 0.58, 'reg_lambda': 8.67, 'gamma': 3.0100000000000002}. Best is trial 0 with value: 1.6521747254735386.\u001b[0m\n",
      "3it [00:07,  2.58s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.5731\n",
      "2th fold: XGBRegressor RMSE: 1.9686\n",
      "3th fold: XGBRegressor RMSE: 1.1425\n",
      "\n",
      "XGBRegressor average RMSE: 1.5614\n",
      "XGBRegressor worst RMSE: 1.9686\n",
      "Corresponding penalty value: 1.6021\n",
      "\u001b[32m[I 2025-03-31 13:53:10,850]\u001b[0m Trial 1 finished with value: 1.602105804559774 and parameters: {'n_estimators': 2270, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 1.83, 'reg_lambda': 3.04, 'gamma': 2.62}. Best is trial 1 with value: 1.602105804559774.\u001b[0m\n",
      "3it [00:02,  1.35it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6413\n",
      "2th fold: XGBRegressor RMSE: 2.5239\n",
      "3th fold: XGBRegressor RMSE: 1.4225\n",
      "\n",
      "XGBRegressor average RMSE: 1.8626\n",
      "XGBRegressor worst RMSE: 2.5239\n",
      "Corresponding penalty value: 1.9287\n",
      "\u001b[32m[I 2025-03-31 13:53:13,069]\u001b[0m Trial 2 finished with value: 1.9287154731388463 and parameters: {'n_estimators': 1580, 'learning_rate': 0.02901, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.64, 'subsample': 0.6799999999999999, 'reg_alpha': 4.5600000000000005, 'reg_lambda': 7.8500000000000005, 'gamma': 1.0}. Best is trial 1 with value: 1.602105804559774.\u001b[0m\n",
      "3it [00:02,  1.46it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6478\n",
      "2th fold: XGBRegressor RMSE: 5.9673\n",
      "3th fold: XGBRegressor RMSE: 2.1516\n",
      "\n",
      "XGBRegressor average RMSE: 3.2556\n",
      "XGBRegressor worst RMSE: 5.9673\n",
      "Corresponding penalty value: 3.5267\n",
      "\u001b[32m[I 2025-03-31 13:53:15,130]\u001b[0m Trial 3 finished with value: 3.526723804488184 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05901000000000001, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.53, 'reg_alpha': 9.49, 'reg_lambda': 9.66, 'gamma': 4.05}. Best is trial 1 with value: 1.602105804559774.\u001b[0m\n",
      "3it [00:02,  1.06it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5523\n",
      "2th fold: XGBRegressor RMSE: 2.4204\n",
      "3th fold: XGBRegressor RMSE: 1.1552\n",
      "\n",
      "XGBRegressor average RMSE: 1.7093\n",
      "XGBRegressor worst RMSE: 2.4204\n",
      "Corresponding penalty value: 1.7804\n",
      "\u001b[32m[I 2025-03-31 13:53:17,964]\u001b[0m Trial 4 finished with value: 1.7804225186307612 and parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}. Best is trial 1 with value: 1.602105804559774.\u001b[0m\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5329\n",
      "2th fold: XGBRegressor RMSE: 2.3083\n",
      "3th fold: XGBRegressor RMSE: 1.1776\n",
      "\n",
      "XGBRegressor average RMSE: 1.6730\n",
      "XGBRegressor worst RMSE: 2.3083\n",
      "Corresponding penalty value: 1.7365\n",
      "\u001b[32m[I 2025-03-31 13:53:20,549]\u001b[0m Trial 5 finished with value: 1.7364894032804847 and parameters: {'n_estimators': 2156, 'learning_rate': 0.03101, 'max_depth': 6, 'max_leaves': 17, 'colsample_bytree': 0.59, 'subsample': 0.99, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'gamma': 4.48}. Best is trial 1 with value: 1.602105804559774.\u001b[0m\n",
      "3it [00:02,  1.35it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6237\n",
      "2th fold: XGBRegressor RMSE: 6.0652\n",
      "3th fold: XGBRegressor RMSE: 2.5008\n",
      "\n",
      "XGBRegressor average RMSE: 3.3966\n",
      "XGBRegressor worst RMSE: 6.0652\n",
      "Corresponding penalty value: 3.6634\n",
      "\u001b[32m[I 2025-03-31 13:53:22,780]\u001b[0m Trial 6 finished with value: 3.6634345618823665 and parameters: {'n_estimators': 1995, 'learning_rate': 0.09201, 'max_depth': 1, 'max_leaves': 7, 'colsample_bytree': 0.52, 'subsample': 0.66, 'reg_alpha': 3.89, 'reg_lambda': 2.71, 'gamma': 4.15}. Best is trial 1 with value: 1.602105804559774.\u001b[0m\n",
      "3it [00:02,  1.47it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7263\n",
      "2th fold: XGBRegressor RMSE: 1.7556\n",
      "3th fold: XGBRegressor RMSE: 1.1772\n",
      "\n",
      "XGBRegressor average RMSE: 1.5530\n",
      "XGBRegressor worst RMSE: 1.7556\n",
      "Corresponding penalty value: 1.5733\n",
      "\u001b[32m[I 2025-03-31 13:53:24,827]\u001b[0m Trial 7 finished with value: 1.5732911058302859 and parameters: {'n_estimators': 1392, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.9, 'subsample': 0.53, 'reg_alpha': 9.870000000000001, 'reg_lambda': 7.73, 'gamma': 0.99}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:00,  3.57it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7172\n",
      "2th fold: XGBRegressor RMSE: 2.1004\n",
      "3th fold: XGBRegressor RMSE: 1.3408\n",
      "\n",
      "XGBRegressor average RMSE: 1.7195\n",
      "XGBRegressor worst RMSE: 2.1004\n",
      "Corresponding penalty value: 1.7576\n",
      "\u001b[32m[I 2025-03-31 13:53:25,671]\u001b[0m Trial 8 finished with value: 1.7575525245967225 and parameters: {'n_estimators': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'max_leaves': 23, 'colsample_bytree': 0.89, 'subsample': 0.53, 'reg_alpha': 3.58, 'reg_lambda': 1.1500000000000001, 'gamma': 4.32}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.28it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7112\n",
      "2th fold: XGBRegressor RMSE: 5.9065\n",
      "3th fold: XGBRegressor RMSE: 1.9704\n",
      "\n",
      "XGBRegressor average RMSE: 3.1960\n",
      "XGBRegressor worst RMSE: 5.9065\n",
      "Corresponding penalty value: 3.4671\n",
      "\u001b[32m[I 2025-03-31 13:53:28,023]\u001b[0m Trial 9 finished with value: 3.467057176172283 and parameters: {'n_estimators': 2058, 'learning_rate': 0.033010000000000005, 'max_depth': 1, 'max_leaves': 11, 'colsample_bytree': 0.66, 'subsample': 0.87, 'reg_alpha': 6.38, 'reg_lambda': 8.88, 'gamma': 2.36}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:03,  1.16s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.7901\n",
      "2th fold: XGBRegressor RMSE: 6.2074\n",
      "3th fold: XGBRegressor RMSE: 2.4281\n",
      "\n",
      "XGBRegressor average RMSE: 3.4752\n",
      "XGBRegressor worst RMSE: 6.2074\n",
      "Corresponding penalty value: 3.7484\n",
      "\u001b[32m[I 2025-03-31 13:53:31,546]\u001b[0m Trial 10 finished with value: 3.7484184324505474 and parameters: {'n_estimators': 2863, 'learning_rate': 0.056010000000000004, 'max_depth': 4, 'max_leaves': 2, 'colsample_bytree': 1.0, 'subsample': 0.8500000000000001, 'reg_alpha': 9.74, 'reg_lambda': 6.24, 'gamma': 0.19}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:09,  3.05s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.6822\n",
      "2th fold: XGBRegressor RMSE: 1.9707\n",
      "3th fold: XGBRegressor RMSE: 1.2464\n",
      "\n",
      "XGBRegressor average RMSE: 1.6331\n",
      "XGBRegressor worst RMSE: 1.9707\n",
      "Corresponding penalty value: 1.6669\n",
      "\u001b[32m[I 2025-03-31 13:53:40,737]\u001b[0m Trial 11 finished with value: 1.666888886018984 and parameters: {'n_estimators': 2760, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 28, 'colsample_bytree': 0.78, 'subsample': 0.62, 'reg_alpha': 2.27, 'reg_lambda': 4.25, 'gamma': 2.35}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.52it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6712\n",
      "2th fold: XGBRegressor RMSE: 1.9308\n",
      "3th fold: XGBRegressor RMSE: 1.1504\n",
      "\n",
      "XGBRegressor average RMSE: 1.5841\n",
      "XGBRegressor worst RMSE: 1.9308\n",
      "Corresponding penalty value: 1.6188\n",
      "\u001b[32m[I 2025-03-31 13:53:42,760]\u001b[0m Trial 12 finished with value: 1.6188027387523585 and parameters: {'n_estimators': 891, 'learning_rate': 0.015009999999999999, 'max_depth': 10, 'max_leaves': 30, 'colsample_bytree': 0.8, 'subsample': 0.75, 'reg_alpha': 6.28, 'reg_lambda': 5.74, 'gamma': 1.47}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:03,  1.05s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.7404\n",
      "2th fold: XGBRegressor RMSE: 2.4294\n",
      "3th fold: XGBRegressor RMSE: 1.2345\n",
      "\n",
      "XGBRegressor average RMSE: 1.8015\n",
      "XGBRegressor worst RMSE: 2.4294\n",
      "Corresponding penalty value: 1.8643\n",
      "\u001b[32m[I 2025-03-31 13:53:45,964]\u001b[0m Trial 13 finished with value: 1.8642684571245718 and parameters: {'n_estimators': 2493, 'learning_rate': 0.01901, 'max_depth': 4, 'max_leaves': 25, 'colsample_bytree': 0.89, 'subsample': 0.51, 'reg_alpha': 2.41, 'reg_lambda': 4.01, 'gamma': 3.21}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.82it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6720\n",
      "2th fold: XGBRegressor RMSE: 2.5193\n",
      "3th fold: XGBRegressor RMSE: 1.1440\n",
      "\n",
      "XGBRegressor average RMSE: 1.7784\n",
      "XGBRegressor worst RMSE: 2.5193\n",
      "Corresponding penalty value: 1.8525\n",
      "\u001b[32m[I 2025-03-31 13:53:47,667]\u001b[0m Trial 14 finished with value: 1.8525214077130976 and parameters: {'n_estimators': 1061, 'learning_rate': 0.042010000000000006, 'max_depth': 4, 'max_leaves': 11, 'colsample_bytree': 0.71, 'subsample': 0.62, 'reg_alpha': 7.98, 'reg_lambda': 6.890000000000001, 'gamma': 0.45}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:09,  3.08s/it]\n",
      "1th fold: XGBRegressor RMSE: 1.6697\n",
      "2th fold: XGBRegressor RMSE: 2.0323\n",
      "3th fold: XGBRegressor RMSE: 1.2880\n",
      "\n",
      "XGBRegressor average RMSE: 1.6633\n",
      "XGBRegressor worst RMSE: 2.0323\n",
      "Corresponding penalty value: 1.7002\n",
      "\u001b[32m[I 2025-03-31 13:53:56,964]\u001b[0m Trial 15 finished with value: 1.7002195686084751 and parameters: {'n_estimators': 2396, 'learning_rate': 0.00101, 'max_depth': 10, 'max_leaves': 24, 'colsample_bytree': 0.88, 'subsample': 0.59, 'reg_alpha': 2.22, 'reg_lambda': 0.1, 'gamma': 2.17}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.59it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7057\n",
      "2th fold: XGBRegressor RMSE: 5.5333\n",
      "3th fold: XGBRegressor RMSE: 1.5356\n",
      "\n",
      "XGBRegressor average RMSE: 2.9249\n",
      "XGBRegressor worst RMSE: 5.5333\n",
      "Corresponding penalty value: 3.1857\n",
      "\u001b[32m[I 2025-03-31 13:53:58,911]\u001b[0m Trial 16 finished with value: 3.1857031142828074 and parameters: {'n_estimators': 1618, 'learning_rate': 0.02001, 'max_depth': 3, 'max_leaves': 2, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.67, 'reg_alpha': 5.42, 'reg_lambda': 2.81, 'gamma': 3.33}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.07it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6686\n",
      "2th fold: XGBRegressor RMSE: 2.4646\n",
      "3th fold: XGBRegressor RMSE: 1.3116\n",
      "\n",
      "XGBRegressor average RMSE: 1.8149\n",
      "XGBRegressor worst RMSE: 2.4646\n",
      "Corresponding penalty value: 1.8799\n",
      "\u001b[32m[I 2025-03-31 13:54:01,770]\u001b[0m Trial 17 finished with value: 1.879894175881963 and parameters: {'n_estimators': 2393, 'learning_rate': 0.04601, 'max_depth': 8, 'max_leaves': 7, 'colsample_bytree': 0.72, 'subsample': 0.8200000000000001, 'reg_alpha': 8.14, 'reg_lambda': 2.56, 'gamma': 1.77}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  2.60it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7764\n",
      "2th fold: XGBRegressor RMSE: 2.1973\n",
      "3th fold: XGBRegressor RMSE: 1.2738\n",
      "\n",
      "XGBRegressor average RMSE: 1.7491\n",
      "XGBRegressor worst RMSE: 2.1973\n",
      "Corresponding penalty value: 1.7940\n",
      "\u001b[32m[I 2025-03-31 13:54:02,982]\u001b[0m Trial 18 finished with value: 1.7939549426977246 and parameters: {'n_estimators': 756, 'learning_rate': 0.06601, 'max_depth': 9, 'max_leaves': 21, 'colsample_bytree': 0.9299999999999999, 'subsample': 0.5700000000000001, 'reg_alpha': 1.1, 'reg_lambda': 4.83, 'gamma': 0.8200000000000001}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.15it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7455\n",
      "2th fold: XGBRegressor RMSE: 2.4624\n",
      "3th fold: XGBRegressor RMSE: 1.0979\n",
      "\n",
      "XGBRegressor average RMSE: 1.7686\n",
      "XGBRegressor worst RMSE: 2.4624\n",
      "Corresponding penalty value: 1.8380\n",
      "\u001b[32m[I 2025-03-31 13:54:05,637]\u001b[0m Trial 19 finished with value: 1.8379712259196888 and parameters: {'n_estimators': 1297, 'learning_rate': 0.01001, 'max_depth': 6, 'max_leaves': 14, 'colsample_bytree': 0.99, 'subsample': 0.5, 'reg_alpha': 3.2, 'reg_lambda': 7.34, 'gamma': 1.77}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.28it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5320\n",
      "2th fold: XGBRegressor RMSE: 2.3190\n",
      "3th fold: XGBRegressor RMSE: 1.1460\n",
      "\n",
      "XGBRegressor average RMSE: 1.6657\n",
      "XGBRegressor worst RMSE: 2.3190\n",
      "Corresponding penalty value: 1.7310\n",
      "\u001b[32m[I 2025-03-31 13:54:08,031]\u001b[0m Trial 20 finished with value: 1.7309966275830102 and parameters: {'n_estimators': 1871, 'learning_rate': 0.02501, 'max_depth': 5, 'max_leaves': 10, 'colsample_bytree': 0.5, 'subsample': 0.73, 'reg_alpha': 5.46, 'reg_lambda': 3.62, 'gamma': 4.97}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.41it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6655\n",
      "2th fold: XGBRegressor RMSE: 1.8722\n",
      "3th fold: XGBRegressor RMSE: 1.1394\n",
      "\n",
      "XGBRegressor average RMSE: 1.5590\n",
      "XGBRegressor worst RMSE: 1.8722\n",
      "Corresponding penalty value: 1.5904\n",
      "\u001b[32m[I 2025-03-31 13:54:10,218]\u001b[0m Trial 21 finished with value: 1.5903538666166868 and parameters: {'n_estimators': 987, 'learning_rate': 0.01401, 'max_depth': 10, 'max_leaves': 30, 'colsample_bytree': 0.79, 'subsample': 0.77, 'reg_alpha': 7.3, 'reg_lambda': 5.93, 'gamma': 1.6600000000000001}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.99it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6846\n",
      "2th fold: XGBRegressor RMSE: 1.8623\n",
      "3th fold: XGBRegressor RMSE: 1.1524\n",
      "\n",
      "XGBRegressor average RMSE: 1.5664\n",
      "XGBRegressor worst RMSE: 1.8623\n",
      "Corresponding penalty value: 1.5960\n",
      "\u001b[32m[I 2025-03-31 13:54:11,788]\u001b[0m Trial 22 finished with value: 1.5960133988063474 and parameters: {'n_estimators': 1051, 'learning_rate': 0.03901, 'max_depth': 9, 'max_leaves': 27, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.9299999999999999, 'reg_alpha': 8.78, 'reg_lambda': 6.07, 'gamma': 2.92}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.99it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6940\n",
      "2th fold: XGBRegressor RMSE: 1.8100\n",
      "3th fold: XGBRegressor RMSE: 1.1567\n",
      "\n",
      "XGBRegressor average RMSE: 1.5536\n",
      "XGBRegressor worst RMSE: 1.8100\n",
      "Corresponding penalty value: 1.5792\n",
      "\u001b[32m[I 2025-03-31 13:54:13,354]\u001b[0m Trial 23 finished with value: 1.5792068954929377 and parameters: {'n_estimators': 947, 'learning_rate': 0.03901, 'max_depth': 9, 'max_leaves': 30, 'colsample_bytree': 0.8400000000000001, 'subsample': 0.96, 'reg_alpha': 8.78, 'reg_lambda': 5.8100000000000005, 'gamma': 0.7000000000000001}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  2.51it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7493\n",
      "2th fold: XGBRegressor RMSE: 1.9334\n",
      "3th fold: XGBRegressor RMSE: 1.2583\n",
      "\n",
      "XGBRegressor average RMSE: 1.6470\n",
      "XGBRegressor worst RMSE: 1.9334\n",
      "Corresponding penalty value: 1.6756\n",
      "\u001b[32m[I 2025-03-31 13:54:14,610]\u001b[0m Trial 24 finished with value: 1.6756148584637962 and parameters: {'n_estimators': 594, 'learning_rate': 0.03801, 'max_depth': 9, 'max_leaves': 30, 'colsample_bytree': 0.9299999999999999, 'subsample': 0.81, 'reg_alpha': 6.97, 'reg_lambda': 5.25, 'gamma': 0.66}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.68it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5473\n",
      "2th fold: XGBRegressor RMSE: 2.3323\n",
      "3th fold: XGBRegressor RMSE: 1.1650\n",
      "\n",
      "XGBRegressor average RMSE: 1.6815\n",
      "XGBRegressor worst RMSE: 2.3323\n",
      "Corresponding penalty value: 1.7466\n",
      "\u001b[32m[I 2025-03-31 13:54:16,456]\u001b[0m Trial 25 finished with value: 1.746615121598808 and parameters: {'n_estimators': 1073, 'learning_rate': 0.050010000000000006, 'max_depth': 7, 'max_leaves': 22, 'colsample_bytree': 0.76, 'subsample': 1.0, 'reg_alpha': 8.98, 'reg_lambda': 8.0, 'gamma': 0.03}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.90it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6857\n",
      "2th fold: XGBRegressor RMSE: 1.9199\n",
      "3th fold: XGBRegressor RMSE: 1.1726\n",
      "\n",
      "XGBRegressor average RMSE: 1.5927\n",
      "XGBRegressor worst RMSE: 1.9199\n",
      "Corresponding penalty value: 1.6254\n",
      "\u001b[32m[I 2025-03-31 13:54:18,102]\u001b[0m Trial 26 finished with value: 1.6254249473266265 and parameters: {'n_estimators': 783, 'learning_rate': 0.02301, 'max_depth': 9, 'max_leaves': 28, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.94, 'reg_alpha': 9.93, 'reg_lambda': 6.49, 'gamma': 1.1500000000000001}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.77it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7548\n",
      "2th fold: XGBRegressor RMSE: 1.6146\n",
      "3th fold: XGBRegressor RMSE: 1.5278\n",
      "\n",
      "XGBRegressor average RMSE: 1.6324\n",
      "XGBRegressor worst RMSE: 1.7548\n",
      "Corresponding penalty value: 1.6446\n",
      "\u001b[32m[I 2025-03-31 13:54:19,856]\u001b[0m Trial 27 finished with value: 1.6446339921950681 and parameters: {'n_estimators': 1277, 'learning_rate': 0.06801, 'max_depth': 8, 'max_leaves': 5, 'colsample_bytree': 0.95, 'subsample': 0.89, 'reg_alpha': 7.43, 'reg_lambda': 5.21, 'gamma': 1.7}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.23it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6975\n",
      "2th fold: XGBRegressor RMSE: 2.0885\n",
      "3th fold: XGBRegressor RMSE: 1.2753\n",
      "\n",
      "XGBRegressor average RMSE: 1.6871\n",
      "XGBRegressor worst RMSE: 2.0885\n",
      "Corresponding penalty value: 1.7272\n",
      "\u001b[32m[I 2025-03-31 13:54:22,350]\u001b[0m Trial 28 finished with value: 1.7272284396112758 and parameters: {'n_estimators': 874, 'learning_rate': 0.011009999999999999, 'max_depth': 5, 'max_leaves': 30, 'colsample_bytree': 0.86, 'subsample': 0.81, 'reg_alpha': 8.59, 'reg_lambda': 7.05, 'gamma': 0.44}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.59it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7078\n",
      "2th fold: XGBRegressor RMSE: 2.8246\n",
      "3th fold: XGBRegressor RMSE: 1.6978\n",
      "\n",
      "XGBRegressor average RMSE: 2.0767\n",
      "XGBRegressor worst RMSE: 2.8246\n",
      "Corresponding penalty value: 2.1515\n",
      "\u001b[32m[I 2025-03-31 13:54:24,306]\u001b[0m Trial 29 finished with value: 2.151506895387655 and parameters: {'n_estimators': 1465, 'learning_rate': 0.034010000000000006, 'max_depth': 2, 'max_leaves': 20, 'colsample_bytree': 0.72, 'subsample': 0.7, 'reg_alpha': 6.8, 'reg_lambda': 7.96, 'gamma': 2.06}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.84it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6646\n",
      "2th fold: XGBRegressor RMSE: 2.5219\n",
      "3th fold: XGBRegressor RMSE: 1.2824\n",
      "\n",
      "XGBRegressor average RMSE: 1.8230\n",
      "XGBRegressor worst RMSE: 2.5219\n",
      "Corresponding penalty value: 1.8928\n",
      "\u001b[32m[I 2025-03-31 13:54:26,002]\u001b[0m Trial 30 finished with value: 1.892846213153339 and parameters: {'n_estimators': 1155, 'learning_rate': 0.05201000000000001, 'max_depth': 8, 'max_leaves': 17, 'colsample_bytree': 0.8, 'subsample': 0.78, 'reg_alpha': 9.040000000000001, 'reg_lambda': 8.44, 'gamma': 0.97}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  2.09it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6681\n",
      "2th fold: XGBRegressor RMSE: 1.8832\n",
      "3th fold: XGBRegressor RMSE: 1.2040\n",
      "\n",
      "XGBRegressor average RMSE: 1.5851\n",
      "XGBRegressor worst RMSE: 1.8832\n",
      "Corresponding penalty value: 1.6149\n",
      "\u001b[32m[I 2025-03-31 13:54:27,501]\u001b[0m Trial 31 finished with value: 1.614931107068683 and parameters: {'n_estimators': 986, 'learning_rate': 0.041010000000000005, 'max_depth': 9, 'max_leaves': 27, 'colsample_bytree': 0.8300000000000001, 'subsample': 0.9299999999999999, 'reg_alpha': 8.700000000000001, 'reg_lambda': 6.22, 'gamma': 3.64}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.57it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6991\n",
      "2th fold: XGBRegressor RMSE: 1.9485\n",
      "3th fold: XGBRegressor RMSE: 1.2361\n",
      "\n",
      "XGBRegressor average RMSE: 1.6279\n",
      "XGBRegressor worst RMSE: 1.9485\n",
      "Corresponding penalty value: 1.6599\n",
      "\u001b[32m[I 2025-03-31 13:54:29,477]\u001b[0m Trial 32 finished with value: 1.6599299743715525 and parameters: {'n_estimators': 1370, 'learning_rate': 0.02901, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.86, 'subsample': 0.9299999999999999, 'reg_alpha': 9.3, 'reg_lambda': 5.61, 'gamma': 2.72}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  2.59it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6285\n",
      "2th fold: XGBRegressor RMSE: 1.9067\n",
      "3th fold: XGBRegressor RMSE: 1.1048\n",
      "\n",
      "XGBRegressor average RMSE: 1.5467\n",
      "XGBRegressor worst RMSE: 1.9067\n",
      "Corresponding penalty value: 1.5827\n",
      "\u001b[32m[I 2025-03-31 13:54:30,701]\u001b[0m Trial 33 finished with value: 1.5826594376674985 and parameters: {'n_estimators': 693, 'learning_rate': 0.03801, 'max_depth': 9, 'max_leaves': 29, 'colsample_bytree': 0.76, 'subsample': 0.96, 'reg_alpha': 8.290000000000001, 'reg_lambda': 4.53, 'gamma': 2.66}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  2.27it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6206\n",
      "2th fold: XGBRegressor RMSE: 1.9867\n",
      "3th fold: XGBRegressor RMSE: 1.1004\n",
      "\n",
      "XGBRegressor average RMSE: 1.5693\n",
      "XGBRegressor worst RMSE: 1.9867\n",
      "Corresponding penalty value: 1.6110\n",
      "\u001b[32m[I 2025-03-31 13:54:32,091]\u001b[0m Trial 34 finished with value: 1.6110009559918763 and parameters: {'n_estimators': 645, 'learning_rate': 0.02501, 'max_depth': 7, 'max_leaves': 29, 'colsample_bytree': 0.67, 'subsample': 0.97, 'reg_alpha': 8.21, 'reg_lambda': 4.48, 'gamma': 1.49}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.56it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6264\n",
      "2th fold: XGBRegressor RMSE: 2.0020\n",
      "3th fold: XGBRegressor RMSE: 1.2334\n",
      "\n",
      "XGBRegressor average RMSE: 1.6206\n",
      "XGBRegressor worst RMSE: 2.0020\n",
      "Corresponding penalty value: 1.6587\n",
      "\u001b[32m[I 2025-03-31 13:54:34,087]\u001b[0m Trial 35 finished with value: 1.6587486749271712 and parameters: {'n_estimators': 1526, 'learning_rate': 0.04601, 'max_depth': 9, 'max_leaves': 25, 'colsample_bytree': 0.75, 'subsample': 0.89, 'reg_alpha': 7.48, 'reg_lambda': 7.44, 'gamma': 2.0300000000000002}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.95it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6556\n",
      "2th fold: XGBRegressor RMSE: 2.5375\n",
      "3th fold: XGBRegressor RMSE: 1.1478\n",
      "\n",
      "XGBRegressor average RMSE: 1.7803\n",
      "XGBRegressor worst RMSE: 2.5375\n",
      "Corresponding penalty value: 1.8560\n",
      "\u001b[32m[I 2025-03-31 13:54:35,694]\u001b[0m Trial 36 finished with value: 1.8560000590375383 and parameters: {'n_estimators': 719, 'learning_rate': 0.01801, 'max_depth': 10, 'max_leaves': 14, 'colsample_bytree': 0.79, 'subsample': 0.96, 'reg_alpha': 9.88, 'reg_lambda': 3.5700000000000003, 'gamma': 1.26}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.27it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6292\n",
      "2th fold: XGBRegressor RMSE: 1.8666\n",
      "3th fold: XGBRegressor RMSE: 1.1305\n",
      "\n",
      "XGBRegressor average RMSE: 1.5421\n",
      "XGBRegressor worst RMSE: 1.8666\n",
      "Corresponding penalty value: 1.5746\n",
      "\u001b[32m[I 2025-03-31 13:54:38,132]\u001b[0m Trial 37 finished with value: 1.5745735827118004 and parameters: {'n_estimators': 1661, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 28, 'colsample_bytree': 0.76, 'subsample': 0.9, 'reg_alpha': 7.22, 'reg_lambda': 9.82, 'gamma': 0.72}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.33it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5916\n",
      "2th fold: XGBRegressor RMSE: 2.3778\n",
      "3th fold: XGBRegressor RMSE: 1.1522\n",
      "\n",
      "XGBRegressor average RMSE: 1.7072\n",
      "XGBRegressor worst RMSE: 2.3778\n",
      "Corresponding penalty value: 1.7743\n",
      "\u001b[32m[I 2025-03-31 13:54:40,454]\u001b[0m Trial 38 finished with value: 1.7742613930025408 and parameters: {'n_estimators': 1662, 'learning_rate': 0.033010000000000005, 'max_depth': 6, 'max_leaves': 19, 'colsample_bytree': 0.69, 'subsample': 0.9, 'reg_alpha': 9.4, 'reg_lambda': 9.93, 'gamma': 0.61}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  1.96it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6078\n",
      "2th fold: XGBRegressor RMSE: 2.1658\n",
      "3th fold: XGBRegressor RMSE: 1.1886\n",
      "\n",
      "XGBRegressor average RMSE: 1.6541\n",
      "XGBRegressor worst RMSE: 2.1658\n",
      "Corresponding penalty value: 1.7053\n",
      "\u001b[32m[I 2025-03-31 13:54:42,059]\u001b[0m Trial 39 finished with value: 1.7052534270560091 and parameters: {'n_estimators': 1173, 'learning_rate': 0.06001, 'max_depth': 5, 'max_leaves': 23, 'colsample_bytree': 0.75, 'subsample': 0.97, 'reg_alpha': 8.41, 'reg_lambda': 9.4, 'gamma': 0.88}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.30it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5766\n",
      "2th fold: XGBRegressor RMSE: 2.1418\n",
      "3th fold: XGBRegressor RMSE: 1.1906\n",
      "\n",
      "XGBRegressor average RMSE: 1.6364\n",
      "XGBRegressor worst RMSE: 2.1418\n",
      "Corresponding penalty value: 1.6869\n",
      "\u001b[32m[I 2025-03-31 13:54:44,446]\u001b[0m Trial 40 finished with value: 1.6869016879766372 and parameters: {'n_estimators': 1681, 'learning_rate': 0.03601000000000001, 'max_depth': 6, 'max_leaves': 28, 'colsample_bytree': 0.64, 'subsample': 0.8500000000000001, 'reg_alpha': 6.03, 'reg_lambda': 1.74, 'gamma': 0.27}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.19it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6259\n",
      "2th fold: XGBRegressor RMSE: 1.8836\n",
      "3th fold: XGBRegressor RMSE: 1.1146\n",
      "\n",
      "XGBRegressor average RMSE: 1.5413\n",
      "XGBRegressor worst RMSE: 1.8836\n",
      "Corresponding penalty value: 1.5756\n",
      "\u001b[32m[I 2025-03-31 13:54:47,029]\u001b[0m Trial 41 finished with value: 1.5755683053450098 and parameters: {'n_estimators': 1800, 'learning_rate': 0.02701, 'max_depth': 7, 'max_leaves': 29, 'colsample_bytree': 0.77, 'subsample': 1.0, 'reg_alpha': 7.18, 'reg_lambda': 8.540000000000001, 'gamma': 1.1500000000000001}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.21it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6509\n",
      "2th fold: XGBRegressor RMSE: 2.0820\n",
      "3th fold: XGBRegressor RMSE: 1.1138\n",
      "\n",
      "XGBRegressor average RMSE: 1.6156\n",
      "XGBRegressor worst RMSE: 2.0820\n",
      "Corresponding penalty value: 1.6622\n",
      "\u001b[32m[I 2025-03-31 13:54:49,576]\u001b[0m Trial 42 finished with value: 1.6622125302631563 and parameters: {'n_estimators': 1818, 'learning_rate': 0.02701, 'max_depth': 7, 'max_leaves': 26, 'colsample_bytree': 0.76, 'subsample': 1.0, 'reg_alpha': 4.7, 'reg_lambda': 8.61, 'gamma': 1.06}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7129\n",
      "2th fold: XGBRegressor RMSE: 1.9467\n",
      "3th fold: XGBRegressor RMSE: 1.2171\n",
      "\n",
      "XGBRegressor average RMSE: 1.6256\n",
      "XGBRegressor worst RMSE: 1.9467\n",
      "Corresponding penalty value: 1.6577\n",
      "\u001b[32m[I 2025-03-31 13:54:52,320]\u001b[0m Trial 43 finished with value: 1.6576741923676324 and parameters: {'n_estimators': 1937, 'learning_rate': 0.03001, 'max_depth': 8, 'max_leaves': 27, 'colsample_bytree': 0.86, 'subsample': 0.95, 'reg_alpha': 7.79, 'reg_lambda': 9.4, 'gamma': 0.61}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6023\n",
      "2th fold: XGBRegressor RMSE: 1.9628\n",
      "3th fold: XGBRegressor RMSE: 1.1481\n",
      "\n",
      "XGBRegressor average RMSE: 1.5710\n",
      "XGBRegressor worst RMSE: 1.9628\n",
      "Corresponding penalty value: 1.6102\n",
      "\u001b[32m[I 2025-03-31 13:54:54,927]\u001b[0m Trial 44 finished with value: 1.6102179461514976 and parameters: {'n_estimators': 2108, 'learning_rate': 0.04401, 'max_depth': 7, 'max_leaves': 29, 'colsample_bytree': 0.74, 'subsample': 0.91, 'reg_alpha': 6.93, 'reg_lambda': 8.27, 'gamma': 1.47}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.40it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.7234\n",
      "2th fold: XGBRegressor RMSE: 2.3705\n",
      "3th fold: XGBRegressor RMSE: 1.7736\n",
      "\n",
      "XGBRegressor average RMSE: 1.9558\n",
      "XGBRegressor worst RMSE: 2.3705\n",
      "Corresponding penalty value: 1.9973\n",
      "\u001b[32m[I 2025-03-31 13:54:57,145]\u001b[0m Trial 45 finished with value: 1.9972954202464512 and parameters: {'n_estimators': 1516, 'learning_rate': 0.02101, 'max_depth': 6, 'max_leaves': 4, 'colsample_bytree': 0.81, 'subsample': 0.98, 'reg_alpha': 5.92, 'reg_lambda': 9.06, 'gamma': 2.57}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.21it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6653\n",
      "2th fold: XGBRegressor RMSE: 2.1133\n",
      "3th fold: XGBRegressor RMSE: 1.2874\n",
      "\n",
      "XGBRegressor average RMSE: 1.6887\n",
      "XGBRegressor worst RMSE: 2.1133\n",
      "Corresponding penalty value: 1.7311\n",
      "\u001b[32m[I 2025-03-31 13:54:59,693]\u001b[0m Trial 46 finished with value: 1.73112101986891 and parameters: {'n_estimators': 1364, 'learning_rate': 0.03701, 'max_depth': 5, 'max_leaves': 25, 'colsample_bytree': 0.91, 'subsample': 0.86, 'reg_alpha': 9.32, 'reg_lambda': 7.5, 'gamma': 0.02}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.6480\n",
      "2th fold: XGBRegressor RMSE: 2.5995\n",
      "3th fold: XGBRegressor RMSE: 1.2765\n",
      "\n",
      "XGBRegressor average RMSE: 1.8413\n",
      "XGBRegressor worst RMSE: 2.5995\n",
      "Corresponding penalty value: 1.9171\n",
      "\u001b[32m[I 2025-03-31 13:55:02,451]\u001b[0m Trial 47 finished with value: 1.9171431637489518 and parameters: {'n_estimators': 2222, 'learning_rate': 0.05401, 'max_depth': 7, 'max_leaves': 10, 'colsample_bytree': 0.77, 'subsample': 0.98, 'reg_alpha': 6.5600000000000005, 'reg_lambda': 9.97, 'gamma': 0.39}. Best is trial 7 with value: 1.5732911058302859.\u001b[0m\n",
      "3it [00:01,  2.74it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5773\n",
      "2th fold: XGBRegressor RMSE: 1.8137\n",
      "3th fold: XGBRegressor RMSE: 1.0948\n",
      "\n",
      "XGBRegressor average RMSE: 1.4953\n",
      "XGBRegressor worst RMSE: 1.8137\n",
      "Corresponding penalty value: 1.5271\n",
      "\u001b[32m[I 2025-03-31 13:55:03,620]\u001b[0m Trial 48 finished with value: 1.5271023710779328 and parameters: {'n_estimators': 515, 'learning_rate': 0.032010000000000004, 'max_depth': 8, 'max_leaves': 29, 'colsample_bytree': 0.62, 'subsample': 0.9199999999999999, 'reg_alpha': 8.08, 'reg_lambda': 8.82, 'gamma': 1.35}. Best is trial 48 with value: 1.5271023710779328.\u001b[0m\n",
      "3it [00:01,  1.69it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.4792\n",
      "2th fold: XGBRegressor RMSE: 2.0068\n",
      "3th fold: XGBRegressor RMSE: 1.0679\n",
      "\n",
      "XGBRegressor average RMSE: 1.5180\n",
      "XGBRegressor worst RMSE: 2.0068\n",
      "Corresponding penalty value: 1.5669\n",
      "\u001b[32m[I 2025-03-31 13:55:05,474]\u001b[0m Trial 49 finished with value: 1.566855173540103 and parameters: {'n_estimators': 511, 'learning_rate': 0.00601, 'max_depth': 7, 'max_leaves': 23, 'colsample_bytree': 0.53, 'subsample': 0.91, 'reg_alpha': 7.75, 'reg_lambda': 8.73, 'gamma': 0.79}. Best is trial 48 with value: 1.5271023710779328.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 515, 'learning_rate': 0.032010000000000004, 'max_depth': 8, 'max_leaves': 29, 'colsample_bytree': 0.62, 'subsample': 0.9199999999999999, 'reg_alpha': 8.08, 'reg_lambda': 8.82, 'gamma': 1.35}\n",
      "3it [00:01,  2.72it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.5582\n",
      "2th fold: XGBRegressor RMSE: 1.8327\n",
      "3th fold: XGBRegressor RMSE: 1.1311\n",
      "\n",
      "XGBRegressor average RMSE: 1.5073\n",
      "XGBRegressor worst RMSE: 1.8327\n",
      "Corresponding penalty value: 1.5399\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB10\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 515, 'learning_rate': 0.032010000000000004, 'max_depth': 8, 'max_leaves': 29, 'colsample_bytree': 0.62, 'subsample': 0.9199999999999999, 'reg_alpha': 8.08, 'reg_lambda': 8.82, 'gamma': 1.35}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.249\n",
      "RMSE_crossval: 1.507\n",
      "RMSE_test: 1.333\n",
      "MAE_test: 1.113\n",
      "Nash-Sutcliffe Test: -0.060\n",
      "Kling-Gupta Test: 0.008\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 126.3539 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 13:55:07,770]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB18\u001b[0m\n",
      "3it [00:01,  1.76it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.9827\n",
      "2th fold: XGBRegressor RMSE: 1.7332\n",
      "3th fold: XGBRegressor RMSE: 5.7874\n",
      "\n",
      "XGBRegressor average RMSE: 3.5011\n",
      "XGBRegressor worst RMSE: 5.7874\n",
      "Corresponding penalty value: 3.7297\n",
      "\u001b[32m[I 2025-03-31 13:55:09,478]\u001b[0m Trial 0 finished with value: 3.729740722917202 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.5700000000000001, 'reg_alpha': 0.58, 'reg_lambda': 8.67, 'gamma': 3.0100000000000002}. Best is trial 0 with value: 3.729740722917202.\u001b[0m\n",
      "3it [00:07,  2.56s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.4744\n",
      "2th fold: XGBRegressor RMSE: 1.7550\n",
      "3th fold: XGBRegressor RMSE: 5.7122\n",
      "\n",
      "XGBRegressor average RMSE: 3.6472\n",
      "XGBRegressor worst RMSE: 5.7122\n",
      "Corresponding penalty value: 3.8537\n",
      "\u001b[32m[I 2025-03-31 13:55:17,153]\u001b[0m Trial 1 finished with value: 3.853724597531719 and parameters: {'n_estimators': 2270, 'learning_rate': 0.00201, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6, 'subsample': 0.59, 'reg_alpha': 1.83, 'reg_lambda': 3.04, 'gamma': 2.62}. Best is trial 0 with value: 3.729740722917202.\u001b[0m\n",
      "3it [00:02,  1.24it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4853\n",
      "2th fold: XGBRegressor RMSE: 1.5840\n",
      "3th fold: XGBRegressor RMSE: 5.4920\n",
      "\n",
      "XGBRegressor average RMSE: 3.5204\n",
      "XGBRegressor worst RMSE: 5.4920\n",
      "Corresponding penalty value: 3.7176\n",
      "\u001b[32m[I 2025-03-31 13:55:19,578]\u001b[0m Trial 2 finished with value: 3.717593093597571 and parameters: {'n_estimators': 1580, 'learning_rate': 0.02901, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.64, 'subsample': 0.6799999999999999, 'reg_alpha': 4.5600000000000005, 'reg_lambda': 7.8500000000000005, 'gamma': 1.0}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.43it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.2654\n",
      "2th fold: XGBRegressor RMSE: 2.5387\n",
      "3th fold: XGBRegressor RMSE: 5.4608\n",
      "\n",
      "XGBRegressor average RMSE: 3.7550\n",
      "XGBRegressor worst RMSE: 5.4608\n",
      "Corresponding penalty value: 3.9256\n",
      "\u001b[32m[I 2025-03-31 13:55:21,683]\u001b[0m Trial 3 finished with value: 3.925575119830073 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05901000000000001, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.58, 'subsample': 0.53, 'reg_alpha': 9.49, 'reg_lambda': 9.66, 'gamma': 4.05}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.3056\n",
      "2th fold: XGBRegressor RMSE: 1.7164\n",
      "3th fold: XGBRegressor RMSE: 5.6034\n",
      "\n",
      "XGBRegressor average RMSE: 3.5418\n",
      "XGBRegressor worst RMSE: 5.6034\n",
      "Corresponding penalty value: 3.7480\n",
      "\u001b[32m[I 2025-03-31 13:55:24,606]\u001b[0m Trial 4 finished with value: 3.7479600466036644 and parameters: {'n_estimators': 1261, 'learning_rate': 0.00901, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.56, 'subsample': 0.75, 'reg_alpha': 0.34, 'reg_lambda': 9.1, 'gamma': 1.29}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.14it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1561\n",
      "2th fold: XGBRegressor RMSE: 1.6962\n",
      "3th fold: XGBRegressor RMSE: 5.6956\n",
      "\n",
      "XGBRegressor average RMSE: 3.5160\n",
      "XGBRegressor worst RMSE: 5.6956\n",
      "Corresponding penalty value: 3.7339\n",
      "\u001b[32m[I 2025-03-31 13:55:27,233]\u001b[0m Trial 5 finished with value: 3.7339413742102163 and parameters: {'n_estimators': 2156, 'learning_rate': 0.03101, 'max_depth': 6, 'max_leaves': 17, 'colsample_bytree': 0.59, 'subsample': 0.99, 'reg_alpha': 7.75, 'reg_lambda': 9.4, 'gamma': 4.48}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.36it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.3832\n",
      "2th fold: XGBRegressor RMSE: 2.6191\n",
      "3th fold: XGBRegressor RMSE: 5.5370\n",
      "\n",
      "XGBRegressor average RMSE: 3.8465\n",
      "XGBRegressor worst RMSE: 5.5370\n",
      "Corresponding penalty value: 4.0155\n",
      "\u001b[32m[I 2025-03-31 13:55:29,439]\u001b[0m Trial 6 finished with value: 4.015523684783445 and parameters: {'n_estimators': 1995, 'learning_rate': 0.09201, 'max_depth': 1, 'max_leaves': 7, 'colsample_bytree': 0.52, 'subsample': 0.66, 'reg_alpha': 3.89, 'reg_lambda': 2.71, 'gamma': 4.15}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 4.2433\n",
      "2th fold: XGBRegressor RMSE: 1.6076\n",
      "3th fold: XGBRegressor RMSE: 5.5631\n",
      "\n",
      "XGBRegressor average RMSE: 3.8047\n",
      "XGBRegressor worst RMSE: 5.5631\n",
      "Corresponding penalty value: 3.9805\n",
      "\u001b[32m[I 2025-03-31 13:55:31,979]\u001b[0m Trial 7 finished with value: 3.9805165716433164 and parameters: {'n_estimators': 1392, 'learning_rate': 0.02801, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.9, 'subsample': 0.53, 'reg_alpha': 9.870000000000001, 'reg_lambda': 7.73, 'gamma': 0.99}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:00,  3.66it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.9762\n",
      "2th fold: XGBRegressor RMSE: 1.7262\n",
      "3th fold: XGBRegressor RMSE: 5.7901\n",
      "\n",
      "XGBRegressor average RMSE: 3.8308\n",
      "XGBRegressor worst RMSE: 5.7901\n",
      "Corresponding penalty value: 4.0268\n",
      "\u001b[32m[I 2025-03-31 13:55:32,801]\u001b[0m Trial 8 finished with value: 4.026758752155749 and parameters: {'n_estimators': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'max_leaves': 23, 'colsample_bytree': 0.89, 'subsample': 0.53, 'reg_alpha': 3.58, 'reg_lambda': 1.1500000000000001, 'gamma': 4.32}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.28it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1283\n",
      "2th fold: XGBRegressor RMSE: 2.6031\n",
      "3th fold: XGBRegressor RMSE: 5.4566\n",
      "\n",
      "XGBRegressor average RMSE: 3.7293\n",
      "XGBRegressor worst RMSE: 5.4566\n",
      "Corresponding penalty value: 3.9021\n",
      "\u001b[32m[I 2025-03-31 13:55:35,146]\u001b[0m Trial 9 finished with value: 3.9020759151412667 and parameters: {'n_estimators': 2058, 'learning_rate': 0.033010000000000005, 'max_depth': 1, 'max_leaves': 11, 'colsample_bytree': 0.66, 'subsample': 0.87, 'reg_alpha': 6.38, 'reg_lambda': 8.88, 'gamma': 2.36}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:03,  1.10s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.8392\n",
      "2th fold: XGBRegressor RMSE: 2.6324\n",
      "3th fold: XGBRegressor RMSE: 5.5254\n",
      "\n",
      "XGBRegressor average RMSE: 3.9990\n",
      "XGBRegressor worst RMSE: 5.5254\n",
      "Corresponding penalty value: 4.1517\n",
      "\u001b[32m[I 2025-03-31 13:55:38,490]\u001b[0m Trial 10 finished with value: 4.151661933390607 and parameters: {'n_estimators': 2863, 'learning_rate': 0.056010000000000004, 'max_depth': 4, 'max_leaves': 2, 'colsample_bytree': 0.75, 'subsample': 0.76, 'reg_alpha': 5.5200000000000005, 'reg_lambda': 6.24, 'gamma': 0.2}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:01,  2.12it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.6558\n",
      "2th fold: XGBRegressor RMSE: 1.6409\n",
      "3th fold: XGBRegressor RMSE: 5.7469\n",
      "\n",
      "XGBRegressor average RMSE: 3.6812\n",
      "XGBRegressor worst RMSE: 5.7469\n",
      "Corresponding penalty value: 3.8878\n",
      "\u001b[32m[I 2025-03-31 13:55:39,959]\u001b[0m Trial 11 finished with value: 3.8877682214433134 and parameters: {'n_estimators': 1078, 'learning_rate': 0.07101, 'max_depth': 9, 'max_leaves': 21, 'colsample_bytree': 0.72, 'subsample': 0.67, 'reg_alpha': 0.47000000000000003, 'reg_lambda': 6.07, 'gamma': 2.85}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:01,  2.25it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.6109\n",
      "2th fold: XGBRegressor RMSE: 1.7180\n",
      "3th fold: XGBRegressor RMSE: 5.7823\n",
      "\n",
      "XGBRegressor average RMSE: 3.7038\n",
      "XGBRegressor worst RMSE: 5.7823\n",
      "Corresponding penalty value: 3.9116\n",
      "\u001b[32m[I 2025-03-31 13:55:41,348]\u001b[0m Trial 12 finished with value: 3.9116150206063764 and parameters: {'n_estimators': 893, 'learning_rate': 0.042010000000000006, 'max_depth': 5, 'max_leaves': 30, 'colsample_bytree': 0.69, 'subsample': 0.66, 'reg_alpha': 1.92, 'reg_lambda': 7.21, 'gamma': 1.68}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:01,  1.57it/s]\n",
      "1th fold: XGBRegressor RMSE: 4.0099\n",
      "2th fold: XGBRegressor RMSE: 1.6512\n",
      "3th fold: XGBRegressor RMSE: 5.7075\n",
      "\n",
      "XGBRegressor average RMSE: 3.7895\n",
      "XGBRegressor worst RMSE: 5.7075\n",
      "Corresponding penalty value: 3.9813\n",
      "\u001b[32m[I 2025-03-31 13:55:43,315]\u001b[0m Trial 13 finished with value: 3.9813045883962324 and parameters: {'n_estimators': 1660, 'learning_rate': 0.09801, 'max_depth': 8, 'max_leaves': 13, 'colsample_bytree': 0.8400000000000001, 'subsample': 0.75, 'reg_alpha': 3.3000000000000003, 'reg_lambda': 4.72, 'gamma': 3.29}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:04,  1.50s/it]\n",
      "1th fold: XGBRegressor RMSE: 4.5418\n",
      "2th fold: XGBRegressor RMSE: 1.5939\n",
      "3th fold: XGBRegressor RMSE: 5.6207\n",
      "\n",
      "XGBRegressor average RMSE: 3.9188\n",
      "XGBRegressor worst RMSE: 5.6207\n",
      "Corresponding penalty value: 4.0890\n",
      "\u001b[32m[I 2025-03-31 13:55:47,877]\u001b[0m Trial 14 finished with value: 4.08899222951513 and parameters: {'n_estimators': 2610, 'learning_rate': 0.015009999999999999, 'max_depth': 4, 'max_leaves': 8, 'colsample_bytree': 0.98, 'subsample': 0.61, 'reg_alpha': 6.6000000000000005, 'reg_lambda': 7.83, 'gamma': 0.45}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:01,  1.66it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1340\n",
      "2th fold: XGBRegressor RMSE: 2.5746\n",
      "3th fold: XGBRegressor RMSE: 5.5419\n",
      "\n",
      "XGBRegressor average RMSE: 3.7502\n",
      "XGBRegressor worst RMSE: 5.5419\n",
      "Corresponding penalty value: 3.9293\n",
      "\u001b[32m[I 2025-03-31 13:55:49,738]\u001b[0m Trial 15 finished with value: 3.929324194014608 and parameters: {'n_estimators': 1552, 'learning_rate': 0.07300999999999999, 'max_depth': 10, 'max_leaves': 2, 'colsample_bytree': 0.65, 'subsample': 0.8400000000000001, 'reg_alpha': 2.09, 'reg_lambda': 5.08, 'gamma': 3.48}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:01,  2.63it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.2564\n",
      "2th fold: XGBRegressor RMSE: 1.7917\n",
      "3th fold: XGBRegressor RMSE: 5.7139\n",
      "\n",
      "XGBRegressor average RMSE: 3.5873\n",
      "XGBRegressor worst RMSE: 5.7139\n",
      "Corresponding penalty value: 3.8000\n",
      "\u001b[32m[I 2025-03-31 13:55:50,935]\u001b[0m Trial 16 finished with value: 3.7999989547845865 and parameters: {'n_estimators': 737, 'learning_rate': 0.04601, 'max_depth': 8, 'max_leaves': 25, 'colsample_bytree': 0.5, 'subsample': 0.6, 'reg_alpha': 4.43, 'reg_lambda': 8.13, 'gamma': 2.0300000000000002}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:01,  1.62it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.5186\n",
      "2th fold: XGBRegressor RMSE: 1.7233\n",
      "3th fold: XGBRegressor RMSE: 5.8013\n",
      "\n",
      "XGBRegressor average RMSE: 3.6810\n",
      "XGBRegressor worst RMSE: 5.8013\n",
      "Corresponding penalty value: 3.8931\n",
      "\u001b[32m[I 2025-03-31 13:55:52,849]\u001b[0m Trial 17 finished with value: 3.893063323410361 and parameters: {'n_estimators': 1238, 'learning_rate': 0.02201, 'max_depth': 7, 'max_leaves': 17, 'colsample_bytree': 0.77, 'subsample': 0.8300000000000001, 'reg_alpha': 8.14, 'reg_lambda': 6.8, 'gamma': 4.96}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.05it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.6124\n",
      "2th fold: XGBRegressor RMSE: 1.6585\n",
      "3th fold: XGBRegressor RMSE: 5.5290\n",
      "\n",
      "XGBRegressor average RMSE: 3.6000\n",
      "XGBRegressor worst RMSE: 5.5290\n",
      "Corresponding penalty value: 3.7929\n",
      "\u001b[32m[I 2025-03-31 13:55:55,752]\u001b[0m Trial 18 finished with value: 3.792881277118577 and parameters: {'n_estimators': 2434, 'learning_rate': 0.06601, 'max_depth': 3, 'max_leaves': 11, 'colsample_bytree': 0.62, 'subsample': 0.71, 'reg_alpha': 5.29, 'reg_lambda': 4.83, 'gamma': 0.8200000000000001}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.38it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.8562\n",
      "2th fold: XGBRegressor RMSE: 1.6420\n",
      "3th fold: XGBRegressor RMSE: 5.7288\n",
      "\n",
      "XGBRegressor average RMSE: 3.7423\n",
      "XGBRegressor worst RMSE: 5.7288\n",
      "Corresponding penalty value: 3.9410\n",
      "\u001b[32m[I 2025-03-31 13:55:57,987]\u001b[0m Trial 19 finished with value: 3.9409957365619412 and parameters: {'n_estimators': 1790, 'learning_rate': 0.08201, 'max_depth': 9, 'max_leaves': 20, 'colsample_bytree': 0.8, 'subsample': 0.5, 'reg_alpha': 2.41, 'reg_lambda': 9.99, 'gamma': 1.67}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:01,  1.52it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.2689\n",
      "2th fold: XGBRegressor RMSE: 1.7524\n",
      "3th fold: XGBRegressor RMSE: 5.7156\n",
      "\n",
      "XGBRegressor average RMSE: 3.5790\n",
      "XGBRegressor worst RMSE: 5.7156\n",
      "Corresponding penalty value: 3.7926\n",
      "\u001b[32m[I 2025-03-31 13:56:00,025]\u001b[0m Trial 20 finished with value: 3.7926182220947 and parameters: {'n_estimators': 1518, 'learning_rate': 0.03801, 'max_depth': 7, 'max_leaves': 29, 'colsample_bytree': 0.55, 'subsample': 0.59, 'reg_alpha': 0.92, 'reg_lambda': 8.59, 'gamma': 3.29}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.20it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.3233\n",
      "2th fold: XGBRegressor RMSE: 1.7235\n",
      "3th fold: XGBRegressor RMSE: 5.7852\n",
      "\n",
      "XGBRegressor average RMSE: 3.6107\n",
      "XGBRegressor worst RMSE: 5.7852\n",
      "Corresponding penalty value: 3.8281\n",
      "\u001b[32m[I 2025-03-31 13:56:02,578]\u001b[0m Trial 21 finished with value: 3.828118604877213 and parameters: {'n_estimators': 2075, 'learning_rate': 0.026010000000000002, 'max_depth': 6, 'max_leaves': 16, 'colsample_bytree': 0.63, 'subsample': 1.0, 'reg_alpha': 8.370000000000001, 'reg_lambda': 9.01, 'gamma': 4.89}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.42it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.3609\n",
      "2th fold: XGBRegressor RMSE: 1.6352\n",
      "3th fold: XGBRegressor RMSE: 5.7925\n",
      "\n",
      "XGBRegressor average RMSE: 3.5962\n",
      "XGBRegressor worst RMSE: 5.7925\n",
      "Corresponding penalty value: 3.8158\n",
      "\u001b[32m[I 2025-03-31 13:56:04,749]\u001b[0m Trial 22 finished with value: 3.8158179899218094 and parameters: {'n_estimators': 1874, 'learning_rate': 0.05101000000000001, 'max_depth': 5, 'max_leaves': 18, 'colsample_bytree': 0.6799999999999999, 'subsample': 1.0, 'reg_alpha': 7.01, 'reg_lambda': 9.98, 'gamma': 3.61}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:02,  1.02it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.0781\n",
      "2th fold: XGBRegressor RMSE: 1.7774\n",
      "3th fold: XGBRegressor RMSE: 5.6645\n",
      "\n",
      "XGBRegressor average RMSE: 3.5067\n",
      "XGBRegressor worst RMSE: 5.6645\n",
      "Corresponding penalty value: 3.7225\n",
      "\u001b[32m[I 2025-03-31 13:56:07,748]\u001b[0m Trial 23 finished with value: 3.7224534069373383 and parameters: {'n_estimators': 2320, 'learning_rate': 0.01901, 'max_depth': 6, 'max_leaves': 15, 'colsample_bytree': 0.54, 'subsample': 0.9199999999999999, 'reg_alpha': 8.06, 'reg_lambda': 6.96, 'gamma': 2.91}. Best is trial 2 with value: 3.717593093597571.\u001b[0m\n",
      "3it [00:03,  1.06s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.0618\n",
      "2th fold: XGBRegressor RMSE: 1.8675\n",
      "3th fold: XGBRegressor RMSE: 5.3074\n",
      "\n",
      "XGBRegressor average RMSE: 3.4122\n",
      "XGBRegressor worst RMSE: 5.3074\n",
      "Corresponding penalty value: 3.6018\n",
      "\u001b[32m[I 2025-03-31 13:56:10,993]\u001b[0m Trial 24 finished with value: 3.601756714191058 and parameters: {'n_estimators': 2479, 'learning_rate': 0.01801, 'max_depth': 7, 'max_leaves': 5, 'colsample_bytree': 0.53, 'subsample': 0.9299999999999999, 'reg_alpha': 8.92, 'reg_lambda': 5.87, 'gamma': 2.98}. Best is trial 24 with value: 3.601756714191058.\u001b[0m\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.0603\n",
      "2th fold: XGBRegressor RMSE: 1.8760\n",
      "3th fold: XGBRegressor RMSE: 5.2766\n",
      "\n",
      "XGBRegressor average RMSE: 3.4043\n",
      "XGBRegressor worst RMSE: 5.2766\n",
      "Corresponding penalty value: 3.5915\n",
      "\u001b[32m[I 2025-03-31 13:56:14,707]\u001b[0m Trial 25 finished with value: 3.59154300769426 and parameters: {'n_estimators': 2948, 'learning_rate': 0.01801, 'max_depth': 7, 'max_leaves': 5, 'colsample_bytree': 0.53, 'subsample': 0.9199999999999999, 'reg_alpha': 9.03, 'reg_lambda': 6.13, 'gamma': 2.16}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:05,  1.91s/it]\n",
      "1th fold: XGBRegressor RMSE: 5.9084\n",
      "2th fold: XGBRegressor RMSE: 3.6241\n",
      "3th fold: XGBRegressor RMSE: 5.9429\n",
      "\n",
      "XGBRegressor average RMSE: 5.1584\n",
      "XGBRegressor worst RMSE: 5.9429\n",
      "Corresponding penalty value: 5.2369\n",
      "\u001b[32m[I 2025-03-31 13:56:20,488]\u001b[0m Trial 26 finished with value: 5.236893266492853 and parameters: {'n_estimators': 2924, 'learning_rate': 1e-05, 'max_depth': 7, 'max_leaves': 5, 'colsample_bytree': 0.51, 'subsample': 0.9299999999999999, 'reg_alpha': 9.19, 'reg_lambda': 5.79, 'gamma': 2.18}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.21s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2388\n",
      "2th fold: XGBRegressor RMSE: 1.9011\n",
      "3th fold: XGBRegressor RMSE: 5.2094\n",
      "\n",
      "XGBRegressor average RMSE: 3.4498\n",
      "XGBRegressor worst RMSE: 5.2094\n",
      "Corresponding penalty value: 3.6257\n",
      "\u001b[32m[I 2025-03-31 13:56:24,173]\u001b[0m Trial 27 finished with value: 3.6257261280028925 and parameters: {'n_estimators': 2666, 'learning_rate': 0.01001, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 5.91, 'reg_lambda': 3.5, 'gamma': 1.71}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.23s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1666\n",
      "2th fold: XGBRegressor RMSE: 1.8481\n",
      "3th fold: XGBRegressor RMSE: 5.2264\n",
      "\n",
      "XGBRegressor average RMSE: 3.4137\n",
      "XGBRegressor worst RMSE: 5.2264\n",
      "Corresponding penalty value: 3.5950\n",
      "\u001b[32m[I 2025-03-31 13:56:27,933]\u001b[0m Trial 28 finished with value: 3.5949586271733858 and parameters: {'n_estimators': 2765, 'learning_rate': 0.011009999999999999, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.53, 'subsample': 0.91, 'reg_alpha': 7.3500000000000005, 'reg_lambda': 4.0, 'gamma': 1.83}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.28s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2351\n",
      "2th fold: XGBRegressor RMSE: 1.7295\n",
      "3th fold: XGBRegressor RMSE: 5.4678\n",
      "\n",
      "XGBRegressor average RMSE: 3.4775\n",
      "XGBRegressor worst RMSE: 5.4678\n",
      "Corresponding penalty value: 3.6765\n",
      "\u001b[32m[I 2025-03-31 13:56:31,840]\u001b[0m Trial 29 finished with value: 3.676505999480604 and parameters: {'n_estimators': 2743, 'learning_rate': 0.011009999999999999, 'max_depth': 8, 'max_leaves': 9, 'colsample_bytree': 0.55, 'subsample': 0.94, 'reg_alpha': 8.82, 'reg_lambda': 3.97, 'gamma': 2.66}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.05s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.4067\n",
      "2th fold: XGBRegressor RMSE: 1.9698\n",
      "3th fold: XGBRegressor RMSE: 5.2421\n",
      "\n",
      "XGBRegressor average RMSE: 3.5395\n",
      "XGBRegressor worst RMSE: 5.2421\n",
      "Corresponding penalty value: 3.7098\n",
      "\u001b[32m[I 2025-03-31 13:56:35,043]\u001b[0m Trial 30 finished with value: 3.7097999143789293 and parameters: {'n_estimators': 2495, 'learning_rate': 0.01901, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.6, 'subsample': 0.89, 'reg_alpha': 7.29, 'reg_lambda': 1.1, 'gamma': 2.09}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:04,  1.36s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.3248\n",
      "2th fold: XGBRegressor RMSE: 1.8619\n",
      "3th fold: XGBRegressor RMSE: 5.2172\n",
      "\n",
      "XGBRegressor average RMSE: 3.4680\n",
      "XGBRegressor worst RMSE: 5.2172\n",
      "Corresponding penalty value: 3.6429\n",
      "\u001b[32m[I 2025-03-31 13:56:39,186]\u001b[0m Trial 31 finished with value: 3.6429016350585033 and parameters: {'n_estimators': 2988, 'learning_rate': 0.00801, 'max_depth': 9, 'max_leaves': 4, 'colsample_bytree': 0.51, 'subsample': 0.79, 'reg_alpha': 6.04, 'reg_lambda': 3.29, 'gamma': 1.77}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:05,  1.72s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1964\n",
      "2th fold: XGBRegressor RMSE: 1.6693\n",
      "3th fold: XGBRegressor RMSE: 5.4968\n",
      "\n",
      "XGBRegressor average RMSE: 3.4541\n",
      "XGBRegressor worst RMSE: 5.4968\n",
      "Corresponding penalty value: 3.6584\n",
      "\u001b[32m[I 2025-03-31 13:56:44,409]\u001b[0m Trial 32 finished with value: 3.6584055671226596 and parameters: {'n_estimators': 2677, 'learning_rate': 0.00501, 'max_depth': 10, 'max_leaves': 10, 'colsample_bytree': 0.54, 'subsample': 0.96, 'reg_alpha': 8.68, 'reg_lambda': 2.0300000000000002, 'gamma': 1.36}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.19s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2171\n",
      "2th fold: XGBRegressor RMSE: 2.2459\n",
      "3th fold: XGBRegressor RMSE: 5.6671\n",
      "\n",
      "XGBRegressor average RMSE: 3.7100\n",
      "XGBRegressor worst RMSE: 5.6671\n",
      "Corresponding penalty value: 3.9058\n",
      "\u001b[32m[I 2025-03-31 13:56:48,037]\u001b[0m Trial 33 finished with value: 3.905757295483795 and parameters: {'n_estimators': 2786, 'learning_rate': 0.01601, 'max_depth': 9, 'max_leaves': 3, 'colsample_bytree': 0.5, 'subsample': 0.89, 'reg_alpha': 7.42, 'reg_lambda': 4.23, 'gamma': 2.44}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.25s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2668\n",
      "2th fold: XGBRegressor RMSE: 1.7194\n",
      "3th fold: XGBRegressor RMSE: 5.5104\n",
      "\n",
      "XGBRegressor average RMSE: 3.4989\n",
      "XGBRegressor worst RMSE: 5.5104\n",
      "Corresponding penalty value: 3.7001\n",
      "\u001b[32m[I 2025-03-31 13:56:51,847]\u001b[0m Trial 34 finished with value: 3.700050016553116 and parameters: {'n_estimators': 2547, 'learning_rate': 0.01201, 'max_depth': 8, 'max_leaves': 7, 'colsample_bytree': 0.58, 'subsample': 0.8400000000000001, 'reg_alpha': 9.94, 'reg_lambda': 5.45, 'gamma': 1.31}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:04,  1.47s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2808\n",
      "2th fold: XGBRegressor RMSE: 1.8156\n",
      "3th fold: XGBRegressor RMSE: 5.3737\n",
      "\n",
      "XGBRegressor average RMSE: 3.4900\n",
      "XGBRegressor worst RMSE: 5.3737\n",
      "Corresponding penalty value: 3.6784\n",
      "\u001b[32m[I 2025-03-31 13:56:56,317]\u001b[0m Trial 35 finished with value: 3.6783914011503462 and parameters: {'n_estimators': 2323, 'learning_rate': 0.00301, 'max_depth': 10, 'max_leaves': 5, 'colsample_bytree': 0.61, 'subsample': 0.96, 'reg_alpha': 8.93, 'reg_lambda': 3.5500000000000003, 'gamma': 1.94}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.13s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.0892\n",
      "2th fold: XGBRegressor RMSE: 1.7023\n",
      "3th fold: XGBRegressor RMSE: 5.4531\n",
      "\n",
      "XGBRegressor average RMSE: 3.4149\n",
      "XGBRegressor worst RMSE: 5.4531\n",
      "Corresponding penalty value: 3.6187\n",
      "\u001b[32m[I 2025-03-31 13:56:59,779]\u001b[0m Trial 36 finished with value: 3.6186977268322487 and parameters: {'n_estimators': 2827, 'learning_rate': 0.02101, 'max_depth': 7, 'max_leaves': 8, 'colsample_bytree': 0.58, 'subsample': 0.9, 'reg_alpha': 5.88, 'reg_lambda': 2.43, 'gamma': 2.66}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.12s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1201\n",
      "2th fold: XGBRegressor RMSE: 1.7180\n",
      "3th fold: XGBRegressor RMSE: 5.6226\n",
      "\n",
      "XGBRegressor average RMSE: 3.4869\n",
      "XGBRegressor worst RMSE: 5.6226\n",
      "Corresponding penalty value: 3.7005\n",
      "\u001b[32m[I 2025-03-31 13:57:03,196]\u001b[0m Trial 37 finished with value: 3.700472372209215 and parameters: {'n_estimators': 2999, 'learning_rate': 0.03601000000000001, 'max_depth': 7, 'max_leaves': 12, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.88, 'reg_alpha': 6.92, 'reg_lambda': 2.46, 'gamma': 3.12}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.07s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1044\n",
      "2th fold: XGBRegressor RMSE: 1.7367\n",
      "3th fold: XGBRegressor RMSE: 5.5199\n",
      "\n",
      "XGBRegressor average RMSE: 3.4537\n",
      "XGBRegressor worst RMSE: 5.5199\n",
      "Corresponding penalty value: 3.6603\n",
      "\u001b[32m[I 2025-03-31 13:57:06,474]\u001b[0m Trial 38 finished with value: 3.6603019835356627 and parameters: {'n_estimators': 2808, 'learning_rate': 0.02401, 'max_depth': 5, 'max_leaves': 8, 'colsample_bytree': 0.53, 'subsample': 0.91, 'reg_alpha': 7.73, 'reg_lambda': 1.76, 'gamma': 2.68}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1779\n",
      "2th fold: XGBRegressor RMSE: 1.6592\n",
      "3th fold: XGBRegressor RMSE: 5.3831\n",
      "\n",
      "XGBRegressor average RMSE: 3.4068\n",
      "XGBRegressor worst RMSE: 5.3831\n",
      "Corresponding penalty value: 3.6044\n",
      "\u001b[32m[I 2025-03-31 13:57:09,461]\u001b[0m Trial 39 finished with value: 3.6043943637590097 and parameters: {'n_estimators': 2420, 'learning_rate': 0.032010000000000004, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.5700000000000001, 'subsample': 0.96, 'reg_alpha': 9.35, 'reg_lambda': 0.54, 'gamma': 2.32}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1442\n",
      "2th fold: XGBRegressor RMSE: 1.6498\n",
      "3th fold: XGBRegressor RMSE: 5.4067\n",
      "\n",
      "XGBRegressor average RMSE: 3.4002\n",
      "XGBRegressor worst RMSE: 5.4067\n",
      "Corresponding penalty value: 3.6009\n",
      "\u001b[32m[I 2025-03-31 13:57:12,127]\u001b[0m Trial 40 finished with value: 3.600861154306877 and parameters: {'n_estimators': 2216, 'learning_rate': 0.034010000000000006, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.56, 'subsample': 0.97, 'reg_alpha': 9.52, 'reg_lambda': 0.5700000000000001, 'gamma': 3.88}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:02,  1.08it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1391\n",
      "2th fold: XGBRegressor RMSE: 1.6460\n",
      "3th fold: XGBRegressor RMSE: 5.3956\n",
      "\n",
      "XGBRegressor average RMSE: 3.3936\n",
      "XGBRegressor worst RMSE: 5.3956\n",
      "Corresponding penalty value: 3.5938\n",
      "\u001b[32m[I 2025-03-31 13:57:14,973]\u001b[0m Trial 41 finished with value: 3.59379269957946 and parameters: {'n_estimators': 2416, 'learning_rate': 0.033010000000000005, 'max_depth': 6, 'max_leaves': 6, 'colsample_bytree': 0.56, 'subsample': 0.97, 'reg_alpha': 9.44, 'reg_lambda': 0.14, 'gamma': 3.74}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:02,  1.17it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.1133\n",
      "2th fold: XGBRegressor RMSE: 1.6082\n",
      "3th fold: XGBRegressor RMSE: 5.5556\n",
      "\n",
      "XGBRegressor average RMSE: 3.4257\n",
      "XGBRegressor worst RMSE: 5.5556\n",
      "Corresponding penalty value: 3.6387\n",
      "\u001b[32m[I 2025-03-31 13:57:17,604]\u001b[0m Trial 42 finished with value: 3.6386830375833865 and parameters: {'n_estimators': 2210, 'learning_rate': 0.03801, 'max_depth': 4, 'max_leaves': 6, 'colsample_bytree': 0.6, 'subsample': 0.97, 'reg_alpha': 9.56, 'reg_lambda': 0.19, 'gamma': 3.89}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.8273\n",
      "2th fold: XGBRegressor RMSE: 2.5590\n",
      "3th fold: XGBRegressor RMSE: 5.4250\n",
      "\n",
      "XGBRegressor average RMSE: 3.6038\n",
      "XGBRegressor worst RMSE: 5.4250\n",
      "Corresponding penalty value: 3.7859\n",
      "\u001b[32m[I 2025-03-31 13:57:20,418]\u001b[0m Trial 43 finished with value: 3.785875866007372 and parameters: {'n_estimators': 2558, 'learning_rate': 0.02801, 'max_depth': 5, 'max_leaves': 2, 'colsample_bytree': 0.53, 'subsample': 0.94, 'reg_alpha': 9.97, 'reg_lambda': 0.92, 'gamma': 3.7600000000000002}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:02,  1.15it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.0954\n",
      "2th fold: XGBRegressor RMSE: 1.6170\n",
      "3th fold: XGBRegressor RMSE: 5.5850\n",
      "\n",
      "XGBRegressor average RMSE: 3.4325\n",
      "XGBRegressor worst RMSE: 5.5850\n",
      "Corresponding penalty value: 3.6477\n",
      "\u001b[32m[I 2025-03-31 13:57:23,099]\u001b[0m Trial 44 finished with value: 3.6477031583187554 and parameters: {'n_estimators': 2293, 'learning_rate': 0.042010000000000006, 'max_depth': 6, 'max_leaves': 10, 'colsample_bytree': 0.56, 'subsample': 0.86, 'reg_alpha': 8.61, 'reg_lambda': 1.67, 'gamma': 4.62}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1595\n",
      "2th fold: XGBRegressor RMSE: 1.8497\n",
      "3th fold: XGBRegressor RMSE: 5.2819\n",
      "\n",
      "XGBRegressor average RMSE: 3.4304\n",
      "XGBRegressor worst RMSE: 5.2819\n",
      "Corresponding penalty value: 3.6155\n",
      "\u001b[32m[I 2025-03-31 13:57:26,240]\u001b[0m Trial 45 finished with value: 3.615538739888629 and parameters: {'n_estimators': 2417, 'learning_rate': 0.01601, 'max_depth': 6, 'max_leaves': 5, 'colsample_bytree': 0.53, 'subsample': 0.98, 'reg_alpha': 9.290000000000001, 'reg_lambda': 0.28, 'gamma': 4.26}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:02,  1.23it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.7238\n",
      "2th fold: XGBRegressor RMSE: 2.4009\n",
      "3th fold: XGBRegressor RMSE: 5.7494\n",
      "\n",
      "XGBRegressor average RMSE: 3.9580\n",
      "XGBRegressor worst RMSE: 5.7494\n",
      "Corresponding penalty value: 4.1372\n",
      "\u001b[32m[I 2025-03-31 13:57:28,748]\u001b[0m Trial 46 finished with value: 4.137161441126249 and parameters: {'n_estimators': 1941, 'learning_rate': 0.03001, 'max_depth': 7, 'max_leaves': 3, 'colsample_bytree': 0.67, 'subsample': 0.94, 'reg_alpha': 7.8, 'reg_lambda': 6.58, 'gamma': 3.98}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:04,  1.36s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.3901\n",
      "2th fold: XGBRegressor RMSE: 1.6577\n",
      "3th fold: XGBRegressor RMSE: 5.5869\n",
      "\n",
      "XGBRegressor average RMSE: 3.5449\n",
      "XGBRegressor worst RMSE: 5.5869\n",
      "Corresponding penalty value: 3.7491\n",
      "\u001b[32m[I 2025-03-31 13:57:32,913]\u001b[0m Trial 47 finished with value: 3.7490938342941456 and parameters: {'n_estimators': 2172, 'learning_rate': 0.00601, 'max_depth': 8, 'max_leaves': 7, 'colsample_bytree': 0.63, 'subsample': 0.98, 'reg_alpha': 8.39, 'reg_lambda': 5.6000000000000005, 'gamma': 3.13}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.01s/it]\n",
      "1th fold: XGBRegressor RMSE: 2.8724\n",
      "2th fold: XGBRegressor RMSE: 2.2641\n",
      "3th fold: XGBRegressor RMSE: 5.6428\n",
      "\n",
      "XGBRegressor average RMSE: 3.5931\n",
      "XGBRegressor worst RMSE: 5.6428\n",
      "Corresponding penalty value: 3.7981\n",
      "\u001b[32m[I 2025-03-31 13:57:36,020]\u001b[0m Trial 48 finished with value: 3.7980666293229723 and parameters: {'n_estimators': 2711, 'learning_rate': 0.05201000000000001, 'max_depth': 4, 'max_leaves': 3, 'colsample_bytree': 0.56, 'subsample': 0.9199999999999999, 'reg_alpha': 9.64, 'reg_lambda': 4.38, 'gamma': 3.72}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "3it [00:03,  1.10s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.2057\n",
      "2th fold: XGBRegressor RMSE: 1.6437\n",
      "3th fold: XGBRegressor RMSE: 5.6759\n",
      "\n",
      "XGBRegressor average RMSE: 3.5084\n",
      "XGBRegressor worst RMSE: 5.6759\n",
      "Corresponding penalty value: 3.7252\n",
      "\u001b[32m[I 2025-03-31 13:57:39,411]\u001b[0m Trial 49 finished with value: 3.7251649732924164 and parameters: {'n_estimators': 2889, 'learning_rate': 0.02501, 'max_depth': 3, 'max_leaves': 7, 'colsample_bytree': 0.59, 'subsample': 0.87, 'reg_alpha': 9.02, 'reg_lambda': 7.47, 'gamma': 3.5100000000000002}. Best is trial 25 with value: 3.59154300769426.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 2948, 'learning_rate': 0.01801, 'max_depth': 7, 'max_leaves': 5, 'colsample_bytree': 0.53, 'subsample': 0.9199999999999999, 'reg_alpha': 9.03, 'reg_lambda': 6.13, 'gamma': 2.16}\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.1852\n",
      "2th fold: XGBRegressor RMSE: 1.8923\n",
      "3th fold: XGBRegressor RMSE: 5.3022\n",
      "\n",
      "XGBRegressor average RMSE: 3.4599\n",
      "XGBRegressor worst RMSE: 5.3022\n",
      "Corresponding penalty value: 3.6441\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB18\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 2948, 'learning_rate': 0.01801, 'max_depth': 7, 'max_leaves': 5, 'colsample_bytree': 0.53, 'subsample': 0.9199999999999999, 'reg_alpha': 9.03, 'reg_lambda': 6.13, 'gamma': 2.16}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.911\n",
      "RMSE_crossval: 3.460\n",
      "RMSE_test: 2.402\n",
      "MAE_test: 1.841\n",
      "Nash-Sutcliffe Test: 0.641\n",
      "Kling-Gupta Test: 0.691\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 158.1186 seconds\n",
      "\n",
      "Total elapsed time: 1028.2893 seconds\n",
      "\n",
      "Output saved to XGBoost_tuning_31_3_pen_01.txt\n"
     ]
    }
   ],
   "source": [
    "!python ./models/XGBoost_tuning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2a6be5-ae50-4a85-8422-5b81386cd953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-03-31 13:57:46,965]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV1\u001b[0m\n",
      "3it [00:06,  2.05s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5122\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3642\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8329\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5698\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8329\n",
      "Corresponding penalty value: 0.5961\n",
      "\u001b[32m[I 2025-03-31 13:57:53,124]\u001b[0m Trial 0 finished with value: 0.5960974463367179 and parameters: {'max_iter': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.56, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 0.5960974463367179.\u001b[0m\n",
      "3it [00:02,  1.10it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4696\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3284\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7141\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5040\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7141\n",
      "Corresponding penalty value: 0.5250\n",
      "\u001b[32m[I 2025-03-31 13:57:55,851]\u001b[0m Trial 1 finished with value: 0.5250199810099747 and parameters: {'max_iter': 2003, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 8.33, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.5250199810099747.\u001b[0m\n",
      "3it [00:05,  1.77s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4417\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3531\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9384\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5778\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9384\n",
      "Corresponding penalty value: 0.6138\n",
      "\u001b[32m[I 2025-03-31 13:58:01,175]\u001b[0m Trial 2 finished with value: 0.6138461855783008 and parameters: {'max_iter': 1260, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 6.12, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.5250199810099747.\u001b[0m\n",
      "3it [00:02,  1.01it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.3989\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2545\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7195\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4576\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7195\n",
      "Corresponding penalty value: 0.4838\n",
      "\u001b[32m[I 2025-03-31 13:58:04,150]\u001b[0m Trial 3 finished with value: 0.483826576026689 and parameters: {'max_iter': 1640, 'learning_rate': 0.07801, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 5.93, 'max_features': 0.52, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:04,  1.46s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5232\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3237\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9320\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5929\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9320\n",
      "Corresponding penalty value: 0.6268\n",
      "\u001b[32m[I 2025-03-31 13:58:08,527]\u001b[0m Trial 4 finished with value: 0.6268490851846608 and parameters: {'max_iter': 662, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 3.04, 'max_features': 0.54, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:01,  2.59it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6693\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3486\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.5864\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5348\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6693\n",
      "Corresponding penalty value: 0.5482\n",
      "\u001b[32m[I 2025-03-31 13:58:09,689]\u001b[0m Trial 5 finished with value: 0.5482319800170659 and parameters: {'max_iter': 805, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.59, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:13,  4.47s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0090\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3681\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9515\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7762\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0090\n",
      "Corresponding penalty value: 0.7995\n",
      "\u001b[32m[I 2025-03-31 13:58:23,092]\u001b[0m Trial 6 finished with value: 0.7994517135488461 and parameters: {'max_iter': 1867, 'learning_rate': 0.01801, 'max_depth': 10, 'min_samples_leaf': 24, 'l2_regularization': 9.4, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:01,  2.71it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6221\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3679\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.5913\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5271\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6221\n",
      "Corresponding penalty value: 0.5366\n",
      "\u001b[32m[I 2025-03-31 13:58:24,202]\u001b[0m Trial 7 finished with value: 0.536589443477368 and parameters: {'max_iter': 721, 'learning_rate': 0.01901, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 3.89, 'max_features': 0.63, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:02,  1.33it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6568\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2422\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.5646\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4879\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6568\n",
      "Corresponding penalty value: 0.5048\n",
      "\u001b[32m[I 2025-03-31 13:58:26,454]\u001b[0m Trial 8 finished with value: 0.5047627811067105 and parameters: {'max_iter': 1202, 'learning_rate': 0.05401, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.74, 'max_features': 1.0, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:03,  1.08s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.3906\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3587\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8760\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5417\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8760\n",
      "Corresponding penalty value: 0.5752\n",
      "\u001b[32m[I 2025-03-31 13:58:29,699]\u001b[0m Trial 9 finished with value: 0.57517005151414 and parameters: {'max_iter': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 7.72, 'max_features': 0.53, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:11,  3.96s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.9005\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0891\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.5572\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.5156\n",
      "HistGradientBoostingRegressor worst RMSE: 3.5572\n",
      "Corresponding penalty value: 2.6198\n",
      "\u001b[32m[I 2025-03-31 13:58:41,605]\u001b[0m Trial 10 finished with value: 2.6197674614296167 and parameters: {'max_iter': 2806, 'learning_rate': 1e-05, 'max_depth': 4, 'min_samples_leaf': 2, 'l2_regularization': 5.66, 'max_features': 0.71, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:03,  1.21s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6313\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3025\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9745\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6361\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9745\n",
      "Corresponding penalty value: 0.6699\n",
      "\u001b[32m[I 2025-03-31 13:58:45,261]\u001b[0m Trial 11 finished with value: 0.669927933886177 and parameters: {'max_iter': 2214, 'learning_rate': 0.057010000000000005, 'max_depth': 3, 'min_samples_leaf': 15, 'l2_regularization': 0.17, 'max_features': 0.98, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:03,  1.03s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7735\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2933\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8148\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6272\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8148\n",
      "Corresponding penalty value: 0.6460\n",
      "\u001b[32m[I 2025-03-31 13:58:48,365]\u001b[0m Trial 12 finished with value: 0.6459608587720053 and parameters: {'max_iter': 1327, 'learning_rate': 0.06901, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 4.83, 'max_features': 0.8200000000000001, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:05,  1.83s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7476\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2799\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9852\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6709\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9852\n",
      "Corresponding penalty value: 0.7023\n",
      "\u001b[32m[I 2025-03-31 13:58:53,870]\u001b[0m Trial 13 finished with value: 0.7022937857661495 and parameters: {'max_iter': 2477, 'learning_rate': 0.04401, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 6.62, 'max_features': 0.89, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:05,  1.86s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4975\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3146\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9980\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6033\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9980\n",
      "Corresponding penalty value: 0.6428\n",
      "\u001b[32m[I 2025-03-31 13:58:59,474]\u001b[0m Trial 14 finished with value: 0.642801166300687 and parameters: {'max_iter': 1586, 'learning_rate': 0.034010000000000006, 'max_depth': 6, 'min_samples_leaf': 6, 'l2_regularization': 0.25, 'max_features': 0.72, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:02,  1.42it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4720\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2414\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6857\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4664\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6857\n",
      "Corresponding penalty value: 0.4883\n",
      "\u001b[32m[I 2025-03-31 13:59:01,610]\u001b[0m Trial 15 finished with value: 0.4882867635677489 and parameters: {'max_iter': 1060, 'learning_rate': 0.07300999999999999, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 4.59, 'max_features': 0.66, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:04,  1.35s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5186\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3649\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8518\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5784\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8518\n",
      "Corresponding penalty value: 0.6058\n",
      "\u001b[32m[I 2025-03-31 13:59:05,695]\u001b[0m Trial 16 finished with value: 0.6057807371199276 and parameters: {'max_iter': 1095, 'learning_rate': 0.07801, 'max_depth': 5, 'min_samples_leaf': 20, 'l2_regularization': 4.7700000000000005, 'max_features': 0.67, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:01,  1.58it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4397\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2386\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7120\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4634\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7120\n",
      "Corresponding penalty value: 0.4883\n",
      "\u001b[32m[I 2025-03-31 13:59:07,621]\u001b[0m Trial 17 finished with value: 0.4882803415025828 and parameters: {'max_iter': 957, 'learning_rate': 0.08501, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 7.1000000000000005, 'max_features': 0.5, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:04,  1.50s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4322\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3207\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9917\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5816\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9917\n",
      "Corresponding penalty value: 0.6226\n",
      "\u001b[32m[I 2025-03-31 13:59:12,158]\u001b[0m Trial 18 finished with value: 0.622574844922002 and parameters: {'max_iter': 1649, 'learning_rate': 0.08601, 'max_depth': 7, 'min_samples_leaf': 16, 'l2_regularization': 7.22, 'max_features': 0.51, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:03,  1.21s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5163\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2822\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8556\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5514\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8556\n",
      "Corresponding penalty value: 0.5818\n",
      "\u001b[32m[I 2025-03-31 13:59:15,824]\u001b[0m Trial 19 finished with value: 0.5817804618671187 and parameters: {'max_iter': 2175, 'learning_rate': 0.09801, 'max_depth': 2, 'min_samples_leaf': 8, 'l2_regularization': 8.53, 'max_features': 0.77, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:03,  1.10s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6114\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3551\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8431\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6032\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8431\n",
      "Corresponding penalty value: 0.6272\n",
      "\u001b[32m[I 2025-03-31 13:59:19,138]\u001b[0m Trial 20 finished with value: 0.6271809022585083 and parameters: {'max_iter': 889, 'learning_rate': 0.06301, 'max_depth': 4, 'min_samples_leaf': 13, 'l2_regularization': 9.53, 'max_features': 0.5, 'early_stopping': True}. Best is trial 3 with value: 0.483826576026689.\u001b[0m\n",
      "3it [00:02,  1.45it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4340\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2521\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6919\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4593\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6919\n",
      "Corresponding penalty value: 0.4826\n",
      "\u001b[32m[I 2025-03-31 13:59:21,239]\u001b[0m Trial 21 finished with value: 0.4825846645144909 and parameters: {'max_iter': 1040, 'learning_rate': 0.07701, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 5.42, 'max_features': 0.66, 'early_stopping': True}. Best is trial 21 with value: 0.4825846645144909.\u001b[0m\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6083\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2981\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8254\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5773\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8254\n",
      "Corresponding penalty value: 0.6021\n",
      "\u001b[32m[I 2025-03-31 13:59:24,944]\u001b[0m Trial 22 finished with value: 0.6021002689383846 and parameters: {'max_iter': 1531, 'learning_rate': 0.08601, 'max_depth': 4, 'min_samples_leaf': 17, 'l2_regularization': 5.82, 'max_features': 0.59, 'early_stopping': True}. Best is trial 21 with value: 0.4825846645144909.\u001b[0m\n",
      "3it [00:01,  1.64it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4525\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2112\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6880\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4506\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6880\n",
      "Corresponding penalty value: 0.4743\n",
      "\u001b[32m[I 2025-03-31 13:59:26,807]\u001b[0m Trial 23 finished with value: 0.4743212333027724 and parameters: {'max_iter': 1004, 'learning_rate': 0.08701, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 6.75, 'max_features': 0.63, 'early_stopping': True}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:04,  1.49s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6112\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2783\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8036\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5644\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8036\n",
      "Corresponding penalty value: 0.5883\n",
      "\u001b[32m[I 2025-03-31 13:59:31,322]\u001b[0m Trial 24 finished with value: 0.5883162411552886 and parameters: {'max_iter': 1781, 'learning_rate': 0.06501, 'max_depth': 3, 'min_samples_leaf': 21, 'l2_regularization': 3.92, 'max_features': 0.64, 'early_stopping': True}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:02,  1.43it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8275\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3401\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6450\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6042\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8275\n",
      "Corresponding penalty value: 0.6265\n",
      "\u001b[32m[I 2025-03-31 13:59:33,451]\u001b[0m Trial 25 finished with value: 0.6265274769113176 and parameters: {'max_iter': 1392, 'learning_rate': 0.07501, 'max_depth': 1, 'min_samples_leaf': 22, 'l2_regularization': 5.5600000000000005, 'max_features': 0.7, 'early_stopping': True}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:01,  1.65it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5116\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2416\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7317\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4950\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7317\n",
      "Corresponding penalty value: 0.5187\n",
      "\u001b[32m[I 2025-03-31 13:59:35,299]\u001b[0m Trial 26 finished with value: 0.5186617854269323 and parameters: {'max_iter': 1093, 'learning_rate': 0.09000999999999999, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 6.2700000000000005, 'max_features': 0.62, 'early_stopping': True}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:02,  1.46it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4644\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3189\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9574\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5802\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9574\n",
      "Corresponding penalty value: 0.6179\n",
      "\u001b[32m[I 2025-03-31 13:59:37,380]\u001b[0m Trial 27 finished with value: 0.6179499515764635 and parameters: {'max_iter': 564, 'learning_rate': 0.09901, 'max_depth': 4, 'min_samples_leaf': 14, 'l2_regularization': 8.31, 'max_features': 0.75, 'early_stopping': 'auto'}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:02,  1.22it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6931\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2844\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7958\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5911\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7958\n",
      "Corresponding penalty value: 0.6115\n",
      "\u001b[32m[I 2025-03-31 13:59:39,871]\u001b[0m Trial 28 finished with value: 0.6115426253233867 and parameters: {'max_iter': 915, 'learning_rate': 0.06301, 'max_depth': 3, 'min_samples_leaf': 27, 'l2_regularization': 6.92, 'max_features': 0.66, 'early_stopping': True}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:06,  2.01s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5610\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3476\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8643\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5910\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8643\n",
      "Corresponding penalty value: 0.6183\n",
      "\u001b[32m[I 2025-03-31 13:59:45,929]\u001b[0m Trial 29 finished with value: 0.618314033728392 and parameters: {'max_iter': 1475, 'learning_rate': 0.08101, 'max_depth': 6, 'min_samples_leaf': 18, 'l2_regularization': 3.7600000000000002, 'max_features': 0.56, 'early_stopping': 'auto'}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:03,  1.33s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6473\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3051\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6654\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5393\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6654\n",
      "Corresponding penalty value: 0.5519\n",
      "\u001b[32m[I 2025-03-31 13:59:49,956]\u001b[0m Trial 30 finished with value: 0.5518827658295986 and parameters: {'max_iter': 2986, 'learning_rate': 0.09101, 'max_depth': 1, 'min_samples_leaf': 23, 'l2_regularization': 2.12, 'max_features': 0.59, 'early_stopping': True}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:01,  1.63it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4850\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2282\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6697\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4610\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6697\n",
      "Corresponding penalty value: 0.4818\n",
      "\u001b[32m[I 2025-03-31 13:59:51,834]\u001b[0m Trial 31 finished with value: 0.481840099007407 and parameters: {'max_iter': 923, 'learning_rate': 0.08401, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 7.5600000000000005, 'max_features': 0.54, 'early_stopping': True}. Best is trial 23 with value: 0.4743212333027724.\u001b[0m\n",
      "3it [00:02,  1.31it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4198\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2638\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6591\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4476\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6591\n",
      "Corresponding penalty value: 0.4687\n",
      "\u001b[32m[I 2025-03-31 13:59:54,163]\u001b[0m Trial 32 finished with value: 0.46870694539758695 and parameters: {'max_iter': 1171, 'learning_rate': 0.07601, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 7.8100000000000005, 'max_features': 0.55, 'early_stopping': True}. Best is trial 32 with value: 0.46870694539758695.\u001b[0m\n",
      "3it [00:01,  1.83it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5342\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2904\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7248\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5165\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7248\n",
      "Corresponding penalty value: 0.5373\n",
      "\u001b[32m[I 2025-03-31 13:59:55,835]\u001b[0m Trial 33 finished with value: 0.537290127124339 and parameters: {'max_iter': 1213, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 21, 'l2_regularization': 7.73, 'max_features': 0.56, 'early_stopping': True}. Best is trial 32 with value: 0.46870694539758695.\u001b[0m\n",
      "3it [00:01,  2.02it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4177\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2294\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6447\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4306\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6447\n",
      "Corresponding penalty value: 0.4520\n",
      "\u001b[32m[I 2025-03-31 13:59:57,351]\u001b[0m Trial 34 finished with value: 0.4520061010038716 and parameters: {'max_iter': 772, 'learning_rate': 0.08900999999999999, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 8.94, 'max_features': 0.59, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:03,  1.13s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4418\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3547\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9290\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5751\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9290\n",
      "Corresponding penalty value: 0.6105\n",
      "\u001b[32m[I 2025-03-31 14:00:00,761]\u001b[0m Trial 35 finished with value: 0.6105336469052347 and parameters: {'max_iter': 735, 'learning_rate': 0.09201, 'max_depth': 5, 'min_samples_leaf': 19, 'l2_regularization': 8.93, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:02,  1.38it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4379\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2979\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7633\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4997\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7633\n",
      "Corresponding penalty value: 0.5261\n",
      "\u001b[32m[I 2025-03-31 14:00:02,963]\u001b[0m Trial 36 finished with value: 0.5260758526527411 and parameters: {'max_iter': 831, 'learning_rate': 0.08501, 'max_depth': 3, 'min_samples_leaf': 18, 'l2_regularization': 7.83, 'max_features': 0.54, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:00,  3.04it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6729\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4059\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6991\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5927\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6991\n",
      "Corresponding penalty value: 0.6033\n",
      "\u001b[32m[I 2025-03-31 14:00:03,981]\u001b[0m Trial 37 finished with value: 0.6032966736200042 and parameters: {'max_iter': 667, 'learning_rate': 0.09501, 'max_depth': 1, 'min_samples_leaf': 25, 'l2_regularization': 9.8, 'max_features': 0.58, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:04,  1.40s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5413\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2973\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9526\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5971\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9526\n",
      "Corresponding penalty value: 0.6326\n",
      "\u001b[32m[I 2025-03-31 14:00:08,201]\u001b[0m Trial 38 finished with value: 0.6326222237584326 and parameters: {'max_iter': 1266, 'learning_rate': 0.08201, 'max_depth': 4, 'min_samples_leaf': 11, 'l2_regularization': 8.9, 'max_features': 0.55, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:04,  1.56s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7724\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3581\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8980\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6762\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8980\n",
      "Corresponding penalty value: 0.6983\n",
      "\u001b[32m[I 2025-03-31 14:00:12,908]\u001b[0m Trial 39 finished with value: 0.69834374274852 and parameters: {'max_iter': 656, 'learning_rate': 0.09101, 'max_depth': 9, 'min_samples_leaf': 30, 'l2_regularization': 8.42, 'max_features': 0.62, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:01,  2.13it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4276\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3550\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6608\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4811\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6608\n",
      "Corresponding penalty value: 0.4991\n",
      "\u001b[32m[I 2025-03-31 14:00:14,346]\u001b[0m Trial 40 finished with value: 0.4990844105479271 and parameters: {'max_iter': 997, 'learning_rate': 0.042010000000000006, 'max_depth': 1, 'min_samples_leaf': 23, 'l2_regularization': 9.99, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:02,  1.30it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4728\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2100\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6949\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4592\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6949\n",
      "Corresponding penalty value: 0.4828\n",
      "\u001b[32m[I 2025-03-31 14:00:16,686]\u001b[0m Trial 41 finished with value: 0.4827925062068845 and parameters: {'max_iter': 1164, 'learning_rate': 0.07601, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 6.38, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:01,  1.73it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4579\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2467\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6835\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4627\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6835\n",
      "Corresponding penalty value: 0.4848\n",
      "\u001b[32m[I 2025-03-31 14:00:18,457]\u001b[0m Trial 42 finished with value: 0.48477142864509365 and parameters: {'max_iter': 848, 'learning_rate': 0.06801, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 7.46, 'max_features': 0.62, 'early_stopping': True}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4510\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2583\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8017\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5036\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8017\n",
      "Corresponding penalty value: 0.5334\n",
      "\u001b[32m[I 2025-03-31 14:00:21,031]\u001b[0m Trial 43 finished with value: 0.5334471022584284 and parameters: {'max_iter': 989, 'learning_rate': 0.05901000000000001, 'max_depth': 3, 'min_samples_leaf': 25, 'l2_regularization': 8.040000000000001, 'max_features': 0.53, 'early_stopping': 'auto'}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:01,  1.92it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4685\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2246\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6197\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4376\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6197\n",
      "Corresponding penalty value: 0.4558\n",
      "\u001b[32m[I 2025-03-31 14:00:22,627]\u001b[0m Trial 44 finished with value: 0.4557852962097838 and parameters: {'max_iter': 774, 'learning_rate': 0.08001, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 9.040000000000001, 'max_features': 0.61, 'early_stopping': True}. Best is trial 34 with value: 0.4520061010038716.\u001b[0m\n",
      "3it [00:01,  2.77it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4063\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2034\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6508\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4201\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6508\n",
      "Corresponding penalty value: 0.4432\n",
      "\u001b[32m[I 2025-03-31 14:00:23,744]\u001b[0m Trial 45 finished with value: 0.443211884821584 and parameters: {'max_iter': 512, 'learning_rate': 0.08800999999999999, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 9.09, 'max_features': 0.64, 'early_stopping': True}. Best is trial 45 with value: 0.443211884821584.\u001b[0m\n",
      "3it [00:00,  3.25it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6946\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3802\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7093\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5947\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7093\n",
      "Corresponding penalty value: 0.6062\n",
      "\u001b[32m[I 2025-03-31 14:00:24,702]\u001b[0m Trial 46 finished with value: 0.6061800031736974 and parameters: {'max_iter': 581, 'learning_rate': 0.09501, 'max_depth': 1, 'min_samples_leaf': 14, 'l2_regularization': 9.07, 'max_features': 0.63, 'early_stopping': True}. Best is trial 45 with value: 0.443211884821584.\u001b[0m\n",
      "3it [00:01,  1.51it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4551\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2777\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8404\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5244\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8404\n",
      "Corresponding penalty value: 0.5560\n",
      "\u001b[32m[I 2025-03-31 14:00:26,727]\u001b[0m Trial 47 finished with value: 0.5560053961035947 and parameters: {'max_iter': 767, 'learning_rate': 0.08800999999999999, 'max_depth': 3, 'min_samples_leaf': 15, 'l2_regularization': 9.35, 'max_features': 0.61, 'early_stopping': 'auto'}. Best is trial 45 with value: 0.443211884821584.\u001b[0m\n",
      "3it [00:01,  2.81it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4216\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2334\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6590\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4380\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6590\n",
      "Corresponding penalty value: 0.4601\n",
      "\u001b[32m[I 2025-03-31 14:00:27,828]\u001b[0m Trial 48 finished with value: 0.4600933126523912 and parameters: {'max_iter': 506, 'learning_rate': 0.08001, 'max_depth': 2, 'min_samples_leaf': 9, 'l2_regularization': 8.66, 'max_features': 0.64, 'early_stopping': True}. Best is trial 45 with value: 0.443211884821584.\u001b[0m\n",
      "3it [00:00,  3.65it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7728\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3668\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6769\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6055\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7728\n",
      "Corresponding penalty value: 0.6222\n",
      "\u001b[32m[I 2025-03-31 14:00:28,685]\u001b[0m Trial 49 finished with value: 0.6222203766578054 and parameters: {'max_iter': 504, 'learning_rate': 0.08001, 'max_depth': 1, 'min_samples_leaf': 4, 'l2_regularization': 8.78, 'max_features': 0.73, 'early_stopping': True}. Best is trial 45 with value: 0.443211884821584.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 512, 'learning_rate': 0.08800999999999999, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 9.09, 'max_features': 0.64, 'early_stopping': True}\n",
      "3it [00:01,  2.77it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5522\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2141\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.6574\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.4746\n",
      "HistGradientBoostingRegressor worst RMSE: 0.6574\n",
      "Corresponding penalty value: 0.4929\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV1\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 512, 'learning_rate': 0.08800999999999999, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 9.09, 'max_features': 0.64, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.077\n",
      "RMSE_crossval: 0.475\n",
      "RMSE_test: 0.341\n",
      "MAE_test: 0.245\n",
      "Nash-Sutcliffe Test: 0.989\n",
      "Kling-Gupta Test: 0.936\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 164.0022 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 14:00:30,961]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV3\u001b[0m\n",
      "3it [00:07,  2.39s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8864\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2974\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4548\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8795\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4548\n",
      "Corresponding penalty value: 0.9371\n",
      "\u001b[32m[I 2025-03-31 14:00:38,134]\u001b[0m Trial 0 finished with value: 0.9370757556221821 and parameters: {'max_iter': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.56, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 0.9370757556221821.\u001b[0m\n",
      "3it [00:02,  1.10it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7672\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3273\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2079\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7675\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2079\n",
      "Corresponding penalty value: 0.8115\n",
      "\u001b[32m[I 2025-03-31 14:00:40,861]\u001b[0m Trial 1 finished with value: 0.8115126308856969 and parameters: {'max_iter': 2003, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 8.33, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:05,  1.97s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9490\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3378\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4558\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9142\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4558\n",
      "Corresponding penalty value: 0.9683\n",
      "\u001b[32m[I 2025-03-31 14:00:46,764]\u001b[0m Trial 2 finished with value: 0.9683209447348426 and parameters: {'max_iter': 1260, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 6.12, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:02,  1.05it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7145\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2625\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4096\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7955\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4096\n",
      "Corresponding penalty value: 0.8569\n",
      "\u001b[32m[I 2025-03-31 14:00:49,631]\u001b[0m Trial 3 finished with value: 0.8569293847241025 and parameters: {'max_iter': 1640, 'learning_rate': 0.07801, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 5.93, 'max_features': 0.52, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:03,  1.33s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2774\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3404\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4356\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0178\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4356\n",
      "Corresponding penalty value: 1.0596\n",
      "\u001b[32m[I 2025-03-31 14:00:53,618]\u001b[0m Trial 4 finished with value: 1.0595659891880445 and parameters: {'max_iter': 662, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 3.04, 'max_features': 0.54, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:01,  2.60it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8304\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3269\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2916\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8163\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2916\n",
      "Corresponding penalty value: 0.8638\n",
      "\u001b[32m[I 2025-03-31 14:00:54,775]\u001b[0m Trial 5 finished with value: 0.8638133240523747 and parameters: {'max_iter': 805, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.59, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:13,  4.65s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1273\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2211\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3627\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9037\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3627\n",
      "Corresponding penalty value: 0.9496\n",
      "\u001b[32m[I 2025-03-31 14:01:08,729]\u001b[0m Trial 6 finished with value: 0.9496138526450245 and parameters: {'max_iter': 1867, 'learning_rate': 0.01801, 'max_depth': 10, 'min_samples_leaf': 24, 'l2_regularization': 9.4, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:01,  2.68it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8982\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3341\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3392\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8572\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3392\n",
      "Corresponding penalty value: 0.9054\n",
      "\u001b[32m[I 2025-03-31 14:01:09,849]\u001b[0m Trial 7 finished with value: 0.9053801494360534 and parameters: {'max_iter': 721, 'learning_rate': 0.01901, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 3.89, 'max_features': 0.63, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:02,  1.33it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1096\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2946\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5858\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9967\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5858\n",
      "Corresponding penalty value: 1.0556\n",
      "\u001b[32m[I 2025-03-31 14:01:12,112]\u001b[0m Trial 8 finished with value: 1.0556045235405833 and parameters: {'max_iter': 1202, 'learning_rate': 0.05401, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.74, 'max_features': 1.0, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:03,  1.17s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2104\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3148\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3414\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9555\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3414\n",
      "Corresponding penalty value: 0.9941\n",
      "\u001b[32m[I 2025-03-31 14:01:15,613]\u001b[0m Trial 9 finished with value: 0.9941087716815775 and parameters: {'max_iter': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 7.72, 'max_features': 0.53, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:11,  3.70s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.1688\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.8557\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.5115\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1787\n",
      "HistGradientBoostingRegressor worst RMSE: 4.5115\n",
      "Corresponding penalty value: 3.3120\n",
      "\u001b[32m[I 2025-03-31 14:01:26,741]\u001b[0m Trial 10 finished with value: 3.3119592693642157 and parameters: {'max_iter': 2727, 'learning_rate': 1e-05, 'max_depth': 4, 'min_samples_leaf': 2, 'l2_regularization': 9.83, 'max_features': 0.71, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:04,  1.47s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8588\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3221\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5026\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8945\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5026\n",
      "Corresponding penalty value: 0.9553\n",
      "\u001b[32m[I 2025-03-31 14:01:31,165]\u001b[0m Trial 11 finished with value: 0.9553087343269923 and parameters: {'max_iter': 2095, 'learning_rate': 0.06901, 'max_depth': 3, 'min_samples_leaf': 15, 'l2_regularization': 6.16, 'max_features': 0.69, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:05,  1.85s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6951\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3013\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4618\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8194\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4618\n",
      "Corresponding penalty value: 0.8837\n",
      "\u001b[32m[I 2025-03-31 14:01:36,742]\u001b[0m Trial 12 finished with value: 0.883655205514988 and parameters: {'max_iter': 2222, 'learning_rate': 0.07001, 'max_depth': 3, 'min_samples_leaf': 30, 'l2_regularization': 7.930000000000001, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:03,  1.20s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8411\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3346\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2426\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8061\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2426\n",
      "Corresponding penalty value: 0.8497\n",
      "\u001b[32m[I 2025-03-31 14:01:40,371]\u001b[0m Trial 13 finished with value: 0.8497415036255344 and parameters: {'max_iter': 2477, 'learning_rate': 0.07501, 'max_depth': 1, 'min_samples_leaf': 18, 'l2_regularization': 5.62, 'max_features': 0.64, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:07,  2.39s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3769\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2785\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4254\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0269\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4254\n",
      "Corresponding penalty value: 1.0668\n",
      "\u001b[32m[I 2025-03-31 14:01:47,560]\u001b[0m Trial 14 finished with value: 1.0667858637299124 and parameters: {'max_iter': 2665, 'learning_rate': 0.041010000000000005, 'max_depth': 6, 'min_samples_leaf': 3, 'l2_regularization': 7.95, 'max_features': 0.78, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:04,  1.34s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9780\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2996\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2847\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8541\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2847\n",
      "Corresponding penalty value: 0.8972\n",
      "\u001b[32m[I 2025-03-31 14:01:51,606]\u001b[0m Trial 15 finished with value: 0.8971564521358435 and parameters: {'max_iter': 2995, 'learning_rate': 0.06401, 'max_depth': 1, 'min_samples_leaf': 20, 'l2_regularization': 4.8100000000000005, 'max_features': 0.64, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:09,  3.05s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9082\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3027\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4047\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8719\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4047\n",
      "Corresponding penalty value: 0.9252\n",
      "\u001b[32m[I 2025-03-31 14:02:00,780]\u001b[0m Trial 16 finished with value: 0.925167262659148 and parameters: {'max_iter': 2374, 'learning_rate': 0.08501, 'max_depth': 6, 'min_samples_leaf': 7, 'l2_regularization': 8.73, 'max_features': 0.63, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:05,  1.84s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9247\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3184\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4688\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9040\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4688\n",
      "Corresponding penalty value: 0.9604\n",
      "\u001b[32m[I 2025-03-31 14:02:06,329]\u001b[0m Trial 17 finished with value: 0.9604434279480092 and parameters: {'max_iter': 2453, 'learning_rate': 0.032010000000000004, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 6.890000000000001, 'max_features': 0.8200000000000001, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:06,  2.11s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7514\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2921\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4421\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8285\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4421\n",
      "Corresponding penalty value: 0.8899\n",
      "\u001b[32m[I 2025-03-31 14:02:12,694]\u001b[0m Trial 18 finished with value: 0.8898861041106882 and parameters: {'max_iter': 1927, 'learning_rate': 0.06201, 'max_depth': 4, 'min_samples_leaf': 12, 'l2_regularization': 4.36, 'max_features': 0.7, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:04,  1.56s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9213\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2937\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5644\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9265\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5644\n",
      "Corresponding penalty value: 0.9903\n",
      "\u001b[32m[I 2025-03-31 14:02:17,403]\u001b[0m Trial 19 finished with value: 0.9902637822454543 and parameters: {'max_iter': 2947, 'learning_rate': 0.08701, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 5.39, 'max_features': 0.59, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:06,  2.25s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.4484\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2674\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2975\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0044\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4484\n",
      "Corresponding penalty value: 1.0488\n",
      "\u001b[32m[I 2025-03-31 14:02:24,184]\u001b[0m Trial 20 finished with value: 1.0488358364977293 and parameters: {'max_iter': 1694, 'learning_rate': 0.07501, 'max_depth': 7, 'min_samples_leaf': 21, 'l2_regularization': 7.16, 'max_features': 0.76, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:02,  1.02it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6597\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2798\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5138\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8178\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5138\n",
      "Corresponding penalty value: 0.8874\n",
      "\u001b[32m[I 2025-03-31 14:02:27,150]\u001b[0m Trial 21 finished with value: 0.8873722394530327 and parameters: {'max_iter': 1579, 'learning_rate': 0.07601, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 6.0, 'max_features': 0.5, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:02,  1.00it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1098\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3437\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3131\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9222\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3131\n",
      "Corresponding penalty value: 0.9613\n",
      "\u001b[32m[I 2025-03-31 14:02:30,177]\u001b[0m Trial 22 finished with value: 0.9612915989759325 and parameters: {'max_iter': 2083, 'learning_rate': 0.06201, 'max_depth': 1, 'min_samples_leaf': 17, 'l2_regularization': 8.77, 'max_features': 0.61, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:03,  1.29s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8549\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3113\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4854\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8839\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4854\n",
      "Corresponding penalty value: 0.9440\n",
      "\u001b[32m[I 2025-03-31 14:02:34,075]\u001b[0m Trial 23 finished with value: 0.9440272402002946 and parameters: {'max_iter': 2443, 'learning_rate': 0.09901, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 5.24, 'max_features': 0.66, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:03,  1.10s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6312\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4225\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4687\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8408\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4687\n",
      "Corresponding penalty value: 0.9036\n",
      "\u001b[32m[I 2025-03-31 14:02:37,419]\u001b[0m Trial 24 finished with value: 0.903625499869933 and parameters: {'max_iter': 1074, 'learning_rate': 0.08601, 'max_depth': 4, 'min_samples_leaf': 7, 'l2_regularization': 6.78, 'max_features': 0.54, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8604\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3109\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2121\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7945\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2121\n",
      "Corresponding penalty value: 0.8363\n",
      "\u001b[32m[I 2025-03-31 14:02:40,027]\u001b[0m Trial 25 finished with value: 0.8362589205810242 and parameters: {'max_iter': 1793, 'learning_rate': 0.07701, 'max_depth': 1, 'min_samples_leaf': 27, 'l2_regularization': 3.68, 'max_features': 0.67, 'early_stopping': True}. Best is trial 1 with value: 0.8115126308856969.\u001b[0m\n",
      "3it [00:02,  1.13it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7745\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2879\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1921\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7515\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1921\n",
      "Corresponding penalty value: 0.7956\n",
      "\u001b[32m[I 2025-03-31 14:02:42,710]\u001b[0m Trial 26 finished with value: 0.795564773697354 and parameters: {'max_iter': 1920, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 3.24, 'max_features': 0.72, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:04,  1.56s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6364\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3666\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4329\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8120\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4329\n",
      "Corresponding penalty value: 0.8741\n",
      "\u001b[32m[I 2025-03-31 14:02:47,411]\u001b[0m Trial 27 finished with value: 0.8740654908437867 and parameters: {'max_iter': 1878, 'learning_rate': 0.058010000000000006, 'max_depth': 3, 'min_samples_leaf': 27, 'l2_regularization': 3.37, 'max_features': 0.73, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:02,  1.50it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9937\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3079\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2497\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8505\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2497\n",
      "Corresponding penalty value: 0.8904\n",
      "\u001b[32m[I 2025-03-31 14:02:49,446]\u001b[0m Trial 28 finished with value: 0.8903849531813973 and parameters: {'max_iter': 1455, 'learning_rate': 0.041010000000000005, 'max_depth': 1, 'min_samples_leaf': 27, 'l2_regularization': 1.81, 'max_features': 0.86, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.27s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6968\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3436\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4236\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8214\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4236\n",
      "Corresponding penalty value: 0.8816\n",
      "\u001b[32m[I 2025-03-31 14:02:53,291]\u001b[0m Trial 29 finished with value: 0.8815790494993481 and parameters: {'max_iter': 2080, 'learning_rate': 0.09201, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 2.17, 'max_features': 0.67, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:05,  1.87s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8493\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2962\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4581\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8679\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4581\n",
      "Corresponding penalty value: 0.9269\n",
      "\u001b[32m[I 2025-03-31 14:02:58,931]\u001b[0m Trial 30 finished with value: 0.9268934312880241 and parameters: {'max_iter': 1500, 'learning_rate': 0.07001, 'max_depth': 5, 'min_samples_leaf': 29, 'l2_regularization': 0.84, 'max_features': 0.77, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8039\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3465\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2479\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7994\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2479\n",
      "Corresponding penalty value: 0.8443\n",
      "\u001b[32m[I 2025-03-31 14:03:02,035]\u001b[0m Trial 31 finished with value: 0.8442912977468083 and parameters: {'max_iter': 2240, 'learning_rate': 0.07201, 'max_depth': 1, 'min_samples_leaf': 26, 'l2_regularization': 3.59, 'max_features': 0.58, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.01s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8976\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3406\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2468\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8283\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2468\n",
      "Corresponding penalty value: 0.8702\n",
      "\u001b[32m[I 2025-03-31 14:03:05,089]\u001b[0m Trial 32 finished with value: 0.8701630923699442 and parameters: {'max_iter': 2231, 'learning_rate': 0.06601, 'max_depth': 1, 'min_samples_leaf': 26, 'l2_regularization': 3.68, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.11s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7509\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2368\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.6574\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8817\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6574\n",
      "Corresponding penalty value: 0.9593\n",
      "\u001b[32m[I 2025-03-31 14:03:08,460]\u001b[0m Trial 33 finished with value: 0.9592646384437337 and parameters: {'max_iter': 1821, 'learning_rate': 0.04701, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 4.12, 'max_features': 0.73, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:04,  1.63s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7367\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3029\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4620\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8339\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4620\n",
      "Corresponding penalty value: 0.8967\n",
      "\u001b[32m[I 2025-03-31 14:03:13,373]\u001b[0m Trial 34 finished with value: 0.896676118985083 and parameters: {'max_iter': 1993, 'learning_rate': 0.08101, 'max_depth': 3, 'min_samples_leaf': 27, 'l2_regularization': 2.9, 'max_features': 0.59, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:02,  1.29it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8533\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3307\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3336\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8392\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3336\n",
      "Corresponding penalty value: 0.8887\n",
      "\u001b[32m[I 2025-03-31 14:03:15,736]\u001b[0m Trial 35 finished with value: 0.8886642566945889 and parameters: {'max_iter': 1710, 'learning_rate': 0.056010000000000004, 'max_depth': 1, 'min_samples_leaf': 24, 'l2_regularization': 2.4, 'max_features': 0.58, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:11,  3.76s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1136\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2703\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3353\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9064\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3353\n",
      "Corresponding penalty value: 0.9493\n",
      "\u001b[32m[I 2025-03-31 14:03:27,038]\u001b[0m Trial 36 finished with value: 0.949272441422759 and parameters: {'max_iter': 2254, 'learning_rate': 0.07201, 'max_depth': 9, 'min_samples_leaf': 28, 'l2_regularization': 4.4, 'max_features': 0.6799999999999999, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:02,  1.22it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8239\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2737\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3823\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8266\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3823\n",
      "Corresponding penalty value: 0.8822\n",
      "\u001b[32m[I 2025-03-31 14:03:29,527]\u001b[0m Trial 37 finished with value: 0.8821818378800586 and parameters: {'max_iter': 1335, 'learning_rate': 0.09101, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.46, 'max_features': 0.55, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:02,  1.24it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8482\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3436\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3255\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8391\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3255\n",
      "Corresponding penalty value: 0.8878\n",
      "\u001b[32m[I 2025-03-31 14:03:31,976]\u001b[0m Trial 38 finished with value: 0.887771096094931 and parameters: {'max_iter': 1779, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 23, 'l2_regularization': 3.15, 'max_features': 0.61, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:01,  1.53it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8204\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2427\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.6253\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8961\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6253\n",
      "Corresponding penalty value: 0.9691\n",
      "\u001b[32m[I 2025-03-31 14:03:33,966]\u001b[0m Trial 39 finished with value: 0.9690521062034454 and parameters: {'max_iter': 1047, 'learning_rate': 0.08101, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 4.82, 'max_features': 0.88, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:05,  1.76s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7619\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2767\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4586\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8324\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4586\n",
      "Corresponding penalty value: 0.8950\n",
      "\u001b[32m[I 2025-03-31 14:03:39,286]\u001b[0m Trial 40 finished with value: 0.8950334143803677 and parameters: {'max_iter': 1601, 'learning_rate': 0.05901000000000001, 'max_depth': 4, 'min_samples_leaf': 26, 'l2_regularization': 3.62, 'max_features': 0.73, 'early_stopping': 'auto'}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.23s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8126\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3130\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2331\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7862\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2331\n",
      "Corresponding penalty value: 0.8309\n",
      "\u001b[32m[I 2025-03-31 14:03:43,025]\u001b[0m Trial 41 finished with value: 0.8309267888581614 and parameters: {'max_iter': 2601, 'learning_rate': 0.07501, 'max_depth': 1, 'min_samples_leaf': 18, 'l2_regularization': 2.77, 'max_features': 0.65, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.29s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8379\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3354\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2063\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7932\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2063\n",
      "Corresponding penalty value: 0.8345\n",
      "\u001b[32m[I 2025-03-31 14:03:46,923]\u001b[0m Trial 42 finished with value: 0.8345207040590834 and parameters: {'max_iter': 2704, 'learning_rate': 0.07901, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.72, 'max_features': 0.65, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.05s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8347\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3064\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2601\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8004\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2601\n",
      "Corresponding penalty value: 0.8463\n",
      "\u001b[32m[I 2025-03-31 14:03:50,116]\u001b[0m Trial 43 finished with value: 0.8463485209488911 and parameters: {'max_iter': 2719, 'learning_rate': 0.08001, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 1.35, 'max_features': 0.66, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:04,  1.58s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7771\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2886\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5350\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8669\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5350\n",
      "Corresponding penalty value: 0.9337\n",
      "\u001b[32m[I 2025-03-31 14:03:54,894]\u001b[0m Trial 44 finished with value: 0.9336993902061157 and parameters: {'max_iter': 2832, 'learning_rate': 0.08800999999999999, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 2.52, 'max_features': 0.71, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:05,  1.71s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8885\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3028\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5363\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9092\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5363\n",
      "Corresponding penalty value: 0.9719\n",
      "\u001b[32m[I 2025-03-31 14:04:00,062]\u001b[0m Trial 45 finished with value: 0.9719158076621492 and parameters: {'max_iter': 2577, 'learning_rate': 0.09701, 'max_depth': 3, 'min_samples_leaf': 30, 'l2_regularization': 0.04, 'max_features': 0.62, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:02,  1.04it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0991\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2455\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2440\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8629\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2440\n",
      "Corresponding penalty value: 0.9010\n",
      "\u001b[32m[I 2025-03-31 14:04:02,985]\u001b[0m Trial 46 finished with value: 0.900988440641687 and parameters: {'max_iter': 2011, 'learning_rate': 0.06801, 'max_depth': 1, 'min_samples_leaf': 22, 'l2_regularization': 2.02, 'max_features': 0.79, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:03,  1.24s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8267\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2762\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2129\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7719\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2129\n",
      "Corresponding penalty value: 0.8160\n",
      "\u001b[32m[I 2025-03-31 14:04:06,746]\u001b[0m Trial 47 finished with value: 0.8159915212842579 and parameters: {'max_iter': 2621, 'learning_rate': 0.07801, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.88, 'max_features': 0.65, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:04,  1.36s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8624\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2817\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5234\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8892\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5234\n",
      "Corresponding penalty value: 0.9526\n",
      "\u001b[32m[I 2025-03-31 14:04:10,850]\u001b[0m Trial 48 finished with value: 0.9525835015775568 and parameters: {'max_iter': 2598, 'learning_rate': 0.08501, 'max_depth': 2, 'min_samples_leaf': 9, 'l2_regularization': 2.98, 'max_features': 0.64, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "3it [00:05,  1.98s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8281\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3165\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4584\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8676\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4584\n",
      "Corresponding penalty value: 0.9267\n",
      "\u001b[32m[I 2025-03-31 14:04:16,818]\u001b[0m Trial 49 finished with value: 0.9267219229768522 and parameters: {'max_iter': 2897, 'learning_rate': 0.06501, 'max_depth': 3, 'min_samples_leaf': 29, 'l2_regularization': 2.75, 'max_features': 0.7, 'early_stopping': True}. Best is trial 26 with value: 0.795564773697354.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1920, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 3.24, 'max_features': 0.72, 'early_stopping': 'auto'}\n",
      "3it [00:02,  1.13it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0330\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4663\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3009\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9334\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3009\n",
      "Corresponding penalty value: 0.9701\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV3\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1920, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 3.24, 'max_features': 0.72, 'early_stopping': 'auto'}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.133\n",
      "RMSE_crossval: 0.933\n",
      "RMSE_test: 0.859\n",
      "MAE_test: 0.690\n",
      "Nash-Sutcliffe Test: 0.955\n",
      "Kling-Gupta Test: 0.932\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 230.9559 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 14:04:21,879]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV51\u001b[0m\n",
      "3it [00:08,  2.73s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3274\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3769\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1168\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9404\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3274\n",
      "Corresponding penalty value: 0.9791\n",
      "\u001b[32m[I 2025-03-31 14:04:30,085]\u001b[0m Trial 0 finished with value: 0.9790592046479538 and parameters: {'max_iter': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.56, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 0.9790592046479538.\u001b[0m\n",
      "3it [00:02,  1.10it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.8386\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4675\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9171\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0744\n",
      "HistGradientBoostingRegressor worst RMSE: 1.8386\n",
      "Corresponding penalty value: 1.1508\n",
      "\u001b[32m[I 2025-03-31 14:04:32,809]\u001b[0m Trial 1 finished with value: 1.1508007132398879 and parameters: {'max_iter': 2003, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 8.33, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 0 with value: 0.9790592046479538.\u001b[0m\n",
      "3it [00:05,  1.98s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2464\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3516\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1472\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9151\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2464\n",
      "Corresponding penalty value: 0.9482\n",
      "\u001b[32m[I 2025-03-31 14:04:38,754]\u001b[0m Trial 2 finished with value: 0.9482074465123951 and parameters: {'max_iter': 1260, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 6.12, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 2 with value: 0.9482074465123951.\u001b[0m\n",
      "3it [00:03,  1.01s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8792\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4200\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2516\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8503\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2516\n",
      "Corresponding penalty value: 0.8904\n",
      "\u001b[32m[I 2025-03-31 14:04:41,776]\u001b[0m Trial 3 finished with value: 0.8904156951758873 and parameters: {'max_iter': 1640, 'learning_rate': 0.07801, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 5.93, 'max_features': 0.52, 'early_stopping': True}. Best is trial 3 with value: 0.8904156951758873.\u001b[0m\n",
      "3it [00:04,  1.43s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0331\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4429\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0723\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8495\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0723\n",
      "Corresponding penalty value: 0.8717\n",
      "\u001b[32m[I 2025-03-31 14:04:46,069]\u001b[0m Trial 4 finished with value: 0.8717426726705882 and parameters: {'max_iter': 662, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 3.04, 'max_features': 0.54, 'early_stopping': True}. Best is trial 4 with value: 0.8717426726705882.\u001b[0m\n",
      "3it [00:01,  2.58it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.9241\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3689\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9403\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0778\n",
      "HistGradientBoostingRegressor worst RMSE: 1.9241\n",
      "Corresponding penalty value: 1.1624\n",
      "\u001b[32m[I 2025-03-31 14:04:47,232]\u001b[0m Trial 5 finished with value: 1.1624023757135908 and parameters: {'max_iter': 805, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.59, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 4 with value: 0.8717426726705882.\u001b[0m\n",
      "3it [00:13,  4.66s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3949\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3913\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0921\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9595\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3949\n",
      "Corresponding penalty value: 1.0030\n",
      "\u001b[32m[I 2025-03-31 14:05:01,205]\u001b[0m Trial 6 finished with value: 1.0029960997286067 and parameters: {'max_iter': 1867, 'learning_rate': 0.01801, 'max_depth': 10, 'min_samples_leaf': 24, 'l2_regularization': 9.4, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 4 with value: 0.8717426726705882.\u001b[0m\n",
      "3it [00:01,  2.71it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.1985\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3755\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0427\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.2056\n",
      "HistGradientBoostingRegressor worst RMSE: 2.1985\n",
      "Corresponding penalty value: 1.3049\n",
      "\u001b[32m[I 2025-03-31 14:05:02,316]\u001b[0m Trial 7 finished with value: 1.3048573716318814 and parameters: {'max_iter': 721, 'learning_rate': 0.01901, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 3.89, 'max_features': 0.63, 'early_stopping': True}. Best is trial 4 with value: 0.8717426726705882.\u001b[0m\n",
      "3it [00:02,  1.32it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8885\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3978\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0405\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7756\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0405\n",
      "Corresponding penalty value: 0.8021\n",
      "\u001b[32m[I 2025-03-31 14:05:04,593]\u001b[0m Trial 8 finished with value: 0.8020894013342017 and parameters: {'max_iter': 1202, 'learning_rate': 0.05401, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.74, 'max_features': 1.0, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6490\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3852\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0893\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0412\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6490\n",
      "Corresponding penalty value: 1.1019\n",
      "\u001b[32m[I 2025-03-31 14:05:08,247]\u001b[0m Trial 9 finished with value: 1.1019442415341825 and parameters: {'max_iter': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 7.72, 'max_features': 0.53, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:13,  4.46s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.1028\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 3.3678\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.8067\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4258\n",
      "HistGradientBoostingRegressor worst RMSE: 4.8067\n",
      "Corresponding penalty value: 3.5639\n",
      "\u001b[32m[I 2025-03-31 14:05:21,650]\u001b[0m Trial 10 finished with value: 3.5638862355661605 and parameters: {'max_iter': 2863, 'learning_rate': 1e-05, 'max_depth': 4, 'min_samples_leaf': 2, 'l2_regularization': 0.14, 'max_features': 0.96, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.95s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1004\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3426\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1337\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8589\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1337\n",
      "Corresponding penalty value: 0.8864\n",
      "\u001b[32m[I 2025-03-31 14:05:27,532]\u001b[0m Trial 11 finished with value: 0.8863875718518109 and parameters: {'max_iter': 1038, 'learning_rate': 0.05401, 'max_depth': 7, 'min_samples_leaf': 24, 'l2_regularization': 0.11, 'max_features': 0.73, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:06,  2.25s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0314\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4026\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0648\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8329\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0648\n",
      "Corresponding penalty value: 0.8561\n",
      "\u001b[32m[I 2025-03-31 14:05:34,319]\u001b[0m Trial 12 finished with value: 0.8560931439251516 and parameters: {'max_iter': 1096, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 19, 'l2_regularization': 2.95, 'max_features': 0.8200000000000001, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.82s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9588\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3771\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1740\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8367\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1740\n",
      "Corresponding penalty value: 0.8704\n",
      "\u001b[32m[I 2025-03-31 14:05:39,820]\u001b[0m Trial 13 finished with value: 0.8703960888851476 and parameters: {'max_iter': 2224, 'learning_rate': 0.03101, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 1.56, 'max_features': 0.87, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.72s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1003\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3880\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0941\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8608\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1003\n",
      "Corresponding penalty value: 0.8848\n",
      "\u001b[32m[I 2025-03-31 14:05:45,005]\u001b[0m Trial 14 finished with value: 0.8847666353013212 and parameters: {'max_iter': 1137, 'learning_rate': 0.06601, 'max_depth': 6, 'min_samples_leaf': 20, 'l2_regularization': 4.3, 'max_features': 1.0, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.71s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2259\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3711\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1007\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8992\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2259\n",
      "Corresponding penalty value: 0.9319\n",
      "\u001b[32m[I 2025-03-31 14:05:50,163]\u001b[0m Trial 15 finished with value: 0.9318944249026311 and parameters: {'max_iter': 1474, 'learning_rate': 0.03701, 'max_depth': 4, 'min_samples_leaf': 12, 'l2_regularization': 1.77, 'max_features': 0.72, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.92s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1068\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4008\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0995\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8690\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1068\n",
      "Corresponding penalty value: 0.8928\n",
      "\u001b[32m[I 2025-03-31 14:05:55,950]\u001b[0m Trial 16 finished with value: 0.8928133020013134 and parameters: {'max_iter': 2633, 'learning_rate': 0.09901, 'max_depth': 9, 'min_samples_leaf': 14, 'l2_regularization': 2.81, 'max_features': 0.8300000000000001, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.80s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1027\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3987\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0727\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8580\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1027\n",
      "Corresponding penalty value: 0.8825\n",
      "\u001b[32m[I 2025-03-31 14:06:01,362]\u001b[0m Trial 17 finished with value: 0.8824772021093957 and parameters: {'max_iter': 976, 'learning_rate': 0.06301, 'max_depth': 6, 'min_samples_leaf': 6, 'l2_regularization': 1.08, 'max_features': 0.88, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:04,  1.59s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8863\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3931\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2425\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8406\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2425\n",
      "Corresponding penalty value: 0.8808\n",
      "\u001b[32m[I 2025-03-31 14:06:06,163]\u001b[0m Trial 18 finished with value: 0.8808072532343577 and parameters: {'max_iter': 2307, 'learning_rate': 0.08301, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 5.4, 'max_features': 0.67, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.99s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1420\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3879\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1327\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8876\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1420\n",
      "Corresponding penalty value: 0.9130\n",
      "\u001b[32m[I 2025-03-31 14:06:12,161]\u001b[0m Trial 19 finished with value: 0.9130167364999024 and parameters: {'max_iter': 1381, 'learning_rate': 0.04301000000000001, 'max_depth': 5, 'min_samples_leaf': 28, 'l2_regularization': 4.26, 'max_features': 0.78, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:10,  3.46s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1087\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3750\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1017\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8618\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1087\n",
      "Corresponding penalty value: 0.8865\n",
      "\u001b[32m[I 2025-03-31 14:06:22,556]\u001b[0m Trial 20 finished with value: 0.8864674042920169 and parameters: {'max_iter': 1714, 'learning_rate': 0.02701, 'max_depth': 7, 'min_samples_leaf': 21, 'l2_regularization': 3.34, 'max_features': 0.9199999999999999, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.72s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.9073\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3780\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1889\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8248\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1889\n",
      "Corresponding penalty value: 0.8612\n",
      "\u001b[32m[I 2025-03-31 14:06:27,751]\u001b[0m Trial 21 finished with value: 0.8611770742038127 and parameters: {'max_iter': 2152, 'learning_rate': 0.035010000000000006, 'max_depth': 3, 'min_samples_leaf': 18, 'l2_regularization': 1.01, 'max_features': 0.87, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:06,  2.07s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0095\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3925\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0855\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8292\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0855\n",
      "Corresponding penalty value: 0.8548\n",
      "\u001b[32m[I 2025-03-31 14:06:33,981]\u001b[0m Trial 22 finished with value: 0.8548116272811016 and parameters: {'max_iter': 2190, 'learning_rate': 0.00701, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 0.66, 'max_features': 0.79, 'early_stopping': True}. Best is trial 8 with value: 0.8020894013342017.\u001b[0m\n",
      "3it [00:05,  1.67s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8113\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4173\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0754\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7680\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0754\n",
      "Corresponding penalty value: 0.7987\n",
      "\u001b[32m[I 2025-03-31 14:06:39,023]\u001b[0m Trial 23 finished with value: 0.7987234567016286 and parameters: {'max_iter': 2478, 'learning_rate': 0.00301, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 2.18, 'max_features': 0.78, 'early_stopping': True}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:05,  1.73s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.1281\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 3.3799\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.8391\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4491\n",
      "HistGradientBoostingRegressor worst RMSE: 4.8391\n",
      "Corresponding penalty value: 3.5881\n",
      "\u001b[32m[I 2025-03-31 14:06:44,230]\u001b[0m Trial 24 finished with value: 3.588058718266462 and parameters: {'max_iter': 2457, 'learning_rate': 1e-05, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.72, 'max_features': 0.77, 'early_stopping': True}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:05,  1.74s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0039\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4296\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1077\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8471\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1077\n",
      "Corresponding penalty value: 0.8731\n",
      "\u001b[32m[I 2025-03-31 14:06:49,467]\u001b[0m Trial 25 finished with value: 0.8731419704998447 and parameters: {'max_iter': 2677, 'learning_rate': 0.01001, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 2.0, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:10,  3.42s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0621\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3964\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0649\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8411\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0649\n",
      "Corresponding penalty value: 0.8635\n",
      "\u001b[32m[I 2025-03-31 14:06:59,752]\u001b[0m Trial 26 finished with value: 0.8635135445233338 and parameters: {'max_iter': 2905, 'learning_rate': 0.01001, 'max_depth': 4, 'min_samples_leaf': 22, 'l2_regularization': 0.13, 'max_features': 0.79, 'early_stopping': 'auto'}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:04,  1.57s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2937\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4071\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0425\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9144\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2937\n",
      "Corresponding penalty value: 0.9524\n",
      "\u001b[32m[I 2025-03-31 14:07:04,484]\u001b[0m Trial 27 finished with value: 0.9523664177197277 and parameters: {'max_iter': 2432, 'learning_rate': 0.00901, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 2.1, 'max_features': 0.67, 'early_stopping': True}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:05,  1.77s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0313\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4078\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0460\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8284\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0460\n",
      "Corresponding penalty value: 0.8501\n",
      "\u001b[32m[I 2025-03-31 14:07:09,833]\u001b[0m Trial 28 finished with value: 0.8501266635312321 and parameters: {'max_iter': 1981, 'learning_rate': 0.02201, 'max_depth': 3, 'min_samples_leaf': 30, 'l2_regularization': 0.8200000000000001, 'max_features': 0.71, 'early_stopping': True}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.0880\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4286\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9554\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.1573\n",
      "HistGradientBoostingRegressor worst RMSE: 2.0880\n",
      "Corresponding penalty value: 1.2504\n",
      "\u001b[32m[I 2025-03-31 14:07:12,544]\u001b[0m Trial 29 finished with value: 1.2503908174301415 and parameters: {'max_iter': 1968, 'learning_rate': 0.02101, 'max_depth': 1, 'min_samples_leaf': 29, 'l2_regularization': 1.28, 'max_features': 0.7, 'early_stopping': 'auto'}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:05,  1.85s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6071\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3904\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1178\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0384\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6071\n",
      "Corresponding penalty value: 1.0953\n",
      "\u001b[32m[I 2025-03-31 14:07:18,124]\u001b[0m Trial 30 finished with value: 1.0953117479485612 and parameters: {'max_iter': 1689, 'learning_rate': 0.04401, 'max_depth': 4, 'min_samples_leaf': 30, 'l2_regularization': 2.37, 'max_features': 0.64, 'early_stopping': True}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:05,  1.99s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1674\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3957\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0679\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8770\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1674\n",
      "Corresponding penalty value: 0.9060\n",
      "\u001b[32m[I 2025-03-31 14:07:24,124]\u001b[0m Trial 31 finished with value: 0.9060486991798402 and parameters: {'max_iter': 2096, 'learning_rate': 0.00601, 'max_depth': 3, 'min_samples_leaf': 26, 'l2_regularization': 0.72, 'max_features': 0.74, 'early_stopping': True}. Best is trial 23 with value: 0.7987234567016286.\u001b[0m\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7195\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4270\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0929\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7465\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0929\n",
      "Corresponding penalty value: 0.7811\n",
      "\u001b[32m[I 2025-03-31 14:07:27,812]\u001b[0m Trial 32 finished with value: 0.7811087614232868 and parameters: {'max_iter': 1862, 'learning_rate': 0.01401, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.64, 'max_features': 0.8, 'early_stopping': True}. Best is trial 32 with value: 0.7811087614232868.\u001b[0m\n",
      "3it [00:02,  1.01it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2005\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3918\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1445\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9123\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2005\n",
      "Corresponding penalty value: 0.9411\n",
      "\u001b[32m[I 2025-03-31 14:07:30,810]\u001b[0m Trial 33 finished with value: 0.9411143686364146 and parameters: {'max_iter': 1506, 'learning_rate': 0.02501, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.49, 'max_features': 0.61, 'early_stopping': True}. Best is trial 32 with value: 0.7811087614232868.\u001b[0m\n",
      "3it [00:02,  1.21it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.4441\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3568\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9901\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9304\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4441\n",
      "Corresponding penalty value: 0.9817\n",
      "\u001b[32m[I 2025-03-31 14:07:33,327]\u001b[0m Trial 34 finished with value: 0.981742827769235 and parameters: {'max_iter': 1890, 'learning_rate': 0.015009999999999999, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 0.05, 'max_features': 1.0, 'early_stopping': 'auto'}. Best is trial 32 with value: 0.7811087614232868.\u001b[0m\n",
      "3it [00:02,  1.19it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0024\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4414\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1419\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8619\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1419\n",
      "Corresponding penalty value: 0.8899\n",
      "\u001b[32m[I 2025-03-31 14:07:35,884]\u001b[0m Trial 35 finished with value: 0.8899180838207145 and parameters: {'max_iter': 1290, 'learning_rate': 0.06301, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 3.59, 'max_features': 0.76, 'early_stopping': True}. Best is trial 32 with value: 0.7811087614232868.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.6211\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3933\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9746\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3296\n",
      "HistGradientBoostingRegressor worst RMSE: 2.6211\n",
      "Corresponding penalty value: 1.4588\n",
      "\u001b[32m[I 2025-03-31 14:07:38,601]\u001b[0m Trial 36 finished with value: 1.4587737120692843 and parameters: {'max_iter': 1844, 'learning_rate': 0.058010000000000006, 'max_depth': 1, 'min_samples_leaf': 25, 'l2_regularization': 7.29, 'max_features': 0.58, 'early_stopping': True}. Best is trial 32 with value: 0.7811087614232868.\u001b[0m\n",
      "3it [00:04,  1.39s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8021\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3815\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0467\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7434\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0467\n",
      "Corresponding penalty value: 0.7738\n",
      "\u001b[32m[I 2025-03-31 14:07:42,804]\u001b[0m Trial 37 finished with value: 0.773752901275122 and parameters: {'max_iter': 1564, 'learning_rate': 0.01401, 'max_depth': 3, 'min_samples_leaf': 8, 'l2_regularization': 2.2600000000000002, 'max_features': 0.91, 'early_stopping': 'auto'}. Best is trial 37 with value: 0.773752901275122.\u001b[0m\n",
      "3it [00:02,  1.04it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6078\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4154\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0911\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7048\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0911\n",
      "Corresponding penalty value: 0.7434\n",
      "\u001b[32m[I 2025-03-31 14:07:45,714]\u001b[0m Trial 38 finished with value: 0.7433869247091008 and parameters: {'max_iter': 1523, 'learning_rate': 0.01401, 'max_depth': 2, 'min_samples_leaf': 8, 'l2_regularization': 5.01, 'max_features': 0.91, 'early_stopping': 'auto'}. Best is trial 38 with value: 0.7433869247091008.\u001b[0m\n",
      "3it [00:08,  2.71s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5085\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4007\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1042\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0045\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5085\n",
      "Corresponding penalty value: 1.0549\n",
      "\u001b[32m[I 2025-03-31 14:07:53,869]\u001b[0m Trial 39 finished with value: 1.0548584511937669 and parameters: {'max_iter': 1561, 'learning_rate': 0.015009999999999999, 'max_depth': 5, 'min_samples_leaf': 8, 'l2_regularization': 5.01, 'max_features': 0.9, 'early_stopping': 'auto'}. Best is trial 38 with value: 0.7433869247091008.\u001b[0m\n",
      "3it [00:02,  1.38it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.4770\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4416\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3314\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0833\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4770\n",
      "Corresponding penalty value: 1.1227\n",
      "\u001b[32m[I 2025-03-31 14:07:56,085]\u001b[0m Trial 40 finished with value: 1.122709435515603 and parameters: {'max_iter': 1579, 'learning_rate': 0.00301, 'max_depth': 1, 'min_samples_leaf': 4, 'l2_regularization': 5.41, 'max_features': 0.9299999999999999, 'early_stopping': 'auto'}. Best is trial 38 with value: 0.7433869247091008.\u001b[0m\n",
      "3it [00:02,  1.20it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6961\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4246\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0749\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7319\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0749\n",
      "Corresponding penalty value: 0.7662\n",
      "\u001b[32m[I 2025-03-31 14:07:58,620]\u001b[0m Trial 41 finished with value: 0.7662017442373729 and parameters: {'max_iter': 1326, 'learning_rate': 0.01401, 'max_depth': 2, 'min_samples_leaf': 8, 'l2_regularization': 5.96, 'max_features': 0.97, 'early_stopping': 'auto'}. Best is trial 38 with value: 0.7433869247091008.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6181\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4213\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0600\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.6998\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0600\n",
      "Corresponding penalty value: 0.7358\n",
      "\u001b[32m[I 2025-03-31 14:08:01,194]\u001b[0m Trial 42 finished with value: 0.7358156855703236 and parameters: {'max_iter': 1338, 'learning_rate': 0.01601, 'max_depth': 2, 'min_samples_leaf': 9, 'l2_regularization': 6.62, 'max_features': 0.96, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "3it [00:01,  1.56it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.4487\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3565\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0056\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9369\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4487\n",
      "Corresponding penalty value: 0.9881\n",
      "\u001b[32m[I 2025-03-31 14:08:03,148]\u001b[0m Trial 43 finished with value: 0.9880851289035969 and parameters: {'max_iter': 1387, 'learning_rate': 0.01601, 'max_depth': 1, 'min_samples_leaf': 9, 'l2_regularization': 6.44, 'max_features': 0.97, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "3it [00:02,  1.19it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7781\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3791\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0607\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7393\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0607\n",
      "Corresponding penalty value: 0.7714\n",
      "\u001b[32m[I 2025-03-31 14:08:05,696]\u001b[0m Trial 44 finished with value: 0.7714063685206675 and parameters: {'max_iter': 888, 'learning_rate': 0.01301, 'max_depth': 3, 'min_samples_leaf': 7, 'l2_regularization': 6.19, 'max_features': 0.94, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "3it [00:03,  1.17s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2581\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4270\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0321\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9057\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2581\n",
      "Corresponding penalty value: 0.9410\n",
      "\u001b[32m[I 2025-03-31 14:08:09,235]\u001b[0m Trial 45 finished with value: 0.940954650025992 and parameters: {'max_iter': 924, 'learning_rate': 0.02801, 'max_depth': 4, 'min_samples_leaf': 7, 'l2_regularization': 6.72, 'max_features': 0.97, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "3it [00:02,  1.29it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7734\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3832\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0821\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7462\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0821\n",
      "Corresponding penalty value: 0.7798\n",
      "\u001b[32m[I 2025-03-31 14:08:11,595]\u001b[0m Trial 46 finished with value: 0.7798375862129399 and parameters: {'max_iter': 855, 'learning_rate': 0.02201, 'max_depth': 3, 'min_samples_leaf': 11, 'l2_regularization': 8.58, 'max_features': 0.94, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "3it [00:04,  1.58s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1767\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4076\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0830\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8891\n",
      "HistGradientBoostingRegressor worst RMSE: 1.1767\n",
      "Corresponding penalty value: 0.9179\n",
      "\u001b[32m[I 2025-03-31 14:08:16,364]\u001b[0m Trial 47 finished with value: 0.9178691051092904 and parameters: {'max_iter': 1281, 'learning_rate': 0.03101, 'max_depth': 4, 'min_samples_leaf': 5, 'l2_regularization': 6.0200000000000005, 'max_features': 0.9, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "3it [00:01,  1.67it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8445\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3764\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0489\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7566\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0489\n",
      "Corresponding penalty value: 0.7858\n",
      "\u001b[32m[I 2025-03-31 14:08:18,195]\u001b[0m Trial 48 finished with value: 0.785834056653496 and parameters: {'max_iter': 593, 'learning_rate': 0.01201, 'max_depth': 3, 'min_samples_leaf': 3, 'l2_regularization': 6.9, 'max_features': 0.98, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "3it [00:06,  2.08s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3708\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3940\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0804\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9484\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3708\n",
      "Corresponding penalty value: 0.9907\n",
      "\u001b[32m[I 2025-03-31 14:08:24,480]\u001b[0m Trial 49 finished with value: 0.990658670405254 and parameters: {'max_iter': 1196, 'learning_rate': 0.01801, 'max_depth': 5, 'min_samples_leaf': 9, 'l2_regularization': 8.13, 'max_features': 0.8500000000000001, 'early_stopping': 'auto'}. Best is trial 42 with value: 0.7358156855703236.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1338, 'learning_rate': 0.01601, 'max_depth': 2, 'min_samples_leaf': 9, 'l2_regularization': 6.62, 'max_features': 0.96, 'early_stopping': 'auto'}\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6083\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4436\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0782\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.7100\n",
      "HistGradientBoostingRegressor worst RMSE: 1.0782\n",
      "Corresponding penalty value: 0.7469\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV51\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1338, 'learning_rate': 0.01601, 'max_depth': 2, 'min_samples_leaf': 9, 'l2_regularization': 6.62, 'max_features': 0.96, 'early_stopping': 'auto'}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.127\n",
      "RMSE_crossval: 0.710\n",
      "RMSE_test: 0.448\n",
      "MAE_test: 0.312\n",
      "Nash-Sutcliffe Test: 0.989\n",
      "Kling-Gupta Test: 0.911\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 247.2740 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 14:08:29,160]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB4\u001b[0m\n",
      "3it [00:04,  1.37s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.7283\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0421\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8938\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.2214\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8938\n",
      "Corresponding penalty value: 3.2886\n",
      "\u001b[32m[I 2025-03-31 14:08:33,285]\u001b[0m Trial 0 finished with value: 3.288638153253336 and parameters: {'max_iter': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.56, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.288638153253336.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.2448\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.9111\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.3991\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8517\n",
      "HistGradientBoostingRegressor worst RMSE: 4.3991\n",
      "Corresponding penalty value: 3.9064\n",
      "\u001b[32m[I 2025-03-31 14:08:36,039]\u001b[0m Trial 1 finished with value: 3.906401545269767 and parameters: {'max_iter': 2003, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 8.33, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.288638153253336.\u001b[0m\n",
      "3it [00:04,  1.51s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.7551\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8472\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8535\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4853\n",
      "HistGradientBoostingRegressor worst RMSE: 4.7551\n",
      "Corresponding penalty value: 3.6123\n",
      "\u001b[32m[I 2025-03-31 14:08:40,585]\u001b[0m Trial 2 finished with value: 3.612253815905303 and parameters: {'max_iter': 1260, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 6.12, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.288638153253336.\u001b[0m\n",
      "3it [00:01,  1.51it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.8841\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1794\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.0452\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0362\n",
      "HistGradientBoostingRegressor worst RMSE: 4.0452\n",
      "Corresponding penalty value: 3.1371\n",
      "\u001b[32m[I 2025-03-31 14:08:42,580]\u001b[0m Trial 3 finished with value: 3.1371465145787476 and parameters: {'max_iter': 1640, 'learning_rate': 0.07801, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 5.93, 'max_features': 0.52, 'early_stopping': True}. Best is trial 3 with value: 3.1371465145787476.\u001b[0m\n",
      "3it [00:01,  1.59it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.1117\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6845\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9032\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8998\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9032\n",
      "Corresponding penalty value: 3.0002\n",
      "\u001b[32m[I 2025-03-31 14:08:44,470]\u001b[0m Trial 4 finished with value: 3.000152482781132 and parameters: {'max_iter': 662, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 3.04, 'max_features': 0.54, 'early_stopping': True}. Best is trial 4 with value: 3.000152482781132.\u001b[0m\n",
      "3it [00:01,  2.53it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.1945\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.7743\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.1458\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7049\n",
      "HistGradientBoostingRegressor worst RMSE: 4.1945\n",
      "Corresponding penalty value: 3.7538\n",
      "\u001b[32m[I 2025-03-31 14:08:45,657]\u001b[0m Trial 5 finished with value: 3.7538434541428534 and parameters: {'max_iter': 805, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.59, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.000152482781132.\u001b[0m\n",
      "3it [00:10,  3.40s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.0439\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2649\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.7929\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.3673\n",
      "HistGradientBoostingRegressor worst RMSE: 4.0439\n",
      "Corresponding penalty value: 3.4349\n",
      "\u001b[32m[I 2025-03-31 14:08:55,860]\u001b[0m Trial 6 finished with value: 3.434918725207401 and parameters: {'max_iter': 1867, 'learning_rate': 0.01801, 'max_depth': 10, 'min_samples_leaf': 24, 'l2_regularization': 9.4, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.000152482781132.\u001b[0m\n",
      "3it [00:01,  2.69it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.8326\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.5757\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.3778\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.2620\n",
      "HistGradientBoostingRegressor worst RMSE: 4.3778\n",
      "Corresponding penalty value: 3.3736\n",
      "\u001b[32m[I 2025-03-31 14:08:56,979]\u001b[0m Trial 7 finished with value: 3.3735933325791345 and parameters: {'max_iter': 721, 'learning_rate': 0.01901, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 3.89, 'max_features': 0.63, 'early_stopping': True}. Best is trial 4 with value: 3.000152482781132.\u001b[0m\n",
      "3it [00:01,  1.65it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.7639\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.6435\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.0833\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1636\n",
      "HistGradientBoostingRegressor worst RMSE: 4.0833\n",
      "Corresponding penalty value: 3.2555\n",
      "\u001b[32m[I 2025-03-31 14:08:58,797]\u001b[0m Trial 8 finished with value: 3.2555497393276194 and parameters: {'max_iter': 1202, 'learning_rate': 0.05401, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.74, 'max_features': 1.0, 'early_stopping': True}. Best is trial 4 with value: 3.000152482781132.\u001b[0m\n",
      "3it [00:02,  1.08it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.8000\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8911\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9968\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8960\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9968\n",
      "Corresponding penalty value: 3.0060\n",
      "\u001b[32m[I 2025-03-31 14:09:01,574]\u001b[0m Trial 9 finished with value: 3.006043996046144 and parameters: {'max_iter': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 7.72, 'max_features': 0.53, 'early_stopping': True}. Best is trial 4 with value: 3.000152482781132.\u001b[0m\n",
      "3it [00:22,  7.64s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.1282\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.8114\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.4077\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 4.1158\n",
      "HistGradientBoostingRegressor worst RMSE: 5.4077\n",
      "Corresponding penalty value: 4.2450\n",
      "\u001b[32m[I 2025-03-31 14:09:24,527]\u001b[0m Trial 10 finished with value: 4.244995770529166 and parameters: {'max_iter': 2863, 'learning_rate': 1e-05, 'max_depth': 10, 'min_samples_leaf': 2, 'l2_regularization': 3.97, 'max_features': 0.71, 'early_stopping': True}. Best is trial 4 with value: 3.000152482781132.\u001b[0m\n",
      "3it [00:01,  1.76it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4013\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6121\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8687\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.6274\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8687\n",
      "Corresponding penalty value: 2.7515\n",
      "\u001b[32m[I 2025-03-31 14:09:26,260]\u001b[0m Trial 11 finished with value: 2.7515092633696883 and parameters: {'max_iter': 527, 'learning_rate': 0.09801, 'max_depth': 7, 'min_samples_leaf': 21, 'l2_regularization': 7.48, 'max_features': 0.7, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  1.65it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4401\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0653\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8379\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7811\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8379\n",
      "Corresponding penalty value: 2.8868\n",
      "\u001b[32m[I 2025-03-31 14:09:28,104]\u001b[0m Trial 12 finished with value: 2.886785216525905 and parameters: {'max_iter': 983, 'learning_rate': 0.09601, 'max_depth': 6, 'min_samples_leaf': 19, 'l2_regularization': 5.8500000000000005, 'max_features': 0.74, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  2.18it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4832\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8957\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8575\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7455\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8575\n",
      "Corresponding penalty value: 2.8567\n",
      "\u001b[32m[I 2025-03-31 14:09:29,503]\u001b[0m Trial 13 finished with value: 2.856701604491884 and parameters: {'max_iter': 1023, 'learning_rate': 0.09901, 'max_depth': 5, 'min_samples_leaf': 18, 'l2_regularization': 6.640000000000001, 'max_features': 0.77, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.5197\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1418\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8642\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8419\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8642\n",
      "Corresponding penalty value: 2.9441\n",
      "\u001b[32m[I 2025-03-31 14:09:32,274]\u001b[0m Trial 14 finished with value: 2.9441461245011786 and parameters: {'max_iter': 2448, 'learning_rate': 0.06701, 'max_depth': 5, 'min_samples_leaf': 14, 'l2_regularization': 7.33, 'max_features': 0.8300000000000001, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  1.70it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.9322\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8828\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9269\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.9139\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9269\n",
      "Corresponding penalty value: 3.0152\n",
      "\u001b[32m[I 2025-03-31 14:09:34,068]\u001b[0m Trial 15 finished with value: 3.0152292396755875 and parameters: {'max_iter': 1060, 'learning_rate': 0.08201, 'max_depth': 7, 'min_samples_leaf': 20, 'l2_regularization': 9.97, 'max_features': 0.67, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  1.53it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.6295\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0939\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.7215\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1483\n",
      "HistGradientBoostingRegressor worst RMSE: 3.7215\n",
      "Corresponding penalty value: 3.2056\n",
      "\u001b[32m[I 2025-03-31 14:09:36,061]\u001b[0m Trial 16 finished with value: 3.205623702998602 and parameters: {'max_iter': 1502, 'learning_rate': 0.09901, 'max_depth': 4, 'min_samples_leaf': 6, 'l2_regularization': 6.62, 'max_features': 0.8, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.01it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.4814\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1162\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.6400\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0792\n",
      "HistGradientBoostingRegressor worst RMSE: 3.6400\n",
      "Corresponding penalty value: 3.1353\n",
      "\u001b[32m[I 2025-03-31 14:09:39,046]\u001b[0m Trial 17 finished with value: 3.1353028962346556 and parameters: {'max_iter': 905, 'learning_rate': 0.032010000000000004, 'max_depth': 4, 'min_samples_leaf': 15, 'l2_regularization': 8.64, 'max_features': 0.9, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.20it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3241\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8996\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9004\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7080\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9004\n",
      "Corresponding penalty value: 2.8273\n",
      "\u001b[32m[I 2025-03-31 14:09:41,577]\u001b[0m Trial 18 finished with value: 2.827263832598872 and parameters: {'max_iter': 502, 'learning_rate': 0.06501, 'max_depth': 7, 'min_samples_leaf': 20, 'l2_regularization': 4.93, 'max_features': 0.78, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4492\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7970\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8464\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.6975\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8464\n",
      "Corresponding penalty value: 2.8124\n",
      "\u001b[32m[I 2025-03-31 14:09:44,300]\u001b[0m Trial 19 finished with value: 2.812426489838037 and parameters: {'max_iter': 2175, 'learning_rate': 0.06101, 'max_depth': 8, 'min_samples_leaf': 22, 'l2_regularization': 4.84, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:03,  1.07s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.5506\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9229\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.7875\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7537\n",
      "HistGradientBoostingRegressor worst RMSE: 3.7875\n",
      "Corresponding penalty value: 2.8571\n",
      "\u001b[32m[I 2025-03-31 14:09:47,537]\u001b[0m Trial 20 finished with value: 2.857057265006949 and parameters: {'max_iter': 2242, 'learning_rate': 0.04701, 'max_depth': 8, 'min_samples_leaf': 27, 'l2_regularization': 4.82, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.25it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3201\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8193\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8749\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.6714\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8749\n",
      "Corresponding penalty value: 2.7918\n",
      "\u001b[32m[I 2025-03-31 14:09:49,974]\u001b[0m Trial 21 finished with value: 2.7917647518091346 and parameters: {'max_iter': 2584, 'learning_rate': 0.06301, 'max_depth': 7, 'min_samples_leaf': 22, 'l2_regularization': 5.16, 'max_features': 0.65, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.05it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4201\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8953\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8377\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7177\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8377\n",
      "Corresponding penalty value: 2.8297\n",
      "\u001b[32m[I 2025-03-31 14:09:52,869]\u001b[0m Trial 22 finished with value: 2.8297160540306656 and parameters: {'max_iter': 2724, 'learning_rate': 0.03901, 'max_depth': 9, 'min_samples_leaf': 22, 'l2_regularization': 4.23, 'max_features': 0.64, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.35it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3634\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8647\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8759\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7013\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8759\n",
      "Corresponding penalty value: 2.8188\n",
      "\u001b[32m[I 2025-03-31 14:09:55,121]\u001b[0m Trial 23 finished with value: 2.818790888778547 and parameters: {'max_iter': 2512, 'learning_rate': 0.06301, 'max_depth': 7, 'min_samples_leaf': 22, 'l2_regularization': 5.3500000000000005, 'max_features': 0.71, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.26it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.6607\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8977\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.7960\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7848\n",
      "HistGradientBoostingRegressor worst RMSE: 3.7960\n",
      "Corresponding penalty value: 2.8859\n",
      "\u001b[32m[I 2025-03-31 14:09:57,537]\u001b[0m Trial 24 finished with value: 2.8859339756653704 and parameters: {'max_iter': 2159, 'learning_rate': 0.08601, 'max_depth': 6, 'min_samples_leaf': 27, 'l2_regularization': 7.37, 'max_features': 0.65, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  1.51it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3359\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8164\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8500\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.6675\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8500\n",
      "Corresponding penalty value: 2.7857\n",
      "\u001b[32m[I 2025-03-31 14:09:59,550]\u001b[0m Trial 25 finished with value: 2.7857257644611164 and parameters: {'max_iter': 2381, 'learning_rate': 0.07400999999999999, 'max_depth': 9, 'min_samples_leaf': 17, 'l2_regularization': 2.98, 'max_features': 0.72, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:07,  2.34s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.3716\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8141\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9304\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7054\n",
      "HistGradientBoostingRegressor worst RMSE: 5.3716\n",
      "Corresponding penalty value: 3.8720\n",
      "\u001b[32m[I 2025-03-31 14:10:06,607]\u001b[0m Trial 26 finished with value: 3.8719899325359566 and parameters: {'max_iter': 2966, 'learning_rate': 0.07701, 'max_depth': 7, 'min_samples_leaf': 12, 'l2_regularization': 2.0300000000000002, 'max_features': 0.73, 'early_stopping': 'auto'}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  1.95it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.4566\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2856\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.7628\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1683\n",
      "HistGradientBoostingRegressor worst RMSE: 3.7628\n",
      "Corresponding penalty value: 3.2278\n",
      "\u001b[32m[I 2025-03-31 14:10:08,175]\u001b[0m Trial 27 finished with value: 3.2277553259143508 and parameters: {'max_iter': 2586, 'learning_rate': 0.08900999999999999, 'max_depth': 9, 'min_samples_leaf': 17, 'l2_regularization': 0.09, 'max_features': 0.88, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.23it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.5501\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8110\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9266\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7626\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9266\n",
      "Corresponding penalty value: 2.8790\n",
      "\u001b[32m[I 2025-03-31 14:10:10,634]\u001b[0m Trial 28 finished with value: 2.8789959448894438 and parameters: {'max_iter': 2370, 'learning_rate': 0.07300999999999999, 'max_depth': 9, 'min_samples_leaf': 13, 'l2_regularization': 3.1, 'max_features': 0.6, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:06,  2.20s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.0777\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6672\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9465\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.2305\n",
      "HistGradientBoostingRegressor worst RMSE: 4.0777\n",
      "Corresponding penalty value: 3.3152\n",
      "\u001b[32m[I 2025-03-31 14:10:17,255]\u001b[0m Trial 29 finished with value: 3.3151868591635387 and parameters: {'max_iter': 2679, 'learning_rate': 0.08900999999999999, 'max_depth': 9, 'min_samples_leaf': 20, 'l2_regularization': 1.23, 'max_features': 0.61, 'early_stopping': 'auto'}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.20it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.6090\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9070\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8247\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7802\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8247\n",
      "Corresponding penalty value: 2.8847\n",
      "\u001b[32m[I 2025-03-31 14:10:19,786]\u001b[0m Trial 30 finished with value: 2.884687599621503 and parameters: {'max_iter': 1802, 'learning_rate': 0.05901000000000001, 'max_depth': 6, 'min_samples_leaf': 9, 'l2_regularization': 1.82, 'max_features': 0.71, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.36it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.5166\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8454\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8339\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7320\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8339\n",
      "Corresponding penalty value: 2.8422\n",
      "\u001b[32m[I 2025-03-31 14:10:22,019]\u001b[0m Trial 31 finished with value: 2.842188073243674 and parameters: {'max_iter': 2107, 'learning_rate': 0.05901000000000001, 'max_depth': 8, 'min_samples_leaf': 21, 'l2_regularization': 3.35, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:03,  1.05s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3765\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9101\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8470\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7112\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8470\n",
      "Corresponding penalty value: 2.8248\n",
      "\u001b[32m[I 2025-03-31 14:10:25,207]\u001b[0m Trial 32 finished with value: 2.8247927609689327 and parameters: {'max_iter': 2316, 'learning_rate': 0.042010000000000006, 'max_depth': 8, 'min_samples_leaf': 18, 'l2_regularization': 4.5, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.7179\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9424\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9675\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8759\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9675\n",
      "Corresponding penalty value: 2.9851\n",
      "\u001b[32m[I 2025-03-31 14:10:27,819]\u001b[0m Trial 33 finished with value: 2.9850871346978245 and parameters: {'max_iter': 2004, 'learning_rate': 0.07101, 'max_depth': 8, 'min_samples_leaf': 30, 'l2_regularization': 5.3, 'max_features': 0.5700000000000001, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:05,  1.78s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.3726\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2049\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9217\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8331\n",
      "HistGradientBoostingRegressor worst RMSE: 5.3726\n",
      "Corresponding penalty value: 3.9870\n",
      "\u001b[32m[I 2025-03-31 14:10:33,176]\u001b[0m Trial 34 finished with value: 3.9870238448059894 and parameters: {'max_iter': 1608, 'learning_rate': 0.057010000000000005, 'max_depth': 7, 'min_samples_leaf': 16, 'l2_regularization': 2.5100000000000002, 'max_features': 0.76, 'early_stopping': 'auto'}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.13it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.0916\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7208\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9595\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.9240\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9595\n",
      "Corresponding penalty value: 3.0275\n",
      "\u001b[32m[I 2025-03-31 14:10:35,859]\u001b[0m Trial 35 finished with value: 3.0275430795689253 and parameters: {'max_iter': 1914, 'learning_rate': 0.07501, 'max_depth': 9, 'min_samples_leaf': 24, 'l2_regularization': 3.58, 'max_features': 0.5700000000000001, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  1.58it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3656\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8879\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8511\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7015\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8511\n",
      "Corresponding penalty value: 2.8165\n",
      "\u001b[32m[I 2025-03-31 14:10:37,786]\u001b[0m Trial 36 finished with value: 2.816492992992037 and parameters: {'max_iter': 2775, 'learning_rate': 0.06901, 'max_depth': 6, 'min_samples_leaf': 22, 'l2_regularization': 5.75, 'max_features': 0.65, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:07,  2.48s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.1714\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1075\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.7762\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.3517\n",
      "HistGradientBoostingRegressor worst RMSE: 4.1714\n",
      "Corresponding penalty value: 3.4337\n",
      "\u001b[32m[I 2025-03-31 14:10:45,255]\u001b[0m Trial 37 finished with value: 3.4336644522521014 and parameters: {'max_iter': 2591, 'learning_rate': 0.06301, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 6.640000000000001, 'max_features': 0.81, 'early_stopping': 'auto'}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:02,  1.19it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4484\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9232\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8680\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7465\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8680\n",
      "Corresponding penalty value: 2.8587\n",
      "\u001b[32m[I 2025-03-31 14:10:47,810]\u001b[0m Trial 38 finished with value: 2.858697716746639 and parameters: {'max_iter': 1324, 'learning_rate': 0.04601, 'max_depth': 7, 'min_samples_leaf': 18, 'l2_regularization': 7.95, 'max_features': 0.73, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:03,  1.19s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.9293\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8084\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9392\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.2256\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9392\n",
      "Corresponding penalty value: 3.2970\n",
      "\u001b[32m[I 2025-03-31 14:10:51,416]\u001b[0m Trial 39 finished with value: 3.2969585375538 and parameters: {'max_iter': 2055, 'learning_rate': 0.08301, 'max_depth': 4, 'min_samples_leaf': 15, 'l2_regularization': 8.77, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:03,  1.16s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.6784\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8162\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8478\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7808\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8478\n",
      "Corresponding penalty value: 2.8875\n",
      "\u001b[32m[I 2025-03-31 14:10:54,935]\u001b[0m Trial 40 finished with value: 2.8875378247249346 and parameters: {'max_iter': 1703, 'learning_rate': 0.034010000000000006, 'max_depth': 8, 'min_samples_leaf': 28, 'l2_regularization': 2.43, 'max_features': 0.59, 'early_stopping': True}. Best is trial 11 with value: 2.7515092633696883.\u001b[0m\n",
      "3it [00:01,  1.53it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.2834\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7686\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8107\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.6209\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8107\n",
      "Corresponding penalty value: 2.7399\n",
      "\u001b[32m[I 2025-03-31 14:10:56,934]\u001b[0m Trial 41 finished with value: 2.739878933317101 and parameters: {'max_iter': 2785, 'learning_rate': 0.07001, 'max_depth': 6, 'min_samples_leaf': 22, 'l2_regularization': 5.69, 'max_features': 0.65, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:02,  1.19it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.9609\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8457\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8443\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8836\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8443\n",
      "Corresponding penalty value: 2.9797\n",
      "\u001b[32m[I 2025-03-31 14:10:59,478]\u001b[0m Trial 42 finished with value: 2.9796831997879965 and parameters: {'max_iter': 2891, 'learning_rate': 0.05501, 'max_depth': 6, 'min_samples_leaf': 24, 'l2_regularization': 6.09, 'max_features': 0.63, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:02,  1.28it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4892\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7232\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8551\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.6892\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8551\n",
      "Corresponding penalty value: 2.8058\n",
      "\u001b[32m[I 2025-03-31 14:11:01,864]\u001b[0m Trial 43 finished with value: 2.8057640989320527 and parameters: {'max_iter': 2417, 'learning_rate': 0.05101000000000001, 'max_depth': 5, 'min_samples_leaf': 21, 'l2_regularization': 5.47, 'max_features': 0.69, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:01,  1.71it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3220\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8330\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8391\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.6647\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8391\n",
      "Corresponding penalty value: 2.7822\n",
      "\u001b[32m[I 2025-03-31 14:11:03,657]\u001b[0m Trial 44 finished with value: 2.782152298087322 and parameters: {'max_iter': 2498, 'learning_rate': 0.07701, 'max_depth': 5, 'min_samples_leaf': 19, 'l2_regularization': 6.890000000000001, 'max_features': 0.7, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:01,  2.14it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.5518\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9397\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.2585\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.9166\n",
      "HistGradientBoostingRegressor worst RMSE: 4.2585\n",
      "Corresponding penalty value: 3.0508\n",
      "\u001b[32m[I 2025-03-31 14:11:05,090]\u001b[0m Trial 45 finished with value: 3.0508340998392156 and parameters: {'max_iter': 2993, 'learning_rate': 0.09201, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 7.23, 'max_features': 0.62, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:01,  1.72it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3893\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0925\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8647\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7822\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8647\n",
      "Corresponding penalty value: 2.8904\n",
      "\u001b[32m[I 2025-03-31 14:11:06,873]\u001b[0m Trial 46 finished with value: 2.8904065416522675 and parameters: {'max_iter': 2604, 'learning_rate': 0.07901, 'max_depth': 5, 'min_samples_leaf': 19, 'l2_regularization': 6.86, 'max_features': 0.75, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:01,  2.09it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.7052\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8542\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.8061\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.7885\n",
      "HistGradientBoostingRegressor worst RMSE: 3.8061\n",
      "Corresponding penalty value: 2.8902\n",
      "\u001b[32m[I 2025-03-31 14:11:08,340]\u001b[0m Trial 47 finished with value: 2.890232107045669 and parameters: {'max_iter': 2796, 'learning_rate': 0.06901, 'max_depth': 4, 'min_samples_leaf': 26, 'l2_regularization': 6.3100000000000005, 'max_features': 0.71, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:01,  1.70it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.9937\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6852\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9401\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8730\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9401\n",
      "Corresponding penalty value: 2.9797\n",
      "\u001b[32m[I 2025-03-31 14:11:10,142]\u001b[0m Trial 48 finished with value: 2.979716489280643 and parameters: {'max_iter': 2484, 'learning_rate': 0.08501, 'max_depth': 6, 'min_samples_leaf': 23, 'l2_regularization': 9.11, 'max_features': 0.54, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "3it [00:01,  1.74it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.4659\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9593\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.0714\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8322\n",
      "HistGradientBoostingRegressor worst RMSE: 4.0714\n",
      "Corresponding penalty value: 2.9561\n",
      "\u001b[32m[I 2025-03-31 14:11:11,896]\u001b[0m Trial 49 finished with value: 2.956107114757854 and parameters: {'max_iter': 2287, 'learning_rate': 0.07601, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 8.19, 'max_features': 0.66, 'early_stopping': True}. Best is trial 41 with value: 2.739878933317101.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 2785, 'learning_rate': 0.07001, 'max_depth': 6, 'min_samples_leaf': 22, 'l2_regularization': 5.69, 'max_features': 0.65, 'early_stopping': True}\n",
      "3it [00:01,  1.54it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.5006\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2360\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9436\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.8934\n",
      "HistGradientBoostingRegressor worst RMSE: 3.9436\n",
      "Corresponding penalty value: 2.9984\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB4\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 2785, 'learning_rate': 0.07001, 'max_depth': 6, 'min_samples_leaf': 22, 'l2_regularization': 5.69, 'max_features': 0.65, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.271\n",
      "RMSE_crossval: 2.893\n",
      "RMSE_test: 1.533\n",
      "MAE_test: 0.965\n",
      "Nash-Sutcliffe Test: 0.881\n",
      "Kling-Gupta Test: 0.819\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 166.1342 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 14:11:15,297]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB8\u001b[0m\n",
      "3it [00:04,  1.40s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1595\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3261\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9485\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1447\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9485\n",
      "Corresponding penalty value: 3.4251\n",
      "\u001b[32m[I 2025-03-31 14:11:19,490]\u001b[0m Trial 0 finished with value: 3.4250590982116575 and parameters: {'max_iter': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.56, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.4250590982116575.\u001b[0m\n",
      "3it [00:02,  1.08it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1442\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 3.6279\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9713\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5811\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9713\n",
      "Corresponding penalty value: 3.8201\n",
      "\u001b[32m[I 2025-03-31 14:11:22,268]\u001b[0m Trial 1 finished with value: 3.8201316089672983 and parameters: {'max_iter': 2003, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 8.33, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.4250590982116575.\u001b[0m\n",
      "3it [00:04,  1.41s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1449\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1939\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9607\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0998\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9607\n",
      "Corresponding penalty value: 3.3859\n",
      "\u001b[32m[I 2025-03-31 14:11:26,511]\u001b[0m Trial 2 finished with value: 3.3858906467777756 and parameters: {'max_iter': 1260, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 6.12, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 2 with value: 3.3858906467777756.\u001b[0m\n",
      "3it [00:02,  1.02it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1434\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3627\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9158\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1407\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9158\n",
      "Corresponding penalty value: 3.4182\n",
      "\u001b[32m[I 2025-03-31 14:11:29,449]\u001b[0m Trial 3 finished with value: 3.4181702512505887 and parameters: {'max_iter': 1640, 'learning_rate': 0.07801, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 5.93, 'max_features': 0.52, 'early_stopping': True}. Best is trial 2 with value: 3.3858906467777756.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1457\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2302\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9311\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1024\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9311\n",
      "Corresponding penalty value: 3.3852\n",
      "\u001b[32m[I 2025-03-31 14:11:32,352]\u001b[0m Trial 4 finished with value: 3.3852307867223392 and parameters: {'max_iter': 662, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 3.04, 'max_features': 0.54, 'early_stopping': True}. Best is trial 4 with value: 3.3852307867223392.\u001b[0m\n",
      "3it [00:01,  2.58it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1574\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 3.2885\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9712\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4723\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9712\n",
      "Corresponding penalty value: 3.7222\n",
      "\u001b[32m[I 2025-03-31 14:11:33,519]\u001b[0m Trial 5 finished with value: 3.7222353199621248 and parameters: {'max_iter': 805, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.59, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.3852307867223392.\u001b[0m\n",
      "3it [00:09,  3.28s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1974\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.4859\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9411\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.2081\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9411\n",
      "Corresponding penalty value: 3.4814\n",
      "\u001b[32m[I 2025-03-31 14:11:43,372]\u001b[0m Trial 6 finished with value: 3.481416267195364 and parameters: {'max_iter': 1867, 'learning_rate': 0.01801, 'max_depth': 10, 'min_samples_leaf': 24, 'l2_regularization': 9.4, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.3852307867223392.\u001b[0m\n",
      "3it [00:01,  2.69it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0924\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.8309\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0124\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.3119\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0124\n",
      "Corresponding penalty value: 3.5819\n",
      "\u001b[32m[I 2025-03-31 14:11:44,488]\u001b[0m Trial 7 finished with value: 3.5819189168582954 and parameters: {'max_iter': 721, 'learning_rate': 0.01901, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 3.89, 'max_features': 0.63, 'early_stopping': True}. Best is trial 4 with value: 3.3852307867223392.\u001b[0m\n",
      "3it [00:02,  1.38it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1771\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.6410\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9278\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.2486\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9278\n",
      "Corresponding penalty value: 3.5165\n",
      "\u001b[32m[I 2025-03-31 14:11:46,659]\u001b[0m Trial 8 finished with value: 3.5165103059400913 and parameters: {'max_iter': 1202, 'learning_rate': 0.05401, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.74, 'max_features': 1.0, 'early_stopping': True}. Best is trial 4 with value: 3.3852307867223392.\u001b[0m\n",
      "3it [00:02,  1.05it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1170\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2576\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9418\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1054\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9418\n",
      "Corresponding penalty value: 3.3891\n",
      "\u001b[32m[I 2025-03-31 14:11:49,530]\u001b[0m Trial 9 finished with value: 3.3890717806978934 and parameters: {'max_iter': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 7.72, 'max_features': 0.53, 'early_stopping': True}. Best is trial 4 with value: 3.3852307867223392.\u001b[0m\n",
      "3it [00:26,  8.94s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3214\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8128\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0349\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0563\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0349\n",
      "Corresponding penalty value: 3.3542\n",
      "\u001b[32m[I 2025-03-31 14:12:16,377]\u001b[0m Trial 10 finished with value: 3.354195506735757 and parameters: {'max_iter': 2863, 'learning_rate': 1e-05, 'max_depth': 10, 'min_samples_leaf': 2, 'l2_regularization': 3.97, 'max_features': 0.71, 'early_stopping': True}. Best is trial 10 with value: 3.354195506735757.\u001b[0m\n",
      "3it [00:18,  6.08s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1763\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2683\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9372\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1273\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9372\n",
      "Corresponding penalty value: 3.4083\n",
      "\u001b[32m[I 2025-03-31 14:12:34,640]\u001b[0m Trial 11 finished with value: 3.408289119178701 and parameters: {'max_iter': 2913, 'learning_rate': 0.00801, 'max_depth': 10, 'min_samples_leaf': 2, 'l2_regularization': 3.68, 'max_features': 0.72, 'early_stopping': True}. Best is trial 10 with value: 3.354195506735757.\u001b[0m\n",
      "3it [00:05,  1.99s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1788\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2512\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9308\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1203\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9308\n",
      "Corresponding penalty value: 3.4013\n",
      "\u001b[32m[I 2025-03-31 14:12:40,635]\u001b[0m Trial 12 finished with value: 3.4013452654113827 and parameters: {'max_iter': 2896, 'learning_rate': 0.034010000000000006, 'max_depth': 7, 'min_samples_leaf': 2, 'l2_regularization': 4.66, 'max_features': 0.71, 'early_stopping': True}. Best is trial 10 with value: 3.354195506735757.\u001b[0m\n",
      "3it [00:02,  1.33it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1803\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1833\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9401\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1013\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9401\n",
      "Corresponding penalty value: 3.3851\n",
      "\u001b[32m[I 2025-03-31 14:12:42,924]\u001b[0m Trial 13 finished with value: 3.385144806635204 and parameters: {'max_iter': 2463, 'learning_rate': 0.09601, 'max_depth': 5, 'min_samples_leaf': 12, 'l2_regularization': 2.45, 'max_features': 0.8, 'early_stopping': True}. Best is trial 10 with value: 3.354195506735757.\u001b[0m\n",
      "3it [00:17,  5.76s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3228\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8068\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0350\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0549\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0350\n",
      "Corresponding penalty value: 3.3529\n",
      "\u001b[32m[I 2025-03-31 14:13:00,222]\u001b[0m Trial 14 finished with value: 3.352909320904025 and parameters: {'max_iter': 2473, 'learning_rate': 1e-05, 'max_depth': 5, 'min_samples_leaf': 8, 'l2_regularization': 0.25, 'max_features': 0.8300000000000001, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:10,  3.66s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1764\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2801\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9474\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1346\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9474\n",
      "Corresponding penalty value: 3.4159\n",
      "\u001b[32m[I 2025-03-31 14:13:11,224]\u001b[0m Trial 15 finished with value: 3.415911137179033 and parameters: {'max_iter': 2460, 'learning_rate': 0.00101, 'max_depth': 4, 'min_samples_leaf': 6, 'l2_regularization': 0.02, 'max_features': 0.89, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:08,  2.69s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1574\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1973\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9454\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1000\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9454\n",
      "Corresponding penalty value: 3.3846\n",
      "\u001b[32m[I 2025-03-31 14:13:19,334]\u001b[0m Trial 16 finished with value: 3.3845562023636218 and parameters: {'max_iter': 2474, 'learning_rate': 0.02901, 'max_depth': 7, 'min_samples_leaf': 6, 'l2_regularization': 5.8, 'max_features': 0.65, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:06,  2.21s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1665\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1326\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9536\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0842\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9536\n",
      "Corresponding penalty value: 3.3711\n",
      "\u001b[32m[I 2025-03-31 14:13:25,982]\u001b[0m Trial 17 finished with value: 3.3711483705563765 and parameters: {'max_iter': 2159, 'learning_rate': 0.011009999999999999, 'max_depth': 4, 'min_samples_leaf': 6, 'l2_regularization': 1.59, 'max_features': 0.78, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:20,  6.78s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3221\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8118\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0350\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0563\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0350\n",
      "Corresponding penalty value: 3.3542\n",
      "\u001b[32m[I 2025-03-31 14:13:46,359]\u001b[0m Trial 18 finished with value: 3.3541795260998817 and parameters: {'max_iter': 2671, 'learning_rate': 1e-05, 'max_depth': 6, 'min_samples_leaf': 15, 'l2_regularization': 7.22, 'max_features': 0.86, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:05,  1.84s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1756\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3773\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9293\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1607\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9293\n",
      "Corresponding penalty value: 3.4376\n",
      "\u001b[32m[I 2025-03-31 14:13:51,915]\u001b[0m Trial 19 finished with value: 3.437588192871419 and parameters: {'max_iter': 2664, 'learning_rate': 0.02801, 'max_depth': 6, 'min_samples_leaf': 16, 'l2_regularization': 7.18, 'max_features': 0.86, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:04,  1.38s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1895\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2509\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9868\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1424\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9868\n",
      "Corresponding penalty value: 3.4268\n",
      "\u001b[32m[I 2025-03-31 14:13:56,073]\u001b[0m Trial 20 finished with value: 3.426807040382153 and parameters: {'max_iter': 2344, 'learning_rate': 0.03901, 'max_depth': 4, 'min_samples_leaf': 14, 'l2_regularization': 9.56, 'max_features': 0.91, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:24,  8.27s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3220\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8102\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0352\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0558\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0352\n",
      "Corresponding penalty value: 3.3537\n",
      "\u001b[32m[I 2025-03-31 14:14:20,921]\u001b[0m Trial 21 finished with value: 3.353720215971519 and parameters: {'max_iter': 2746, 'learning_rate': 1e-05, 'max_depth': 9, 'min_samples_leaf': 8, 'l2_regularization': 6.82, 'max_features': 0.73, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:14,  4.77s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1781\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2592\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9431\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1268\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9431\n",
      "Corresponding penalty value: 3.4084\n",
      "\u001b[32m[I 2025-03-31 14:14:35,247]\u001b[0m Trial 22 finished with value: 3.408444614228826 and parameters: {'max_iter': 2673, 'learning_rate': 0.01401, 'max_depth': 8, 'min_samples_leaf': 9, 'l2_regularization': 7.08, 'max_features': 0.76, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:14,  4.72s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1800\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3537\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9421\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1586\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9421\n",
      "Corresponding penalty value: 3.4370\n",
      "\u001b[32m[I 2025-03-31 14:14:49,439]\u001b[0m Trial 23 finished with value: 3.436955134483172 and parameters: {'max_iter': 2153, 'learning_rate': 0.00501, 'max_depth': 6, 'min_samples_leaf': 19, 'l2_regularization': 8.39, 'max_features': 0.8300000000000001, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:06,  2.09s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1812\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2866\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9221\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1299\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9221\n",
      "Corresponding penalty value: 3.4092\n",
      "\u001b[32m[I 2025-03-31 14:14:55,733]\u001b[0m Trial 24 finished with value: 3.4091686429540218 and parameters: {'max_iter': 2687, 'learning_rate': 0.02401, 'max_depth': 3, 'min_samples_leaf': 8, 'l2_regularization': 6.7, 'max_features': 0.91, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:14,  4.73s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1647\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3154\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9409\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1403\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9409\n",
      "Corresponding penalty value: 3.4204\n",
      "\u001b[32m[I 2025-03-31 14:15:09,943]\u001b[0m Trial 25 finished with value: 3.420390850288229 and parameters: {'max_iter': 2225, 'learning_rate': 0.00901, 'max_depth': 9, 'min_samples_leaf': 13, 'l2_regularization': 5.08, 'max_features': 0.67, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:25,  8.44s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1753\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.4654\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9500\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1969\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9500\n",
      "Corresponding penalty value: 3.4722\n",
      "\u001b[32m[I 2025-03-31 14:15:35,287]\u001b[0m Trial 26 finished with value: 3.4722067130111283 and parameters: {'max_iter': 2972, 'learning_rate': 0.00101, 'max_depth': 7, 'min_samples_leaf': 20, 'l2_regularization': 8.63, 'max_features': 0.8400000000000001, 'early_stopping': 'auto'}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:10,  3.61s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1662\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2455\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9463\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1193\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9463\n",
      "Corresponding penalty value: 3.4020\n",
      "\u001b[32m[I 2025-03-31 14:15:46,163]\u001b[0m Trial 27 finished with value: 3.4020262321214365 and parameters: {'max_iter': 2681, 'learning_rate': 0.01901, 'max_depth': 6, 'min_samples_leaf': 8, 'l2_regularization': 5.28, 'max_features': 0.75, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:04,  1.51s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1677\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.4828\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9338\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1948\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9338\n",
      "Corresponding penalty value: 3.4687\n",
      "\u001b[32m[I 2025-03-31 14:15:50,730]\u001b[0m Trial 28 finished with value: 3.4686896933566227 and parameters: {'max_iter': 1874, 'learning_rate': 0.041010000000000005, 'max_depth': 9, 'min_samples_leaf': 16, 'l2_regularization': 7.55, 'max_features': 0.8, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:14,  4.74s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1957\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3316\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9439\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1571\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9439\n",
      "Corresponding penalty value: 3.4358\n",
      "\u001b[32m[I 2025-03-31 14:16:04,976]\u001b[0m Trial 29 finished with value: 3.4357626502116623 and parameters: {'max_iter': 2520, 'learning_rate': 0.01401, 'max_depth': 8, 'min_samples_leaf': 4, 'l2_regularization': 6.57, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:09,  3.11s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1863\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3713\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9512\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1696\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9512\n",
      "Corresponding penalty value: 3.4478\n",
      "\u001b[32m[I 2025-03-31 14:16:14,338]\u001b[0m Trial 30 finished with value: 3.4477598468242654 and parameters: {'max_iter': 1642, 'learning_rate': 0.00501, 'max_depth': 5, 'min_samples_leaf': 19, 'l2_regularization': 4.57, 'max_features': 0.87, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:24,  8.33s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1765\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2778\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9367\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1303\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9367\n",
      "Corresponding penalty value: 3.4110\n",
      "\u001b[32m[I 2025-03-31 14:16:39,359]\u001b[0m Trial 31 finished with value: 3.4109539510682203 and parameters: {'max_iter': 2793, 'learning_rate': 0.00201, 'max_depth': 9, 'min_samples_leaf': 5, 'l2_regularization': 1.49, 'max_features': 0.71, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:25,  8.62s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3218\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8094\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0351\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0555\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0351\n",
      "Corresponding penalty value: 3.3534\n",
      "\u001b[32m[I 2025-03-31 14:17:05,256]\u001b[0m Trial 32 finished with value: 3.3534245736474975 and parameters: {'max_iter': 2810, 'learning_rate': 1e-05, 'max_depth': 9, 'min_samples_leaf': 3, 'l2_regularization': 7.88, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:14,  4.75s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1662\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2554\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9366\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1194\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9366\n",
      "Corresponding penalty value: 3.4012\n",
      "\u001b[32m[I 2025-03-31 14:17:19,527]\u001b[0m Trial 33 finished with value: 3.4011503352471917 and parameters: {'max_iter': 2313, 'learning_rate': 0.011009999999999999, 'max_depth': 9, 'min_samples_leaf': 4, 'l2_regularization': 8.88, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:18,  6.11s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1540\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2401\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9380\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1107\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9380\n",
      "Corresponding penalty value: 3.3934\n",
      "\u001b[32m[I 2025-03-31 14:17:37,901]\u001b[0m Trial 34 finished with value: 3.3934478239120605 and parameters: {'max_iter': 2990, 'learning_rate': 0.00701, 'max_depth': 8, 'min_samples_leaf': 10, 'l2_regularization': 7.91, 'max_features': 0.59, 'early_stopping': 'auto'}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:05,  1.70s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1711\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2647\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9564\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1308\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9564\n",
      "Corresponding penalty value: 3.4133\n",
      "\u001b[32m[I 2025-03-31 14:17:43,049]\u001b[0m Trial 35 finished with value: 3.413318808402519 and parameters: {'max_iter': 2770, 'learning_rate': 0.06401, 'max_depth': 7, 'min_samples_leaf': 8, 'l2_regularization': 9.93, 'max_features': 0.75, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:07,  2.38s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1713\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2972\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9514\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1400\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9514\n",
      "Corresponding penalty value: 3.4211\n",
      "\u001b[32m[I 2025-03-31 14:17:50,221]\u001b[0m Trial 36 finished with value: 3.421092774863377 and parameters: {'max_iter': 2516, 'learning_rate': 0.02401, 'max_depth': 5, 'min_samples_leaf': 15, 'l2_regularization': 6.16, 'max_features': 0.8, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:10,  3.66s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1569\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2442\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9398\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1136\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9398\n",
      "Corresponding penalty value: 3.3963\n",
      "\u001b[32m[I 2025-03-31 14:18:01,235]\u001b[0m Trial 37 finished with value: 3.396255553090384 and parameters: {'max_iter': 2591, 'learning_rate': 0.015009999999999999, 'max_depth': 6, 'min_samples_leaf': 11, 'l2_regularization': 7.87, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:06,  2.03s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3253\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8048\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0363\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0555\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0363\n",
      "Corresponding penalty value: 3.3535\n",
      "\u001b[32m[I 2025-03-31 14:18:07,364]\u001b[0m Trial 38 finished with value: 3.3535435832979887 and parameters: {'max_iter': 2054, 'learning_rate': 1e-05, 'max_depth': 3, 'min_samples_leaf': 4, 'l2_regularization': 5.75, 'max_features': 0.64, 'early_stopping': True}. Best is trial 14 with value: 3.352909320904025.\u001b[0m\n",
      "3it [00:05,  1.77s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1346\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1536\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9129\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0670\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9129\n",
      "Corresponding penalty value: 3.3516\n",
      "\u001b[32m[I 2025-03-31 14:18:12,703]\u001b[0m Trial 39 finished with value: 3.3516216950998707 and parameters: {'max_iter': 2052, 'learning_rate': 0.02101, 'max_depth': 3, 'min_samples_leaf': 4, 'l2_regularization': 5.95, 'max_features': 0.63, 'early_stopping': 'auto'}. Best is trial 39 with value: 3.3516216950998707.\u001b[0m\n",
      "3it [00:04,  1.54s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1426\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0662\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9086\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0391\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9086\n",
      "Corresponding penalty value: 3.3261\n",
      "\u001b[32m[I 2025-03-31 14:18:17,373]\u001b[0m Trial 40 finished with value: 3.326089216082314 and parameters: {'max_iter': 2021, 'learning_rate': 0.02301, 'max_depth': 3, 'min_samples_leaf': 4, 'l2_regularization': 5.5200000000000005, 'max_features': 0.62, 'early_stopping': 'auto'}. Best is trial 40 with value: 3.326089216082314.\u001b[0m\n",
      "3it [00:05,  1.74s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1441\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1205\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8892\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0513\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8892\n",
      "Corresponding penalty value: 3.3350\n",
      "\u001b[32m[I 2025-03-31 14:18:22,634]\u001b[0m Trial 41 finished with value: 3.3350462428420724 and parameters: {'max_iter': 1998, 'learning_rate': 0.02301, 'max_depth': 3, 'min_samples_leaf': 4, 'l2_regularization': 5.69, 'max_features': 0.63, 'early_stopping': 'auto'}. Best is trial 40 with value: 3.326089216082314.\u001b[0m\n",
      "3it [00:03,  1.28s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1420\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0025\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9120\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0188\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9120\n",
      "Corresponding penalty value: 3.3081\n",
      "\u001b[32m[I 2025-03-31 14:18:26,522]\u001b[0m Trial 42 finished with value: 3.3081491911385936 and parameters: {'max_iter': 1472, 'learning_rate': 0.02301, 'max_depth': 3, 'min_samples_leaf': 3, 'l2_regularization': 5.5, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 42 with value: 3.3081491911385936.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1588\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0316\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8904\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0269\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8904\n",
      "Corresponding penalty value: 3.3133\n",
      "\u001b[32m[I 2025-03-31 14:18:29,630]\u001b[0m Trial 43 finished with value: 3.3132971741497474 and parameters: {'max_iter': 1356, 'learning_rate': 0.035010000000000006, 'max_depth': 3, 'min_samples_leaf': 6, 'l2_regularization': 5.39, 'max_features': 0.55, 'early_stopping': 'auto'}. Best is trial 42 with value: 3.3081491911385936.\u001b[0m\n",
      "3it [00:02,  1.20it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1631\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2774\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9125\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1177\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9125\n",
      "Corresponding penalty value: 3.3971\n",
      "\u001b[32m[I 2025-03-31 14:18:32,164]\u001b[0m Trial 44 finished with value: 3.3971471780547744 and parameters: {'max_iter': 1351, 'learning_rate': 0.03801, 'max_depth': 2, 'min_samples_leaf': 5, 'l2_regularization': 5.41, 'max_features': 0.56, 'early_stopping': 'auto'}. Best is trial 42 with value: 3.3081491911385936.\u001b[0m\n",
      "3it [00:02,  1.26it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1625\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9746\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9172\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0181\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9172\n",
      "Corresponding penalty value: 3.3080\n",
      "\u001b[32m[I 2025-03-31 14:18:34,580]\u001b[0m Trial 45 finished with value: 3.308007343763215 and parameters: {'max_iter': 1048, 'learning_rate': 0.048010000000000004, 'max_depth': 3, 'min_samples_leaf': 3, 'l2_regularization': 4.5, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 45 with value: 3.308007343763215.\u001b[0m\n",
      "3it [00:01,  1.67it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1662\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2861\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9080\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.1201\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9080\n",
      "Corresponding penalty value: 3.3989\n",
      "\u001b[32m[I 2025-03-31 14:18:36,417]\u001b[0m Trial 46 finished with value: 3.398909967154994 and parameters: {'max_iter': 947, 'learning_rate': 0.05201000000000001, 'max_depth': 2, 'min_samples_leaf': 2, 'l2_regularization': 4.46, 'max_features': 0.52, 'early_stopping': 'auto'}. Best is trial 45 with value: 3.308007343763215.\u001b[0m\n",
      "3it [00:01,  1.90it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1190\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 3.3555\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9525\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4756\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9525\n",
      "Corresponding penalty value: 3.7233\n",
      "\u001b[32m[I 2025-03-31 14:18:38,029]\u001b[0m Trial 47 finished with value: 3.72333112493037 and parameters: {'max_iter': 1116, 'learning_rate': 0.048010000000000004, 'max_depth': 1, 'min_samples_leaf': 6, 'l2_regularization': 3.43, 'max_features': 0.55, 'early_stopping': 'auto'}. Best is trial 45 with value: 3.308007343763215.\u001b[0m\n",
      "3it [00:03,  1.13s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1399\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9390\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9386\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0059\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9386\n",
      "Corresponding penalty value: 3.2991\n",
      "\u001b[32m[I 2025-03-31 14:18:41,453]\u001b[0m Trial 48 finished with value: 3.2991477865178087 and parameters: {'max_iter': 1542, 'learning_rate': 0.04601, 'max_depth': 3, 'min_samples_leaf': 3, 'l2_regularization': 4.0200000000000005, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 48 with value: 3.2991477865178087.\u001b[0m\n",
      "3it [00:03,  1.24s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1499\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0726\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9398\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0541\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9398\n",
      "Corresponding penalty value: 3.3427\n",
      "\u001b[32m[I 2025-03-31 14:18:45,215]\u001b[0m Trial 49 finished with value: 3.342658299069812 and parameters: {'max_iter': 1514, 'learning_rate': 0.04501, 'max_depth': 4, 'min_samples_leaf': 2, 'l2_regularization': 4.11, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 48 with value: 3.2991477865178087.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1542, 'learning_rate': 0.04601, 'max_depth': 3, 'min_samples_leaf': 3, 'l2_regularization': 4.0200000000000005, 'max_features': 0.5, 'early_stopping': 'auto'}\n",
      "3it [00:03,  1.33s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1734\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1066\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8797\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0532\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8797\n",
      "Corresponding penalty value: 3.3359\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB8\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1542, 'learning_rate': 0.04601, 'max_depth': 3, 'min_samples_leaf': 3, 'l2_regularization': 4.0200000000000005, 'max_features': 0.5, 'early_stopping': 'auto'}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.981\n",
      "RMSE_crossval: 3.053\n",
      "RMSE_test: 3.426\n",
      "MAE_test: 2.225\n",
      "Nash-Sutcliffe Test: -6.546\n",
      "Kling-Gupta Test: -2.937\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 454.8682 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 14:18:50,157]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB10\u001b[0m\n",
      "3it [00:08,  2.81s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6268\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2183\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2628\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3693\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6268\n",
      "Corresponding penalty value: 1.3950\n",
      "\u001b[32m[I 2025-03-31 14:18:58,582]\u001b[0m Trial 0 finished with value: 1.3950108805623147 and parameters: {'max_iter': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.56, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7815\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 5.8399\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 2.2888\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.3034\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8399\n",
      "Corresponding penalty value: 3.5570\n",
      "\u001b[32m[I 2025-03-31 14:19:01,329]\u001b[0m Trial 1 finished with value: 3.5570373438416683 and parameters: {'max_iter': 2003, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 8.33, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:05,  1.98s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6566\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.5424\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2178\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4722\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6566\n",
      "Corresponding penalty value: 1.4907\n",
      "\u001b[32m[I 2025-03-31 14:19:07,261]\u001b[0m Trial 2 finished with value: 1.4906706071265514 and parameters: {'max_iter': 1260, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 6.12, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:03,  1.05s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7409\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8436\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.6475\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.7440\n",
      "HistGradientBoostingRegressor worst RMSE: 1.8436\n",
      "Corresponding penalty value: 1.7540\n",
      "\u001b[32m[I 2025-03-31 14:19:10,426]\u001b[0m Trial 3 finished with value: 1.7539509043212658 and parameters: {'max_iter': 1640, 'learning_rate': 0.07801, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 5.93, 'max_features': 0.52, 'early_stopping': True}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:04,  1.61s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5990\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3545\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3147\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4227\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5990\n",
      "Corresponding penalty value: 1.4404\n",
      "\u001b[32m[I 2025-03-31 14:19:15,258]\u001b[0m Trial 4 finished with value: 1.4403663564441 and parameters: {'max_iter': 662, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 3.04, 'max_features': 0.54, 'early_stopping': True}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:01,  2.59it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7758\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 5.6150\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.7089\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.0332\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6150\n",
      "Corresponding penalty value: 3.2914\n",
      "\u001b[32m[I 2025-03-31 14:19:16,419]\u001b[0m Trial 5 finished with value: 3.2914084166881654 and parameters: {'max_iter': 805, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.59, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:13,  4.49s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7925\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7824\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4100\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.6616\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7925\n",
      "Corresponding penalty value: 1.6747\n",
      "\u001b[32m[I 2025-03-31 14:19:29,901]\u001b[0m Trial 6 finished with value: 1.6747124591242217 and parameters: {'max_iter': 1867, 'learning_rate': 0.01801, 'max_depth': 10, 'min_samples_leaf': 24, 'l2_regularization': 9.4, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:01,  2.68it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7026\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 4.8594\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0850\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 2.5490\n",
      "HistGradientBoostingRegressor worst RMSE: 4.8594\n",
      "Corresponding penalty value: 2.7800\n",
      "\u001b[32m[I 2025-03-31 14:19:31,021]\u001b[0m Trial 7 finished with value: 2.7800388032710637 and parameters: {'max_iter': 721, 'learning_rate': 0.01901, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 3.89, 'max_features': 0.63, 'early_stopping': True}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:02,  1.40it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.8274\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0377\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.5856\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.8169\n",
      "HistGradientBoostingRegressor worst RMSE: 2.0377\n",
      "Corresponding penalty value: 1.8390\n",
      "\u001b[32m[I 2025-03-31 14:19:33,160]\u001b[0m Trial 8 finished with value: 1.839012582955338 and parameters: {'max_iter': 1202, 'learning_rate': 0.05401, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.74, 'max_features': 1.0, 'early_stopping': True}. Best is trial 0 with value: 1.3950108805623147.\u001b[0m\n",
      "3it [00:03,  1.15s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6127\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2707\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1879\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3571\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6127\n",
      "Corresponding penalty value: 1.3826\n",
      "\u001b[32m[I 2025-03-31 14:19:36,616]\u001b[0m Trial 9 finished with value: 1.3826489779991844 and parameters: {'max_iter': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 7.72, 'max_features': 0.53, 'early_stopping': True}. Best is trial 9 with value: 1.3826489779991844.\u001b[0m\n",
      "3it [00:21,  7.08s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6365\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.1332\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4054\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3917\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6365\n",
      "Corresponding penalty value: 1.4162\n",
      "\u001b[32m[I 2025-03-31 14:19:57,887]\u001b[0m Trial 10 finished with value: 1.4161788586038495 and parameters: {'max_iter': 2697, 'learning_rate': 1e-05, 'max_depth': 6, 'min_samples_leaf': 2, 'l2_regularization': 7.55, 'max_features': 0.71, 'early_stopping': True}. Best is trial 9 with value: 1.3826489779991844.\u001b[0m\n",
      "3it [00:12,  4.29s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6513\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6208\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2632\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.5118\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6513\n",
      "Corresponding penalty value: 1.5257\n",
      "\u001b[32m[I 2025-03-31 14:20:10,798]\u001b[0m Trial 11 finished with value: 1.5257304787048065 and parameters: {'max_iter': 2758, 'learning_rate': 0.09801, 'max_depth': 8, 'min_samples_leaf': 20, 'l2_regularization': 0.09, 'max_features': 0.69, 'early_stopping': 'auto'}. Best is trial 9 with value: 1.3826489779991844.\u001b[0m\n",
      "3it [00:07,  2.52s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5360\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2591\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1304\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3085\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5360\n",
      "Corresponding penalty value: 1.3313\n",
      "\u001b[32m[I 2025-03-31 14:20:18,370]\u001b[0m Trial 12 finished with value: 1.3312552901219434 and parameters: {'max_iter': 1245, 'learning_rate': 0.07801, 'max_depth': 7, 'min_samples_leaf': 18, 'l2_regularization': 4.55, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.90s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6559\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3520\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2217\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4099\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6559\n",
      "Corresponding penalty value: 1.4345\n",
      "\u001b[32m[I 2025-03-31 14:20:24,087]\u001b[0m Trial 13 finished with value: 1.4344787972826742 and parameters: {'max_iter': 1045, 'learning_rate': 0.07400999999999999, 'max_depth': 6, 'min_samples_leaf': 17, 'l2_regularization': 4.9, 'max_features': 0.5, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:11,  3.96s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7653\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7087\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3489\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.6076\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7653\n",
      "Corresponding penalty value: 1.6234\n",
      "\u001b[32m[I 2025-03-31 14:20:36,003]\u001b[0m Trial 14 finished with value: 1.6234073359086612 and parameters: {'max_iter': 2128, 'learning_rate': 0.06601, 'max_depth': 8, 'min_samples_leaf': 13, 'l2_regularization': 7.2, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:01,  1.54it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7798\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.5089\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4048\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.5645\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7798\n",
      "Corresponding penalty value: 1.5861\n",
      "\u001b[32m[I 2025-03-31 14:20:37,979]\u001b[0m Trial 15 finished with value: 1.5860520414479908 and parameters: {'max_iter': 554, 'learning_rate': 0.08601, 'max_depth': 4, 'min_samples_leaf': 22, 'l2_regularization': 9.97, 'max_features': 0.66, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:06,  2.29s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5754\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4265\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1938\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3986\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5754\n",
      "Corresponding penalty value: 1.4163\n",
      "\u001b[32m[I 2025-03-31 14:20:44,887]\u001b[0m Trial 16 finished with value: 1.4162566392704976 and parameters: {'max_iter': 952, 'learning_rate': 0.03801, 'max_depth': 7, 'min_samples_leaf': 6, 'l2_regularization': 4.74, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:11,  3.93s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7644\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6801\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2867\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.5771\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7644\n",
      "Corresponding penalty value: 1.5958\n",
      "\u001b[32m[I 2025-03-31 14:20:56,694]\u001b[0m Trial 17 finished with value: 1.5957983459869958 and parameters: {'max_iter': 2283, 'learning_rate': 0.06301, 'max_depth': 9, 'min_samples_leaf': 21, 'l2_regularization': 6.2, 'max_features': 0.78, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.84s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7500\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2319\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2991\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4270\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7500\n",
      "Corresponding penalty value: 1.4593\n",
      "\u001b[32m[I 2025-03-31 14:21:02,245]\u001b[0m Trial 18 finished with value: 1.4593468121876836 and parameters: {'max_iter': 1649, 'learning_rate': 0.08301, 'max_depth': 4, 'min_samples_leaf': 15, 'l2_regularization': 8.73, 'max_features': 0.63, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7546\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6088\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3168\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.5601\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7546\n",
      "Corresponding penalty value: 1.5795\n",
      "\u001b[32m[I 2025-03-31 14:21:05,327]\u001b[0m Trial 19 finished with value: 1.5795342676142807 and parameters: {'max_iter': 514, 'learning_rate': 0.08601, 'max_depth': 7, 'min_samples_leaf': 27, 'l2_regularization': 7.22, 'max_features': 0.77, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:09,  3.07s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5998\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4427\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2128\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4184\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5998\n",
      "Corresponding penalty value: 1.4366\n",
      "\u001b[32m[I 2025-03-31 14:21:14,577]\u001b[0m Trial 20 finished with value: 1.4365564658484047 and parameters: {'max_iter': 1332, 'learning_rate': 0.06201, 'max_depth': 9, 'min_samples_leaf': 18, 'l2_regularization': 3.77, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:08,  2.96s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5661\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2681\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3000\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3781\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5661\n",
      "Corresponding penalty value: 1.3969\n",
      "\u001b[32m[I 2025-03-31 14:21:23,490]\u001b[0m Trial 21 finished with value: 1.3968551330766934 and parameters: {'max_iter': 1373, 'learning_rate': 0.09201, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.67, 'max_features': 0.56, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:07,  2.53s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6702\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4434\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2970\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4702\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6702\n",
      "Corresponding penalty value: 1.4902\n",
      "\u001b[32m[I 2025-03-31 14:21:31,095]\u001b[0m Trial 22 finished with value: 1.4901908017919694 and parameters: {'max_iter': 1500, 'learning_rate': 0.09801, 'max_depth': 7, 'min_samples_leaf': 23, 'l2_regularization': 1.92, 'max_features': 0.61, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:08,  2.69s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6848\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4076\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2010\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4311\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6848\n",
      "Corresponding penalty value: 1.4565\n",
      "\u001b[32m[I 2025-03-31 14:21:39,196]\u001b[0m Trial 23 finished with value: 1.4565165235383088 and parameters: {'max_iter': 1127, 'learning_rate': 0.07901, 'max_depth': 9, 'min_samples_leaf': 14, 'l2_regularization': 3.98, 'max_features': 0.55, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.85s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5455\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4440\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.0455\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3450\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5455\n",
      "Corresponding penalty value: 1.3650\n",
      "\u001b[32m[I 2025-03-31 14:21:44,785]\u001b[0m Trial 24 finished with value: 1.3650381946829442 and parameters: {'max_iter': 920, 'learning_rate': 0.08601, 'max_depth': 7, 'min_samples_leaf': 20, 'l2_regularization': 5.5, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:03,  1.31s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6054\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4868\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1220\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4047\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6054\n",
      "Corresponding penalty value: 1.4248\n",
      "\u001b[32m[I 2025-03-31 14:21:48,733]\u001b[0m Trial 25 finished with value: 1.4248132151997517 and parameters: {'max_iter': 881, 'learning_rate': 0.03801, 'max_depth': 5, 'min_samples_leaf': 21, 'l2_regularization': 6.44, 'max_features': 0.53, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.71s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7538\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.5027\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1491\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4685\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7538\n",
      "Corresponding penalty value: 1.4971\n",
      "\u001b[32m[I 2025-03-31 14:21:53,888]\u001b[0m Trial 26 finished with value: 1.4970600866776047 and parameters: {'max_iter': 932, 'learning_rate': 0.07201, 'max_depth': 6, 'min_samples_leaf': 12, 'l2_regularization': 5.36, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:03,  1.25s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5769\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3764\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1776\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3770\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5769\n",
      "Corresponding penalty value: 1.3970\n",
      "\u001b[32m[I 2025-03-31 14:21:57,657]\u001b[0m Trial 27 finished with value: 1.3969772848977944 and parameters: {'max_iter': 657, 'learning_rate': 0.08301, 'max_depth': 7, 'min_samples_leaf': 27, 'l2_regularization': 8.05, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:03,  1.22s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7206\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4283\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2665\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4718\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7206\n",
      "Corresponding penalty value: 1.4967\n",
      "\u001b[32m[I 2025-03-31 14:22:01,353]\u001b[0m Trial 28 finished with value: 1.4966596250335913 and parameters: {'max_iter': 1035, 'learning_rate': 0.058010000000000006, 'max_depth': 4, 'min_samples_leaf': 17, 'l2_regularization': 4.3500000000000005, 'max_features': 0.59, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:08,  2.83s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7073\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.5336\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3637\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.5349\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7073\n",
      "Corresponding penalty value: 1.5521\n",
      "\u001b[32m[I 2025-03-31 14:22:09,885]\u001b[0m Trial 29 finished with value: 1.5521081214990633 and parameters: {'max_iter': 1479, 'learning_rate': 0.09000999999999999, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 5.47, 'max_features': 0.9, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:06,  2.06s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7594\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8037\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3026\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.6219\n",
      "HistGradientBoostingRegressor worst RMSE: 1.8037\n",
      "Corresponding penalty value: 1.6401\n",
      "\u001b[32m[I 2025-03-31 14:22:16,105]\u001b[0m Trial 30 finished with value: 1.6400794792897353 and parameters: {'max_iter': 803, 'learning_rate': 0.042010000000000006, 'max_depth': 9, 'min_samples_leaf': 9, 'l2_regularization': 3.0300000000000002, 'max_features': 0.72, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:10,  3.52s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6140\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2883\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2529\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3851\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6140\n",
      "Corresponding penalty value: 1.4080\n",
      "\u001b[32m[I 2025-03-31 14:22:26,700]\u001b[0m Trial 31 finished with value: 1.407968627785162 and parameters: {'max_iter': 1848, 'learning_rate': 0.07101, 'max_depth': 7, 'min_samples_leaf': 23, 'l2_regularization': 8.68, 'max_features': 0.59, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:08,  2.79s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5740\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4409\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1698\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3949\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5740\n",
      "Corresponding penalty value: 1.4128\n",
      "\u001b[32m[I 2025-03-31 14:22:35,101]\u001b[0m Trial 32 finished with value: 1.4128189977808168 and parameters: {'max_iter': 1279, 'learning_rate': 0.07801, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 6.9, 'max_features': 0.53, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.86s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6615\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3936\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2682\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4411\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6615\n",
      "Corresponding penalty value: 1.4631\n",
      "\u001b[32m[I 2025-03-31 14:22:40,714]\u001b[0m Trial 33 finished with value: 1.463141539595 and parameters: {'max_iter': 1500, 'learning_rate': 0.08800999999999999, 'max_depth': 5, 'min_samples_leaf': 29, 'l2_regularization': 1.53, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.87s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6725\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4816\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2214\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4585\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6725\n",
      "Corresponding penalty value: 1.4799\n",
      "\u001b[32m[I 2025-03-31 14:22:46,343]\u001b[0m Trial 34 finished with value: 1.479879257935236 and parameters: {'max_iter': 1043, 'learning_rate': 0.09401, 'max_depth': 6, 'min_samples_leaf': 15, 'l2_regularization': 5.66, 'max_features': 0.63, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:07,  2.65s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5754\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4715\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2510\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4326\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5754\n",
      "Corresponding penalty value: 1.4469\n",
      "\u001b[32m[I 2025-03-31 14:22:54,327]\u001b[0m Trial 35 finished with value: 1.4468962800353447 and parameters: {'max_iter': 1148, 'learning_rate': 0.07801, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 2.47, 'max_features': 0.53, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:04,  1.46s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5636\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2822\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1380\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3279\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5636\n",
      "Corresponding penalty value: 1.3515\n",
      "\u001b[32m[I 2025-03-31 14:22:58,749]\u001b[0m Trial 36 finished with value: 1.3515131255635984 and parameters: {'max_iter': 669, 'learning_rate': 0.09901, 'max_depth': 8, 'min_samples_leaf': 21, 'l2_regularization': 8.06, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:03,  1.25s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5668\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4547\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1933\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4049\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5668\n",
      "Corresponding penalty value: 1.4211\n",
      "\u001b[32m[I 2025-03-31 14:23:02,523]\u001b[0m Trial 37 finished with value: 1.4211266751263798 and parameters: {'max_iter': 611, 'learning_rate': 0.09801, 'max_depth': 7, 'min_samples_leaf': 21, 'l2_regularization': 8.15, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.72s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7155\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.5497\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1803\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4818\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7155\n",
      "Corresponding penalty value: 1.5052\n",
      "\u001b[32m[I 2025-03-31 14:23:07,721]\u001b[0m Trial 38 finished with value: 1.5051921361913567 and parameters: {'max_iter': 767, 'learning_rate': 0.09101, 'max_depth': 8, 'min_samples_leaf': 17, 'l2_regularization': 6.55, 'max_features': 0.55, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:04,  1.54s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6400\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3957\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2923\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4426\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6400\n",
      "Corresponding penalty value: 1.4624\n",
      "\u001b[32m[I 2025-03-31 14:23:12,359]\u001b[0m Trial 39 finished with value: 1.4623795201328746 and parameters: {'max_iter': 678, 'learning_rate': 0.06801, 'max_depth': 9, 'min_samples_leaf': 26, 'l2_regularization': 7.61, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:02,  1.08it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.7095\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7042\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1510\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.5216\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7095\n",
      "Corresponding penalty value: 1.5404\n",
      "\u001b[32m[I 2025-03-31 14:23:15,173]\u001b[0m Trial 40 finished with value: 1.5403607222598585 and parameters: {'max_iter': 529, 'learning_rate': 0.08101, 'max_depth': 6, 'min_samples_leaf': 30, 'l2_regularization': 9.28, 'max_features': 0.53, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:15,  5.23s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5650\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2396\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1584\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3210\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5650\n",
      "Corresponding penalty value: 1.3454\n",
      "\u001b[32m[I 2025-03-31 14:23:30,901]\u001b[0m Trial 41 finished with value: 1.3453744034652808 and parameters: {'max_iter': 2984, 'learning_rate': 0.09301, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 8.99, 'max_features': 0.52, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:12,  4.02s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5867\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.2926\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2218\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3670\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5867\n",
      "Corresponding penalty value: 1.3890\n",
      "\u001b[32m[I 2025-03-31 14:23:42,999]\u001b[0m Trial 42 finished with value: 1.3889982534326053 and parameters: {'max_iter': 2554, 'learning_rate': 0.09901, 'max_depth': 7, 'min_samples_leaf': 23, 'l2_regularization': 9.28, 'max_features': 0.52, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:05,  1.80s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5837\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3112\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3699\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4216\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5837\n",
      "Corresponding penalty value: 1.4378\n",
      "\u001b[32m[I 2025-03-31 14:23:48,434]\u001b[0m Trial 43 finished with value: 1.437809965131667 and parameters: {'max_iter': 856, 'learning_rate': 0.07501, 'max_depth': 8, 'min_samples_leaf': 24, 'l2_regularization': 8.700000000000001, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:15,  5.28s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5797\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3348\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1833\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3659\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5797\n",
      "Corresponding penalty value: 1.3873\n",
      "\u001b[32m[I 2025-03-31 14:24:04,303]\u001b[0m Trial 44 finished with value: 1.387314076617604 and parameters: {'max_iter': 2858, 'learning_rate': 0.09301, 'max_depth': 9, 'min_samples_leaf': 20, 'l2_regularization': 9.99, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:15,  5.27s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5528\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4481\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2113\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4041\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5528\n",
      "Corresponding penalty value: 1.4190\n",
      "\u001b[32m[I 2025-03-31 14:24:20,143]\u001b[0m Trial 45 finished with value: 1.4189623024031168 and parameters: {'max_iter': 2990, 'learning_rate': 0.08501, 'max_depth': 10, 'min_samples_leaf': 22, 'l2_regularization': 7.86, 'max_features': 0.52, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:11,  3.74s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6607\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3288\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1695\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.3864\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6607\n",
      "Corresponding penalty value: 1.4138\n",
      "\u001b[32m[I 2025-03-31 14:24:31,410]\u001b[0m Trial 46 finished with value: 1.4137849130874944 and parameters: {'max_iter': 2402, 'learning_rate': 0.08900999999999999, 'max_depth': 8, 'min_samples_leaf': 24, 'l2_regularization': 6.98, 'max_features': 0.55, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:09,  3.24s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6285\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4257\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2930\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4491\n",
      "HistGradientBoostingRegressor worst RMSE: 1.6285\n",
      "Corresponding penalty value: 1.4670\n",
      "\u001b[32m[I 2025-03-31 14:24:41,166]\u001b[0m Trial 47 finished with value: 1.4670097367787736 and parameters: {'max_iter': 1958, 'learning_rate': 0.09401, 'max_depth': 7, 'min_samples_leaf': 20, 'l2_regularization': 8.42, 'max_features': 0.58, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:06,  2.14s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.6506\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8003\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2271\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.5593\n",
      "HistGradientBoostingRegressor worst RMSE: 1.8003\n",
      "Corresponding penalty value: 1.5834\n",
      "\u001b[32m[I 2025-03-31 14:24:47,625]\u001b[0m Trial 48 finished with value: 1.583432630097191 and parameters: {'max_iter': 751, 'learning_rate': 0.00801, 'max_depth': 8, 'min_samples_leaf': 18, 'l2_regularization': 5.93, 'max_features': 0.63, 'early_stopping': 'auto'}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "3it [00:07,  2.39s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.8030\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4064\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.2732\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.4942\n",
      "HistGradientBoostingRegressor worst RMSE: 1.8030\n",
      "Corresponding penalty value: 1.5251\n",
      "\u001b[32m[I 2025-03-31 14:24:54,842]\u001b[0m Trial 49 finished with value: 1.5250860845784378 and parameters: {'max_iter': 1637, 'learning_rate': 0.07400999999999999, 'max_depth': 6, 'min_samples_leaf': 22, 'l2_regularization': 5.1000000000000005, 'max_features': 0.87, 'early_stopping': True}. Best is trial 12 with value: 1.3312552901219434.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1245, 'learning_rate': 0.07801, 'max_depth': 7, 'min_samples_leaf': 18, 'l2_regularization': 4.55, 'max_features': 0.5, 'early_stopping': 'auto'}\n",
      "3it [00:06,  2.17s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.5632\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.0967\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1456\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.2685\n",
      "HistGradientBoostingRegressor worst RMSE: 1.5632\n",
      "Corresponding penalty value: 1.2980\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB10\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1245, 'learning_rate': 0.07801, 'max_depth': 7, 'min_samples_leaf': 18, 'l2_regularization': 4.55, 'max_features': 0.5, 'early_stopping': 'auto'}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.143\n",
      "RMSE_crossval: 1.268\n",
      "RMSE_test: 1.458\n",
      "MAE_test: 1.109\n",
      "Nash-Sutcliffe Test: -0.267\n",
      "Kling-Gupta Test: 0.138\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 373.0986 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-31 14:25:03,259]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB18\u001b[0m\n",
      "3it [00:04,  1.59s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.1177\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6988\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8114\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5426\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8114\n",
      "Corresponding penalty value: 3.7695\n",
      "\u001b[32m[I 2025-03-31 14:25:08,040]\u001b[0m Trial 0 finished with value: 3.7695143165670393 and parameters: {'max_iter': 1436, 'learning_rate': 0.09501, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 1.56, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.7695143165670393.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5260\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.5750\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6128\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.9046\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6128\n",
      "Corresponding penalty value: 4.0754\n",
      "\u001b[32m[I 2025-03-31 14:25:10,754]\u001b[0m Trial 1 finished with value: 4.075444138022509 and parameters: {'max_iter': 2003, 'learning_rate': 0.07001, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 8.33, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.7695143165670393.\u001b[0m\n",
      "3it [00:04,  1.56s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.2959\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9357\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6727\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6348\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6727\n",
      "Corresponding penalty value: 3.8386\n",
      "\u001b[32m[I 2025-03-31 14:25:15,450]\u001b[0m Trial 2 finished with value: 3.8385507466369813 and parameters: {'max_iter': 1260, 'learning_rate': 0.05201000000000001, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 6.12, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 0 with value: 3.7695143165670393.\u001b[0m\n",
      "3it [00:02,  1.24it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.3064\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8646\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.3137\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8282\n",
      "HistGradientBoostingRegressor worst RMSE: 5.3137\n",
      "Corresponding penalty value: 3.9768\n",
      "\u001b[32m[I 2025-03-31 14:25:17,883]\u001b[0m Trial 3 finished with value: 3.976762557039229 and parameters: {'max_iter': 1640, 'learning_rate': 0.07801, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 5.93, 'max_features': 0.52, 'early_stopping': True}. Best is trial 0 with value: 3.7695143165670393.\u001b[0m\n",
      "3it [00:03,  1.13s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.0463\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6989\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7467\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4973\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7467\n",
      "Corresponding penalty value: 3.7222\n",
      "\u001b[32m[I 2025-03-31 14:25:21,279]\u001b[0m Trial 4 finished with value: 3.7222466688912834 and parameters: {'max_iter': 662, 'learning_rate': 0.09401, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 3.04, 'max_features': 0.54, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:01,  2.55it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.1909\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.5541\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.5267\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 4.0906\n",
      "HistGradientBoostingRegressor worst RMSE: 5.5267\n",
      "Corresponding penalty value: 4.2342\n",
      "\u001b[32m[I 2025-03-31 14:25:22,459]\u001b[0m Trial 5 finished with value: 4.234183260925241 and parameters: {'max_iter': 805, 'learning_rate': 0.049010000000000005, 'max_depth': 1, 'min_samples_leaf': 28, 'l2_regularization': 2.59, 'max_features': 0.8300000000000001, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:12,  4.08s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.9761\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7986\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9840\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.9196\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9840\n",
      "Corresponding penalty value: 4.1260\n",
      "\u001b[32m[I 2025-03-31 14:25:34,700]\u001b[0m Trial 6 finished with value: 4.1260107166149975 and parameters: {'max_iter': 1867, 'learning_rate': 0.01801, 'max_depth': 10, 'min_samples_leaf': 24, 'l2_regularization': 9.4, 'max_features': 0.95, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:01,  2.69it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.9432\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3440\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.5267\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.9380\n",
      "HistGradientBoostingRegressor worst RMSE: 5.5267\n",
      "Corresponding penalty value: 4.0968\n",
      "\u001b[32m[I 2025-03-31 14:25:35,816]\u001b[0m Trial 7 finished with value: 4.096834156730366 and parameters: {'max_iter': 721, 'learning_rate': 0.01901, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 3.89, 'max_features': 0.63, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:01,  1.51it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.6882\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0074\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.2790\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.9915\n",
      "HistGradientBoostingRegressor worst RMSE: 5.2790\n",
      "Corresponding penalty value: 4.1203\n",
      "\u001b[32m[I 2025-03-31 14:25:37,809]\u001b[0m Trial 8 finished with value: 4.120278565289503 and parameters: {'max_iter': 1202, 'learning_rate': 0.05401, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.74, 'max_features': 1.0, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.06s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.7912\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7313\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7337\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7521\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7337\n",
      "Corresponding penalty value: 3.9502\n",
      "\u001b[32m[I 2025-03-31 14:25:40,989]\u001b[0m Trial 9 finished with value: 3.950247221381101 and parameters: {'max_iter': 513, 'learning_rate': 0.08101, 'max_depth': 8, 'min_samples_leaf': 23, 'l2_regularization': 7.72, 'max_features': 0.53, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:26,  8.73s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.9114\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 3.6215\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9470\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 5.1600\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9470\n",
      "Corresponding penalty value: 5.2387\n",
      "\u001b[32m[I 2025-03-31 14:26:07,221]\u001b[0m Trial 10 finished with value: 5.238651306690638 and parameters: {'max_iter': 2863, 'learning_rate': 1e-05, 'max_depth': 10, 'min_samples_leaf': 2, 'l2_regularization': 3.97, 'max_features': 0.71, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.23s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.7645\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6173\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9216\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7678\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9216\n",
      "Corresponding penalty value: 3.9832\n",
      "\u001b[32m[I 2025-03-31 14:26:10,926]\u001b[0m Trial 11 finished with value: 3.983175903003272 and parameters: {'max_iter': 1313, 'learning_rate': 0.09801, 'max_depth': 7, 'min_samples_leaf': 20, 'l2_regularization': 0.08, 'max_features': 0.69, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.92s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.6557\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8452\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8170\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7726\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8170\n",
      "Corresponding penalty value: 3.9771\n",
      "\u001b[32m[I 2025-03-31 14:26:16,723]\u001b[0m Trial 12 finished with value: 3.9770712497406278 and parameters: {'max_iter': 2505, 'learning_rate': 0.09601, 'max_depth': 7, 'min_samples_leaf': 18, 'l2_regularization': 2.0300000000000002, 'max_features': 0.8200000000000001, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:02,  1.07it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.3708\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8926\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8500\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7045\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8500\n",
      "Corresponding penalty value: 3.9190\n",
      "\u001b[32m[I 2025-03-31 14:26:19,564]\u001b[0m Trial 13 finished with value: 3.919027663646636 and parameters: {'max_iter': 1057, 'learning_rate': 0.08701, 'max_depth': 9, 'min_samples_leaf': 15, 'l2_regularization': 1.92, 'max_features': 0.5, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5402\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6873\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6073\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6116\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6073\n",
      "Corresponding penalty value: 3.8112\n",
      "\u001b[32m[I 2025-03-31 14:26:22,662]\u001b[0m Trial 14 finished with value: 3.8111792272945637 and parameters: {'max_iter': 2287, 'learning_rate': 0.06601, 'max_depth': 5, 'min_samples_leaf': 21, 'l2_regularization': 3.73, 'max_features': 0.64, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.38s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.8525\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7345\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8938\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8269\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8938\n",
      "Corresponding penalty value: 4.0336\n",
      "\u001b[32m[I 2025-03-31 14:26:26,835]\u001b[0m Trial 15 finished with value: 4.0336135386057395 and parameters: {'max_iter': 1541, 'learning_rate': 0.09901, 'max_depth': 8, 'min_samples_leaf': 27, 'l2_regularization': 1.3, 'max_features': 0.76, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.57s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.9740\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8889\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6774\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5134\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6774\n",
      "Corresponding penalty value: 3.7298\n",
      "\u001b[32m[I 2025-03-31 14:26:31,560]\u001b[0m Trial 16 finished with value: 3.729813575969343 and parameters: {'max_iter': 930, 'learning_rate': 0.03801, 'max_depth': 6, 'min_samples_leaf': 12, 'l2_regularization': 2.91, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.14s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.7154\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6948\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6548\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6883\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6548\n",
      "Corresponding penalty value: 3.8850\n",
      "\u001b[32m[I 2025-03-31 14:26:35,012]\u001b[0m Trial 17 finished with value: 3.88499026803798 and parameters: {'max_iter': 915, 'learning_rate': 0.033010000000000005, 'max_depth': 4, 'min_samples_leaf': 6, 'l2_regularization': 5.36, 'max_features': 0.66, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:01,  1.61it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.8499\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6943\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6733\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7392\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6733\n",
      "Corresponding penalty value: 3.9326\n",
      "\u001b[32m[I 2025-03-31 14:26:36,900]\u001b[0m Trial 18 finished with value: 3.932572561932194 and parameters: {'max_iter': 502, 'learning_rate': 0.03701, 'max_depth': 4, 'min_samples_leaf': 12, 'l2_regularization': 3.1, 'max_features': 0.76, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:06,  2.06s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.6394\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7703\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6247\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6781\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6247\n",
      "Corresponding penalty value: 3.8728\n",
      "\u001b[32m[I 2025-03-31 14:26:43,094]\u001b[0m Trial 19 finished with value: 3.872777615685546 and parameters: {'max_iter': 1033, 'learning_rate': 0.02901, 'max_depth': 6, 'min_samples_leaf': 7, 'l2_regularization': 4.53, 'max_features': 0.5700000000000001, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.60s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5950\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.9872\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9352\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8391\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9352\n",
      "Corresponding penalty value: 4.0487\n",
      "\u001b[32m[I 2025-03-31 14:26:47,926]\u001b[0m Trial 20 finished with value: 4.048743264208002 and parameters: {'max_iter': 679, 'learning_rate': 0.06401, 'max_depth': 9, 'min_samples_leaf': 14, 'l2_regularization': 7.16, 'max_features': 0.87, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.60s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.2259\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7144\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8319\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5907\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8319\n",
      "Corresponding penalty value: 3.8149\n",
      "\u001b[32m[I 2025-03-31 14:26:52,761]\u001b[0m Trial 21 finished with value: 3.814857114328571 and parameters: {'max_iter': 1440, 'learning_rate': 0.08900999999999999, 'max_depth': 8, 'min_samples_leaf': 18, 'l2_regularization': 2.73, 'max_features': 0.56, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.97s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.4416\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7118\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7438\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6324\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7438\n",
      "Corresponding penalty value: 3.8435\n",
      "\u001b[32m[I 2025-03-31 14:26:58,699]\u001b[0m Trial 22 finished with value: 3.843537706658949 and parameters: {'max_iter': 1045, 'learning_rate': 0.04401, 'max_depth': 9, 'min_samples_leaf': 20, 'l2_regularization': 1.3800000000000001, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.89s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.9026\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6424\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7566\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7672\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7566\n",
      "Corresponding penalty value: 3.9661\n",
      "\u001b[32m[I 2025-03-31 14:27:04,386]\u001b[0m Trial 23 finished with value: 3.9661327027886504 and parameters: {'max_iter': 1795, 'learning_rate': 0.07901, 'max_depth': 7, 'min_samples_leaf': 18, 'l2_regularization': 3.19, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.20s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.9223\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7534\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8310\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8356\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8310\n",
      "Corresponding penalty value: 4.0351\n",
      "\u001b[32m[I 2025-03-31 14:27:08,027]\u001b[0m Trial 24 finished with value: 4.035115882598121 and parameters: {'max_iter': 845, 'learning_rate': 0.06001, 'max_depth': 6, 'min_samples_leaf': 22, 'l2_regularization': 0.25, 'max_features': 0.71, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.79s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5274\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8019\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8751\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7348\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8751\n",
      "Corresponding penalty value: 3.9489\n",
      "\u001b[32m[I 2025-03-31 14:27:13,441]\u001b[0m Trial 25 finished with value: 3.948854391995283 and parameters: {'max_iter': 1425, 'learning_rate': 0.07300999999999999, 'max_depth': 10, 'min_samples_leaf': 13, 'l2_regularization': 2.0, 'max_features': 0.6, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:07,  2.63s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5439\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7926\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6798\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6721\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6798\n",
      "Corresponding penalty value: 3.8729\n",
      "\u001b[32m[I 2025-03-31 14:27:21,373]\u001b[0m Trial 26 finished with value: 3.872858664941935 and parameters: {'max_iter': 1128, 'learning_rate': 0.02401, 'max_depth': 9, 'min_samples_leaf': 9, 'l2_regularization': 4.99, 'max_features': 0.55, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.87s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.2591\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7462\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8982\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6345\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8982\n",
      "Corresponding penalty value: 3.8609\n",
      "\u001b[32m[I 2025-03-31 14:27:27,027]\u001b[0m Trial 27 finished with value: 3.8608682146336535 and parameters: {'max_iter': 2066, 'learning_rate': 0.08900999999999999, 'max_depth': 8, 'min_samples_leaf': 27, 'l2_regularization': 1.11, 'max_features': 0.67, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.71s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5199\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7551\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8040\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6930\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8040\n",
      "Corresponding penalty value: 3.9041\n",
      "\u001b[32m[I 2025-03-31 14:27:32,199]\u001b[0m Trial 28 finished with value: 3.904121297884105 and parameters: {'max_iter': 694, 'learning_rate': 0.00801, 'max_depth': 6, 'min_samples_leaf': 25, 'l2_regularization': 2.32, 'max_features': 0.61, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.78s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.1962\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6905\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7759\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5542\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7759\n",
      "Corresponding penalty value: 3.7764\n",
      "\u001b[32m[I 2025-03-31 14:27:37,558]\u001b[0m Trial 29 finished with value: 3.7763758658042654 and parameters: {'max_iter': 916, 'learning_rate': 0.041010000000000005, 'max_depth': 7, 'min_samples_leaf': 30, 'l2_regularization': 3.36, 'max_features': 0.54, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.36s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5194\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6980\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.5862\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6012\n",
      "HistGradientBoostingRegressor worst RMSE: 5.5862\n",
      "Corresponding penalty value: 3.7997\n",
      "\u001b[32m[I 2025-03-31 14:27:41,676]\u001b[0m Trial 30 finished with value: 3.799664247549193 and parameters: {'max_iter': 1969, 'learning_rate': 0.07300999999999999, 'max_depth': 4, 'min_samples_leaf': 17, 'l2_regularization': 4.51, 'max_features': 0.59, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.78s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.3856\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7061\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8236\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6384\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8236\n",
      "Corresponding penalty value: 3.8569\n",
      "\u001b[32m[I 2025-03-31 14:27:47,047]\u001b[0m Trial 31 finished with value: 3.8569434118236643 and parameters: {'max_iter': 922, 'learning_rate': 0.041010000000000005, 'max_depth': 7, 'min_samples_leaf': 30, 'l2_regularization': 3.43, 'max_features': 0.54, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.62s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.4981\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7545\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6905\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6477\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6905\n",
      "Corresponding penalty value: 3.8520\n",
      "\u001b[32m[I 2025-03-31 14:27:51,942]\u001b[0m Trial 32 finished with value: 3.852009058005685 and parameters: {'max_iter': 1279, 'learning_rate': 0.048010000000000004, 'max_depth': 5, 'min_samples_leaf': 29, 'l2_regularization': 2.65, 'max_features': 0.5700000000000001, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.34s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.6508\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6827\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8352\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7229\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8352\n",
      "Corresponding penalty value: 3.9342\n",
      "\u001b[32m[I 2025-03-31 14:27:55,996]\u001b[0m Trial 33 finished with value: 3.934150644118566 and parameters: {'max_iter': 635, 'learning_rate': 0.035010000000000006, 'max_depth': 7, 'min_samples_leaf': 25, 'l2_regularization': 1.7, 'max_features': 0.52, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.73s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.7817\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6753\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8202\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7591\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8202\n",
      "Corresponding penalty value: 3.9652\n",
      "\u001b[32m[I 2025-03-31 14:28:01,234]\u001b[0m Trial 34 finished with value: 3.965206120999855 and parameters: {'max_iter': 1655, 'learning_rate': 0.05501, 'max_depth': 6, 'min_samples_leaf': 27, 'l2_regularization': 4.32, 'max_features': 0.63, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.77s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.3005\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7797\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7206\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6002\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7206\n",
      "Corresponding penalty value: 3.8123\n",
      "\u001b[32m[I 2025-03-31 14:28:06,580]\u001b[0m Trial 35 finished with value: 3.812275828848536 and parameters: {'max_iter': 919, 'learning_rate': 0.041010000000000005, 'max_depth': 8, 'min_samples_leaf': 30, 'l2_regularization': 6.0, 'max_features': 0.5, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:08,  2.95s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.3113\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7637\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8441\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6397\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8441\n",
      "Corresponding penalty value: 3.8601\n",
      "\u001b[32m[I 2025-03-31 14:28:15,466]\u001b[0m Trial 36 finished with value: 3.8601437541208172 and parameters: {'max_iter': 1362, 'learning_rate': 0.026010000000000002, 'max_depth': 10, 'min_samples_leaf': 28, 'l2_regularization': 2.91, 'max_features': 0.54, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.02s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.7438\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8693\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7253\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7795\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7253\n",
      "Corresponding penalty value: 3.9741\n",
      "\u001b[32m[I 2025-03-31 14:28:18,566]\u001b[0m Trial 37 finished with value: 3.974092360200728 and parameters: {'max_iter': 1168, 'learning_rate': 0.08401, 'max_depth': 5, 'min_samples_leaf': 9, 'l2_regularization': 5.3100000000000005, 'max_features': 0.58, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:05,  1.81s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.3903\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7403\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9350\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6885\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9350\n",
      "Corresponding penalty value: 3.9132\n",
      "\u001b[32m[I 2025-03-31 14:28:24,028]\u001b[0m Trial 38 finished with value: 3.9131796023492016 and parameters: {'max_iter': 786, 'learning_rate': 0.049010000000000005, 'max_depth': 9, 'min_samples_leaf': 23, 'l2_regularization': 0.6, 'max_features': 0.62, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:02,  1.22it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.8205\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7300\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.5291\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6932\n",
      "HistGradientBoostingRegressor worst RMSE: 5.5291\n",
      "Corresponding penalty value: 3.8768\n",
      "\u001b[32m[I 2025-03-31 14:28:26,512]\u001b[0m Trial 39 finished with value: 3.8767862915510922 and parameters: {'max_iter': 1561, 'learning_rate': 0.09301, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 3.61, 'max_features': 0.65, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:04,  1.57s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.4804\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7708\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8127\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6880\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8127\n",
      "Corresponding penalty value: 3.9005\n",
      "\u001b[32m[I 2025-03-31 14:28:31,259]\u001b[0m Trial 40 finished with value: 3.9004576604963836 and parameters: {'max_iter': 573, 'learning_rate': 0.015009999999999999, 'max_depth': 10, 'min_samples_leaf': 26, 'l2_regularization': 9.03, 'max_features': 0.53, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.17s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.4766\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6731\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6800\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6099\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6800\n",
      "Corresponding penalty value: 3.8169\n",
      "\u001b[32m[I 2025-03-31 14:28:34,816]\u001b[0m Trial 41 finished with value: 3.816913973257194 and parameters: {'max_iter': 1960, 'learning_rate': 0.07501, 'max_depth': 4, 'min_samples_leaf': 19, 'l2_regularization': 4.5, 'max_features': 0.58, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.15s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.0645\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8998\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.1236\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6960\n",
      "HistGradientBoostingRegressor worst RMSE: 5.1236\n",
      "Corresponding penalty value: 3.8387\n",
      "\u001b[32m[I 2025-03-31 14:28:38,313]\u001b[0m Trial 42 finished with value: 3.8387294302868886 and parameters: {'max_iter': 2162, 'learning_rate': 0.058010000000000006, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 6.62, 'max_features': 0.59, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.04s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.6622\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6248\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.4632\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5834\n",
      "HistGradientBoostingRegressor worst RMSE: 5.4632\n",
      "Corresponding penalty value: 3.7714\n",
      "\u001b[32m[I 2025-03-31 14:28:41,459]\u001b[0m Trial 43 finished with value: 3.771374871194941 and parameters: {'max_iter': 2380, 'learning_rate': 0.09301, 'max_depth': 3, 'min_samples_leaf': 15, 'l2_regularization': 4.16, 'max_features': 0.55, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.27s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.3508\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.5743\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6659\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8637\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6659\n",
      "Corresponding penalty value: 4.0439\n",
      "\u001b[32m[I 2025-03-31 14:28:45,308]\u001b[0m Trial 44 finished with value: 4.0439017281333465 and parameters: {'max_iter': 2822, 'learning_rate': 0.09301, 'max_depth': 1, 'min_samples_leaf': 11, 'l2_regularization': 2.5100000000000002, 'max_features': 0.55, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:06,  2.00s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.2927\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8573\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7160\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6220\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7160\n",
      "Corresponding penalty value: 3.8314\n",
      "\u001b[32m[I 2025-03-31 14:28:51,356]\u001b[0m Trial 45 finished with value: 3.831421129744841 and parameters: {'max_iter': 2554, 'learning_rate': 0.09301, 'max_depth': 7, 'min_samples_leaf': 14, 'l2_regularization': 4.05, 'max_features': 0.51, 'early_stopping': 'auto'}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.0264\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.6931\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7573\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8256\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7573\n",
      "Corresponding penalty value: 4.0188\n",
      "\u001b[32m[I 2025-03-31 14:28:54,086]\u001b[0m Trial 46 finished with value: 4.018771684507469 and parameters: {'max_iter': 2977, 'learning_rate': 0.08401, 'max_depth': 3, 'min_samples_leaf': 23, 'l2_regularization': 3.2600000000000002, 'max_features': 0.87, 'early_stopping': True}. Best is trial 4 with value: 3.7222466688912834.\u001b[0m\n",
      "3it [00:03,  1.01s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.0728\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7496\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6696\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4973\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6696\n",
      "Corresponding penalty value: 3.7145\n",
      "\u001b[32m[I 2025-03-31 14:28:57,160]\u001b[0m Trial 47 finished with value: 3.7145325197357093 and parameters: {'max_iter': 766, 'learning_rate': 0.09901, 'max_depth': 6, 'min_samples_leaf': 15, 'l2_regularization': 2.3000000000000003, 'max_features': 0.52, 'early_stopping': 'auto'}. Best is trial 47 with value: 3.7145325197357093.\u001b[0m\n",
      "3it [00:02,  1.25it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.7254\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7767\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7426\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7482\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7426\n",
      "Corresponding penalty value: 3.9477\n",
      "\u001b[32m[I 2025-03-31 14:28:59,589]\u001b[0m Trial 48 finished with value: 3.9476697349067407 and parameters: {'max_iter': 2543, 'learning_rate': 0.09801, 'max_depth': 6, 'min_samples_leaf': 12, 'l2_regularization': 1.69, 'max_features': 0.6799999999999999, 'early_stopping': True}. Best is trial 47 with value: 3.7145325197357093.\u001b[0m\n",
      "3it [00:05,  1.72s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.5694\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0004\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7835\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7844\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7835\n",
      "Corresponding penalty value: 3.9844\n",
      "\u001b[32m[I 2025-03-31 14:29:04,773]\u001b[0m Trial 49 finished with value: 3.98435053049722 and parameters: {'max_iter': 2399, 'learning_rate': 0.08301, 'max_depth': 5, 'min_samples_leaf': 16, 'l2_regularization': 0.89, 'max_features': 0.73, 'early_stopping': 'auto'}. Best is trial 47 with value: 3.7145325197357093.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 766, 'learning_rate': 0.09901, 'max_depth': 6, 'min_samples_leaf': 15, 'l2_regularization': 2.3000000000000003, 'max_features': 0.52, 'early_stopping': 'auto'}\n",
      "3it [00:03,  1.20s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.1351\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8135\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.6164\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5217\n",
      "HistGradientBoostingRegressor worst RMSE: 5.6164\n",
      "Corresponding penalty value: 3.7311\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB18\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 766, 'learning_rate': 0.09901, 'max_depth': 6, 'min_samples_leaf': 15, 'l2_regularization': 2.3000000000000003, 'max_features': 0.52, 'early_stopping': 'auto'}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.570\n",
      "RMSE_crossval: 3.522\n",
      "RMSE_test: 4.874\n",
      "MAE_test: 4.244\n",
      "Nash-Sutcliffe Test: -0.476\n",
      "Kling-Gupta Test: 0.004\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.1\n",
      "Trial time: 247.0023 seconds\n",
      "\n",
      "Total elapsed time: 1883.3361 seconds\n",
      "\n",
      "Output saved to GBRT_tuning_31_3_pen_01.txt\n"
     ]
    }
   ],
   "source": [
    "!python ./models/GBRT_tuning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc86dc5-cf9a-43e3-add4-2197358097b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
