{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb60609e-9b1f-4738-aacf-42bcdf8f28ea",
   "metadata": {},
   "source": [
    "## Notebook execution in Jupyter for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b04d890-fbb2-47ef-82a5-272960b9bd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/Master-thesis-GBRT-dam'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2cdcc61-9e01-4102-9e94-fc1e2c57aa42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-03-27 08:20:50,872]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV1\u001b[0m\n",
      "3it [00:00,  3.33it/s]\n",
      "1th fold: LGBMRegressor RMSE: 61.9984\n",
      "2th fold: LGBMRegressor RMSE: 31.0557\n",
      "3th fold: LGBMRegressor RMSE: 3.2389\n",
      "\n",
      "LGBMRegressor average RMSE: 32.0977\n",
      "LGBMRegressor worst RMSE: 61.9984\n",
      "Corresponding penalty value: 44.0580\n",
      "\u001b[32m[I 2025-03-27 08:20:51,777]\u001b[0m Trial 0 finished with value: 44.0579504912254 and parameters: {'max_depth': 6, 'num_leaves': 29, 'learning_rate': 0.0732020742417224, 'n_estimators': 1997, 'subsample': 0.5780093202212182, 'feature_fraction': 0.32479561626896214, 'min_gain_to_split': 0.8712541825229919, 'reg_alpha': 4.330880728874676, 'reg_lambda': 3.005575058716044, 'linear_tree': True}. Best is trial 0 with value: 44.0579504912254.\u001b[0m\n",
      "3it [00:00,  4.55it/s]\n",
      "1th fold: LGBMRegressor RMSE: 31.8711\n",
      "2th fold: LGBMRegressor RMSE: 37.9226\n",
      "3th fold: LGBMRegressor RMSE: 3.5038\n",
      "\n",
      "LGBMRegressor average RMSE: 24.4325\n",
      "LGBMRegressor worst RMSE: 37.9226\n",
      "Corresponding penalty value: 29.8285\n",
      "\u001b[32m[I 2025-03-27 08:20:52,439]\u001b[0m Trial 1 finished with value: 29.82852726778684 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.021241787676720834, 'n_estimators': 954, 'subsample': 0.5917022549267169, 'feature_fraction': 0.4433937943676302, 'min_gain_to_split': 7.871346474483568, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097, 'linear_tree': True}. Best is trial 1 with value: 29.82852726778684.\u001b[0m\n",
      "3it [00:01,  2.39it/s]\n",
      "1th fold: LGBMRegressor RMSE: 7.5518\n",
      "2th fold: LGBMRegressor RMSE: 0.3258\n",
      "3th fold: LGBMRegressor RMSE: 0.8777\n",
      "\n",
      "LGBMRegressor average RMSE: 2.9184\n",
      "LGBMRegressor worst RMSE: 7.5518\n",
      "Corresponding penalty value: 4.7718\n",
      "\u001b[32m[I 2025-03-27 08:20:53,698]\u001b[0m Trial 2 finished with value: 4.771797957289482 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.04561243772186143, 'n_estimators': 2463, 'subsample': 0.5998368910791798, 'feature_fraction': 0.6113875507308892, 'min_gain_to_split': 8.886218532930638, 'reg_alpha': 0.23225206359998862, 'reg_lambda': 3.0377242595071916, 'linear_tree': True}. Best is trial 2 with value: 4.771797957289482.\u001b[0m\n",
      "3it [00:00,  5.36it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4083\n",
      "2th fold: LGBMRegressor RMSE: 0.2841\n",
      "3th fold: LGBMRegressor RMSE: 0.8812\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5245\n",
      "LGBMRegressor worst RMSE: 0.8812\n",
      "Corresponding penalty value: 0.6672\n",
      "\u001b[32m[I 2025-03-27 08:20:54,259]\u001b[0m Trial 3 finished with value: 0.6671973722636048 and parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}. Best is trial 3 with value: 0.6671973722636048.\u001b[0m\n",
      "3it [00:00,  3.76it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.5759\n",
      "2th fold: LGBMRegressor RMSE: 48.6948\n",
      "3th fold: LGBMRegressor RMSE: 2.3435\n",
      "\n",
      "LGBMRegressor average RMSE: 18.2047\n",
      "LGBMRegressor worst RMSE: 48.6948\n",
      "Corresponding penalty value: 30.4008\n",
      "\u001b[32m[I 2025-03-27 08:20:55,060]\u001b[0m Trial 4 finished with value: 30.400758566296926 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.031177990498180205, 'n_estimators': 1800, 'subsample': 0.7733551396716398, 'feature_fraction': 0.3478835644204217, 'min_gain_to_split': 14.543769416468379, 'reg_alpha': 3.8756641168055728, 'reg_lambda': 4.697494707820946, 'linear_tree': True}. Best is trial 3 with value: 0.6671973722636048.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "3it [00:00,  5.31it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.4322\n",
      "2th fold: LGBMRegressor RMSE: 0.2926\n",
      "3th fold: LGBMRegressor RMSE: 0.9023\n",
      "\n",
      "LGBMRegressor average RMSE: 0.5424\n",
      "LGBMRegressor worst RMSE: 0.9023\n",
      "Corresponding penalty value: 0.6864\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV1\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.084\n",
      "RMSE_crossval: 0.542\n",
      "RMSE_test: 0.333\n",
      "MAE_test: 0.249\n",
      "Willmott's d Test: 0.997\n",
      "Nash-Sutcliffe Test: 0.990\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 5.6407 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:20:56,473]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV3\u001b[0m\n",
      "3it [00:00,  3.46it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.8662\n",
      "2th fold: LGBMRegressor RMSE: 27.0676\n",
      "3th fold: LGBMRegressor RMSE: 4.4642\n",
      "\n",
      "LGBMRegressor average RMSE: 12.4660\n",
      "LGBMRegressor worst RMSE: 27.0676\n",
      "Corresponding penalty value: 18.3067\n",
      "\u001b[32m[I 2025-03-27 08:20:57,343]\u001b[0m Trial 0 finished with value: 18.306653590093397 and parameters: {'max_depth': 6, 'num_leaves': 29, 'learning_rate': 0.0732020742417224, 'n_estimators': 1997, 'subsample': 0.5780093202212182, 'feature_fraction': 0.32479561626896214, 'min_gain_to_split': 0.8712541825229919, 'reg_alpha': 4.330880728874676, 'reg_lambda': 3.005575058716044, 'linear_tree': True}. Best is trial 0 with value: 18.306653590093397.\u001b[0m\n",
      "3it [00:00,  4.29it/s]\n",
      "1th fold: LGBMRegressor RMSE: 12.5801\n",
      "2th fold: LGBMRegressor RMSE: 144.6816\n",
      "3th fold: LGBMRegressor RMSE: 5.8837\n",
      "\n",
      "LGBMRegressor average RMSE: 54.3818\n",
      "LGBMRegressor worst RMSE: 144.6816\n",
      "Corresponding penalty value: 90.5017\n",
      "\u001b[32m[I 2025-03-27 08:20:58,045]\u001b[0m Trial 1 finished with value: 90.50174973298658 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.021241787676720834, 'n_estimators': 954, 'subsample': 0.5917022549267169, 'feature_fraction': 0.4433937943676302, 'min_gain_to_split': 7.871346474483568, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097, 'linear_tree': True}. Best is trial 0 with value: 18.306653590093397.\u001b[0m\n",
      "3it [00:01,  2.38it/s]\n",
      "1th fold: LGBMRegressor RMSE: 9.2797\n",
      "2th fold: LGBMRegressor RMSE: 2.1007\n",
      "3th fold: LGBMRegressor RMSE: 2.6001\n",
      "\n",
      "LGBMRegressor average RMSE: 4.6602\n",
      "LGBMRegressor worst RMSE: 9.2797\n",
      "Corresponding penalty value: 6.5080\n",
      "\u001b[32m[I 2025-03-27 08:20:59,306]\u001b[0m Trial 2 finished with value: 6.50797377409833 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.04561243772186143, 'n_estimators': 2463, 'subsample': 0.5998368910791798, 'feature_fraction': 0.6113875507308892, 'min_gain_to_split': 8.886218532930638, 'reg_alpha': 0.23225206359998862, 'reg_lambda': 3.0377242595071916, 'linear_tree': True}. Best is trial 2 with value: 6.50797377409833.\u001b[0m\n",
      "3it [00:00,  5.19it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8584\n",
      "2th fold: LGBMRegressor RMSE: 0.2965\n",
      "3th fold: LGBMRegressor RMSE: 1.3262\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8270\n",
      "LGBMRegressor worst RMSE: 1.3262\n",
      "Corresponding penalty value: 1.0267\n",
      "\u001b[32m[I 2025-03-27 08:20:59,887]\u001b[0m Trial 3 finished with value: 1.0266679982423836 and parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}. Best is trial 3 with value: 1.0266679982423836.\u001b[0m\n",
      "3it [00:00,  3.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 15.1129\n",
      "2th fold: LGBMRegressor RMSE: 17.5713\n",
      "3th fold: LGBMRegressor RMSE: 6.4891\n",
      "\n",
      "LGBMRegressor average RMSE: 13.0577\n",
      "LGBMRegressor worst RMSE: 17.5713\n",
      "Corresponding penalty value: 14.8632\n",
      "\u001b[32m[I 2025-03-27 08:21:00,707]\u001b[0m Trial 4 finished with value: 14.863150071439179 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.031177990498180205, 'n_estimators': 1800, 'subsample': 0.7733551396716398, 'feature_fraction': 0.3478835644204217, 'min_gain_to_split': 14.543769416468379, 'reg_alpha': 3.8756641168055728, 'reg_lambda': 4.697494707820946, 'linear_tree': True}. Best is trial 3 with value: 1.0266679982423836.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "3it [00:00,  5.14it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.9212\n",
      "2th fold: LGBMRegressor RMSE: 0.2784\n",
      "3th fold: LGBMRegressor RMSE: 1.2823\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8273\n",
      "LGBMRegressor worst RMSE: 1.2823\n",
      "Corresponding penalty value: 1.0093\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV3\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.105\n",
      "RMSE_crossval: 0.827\n",
      "RMSE_test: 0.680\n",
      "MAE_test: 0.439\n",
      "Willmott's d Test: 0.993\n",
      "Nash-Sutcliffe Test: 0.972\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 5.6676 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:21:02,139]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV51\u001b[0m\n",
      "3it [00:00,  3.37it/s]\n",
      "1th fold: LGBMRegressor RMSE: 16.3293\n",
      "2th fold: LGBMRegressor RMSE: 29.8227\n",
      "3th fold: LGBMRegressor RMSE: 48.1472\n",
      "\n",
      "LGBMRegressor average RMSE: 31.4331\n",
      "LGBMRegressor worst RMSE: 48.1472\n",
      "Corresponding penalty value: 38.1187\n",
      "\u001b[32m[I 2025-03-27 08:21:03,030]\u001b[0m Trial 0 finished with value: 38.118713769107956 and parameters: {'max_depth': 6, 'num_leaves': 29, 'learning_rate': 0.0732020742417224, 'n_estimators': 1997, 'subsample': 0.5780093202212182, 'feature_fraction': 0.32479561626896214, 'min_gain_to_split': 0.8712541825229919, 'reg_alpha': 4.330880728874676, 'reg_lambda': 3.005575058716044, 'linear_tree': True}. Best is trial 0 with value: 38.118713769107956.\u001b[0m\n",
      "3it [00:00,  3.88it/s]\n",
      "1th fold: LGBMRegressor RMSE: 128.0073\n",
      "2th fold: LGBMRegressor RMSE: 31.9165\n",
      "3th fold: LGBMRegressor RMSE: 12.7499\n",
      "\n",
      "LGBMRegressor average RMSE: 57.5579\n",
      "LGBMRegressor worst RMSE: 128.0073\n",
      "Corresponding penalty value: 85.7376\n",
      "\u001b[32m[I 2025-03-27 08:21:03,805]\u001b[0m Trial 1 finished with value: 85.73764530648975 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.021241787676720834, 'n_estimators': 954, 'subsample': 0.5917022549267169, 'feature_fraction': 0.4433937943676302, 'min_gain_to_split': 7.871346474483568, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097, 'linear_tree': True}. Best is trial 0 with value: 38.118713769107956.\u001b[0m\n",
      "3it [00:01,  2.34it/s]\n",
      "1th fold: LGBMRegressor RMSE: 8.5300\n",
      "2th fold: LGBMRegressor RMSE: 14.0360\n",
      "3th fold: LGBMRegressor RMSE: 0.6451\n",
      "\n",
      "LGBMRegressor average RMSE: 7.7370\n",
      "LGBMRegressor worst RMSE: 14.0360\n",
      "Corresponding penalty value: 10.2566\n",
      "\u001b[32m[I 2025-03-27 08:21:05,090]\u001b[0m Trial 2 finished with value: 10.256586924485418 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.04561243772186143, 'n_estimators': 2463, 'subsample': 0.5998368910791798, 'feature_fraction': 0.6113875507308892, 'min_gain_to_split': 8.886218532930638, 'reg_alpha': 0.23225206359998862, 'reg_lambda': 3.0377242595071916, 'linear_tree': True}. Best is trial 2 with value: 10.256586924485418.\u001b[0m\n",
      "3it [00:00,  5.09it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8698\n",
      "2th fold: LGBMRegressor RMSE: 0.4542\n",
      "3th fold: LGBMRegressor RMSE: 1.0625\n",
      "\n",
      "LGBMRegressor average RMSE: 0.7955\n",
      "LGBMRegressor worst RMSE: 1.0625\n",
      "Corresponding penalty value: 0.9023\n",
      "\u001b[32m[I 2025-03-27 08:21:05,681]\u001b[0m Trial 3 finished with value: 0.9023029436987915 and parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}. Best is trial 3 with value: 0.9023029436987915.\u001b[0m\n",
      "3it [00:00,  3.56it/s]\n",
      "1th fold: LGBMRegressor RMSE: 357.1763\n",
      "2th fold: LGBMRegressor RMSE: 33.0268\n",
      "3th fold: LGBMRegressor RMSE: 3.9864\n",
      "\n",
      "LGBMRegressor average RMSE: 131.3965\n",
      "LGBMRegressor worst RMSE: 357.1763\n",
      "Corresponding penalty value: 221.7084\n",
      "\u001b[32m[I 2025-03-27 08:21:06,526]\u001b[0m Trial 4 finished with value: 221.70843287327955 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.031177990498180205, 'n_estimators': 1800, 'subsample': 0.7733551396716398, 'feature_fraction': 0.3478835644204217, 'min_gain_to_split': 14.543769416468379, 'reg_alpha': 3.8756641168055728, 'reg_lambda': 4.697494707820946, 'linear_tree': True}. Best is trial 3 with value: 0.9023029436987915.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "3it [00:00,  5.01it/s]\n",
      "1th fold: LGBMRegressor RMSE: 0.8892\n",
      "2th fold: LGBMRegressor RMSE: 0.5194\n",
      "3th fold: LGBMRegressor RMSE: 1.0521\n",
      "\n",
      "LGBMRegressor average RMSE: 0.8202\n",
      "LGBMRegressor worst RMSE: 1.0521\n",
      "Corresponding penalty value: 0.9130\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV51\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.117\n",
      "RMSE_crossval: 0.820\n",
      "RMSE_test: 0.426\n",
      "MAE_test: 0.314\n",
      "Willmott's d Test: 0.998\n",
      "Nash-Sutcliffe Test: 0.990\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 5.8202 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:21:07,955]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB4\u001b[0m\n",
      "3it [00:00,  3.54it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.6463\n",
      "2th fold: LGBMRegressor RMSE: 413.1048\n",
      "3th fold: LGBMRegressor RMSE: 916.8139\n",
      "\n",
      "LGBMRegressor average RMSE: 444.8550\n",
      "LGBMRegressor worst RMSE: 916.8139\n",
      "Corresponding penalty value: 633.6386\n",
      "\u001b[32m[I 2025-03-27 08:21:08,805]\u001b[0m Trial 0 finished with value: 633.6385637415729 and parameters: {'max_depth': 6, 'num_leaves': 29, 'learning_rate': 0.0732020742417224, 'n_estimators': 1997, 'subsample': 0.5780093202212182, 'feature_fraction': 0.32479561626896214, 'min_gain_to_split': 0.8712541825229919, 'reg_alpha': 4.330880728874676, 'reg_lambda': 3.005575058716044, 'linear_tree': True}. Best is trial 0 with value: 633.6385637415729.\u001b[0m\n",
      "3it [00:00,  4.30it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.1738\n",
      "2th fold: LGBMRegressor RMSE: 233.1178\n",
      "3th fold: LGBMRegressor RMSE: 1912.9975\n",
      "\n",
      "LGBMRegressor average RMSE: 716.4297\n",
      "LGBMRegressor worst RMSE: 1912.9975\n",
      "Corresponding penalty value: 1195.0568\n",
      "\u001b[32m[I 2025-03-27 08:21:09,506]\u001b[0m Trial 1 finished with value: 1195.0568208653985 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.021241787676720834, 'n_estimators': 954, 'subsample': 0.5917022549267169, 'feature_fraction': 0.4433937943676302, 'min_gain_to_split': 7.871346474483568, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097, 'linear_tree': True}. Best is trial 0 with value: 633.6385637415729.\u001b[0m\n",
      "3it [00:01,  2.35it/s]\n",
      "1th fold: LGBMRegressor RMSE: 12.8422\n",
      "2th fold: LGBMRegressor RMSE: 64.9539\n",
      "3th fold: LGBMRegressor RMSE: 1768.6178\n",
      "\n",
      "LGBMRegressor average RMSE: 615.4713\n",
      "LGBMRegressor worst RMSE: 1768.6178\n",
      "Corresponding penalty value: 1076.7299\n",
      "\u001b[32m[I 2025-03-27 08:21:10,785]\u001b[0m Trial 2 finished with value: 1076.7299218491771 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.04561243772186143, 'n_estimators': 2463, 'subsample': 0.5998368910791798, 'feature_fraction': 0.6113875507308892, 'min_gain_to_split': 8.886218532930638, 'reg_alpha': 0.23225206359998862, 'reg_lambda': 3.0377242595071916, 'linear_tree': True}. Best is trial 0 with value: 633.6385637415729.\u001b[0m\n",
      "3it [00:00,  5.07it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.0629\n",
      "2th fold: LGBMRegressor RMSE: 2.0755\n",
      "3th fold: LGBMRegressor RMSE: 3.9787\n",
      "\n",
      "LGBMRegressor average RMSE: 3.7057\n",
      "LGBMRegressor worst RMSE: 5.0629\n",
      "Corresponding penalty value: 4.2486\n",
      "\u001b[32m[I 2025-03-27 08:21:11,378]\u001b[0m Trial 3 finished with value: 4.248576961184946 and parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}. Best is trial 3 with value: 4.248576961184946.\u001b[0m\n",
      "3it [00:00,  3.64it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2.7513\n",
      "2th fold: LGBMRegressor RMSE: 216.6689\n",
      "3th fold: LGBMRegressor RMSE: 296.1540\n",
      "\n",
      "LGBMRegressor average RMSE: 171.8581\n",
      "LGBMRegressor worst RMSE: 296.1540\n",
      "Corresponding penalty value: 221.5764\n",
      "\u001b[32m[I 2025-03-27 08:21:12,203]\u001b[0m Trial 4 finished with value: 221.5764154902543 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.031177990498180205, 'n_estimators': 1800, 'subsample': 0.7733551396716398, 'feature_fraction': 0.3478835644204217, 'min_gain_to_split': 14.543769416468379, 'reg_alpha': 3.8756641168055728, 'reg_lambda': 4.697494707820946, 'linear_tree': True}. Best is trial 3 with value: 4.248576961184946.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "3it [00:00,  5.14it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.1618\n",
      "2th fold: LGBMRegressor RMSE: 1.8219\n",
      "3th fold: LGBMRegressor RMSE: 3.9945\n",
      "\n",
      "LGBMRegressor average RMSE: 3.6594\n",
      "LGBMRegressor worst RMSE: 5.1618\n",
      "Corresponding penalty value: 4.2604\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB4\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.325\n",
      "RMSE_crossval: 3.659\n",
      "RMSE_test: 1.560\n",
      "MAE_test: 0.966\n",
      "Willmott's d Test: 0.965\n",
      "Nash-Sutcliffe Test: 0.877\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 5.6795 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:21:13,642]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB8\u001b[0m\n",
      "3it [00:00,  3.19it/s]\n",
      "1th fold: LGBMRegressor RMSE: 253.6638\n",
      "2th fold: LGBMRegressor RMSE: 444.7392\n",
      "3th fold: LGBMRegressor RMSE: 2865.6043\n",
      "\n",
      "LGBMRegressor average RMSE: 1188.0024\n",
      "LGBMRegressor worst RMSE: 2865.6043\n",
      "Corresponding penalty value: 1859.0432\n",
      "\u001b[32m[I 2025-03-27 08:21:14,584]\u001b[0m Trial 0 finished with value: 1859.04316819786 and parameters: {'max_depth': 6, 'num_leaves': 29, 'learning_rate': 0.0732020742417224, 'n_estimators': 1997, 'subsample': 0.5780093202212182, 'feature_fraction': 0.32479561626896214, 'min_gain_to_split': 0.8712541825229919, 'reg_alpha': 4.330880728874676, 'reg_lambda': 3.005575058716044, 'linear_tree': True}. Best is trial 0 with value: 1859.04316819786.\u001b[0m\n",
      "3it [00:00,  3.39it/s]\n",
      "1th fold: LGBMRegressor RMSE: 2075.7886\n",
      "2th fold: LGBMRegressor RMSE: 79.3281\n",
      "3th fold: LGBMRegressor RMSE: 365.9835\n",
      "\n",
      "LGBMRegressor average RMSE: 840.3667\n",
      "LGBMRegressor worst RMSE: 2075.7886\n",
      "Corresponding penalty value: 1334.5355\n",
      "\u001b[32m[I 2025-03-27 08:21:15,471]\u001b[0m Trial 1 finished with value: 1334.5354745731543 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.021241787676720834, 'n_estimators': 954, 'subsample': 0.5917022549267169, 'feature_fraction': 0.4433937943676302, 'min_gain_to_split': 7.871346474483568, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097, 'linear_tree': True}. Best is trial 1 with value: 1334.5354745731543.\u001b[0m\n",
      "3it [00:01,  2.28it/s]\n",
      "1th fold: LGBMRegressor RMSE: 11.8398\n",
      "2th fold: LGBMRegressor RMSE: 9.4747\n",
      "3th fold: LGBMRegressor RMSE: 64.7056\n",
      "\n",
      "LGBMRegressor average RMSE: 28.6734\n",
      "LGBMRegressor worst RMSE: 64.7056\n",
      "Corresponding penalty value: 43.0862\n",
      "\u001b[32m[I 2025-03-27 08:21:16,791]\u001b[0m Trial 2 finished with value: 43.086249867261586 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.04561243772186143, 'n_estimators': 2463, 'subsample': 0.5998368910791798, 'feature_fraction': 0.6113875507308892, 'min_gain_to_split': 8.886218532930638, 'reg_alpha': 0.23225206359998862, 'reg_lambda': 3.0377242595071916, 'linear_tree': True}. Best is trial 2 with value: 43.086249867261586.\u001b[0m\n",
      "3it [00:00,  4.88it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.9158\n",
      "2th fold: LGBMRegressor RMSE: 1.5210\n",
      "3th fold: LGBMRegressor RMSE: 5.9431\n",
      "\n",
      "LGBMRegressor average RMSE: 3.7933\n",
      "LGBMRegressor worst RMSE: 5.9431\n",
      "Corresponding penalty value: 4.6532\n",
      "\u001b[32m[I 2025-03-27 08:21:17,407]\u001b[0m Trial 3 finished with value: 4.653205503626066 and parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}. Best is trial 3 with value: 4.653205503626066.\u001b[0m\n",
      "3it [00:00,  3.40it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1893.8522\n",
      "2th fold: LGBMRegressor RMSE: 97.5658\n",
      "3th fold: LGBMRegressor RMSE: 96.6060\n",
      "\n",
      "LGBMRegressor average RMSE: 696.0080\n",
      "LGBMRegressor worst RMSE: 1893.8522\n",
      "Corresponding penalty value: 1175.1457\n",
      "\u001b[32m[I 2025-03-27 08:21:18,291]\u001b[0m Trial 4 finished with value: 1175.1456544631922 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.031177990498180205, 'n_estimators': 1800, 'subsample': 0.7733551396716398, 'feature_fraction': 0.3478835644204217, 'min_gain_to_split': 14.543769416468379, 'reg_alpha': 3.8756641168055728, 'reg_lambda': 4.697494707820946, 'linear_tree': True}. Best is trial 3 with value: 4.653205503626066.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "3it [00:00,  4.83it/s]\n",
      "1th fold: LGBMRegressor RMSE: 3.9582\n",
      "2th fold: LGBMRegressor RMSE: 1.5546\n",
      "3th fold: LGBMRegressor RMSE: 5.9549\n",
      "\n",
      "LGBMRegressor average RMSE: 3.8226\n",
      "LGBMRegressor worst RMSE: 5.9549\n",
      "Corresponding penalty value: 4.6755\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB8\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.927\n",
      "RMSE_crossval: 3.823\n",
      "RMSE_test: 1.894\n",
      "MAE_test: 1.487\n",
      "Willmott's d Test: 0.453\n",
      "Nash-Sutcliffe Test: -1.307\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 6.1442 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:21:19,800]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB10\u001b[0m\n",
      "3it [00:00,  3.08it/s]\n",
      "1th fold: LGBMRegressor RMSE: 8168.4524\n",
      "2th fold: LGBMRegressor RMSE: 3575.4952\n",
      "3th fold: LGBMRegressor RMSE: 98.3806\n",
      "\n",
      "LGBMRegressor average RMSE: 3947.4427\n",
      "LGBMRegressor worst RMSE: 8168.4524\n",
      "Corresponding penalty value: 5635.8466\n",
      "\u001b[32m[I 2025-03-27 08:21:20,777]\u001b[0m Trial 0 finished with value: 5635.846623204429 and parameters: {'max_depth': 6, 'num_leaves': 29, 'learning_rate': 0.0732020742417224, 'n_estimators': 1997, 'subsample': 0.5780093202212182, 'feature_fraction': 0.32479561626896214, 'min_gain_to_split': 0.8712541825229919, 'reg_alpha': 4.330880728874676, 'reg_lambda': 3.005575058716044, 'linear_tree': True}. Best is trial 0 with value: 5635.846623204429.\u001b[0m\n",
      "3it [00:01,  2.05it/s]\n",
      "1th fold: LGBMRegressor RMSE: 18908388664.8649\n",
      "2th fold: LGBMRegressor RMSE: 884.3003\n",
      "3th fold: LGBMRegressor RMSE: 186.8118\n",
      "\n",
      "LGBMRegressor average RMSE: 6302796578.6590\n",
      "LGBMRegressor worst RMSE: 18908388664.8649\n",
      "Corresponding penalty value: 11345033413.1413\n",
      "\u001b[32m[I 2025-03-27 08:21:22,241]\u001b[0m Trial 1 finished with value: 11345033413.141344 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.021241787676720834, 'n_estimators': 954, 'subsample': 0.5917022549267169, 'feature_fraction': 0.4433937943676302, 'min_gain_to_split': 7.871346474483568, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097, 'linear_tree': True}. Best is trial 0 with value: 5635.846623204429.\u001b[0m\n",
      "3it [00:01,  2.24it/s]\n",
      "1th fold: LGBMRegressor RMSE: 24.6845\n",
      "2th fold: LGBMRegressor RMSE: 357.7684\n",
      "3th fold: LGBMRegressor RMSE: 282.8481\n",
      "\n",
      "LGBMRegressor average RMSE: 221.7670\n",
      "LGBMRegressor worst RMSE: 357.7684\n",
      "Corresponding penalty value: 276.1676\n",
      "\u001b[32m[I 2025-03-27 08:21:23,585]\u001b[0m Trial 2 finished with value: 276.1675757451145 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.04561243772186143, 'n_estimators': 2463, 'subsample': 0.5998368910791798, 'feature_fraction': 0.6113875507308892, 'min_gain_to_split': 8.886218532930638, 'reg_alpha': 0.23225206359998862, 'reg_lambda': 3.0377242595071916, 'linear_tree': True}. Best is trial 2 with value: 276.1675757451145.\u001b[0m\n",
      "3it [00:00,  4.63it/s]\n",
      "1th fold: LGBMRegressor RMSE: 6.2036\n",
      "2th fold: LGBMRegressor RMSE: 7.9324\n",
      "3th fold: LGBMRegressor RMSE: 3.2995\n",
      "\n",
      "LGBMRegressor average RMSE: 5.8118\n",
      "LGBMRegressor worst RMSE: 7.9324\n",
      "Corresponding penalty value: 6.6601\n",
      "\u001b[32m[I 2025-03-27 08:21:24,236]\u001b[0m Trial 3 finished with value: 6.660072810090027 and parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}. Best is trial 3 with value: 6.660072810090027.\u001b[0m\n",
      "3it [00:00,  3.17it/s]\n",
      "1th fold: LGBMRegressor RMSE: 1225.8996\n",
      "2th fold: LGBMRegressor RMSE: 3240.3839\n",
      "3th fold: LGBMRegressor RMSE: 1061.2893\n",
      "\n",
      "LGBMRegressor average RMSE: 1842.5243\n",
      "LGBMRegressor worst RMSE: 3240.3839\n",
      "Corresponding penalty value: 2401.6681\n",
      "\u001b[32m[I 2025-03-27 08:21:25,184]\u001b[0m Trial 4 finished with value: 2401.6681141753556 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.031177990498180205, 'n_estimators': 1800, 'subsample': 0.7733551396716398, 'feature_fraction': 0.3478835644204217, 'min_gain_to_split': 14.543769416468379, 'reg_alpha': 3.8756641168055728, 'reg_lambda': 4.697494707820946, 'linear_tree': True}. Best is trial 3 with value: 6.660072810090027.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "3it [00:00,  4.67it/s]\n",
      "1th fold: LGBMRegressor RMSE: 5.8723\n",
      "2th fold: LGBMRegressor RMSE: 8.0164\n",
      "3th fold: LGBMRegressor RMSE: 3.3993\n",
      "\n",
      "LGBMRegressor average RMSE: 5.7627\n",
      "LGBMRegressor worst RMSE: 8.0164\n",
      "Corresponding penalty value: 6.6641\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB10\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.419\n",
      "RMSE_crossval: 5.763\n",
      "RMSE_test: 4.717\n",
      "MAE_test: 3.266\n",
      "Willmott's d Test: 0.178\n",
      "Nash-Sutcliffe Test: -12.145\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 6.9194 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:21:26,693]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB18\u001b[0m\n",
      "3it [00:01,  3.00it/s]\n",
      "1th fold: LGBMRegressor RMSE: 207.1185\n",
      "2th fold: LGBMRegressor RMSE: 659.8927\n",
      "3th fold: LGBMRegressor RMSE: 457.2923\n",
      "\n",
      "LGBMRegressor average RMSE: 441.4345\n",
      "LGBMRegressor worst RMSE: 659.8927\n",
      "Corresponding penalty value: 528.8178\n",
      "\u001b[32m[I 2025-03-27 08:21:27,697]\u001b[0m Trial 0 finished with value: 528.8177748426899 and parameters: {'max_depth': 6, 'num_leaves': 29, 'learning_rate': 0.0732020742417224, 'n_estimators': 1997, 'subsample': 0.5780093202212182, 'feature_fraction': 0.32479561626896214, 'min_gain_to_split': 0.8712541825229919, 'reg_alpha': 4.330880728874676, 'reg_lambda': 3.005575058716044, 'linear_tree': True}. Best is trial 0 with value: 528.8177748426899.\u001b[0m\n",
      "3it [00:00,  4.13it/s]\n",
      "1th fold: LGBMRegressor RMSE: 66.2994\n",
      "2th fold: LGBMRegressor RMSE: 144.8678\n",
      "3th fold: LGBMRegressor RMSE: 446.2241\n",
      "\n",
      "LGBMRegressor average RMSE: 219.1304\n",
      "LGBMRegressor worst RMSE: 446.2241\n",
      "Corresponding penalty value: 309.9679\n",
      "\u001b[32m[I 2025-03-27 08:21:28,424]\u001b[0m Trial 1 finished with value: 309.9678881938309 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.021241787676720834, 'n_estimators': 954, 'subsample': 0.5917022549267169, 'feature_fraction': 0.4433937943676302, 'min_gain_to_split': 7.871346474483568, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097, 'linear_tree': True}. Best is trial 1 with value: 309.9678881938309.\u001b[0m\n",
      "3it [00:01,  2.34it/s]\n",
      "1th fold: LGBMRegressor RMSE: 61.0865\n",
      "2th fold: LGBMRegressor RMSE: 8919.4445\n",
      "3th fold: LGBMRegressor RMSE: 508.2249\n",
      "\n",
      "LGBMRegressor average RMSE: 3162.9186\n",
      "LGBMRegressor worst RMSE: 8919.4445\n",
      "Corresponding penalty value: 5465.5290\n",
      "\u001b[32m[I 2025-03-27 08:21:29,709]\u001b[0m Trial 2 finished with value: 5465.5289834838595 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.04561243772186143, 'n_estimators': 2463, 'subsample': 0.5998368910791798, 'feature_fraction': 0.6113875507308892, 'min_gain_to_split': 8.886218532930638, 'reg_alpha': 0.23225206359998862, 'reg_lambda': 3.0377242595071916, 'linear_tree': True}. Best is trial 1 with value: 309.9678881938309.\u001b[0m\n",
      "3it [00:00,  5.03it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.1145\n",
      "2th fold: LGBMRegressor RMSE: 1.8202\n",
      "3th fold: LGBMRegressor RMSE: 5.3862\n",
      "\n",
      "LGBMRegressor average RMSE: 3.7736\n",
      "LGBMRegressor worst RMSE: 5.3862\n",
      "Corresponding penalty value: 4.4186\n",
      "\u001b[32m[I 2025-03-27 08:21:30,307]\u001b[0m Trial 3 finished with value: 4.418649264835867 and parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}. Best is trial 3 with value: 4.418649264835867.\u001b[0m\n",
      "3it [00:00,  3.61it/s]\n",
      "1th fold: LGBMRegressor RMSE: 14.7963\n",
      "2th fold: LGBMRegressor RMSE: 66.8538\n",
      "3th fold: LGBMRegressor RMSE: 139.9638\n",
      "\n",
      "LGBMRegressor average RMSE: 73.8713\n",
      "LGBMRegressor worst RMSE: 139.9638\n",
      "Corresponding penalty value: 100.3083\n",
      "\u001b[32m[I 2025-03-27 08:21:31,141]\u001b[0m Trial 4 finished with value: 100.3082683891928 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.031177990498180205, 'n_estimators': 1800, 'subsample': 0.7733551396716398, 'feature_fraction': 0.3478835644204217, 'min_gain_to_split': 14.543769416468379, 'reg_alpha': 3.8756641168055728, 'reg_lambda': 4.697494707820946, 'linear_tree': True}. Best is trial 3 with value: 4.418649264835867.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "3it [00:00,  5.07it/s]\n",
      "1th fold: LGBMRegressor RMSE: 4.1445\n",
      "2th fold: LGBMRegressor RMSE: 1.8733\n",
      "3th fold: LGBMRegressor RMSE: 5.4548\n",
      "\n",
      "LGBMRegressor average RMSE: 3.8242\n",
      "LGBMRegressor worst RMSE: 5.4548\n",
      "Corresponding penalty value: 4.4765\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB18\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_depth': 12, 'num_leaves': 30, 'learning_rate': 0.08084165083816496, 'n_estimators': 1261, 'subsample': 0.5488360570031919, 'feature_fraction': 0.7473864212097256, 'min_gain_to_split': 6.602287406094019, 'reg_alpha': 0.6101911742238941, 'reg_lambda': 2.475884550556351, 'linear_tree': False}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.967\n",
      "RMSE_crossval: 3.824\n",
      "RMSE_test: 3.222\n",
      "MAE_test: 2.647\n",
      "Willmott's d Test: 0.851\n",
      "Nash-Sutcliffe Test: 0.355\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 5.9279 seconds\n",
      "\n",
      "Total elapsed time: 41.8011 seconds\n",
      "\n",
      "Output saved to LightGBM_output_test_26_3_pen_04.txt\n"
     ]
    }
   ],
   "source": [
    "!python ./models/LightGBM.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c953144f-b001-4106-b9eb-e293f4096a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-03-27 08:21:33,869]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV1\u001b[0m\n",
      "3it [00:01,  2.02it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6523\n",
      "2th fold: XGBRegressor RMSE: 0.2346\n",
      "3th fold: XGBRegressor RMSE: 1.0487\n",
      "\n",
      "XGBRegressor average RMSE: 0.6452\n",
      "XGBRegressor worst RMSE: 1.0487\n",
      "Corresponding penalty value: 0.8066\n",
      "\u001b[32m[I 2025-03-27 08:21:35,358]\u001b[0m Trial 0 finished with value: 0.8066049240878171 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}. Best is trial 0 with value: 0.8066049240878171.\u001b[0m\n",
      "3it [00:05,  1.74s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.4838\n",
      "2th fold: XGBRegressor RMSE: 0.2492\n",
      "3th fold: XGBRegressor RMSE: 0.9264\n",
      "\n",
      "XGBRegressor average RMSE: 0.5531\n",
      "XGBRegressor worst RMSE: 0.9264\n",
      "Corresponding penalty value: 0.7024\n",
      "\u001b[32m[I 2025-03-27 08:21:40,577]\u001b[0m Trial 1 finished with value: 0.7024203824161503 and parameters: {'n_estimators': 2270, 'learning_rate': 0.002068243584637287, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6061695553391381, 'subsample': 0.5909124836035503, 'reg_alpha': 0.9170225492671691, 'reg_lambda': 1.5212112147976886, 'gamma': 2.6237821581611893}. Best is trial 1 with value: 0.7024203824161503.\u001b[0m\n",
      "3it [00:01,  1.71it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5896\n",
      "2th fold: XGBRegressor RMSE: 0.1806\n",
      "3th fold: XGBRegressor RMSE: 0.7862\n",
      "\n",
      "XGBRegressor average RMSE: 0.5188\n",
      "XGBRegressor worst RMSE: 0.7862\n",
      "Corresponding penalty value: 0.6258\n",
      "\u001b[32m[I 2025-03-27 08:21:42,337]\u001b[0m Trial 2 finished with value: 0.6257570215845908 and parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}. Best is trial 2 with value: 0.6257570215845908.\u001b[0m\n",
      "3it [00:01,  1.73it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5693\n",
      "2th fold: XGBRegressor RMSE: 0.3803\n",
      "3th fold: XGBRegressor RMSE: 0.8096\n",
      "\n",
      "XGBRegressor average RMSE: 0.5864\n",
      "XGBRegressor worst RMSE: 0.8096\n",
      "Corresponding penalty value: 0.6757\n",
      "\u001b[32m[I 2025-03-27 08:21:44,072]\u001b[0m Trial 3 finished with value: 0.6756557158079646 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05924553274051564, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.5852620618436457, 'subsample': 0.5325257964926398, 'reg_alpha': 4.7444276862666666, 'reg_lambda': 4.828160165372797, 'gamma': 4.041986740582305}. Best is trial 2 with value: 0.6257570215845908.\u001b[0m\n",
      "3it [00:01,  1.56it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.4881\n",
      "2th fold: XGBRegressor RMSE: 0.2575\n",
      "3th fold: XGBRegressor RMSE: 0.9185\n",
      "\n",
      "XGBRegressor average RMSE: 0.5547\n",
      "XGBRegressor worst RMSE: 0.9185\n",
      "Corresponding penalty value: 0.7002\n",
      "\u001b[32m[I 2025-03-27 08:21:45,999]\u001b[0m Trial 4 finished with value: 0.7002494541563723 and parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}. Best is trial 2 with value: 0.6257570215845908.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}\n",
      "3it [00:01,  1.71it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.5900\n",
      "2th fold: XGBRegressor RMSE: 0.1679\n",
      "3th fold: XGBRegressor RMSE: 0.8254\n",
      "\n",
      "XGBRegressor average RMSE: 0.5278\n",
      "XGBRegressor worst RMSE: 0.8254\n",
      "Corresponding penalty value: 0.6468\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV1\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.093\n",
      "RMSE_crossval: 0.528\n",
      "RMSE_test: 0.364\n",
      "MAE_test: 0.257\n",
      "Willmott's d Test: 0.997\n",
      "Nash-Sutcliffe Test: 0.987\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 15.2564 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:21:49,154]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV3\u001b[0m\n",
      "3it [00:01,  2.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9445\n",
      "2th fold: XGBRegressor RMSE: 0.5514\n",
      "3th fold: XGBRegressor RMSE: 1.4462\n",
      "\n",
      "XGBRegressor average RMSE: 0.9807\n",
      "XGBRegressor worst RMSE: 1.4462\n",
      "Corresponding penalty value: 1.1669\n",
      "\u001b[32m[I 2025-03-27 08:21:50,632]\u001b[0m Trial 0 finished with value: 1.166899577566789 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}. Best is trial 0 with value: 1.166899577566789.\u001b[0m\n",
      "3it [00:05,  1.96s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.9342\n",
      "2th fold: XGBRegressor RMSE: 0.3290\n",
      "3th fold: XGBRegressor RMSE: 1.3928\n",
      "\n",
      "XGBRegressor average RMSE: 0.8853\n",
      "XGBRegressor worst RMSE: 1.3928\n",
      "Corresponding penalty value: 1.0883\n",
      "\u001b[32m[I 2025-03-27 08:21:56,525]\u001b[0m Trial 1 finished with value: 1.088312479136393 and parameters: {'n_estimators': 2270, 'learning_rate': 0.002068243584637287, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6061695553391381, 'subsample': 0.5909124836035503, 'reg_alpha': 0.9170225492671691, 'reg_lambda': 1.5212112147976886, 'gamma': 2.6237821581611893}. Best is trial 1 with value: 1.088312479136393.\u001b[0m\n",
      "3it [00:01,  1.66it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9613\n",
      "2th fold: XGBRegressor RMSE: 0.3824\n",
      "3th fold: XGBRegressor RMSE: 1.5288\n",
      "\n",
      "XGBRegressor average RMSE: 0.9575\n",
      "XGBRegressor worst RMSE: 1.5288\n",
      "Corresponding penalty value: 1.1860\n",
      "\u001b[32m[I 2025-03-27 08:21:58,330]\u001b[0m Trial 2 finished with value: 1.1860132163424775 and parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}. Best is trial 1 with value: 1.088312479136393.\u001b[0m\n",
      "3it [00:01,  1.69it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9464\n",
      "2th fold: XGBRegressor RMSE: 0.7446\n",
      "3th fold: XGBRegressor RMSE: 1.8276\n",
      "\n",
      "XGBRegressor average RMSE: 1.1729\n",
      "XGBRegressor worst RMSE: 1.8276\n",
      "Corresponding penalty value: 1.4348\n",
      "\u001b[32m[I 2025-03-27 08:22:00,107]\u001b[0m Trial 3 finished with value: 1.4347705021685275 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05924553274051564, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.5852620618436457, 'subsample': 0.5325257964926398, 'reg_alpha': 4.7444276862666666, 'reg_lambda': 4.828160165372797, 'gamma': 4.041986740582305}. Best is trial 1 with value: 1.088312479136393.\u001b[0m\n",
      "3it [00:02,  1.47it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9669\n",
      "2th fold: XGBRegressor RMSE: 0.3950\n",
      "3th fold: XGBRegressor RMSE: 1.3210\n",
      "\n",
      "XGBRegressor average RMSE: 0.8943\n",
      "XGBRegressor worst RMSE: 1.3210\n",
      "Corresponding penalty value: 1.0650\n",
      "\u001b[32m[I 2025-03-27 08:22:02,156]\u001b[0m Trial 4 finished with value: 1.0650072004089761 and parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}. Best is trial 4 with value: 1.0650072004089761.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "3it [00:02,  1.47it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.9435\n",
      "2th fold: XGBRegressor RMSE: 0.3955\n",
      "3th fold: XGBRegressor RMSE: 1.3250\n",
      "\n",
      "XGBRegressor average RMSE: 0.8880\n",
      "XGBRegressor worst RMSE: 1.3250\n",
      "Corresponding penalty value: 1.0628\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV3\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.101\n",
      "RMSE_crossval: 0.888\n",
      "RMSE_test: 0.622\n",
      "MAE_test: 0.386\n",
      "Willmott's d Test: 0.994\n",
      "Nash-Sutcliffe Test: 0.977\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 16.5682 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:22:05,712]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV51\u001b[0m\n",
      "3it [00:01,  1.77it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8347\n",
      "2th fold: XGBRegressor RMSE: 0.5644\n",
      "3th fold: XGBRegressor RMSE: 1.2055\n",
      "\n",
      "XGBRegressor average RMSE: 0.8682\n",
      "XGBRegressor worst RMSE: 1.2055\n",
      "Corresponding penalty value: 1.0031\n",
      "\u001b[32m[I 2025-03-27 08:22:07,409]\u001b[0m Trial 0 finished with value: 1.0031427138601257 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}. Best is trial 0 with value: 1.0031427138601257.\u001b[0m\n",
      "3it [00:06,  2.13s/it]\n",
      "1th fold: XGBRegressor RMSE: 0.9461\n",
      "2th fold: XGBRegressor RMSE: 0.4954\n",
      "3th fold: XGBRegressor RMSE: 1.0709\n",
      "\n",
      "XGBRegressor average RMSE: 0.8375\n",
      "XGBRegressor worst RMSE: 1.0709\n",
      "Corresponding penalty value: 0.9308\n",
      "\u001b[32m[I 2025-03-27 08:22:13,809]\u001b[0m Trial 1 finished with value: 0.9308197143610717 and parameters: {'n_estimators': 2270, 'learning_rate': 0.002068243584637287, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6061695553391381, 'subsample': 0.5909124836035503, 'reg_alpha': 0.9170225492671691, 'reg_lambda': 1.5212112147976886, 'gamma': 2.6237821581611893}. Best is trial 1 with value: 0.9308197143610717.\u001b[0m\n",
      "3it [00:01,  1.68it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.8179\n",
      "2th fold: XGBRegressor RMSE: 0.3582\n",
      "3th fold: XGBRegressor RMSE: 1.0740\n",
      "\n",
      "XGBRegressor average RMSE: 0.7500\n",
      "XGBRegressor worst RMSE: 1.0740\n",
      "Corresponding penalty value: 0.8796\n",
      "\u001b[32m[I 2025-03-27 08:22:15,600]\u001b[0m Trial 2 finished with value: 0.8796335676548317 and parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}. Best is trial 2 with value: 0.8796335676548317.\u001b[0m\n",
      "3it [00:01,  1.74it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.9374\n",
      "2th fold: XGBRegressor RMSE: 0.4978\n",
      "3th fold: XGBRegressor RMSE: 0.9770\n",
      "\n",
      "XGBRegressor average RMSE: 1.1374\n",
      "XGBRegressor worst RMSE: 1.9374\n",
      "Corresponding penalty value: 1.4574\n",
      "\u001b[32m[I 2025-03-27 08:22:17,326]\u001b[0m Trial 3 finished with value: 1.457359910471974 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05924553274051564, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.5852620618436457, 'subsample': 0.5325257964926398, 'reg_alpha': 4.7444276862666666, 'reg_lambda': 4.828160165372797, 'gamma': 4.041986740582305}. Best is trial 2 with value: 0.8796335676548317.\u001b[0m\n",
      "3it [00:02,  1.46it/s]\n",
      "1th fold: XGBRegressor RMSE: 1.0078\n",
      "2th fold: XGBRegressor RMSE: 0.4913\n",
      "3th fold: XGBRegressor RMSE: 1.1116\n",
      "\n",
      "XGBRegressor average RMSE: 0.8702\n",
      "XGBRegressor worst RMSE: 1.1116\n",
      "Corresponding penalty value: 0.9668\n",
      "\u001b[32m[I 2025-03-27 08:22:19,378]\u001b[0m Trial 4 finished with value: 0.9667557535515883 and parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}. Best is trial 2 with value: 0.8796335676548317.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}\n",
      "3it [00:01,  1.65it/s]\n",
      "1th fold: XGBRegressor RMSE: 0.6872\n",
      "2th fold: XGBRegressor RMSE: 0.3300\n",
      "3th fold: XGBRegressor RMSE: 1.0313\n",
      "\n",
      "XGBRegressor average RMSE: 0.6828\n",
      "XGBRegressor worst RMSE: 1.0313\n",
      "Corresponding penalty value: 0.8222\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV51\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.138\n",
      "RMSE_crossval: 0.683\n",
      "RMSE_test: 0.451\n",
      "MAE_test: 0.310\n",
      "Willmott's d Test: 0.997\n",
      "Nash-Sutcliffe Test: 0.989\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 16.8714 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:22:22,579]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB4\u001b[0m\n",
      "3it [00:01,  2.02it/s]\n",
      "1th fold: XGBRegressor RMSE: 4.3063\n",
      "2th fold: XGBRegressor RMSE: 2.1026\n",
      "3th fold: XGBRegressor RMSE: 4.0515\n",
      "\n",
      "XGBRegressor average RMSE: 3.4868\n",
      "XGBRegressor worst RMSE: 4.3063\n",
      "Corresponding penalty value: 3.8146\n",
      "\u001b[32m[I 2025-03-27 08:22:24,065]\u001b[0m Trial 0 finished with value: 3.814620179373041 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}. Best is trial 0 with value: 3.814620179373041.\u001b[0m\n",
      "3it [00:06,  2.14s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.7438\n",
      "2th fold: XGBRegressor RMSE: 1.8337\n",
      "3th fold: XGBRegressor RMSE: 4.0898\n",
      "\n",
      "XGBRegressor average RMSE: 3.2224\n",
      "XGBRegressor worst RMSE: 4.0898\n",
      "Corresponding penalty value: 3.5694\n",
      "\u001b[32m[I 2025-03-27 08:22:30,497]\u001b[0m Trial 1 finished with value: 3.5693751318335227 and parameters: {'n_estimators': 2270, 'learning_rate': 0.002068243584637287, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6061695553391381, 'subsample': 0.5909124836035503, 'reg_alpha': 0.9170225492671691, 'reg_lambda': 1.5212112147976886, 'gamma': 2.6237821581611893}. Best is trial 1 with value: 3.5693751318335227.\u001b[0m\n",
      "3it [00:01,  1.55it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.7656\n",
      "2th fold: XGBRegressor RMSE: 2.0527\n",
      "3th fold: XGBRegressor RMSE: 3.9189\n",
      "\n",
      "XGBRegressor average RMSE: 3.2457\n",
      "XGBRegressor worst RMSE: 3.9189\n",
      "Corresponding penalty value: 3.5150\n",
      "\u001b[32m[I 2025-03-27 08:22:32,438]\u001b[0m Trial 2 finished with value: 3.5150066917136757 and parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}. Best is trial 2 with value: 3.5150066917136757.\u001b[0m\n",
      "3it [00:01,  1.63it/s]\n",
      "1th fold: XGBRegressor RMSE: 4.5455\n",
      "2th fold: XGBRegressor RMSE: 2.7072\n",
      "3th fold: XGBRegressor RMSE: 3.9745\n",
      "\n",
      "XGBRegressor average RMSE: 3.7424\n",
      "XGBRegressor worst RMSE: 4.5455\n",
      "Corresponding penalty value: 4.0637\n",
      "\u001b[32m[I 2025-03-27 08:22:34,277]\u001b[0m Trial 3 finished with value: 4.063663926978983 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05924553274051564, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.5852620618436457, 'subsample': 0.5325257964926398, 'reg_alpha': 4.7444276862666666, 'reg_lambda': 4.828160165372797, 'gamma': 4.041986740582305}. Best is trial 2 with value: 3.5150066917136757.\u001b[0m\n",
      "3it [00:02,  1.34it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4742\n",
      "2th fold: XGBRegressor RMSE: 1.8903\n",
      "3th fold: XGBRegressor RMSE: 3.9866\n",
      "\n",
      "XGBRegressor average RMSE: 3.1170\n",
      "XGBRegressor worst RMSE: 3.9866\n",
      "Corresponding penalty value: 3.4648\n",
      "\u001b[32m[I 2025-03-27 08:22:36,520]\u001b[0m Trial 4 finished with value: 3.4648455531919873 and parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}. Best is trial 4 with value: 3.4648455531919873.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "3it [00:02,  1.35it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.4204\n",
      "2th fold: XGBRegressor RMSE: 1.8524\n",
      "3th fold: XGBRegressor RMSE: 3.9740\n",
      "\n",
      "XGBRegressor average RMSE: 3.0823\n",
      "XGBRegressor worst RMSE: 3.9740\n",
      "Corresponding penalty value: 3.4389\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB4\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.322\n",
      "RMSE_crossval: 3.082\n",
      "RMSE_test: 1.656\n",
      "MAE_test: 1.039\n",
      "Willmott's d Test: 0.955\n",
      "Nash-Sutcliffe Test: 0.861\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 18.0770 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:22:40,654]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB8\u001b[0m\n",
      "3it [00:01,  1.97it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.9997\n",
      "2th fold: XGBRegressor RMSE: 1.3812\n",
      "3th fold: XGBRegressor RMSE: 5.9122\n",
      "\n",
      "XGBRegressor average RMSE: 3.7644\n",
      "XGBRegressor worst RMSE: 5.9122\n",
      "Corresponding penalty value: 4.6235\n",
      "\u001b[32m[I 2025-03-27 08:22:42,176]\u001b[0m Trial 0 finished with value: 4.623516432368052 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}. Best is trial 0 with value: 4.623516432368052.\u001b[0m\n",
      "3it [00:07,  2.44s/it]\n",
      "1th fold: XGBRegressor RMSE: 3.9446\n",
      "2th fold: XGBRegressor RMSE: 0.9846\n",
      "3th fold: XGBRegressor RMSE: 6.0112\n",
      "\n",
      "XGBRegressor average RMSE: 3.6468\n",
      "XGBRegressor worst RMSE: 6.0112\n",
      "Corresponding penalty value: 4.5926\n",
      "\u001b[32m[I 2025-03-27 08:22:49,492]\u001b[0m Trial 1 finished with value: 4.5925513247031375 and parameters: {'n_estimators': 2270, 'learning_rate': 0.002068243584637287, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6061695553391381, 'subsample': 0.5909124836035503, 'reg_alpha': 0.9170225492671691, 'reg_lambda': 1.5212112147976886, 'gamma': 2.6237821581611893}. Best is trial 1 with value: 4.5925513247031375.\u001b[0m\n",
      "3it [00:02,  1.27it/s]\n",
      "1th fold: XGBRegressor RMSE: 4.0576\n",
      "2th fold: XGBRegressor RMSE: 1.5807\n",
      "3th fold: XGBRegressor RMSE: 5.9612\n",
      "\n",
      "XGBRegressor average RMSE: 3.8665\n",
      "XGBRegressor worst RMSE: 5.9612\n",
      "Corresponding penalty value: 4.7044\n",
      "\u001b[32m[I 2025-03-27 08:22:51,853]\u001b[0m Trial 2 finished with value: 4.704369738070227 and parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}. Best is trial 1 with value: 4.5925513247031375.\u001b[0m\n",
      "3it [00:01,  1.63it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.9483\n",
      "2th fold: XGBRegressor RMSE: 7.2222\n",
      "3th fold: XGBRegressor RMSE: 6.9900\n",
      "\n",
      "XGBRegressor average RMSE: 6.0535\n",
      "XGBRegressor worst RMSE: 7.2222\n",
      "Corresponding penalty value: 6.5210\n",
      "\u001b[32m[I 2025-03-27 08:22:53,693]\u001b[0m Trial 3 finished with value: 6.5209555771176415 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05924553274051564, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.5852620618436457, 'subsample': 0.5325257964926398, 'reg_alpha': 4.7444276862666666, 'reg_lambda': 4.828160165372797, 'gamma': 4.041986740582305}. Best is trial 1 with value: 4.5925513247031375.\u001b[0m\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.9554\n",
      "2th fold: XGBRegressor RMSE: 1.0050\n",
      "3th fold: XGBRegressor RMSE: 5.9411\n",
      "\n",
      "XGBRegressor average RMSE: 3.6338\n",
      "XGBRegressor worst RMSE: 5.9411\n",
      "Corresponding penalty value: 4.5568\n",
      "\u001b[32m[I 2025-03-27 08:22:56,442]\u001b[0m Trial 4 finished with value: 4.556755054055104 and parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}. Best is trial 4 with value: 4.556755054055104.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: XGBRegressor RMSE: 3.9752\n",
      "2th fold: XGBRegressor RMSE: 0.9827\n",
      "3th fold: XGBRegressor RMSE: 5.9356\n",
      "\n",
      "XGBRegressor average RMSE: 3.6312\n",
      "XGBRegressor worst RMSE: 5.9356\n",
      "Corresponding penalty value: 4.5529\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB8\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.870\n",
      "RMSE_crossval: 3.631\n",
      "RMSE_test: 2.160\n",
      "MAE_test: 1.715\n",
      "Willmott's d Test: 0.343\n",
      "Nash-Sutcliffe Test: -2.000\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 20.4143 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:23:01,078]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB10\u001b[0m\n",
      "3it [00:01,  1.90it/s]\n",
      "1th fold: XGBRegressor RMSE: 5.8906\n",
      "2th fold: XGBRegressor RMSE: 4.8291\n",
      "3th fold: XGBRegressor RMSE: 3.4479\n",
      "\n",
      "XGBRegressor average RMSE: 4.7225\n",
      "XGBRegressor worst RMSE: 5.8906\n",
      "Corresponding penalty value: 5.1898\n",
      "\u001b[32m[I 2025-03-27 08:23:02,660]\u001b[0m Trial 0 finished with value: 5.189751040539097 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}. Best is trial 0 with value: 5.189751040539097.\u001b[0m\n",
      "3it [00:07,  2.45s/it]\n",
      "1th fold: XGBRegressor RMSE: 5.6506\n",
      "2th fold: XGBRegressor RMSE: 5.8259\n",
      "3th fold: XGBRegressor RMSE: 3.7469\n",
      "\n",
      "XGBRegressor average RMSE: 5.0745\n",
      "XGBRegressor worst RMSE: 5.8259\n",
      "Corresponding penalty value: 5.3751\n",
      "\u001b[32m[I 2025-03-27 08:23:10,001]\u001b[0m Trial 1 finished with value: 5.375067436327866 and parameters: {'n_estimators': 2270, 'learning_rate': 0.002068243584637287, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6061695553391381, 'subsample': 0.5909124836035503, 'reg_alpha': 0.9170225492671691, 'reg_lambda': 1.5212112147976886, 'gamma': 2.6237821581611893}. Best is trial 0 with value: 5.189751040539097.\u001b[0m\n",
      "3it [00:02,  1.15it/s]\n",
      "1th fold: XGBRegressor RMSE: 6.1096\n",
      "2th fold: XGBRegressor RMSE: 4.6558\n",
      "3th fold: XGBRegressor RMSE: 3.4584\n",
      "\n",
      "XGBRegressor average RMSE: 4.7413\n",
      "XGBRegressor worst RMSE: 6.1096\n",
      "Corresponding penalty value: 5.2886\n",
      "\u001b[32m[I 2025-03-27 08:23:12,615]\u001b[0m Trial 2 finished with value: 5.288604243203629 and parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}. Best is trial 0 with value: 5.189751040539097.\u001b[0m\n",
      "3it [00:01,  1.58it/s]\n",
      "1th fold: XGBRegressor RMSE: 6.2373\n",
      "2th fold: XGBRegressor RMSE: 16.7822\n",
      "3th fold: XGBRegressor RMSE: 5.6493\n",
      "\n",
      "XGBRegressor average RMSE: 9.5563\n",
      "XGBRegressor worst RMSE: 16.7822\n",
      "Corresponding penalty value: 12.4467\n",
      "\u001b[32m[I 2025-03-27 08:23:14,519]\u001b[0m Trial 3 finished with value: 12.446657470553053 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05924553274051564, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.5852620618436457, 'subsample': 0.5325257964926398, 'reg_alpha': 4.7444276862666666, 'reg_lambda': 4.828160165372797, 'gamma': 4.041986740582305}. Best is trial 0 with value: 5.189751040539097.\u001b[0m\n",
      "3it [00:02,  1.03it/s]\n",
      "1th fold: XGBRegressor RMSE: 5.6373\n",
      "2th fold: XGBRegressor RMSE: 5.3280\n",
      "3th fold: XGBRegressor RMSE: 3.9997\n",
      "\n",
      "XGBRegressor average RMSE: 4.9883\n",
      "XGBRegressor worst RMSE: 5.6373\n",
      "Corresponding penalty value: 5.2479\n",
      "\u001b[32m[I 2025-03-27 08:23:17,436]\u001b[0m Trial 4 finished with value: 5.247920719790394 and parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}. Best is trial 0 with value: 5.189751040539097.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}\n",
      "3it [00:01,  1.88it/s]\n",
      "1th fold: XGBRegressor RMSE: 5.8170\n",
      "2th fold: XGBRegressor RMSE: 5.0182\n",
      "3th fold: XGBRegressor RMSE: 3.9792\n",
      "\n",
      "XGBRegressor average RMSE: 4.9381\n",
      "XGBRegressor worst RMSE: 5.8170\n",
      "Corresponding penalty value: 5.2897\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB10\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.374\n",
      "RMSE_crossval: 4.938\n",
      "RMSE_test: 3.339\n",
      "MAE_test: 2.435\n",
      "Willmott's d Test: 0.224\n",
      "Nash-Sutcliffe Test: -5.588\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 19.2783 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:23:20,367]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB18\u001b[0m\n",
      "3it [00:01,  2.00it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.2768\n",
      "2th fold: XGBRegressor RMSE: 1.7777\n",
      "3th fold: XGBRegressor RMSE: 5.3337\n",
      "\n",
      "XGBRegressor average RMSE: 3.1294\n",
      "XGBRegressor worst RMSE: 5.3337\n",
      "Corresponding penalty value: 4.0111\n",
      "\u001b[32m[I 2025-03-27 08:23:21,871]\u001b[0m Trial 0 finished with value: 4.011096751218924 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'max_leaves': 19, 'colsample_bytree': 0.5780093202212182, 'subsample': 0.5779972601681014, 'reg_alpha': 0.2904180608409973, 'reg_lambda': 4.330880728874676, 'gamma': 3.005575058716044}. Best is trial 0 with value: 4.011096751218924.\u001b[0m\n",
      "3it [00:06,  2.29s/it]\n",
      "1th fold: XGBRegressor RMSE: 2.6355\n",
      "2th fold: XGBRegressor RMSE: 1.7934\n",
      "3th fold: XGBRegressor RMSE: 5.3805\n",
      "\n",
      "XGBRegressor average RMSE: 3.2698\n",
      "XGBRegressor worst RMSE: 5.3805\n",
      "Corresponding penalty value: 4.1141\n",
      "\u001b[32m[I 2025-03-27 08:23:28,748]\u001b[0m Trial 1 finished with value: 4.114070506623799 and parameters: {'n_estimators': 2270, 'learning_rate': 0.002068243584637287, 'max_depth': 10, 'max_leaves': 26, 'colsample_bytree': 0.6061695553391381, 'subsample': 0.5909124836035503, 'reg_alpha': 0.9170225492671691, 'reg_lambda': 1.5212112147976886, 'gamma': 2.6237821581611893}. Best is trial 0 with value: 4.011096751218924.\u001b[0m\n",
      "3it [00:02,  1.31it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.1219\n",
      "2th fold: XGBRegressor RMSE: 1.8651\n",
      "3th fold: XGBRegressor RMSE: 5.1790\n",
      "\n",
      "XGBRegressor average RMSE: 3.0553\n",
      "XGBRegressor worst RMSE: 5.1790\n",
      "Corresponding penalty value: 3.9048\n",
      "\u001b[32m[I 2025-03-27 08:23:31,045]\u001b[0m Trial 2 finished with value: 3.9048068691755615 and parameters: {'n_estimators': 1580, 'learning_rate': 0.029130001728402213, 'max_depth': 7, 'max_leaves': 6, 'colsample_bytree': 0.6460723242676091, 'subsample': 0.6831809216468459, 'reg_alpha': 2.28034992108518, 'reg_lambda': 3.925879806965068, 'gamma': 0.9983689107917987}. Best is trial 2 with value: 3.9048068691755615.\u001b[0m\n",
      "3it [00:01,  1.60it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.4504\n",
      "2th fold: XGBRegressor RMSE: 2.3699\n",
      "3th fold: XGBRegressor RMSE: 5.1666\n",
      "\n",
      "XGBRegressor average RMSE: 3.3290\n",
      "XGBRegressor worst RMSE: 5.1666\n",
      "Corresponding penalty value: 4.0640\n",
      "\u001b[32m[I 2025-03-27 08:23:32,927]\u001b[0m Trial 3 finished with value: 4.064039231441365 and parameters: {'n_estimators': 1786, 'learning_rate': 0.05924553274051564, 'max_depth': 1, 'max_leaves': 19, 'colsample_bytree': 0.5852620618436457, 'subsample': 0.5325257964926398, 'reg_alpha': 4.7444276862666666, 'reg_lambda': 4.828160165372797, 'gamma': 4.041986740582305}. Best is trial 2 with value: 3.9048068691755615.\u001b[0m\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.3856\n",
      "2th fold: XGBRegressor RMSE: 1.7124\n",
      "3th fold: XGBRegressor RMSE: 5.1264\n",
      "\n",
      "XGBRegressor average RMSE: 3.0748\n",
      "XGBRegressor worst RMSE: 5.1264\n",
      "Corresponding penalty value: 3.8955\n",
      "\u001b[32m[I 2025-03-27 08:23:35,473]\u001b[0m Trial 4 finished with value: 3.895482039263477 and parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}. Best is trial 4 with value: 3.895482039263477.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "3it [00:02,  1.18it/s]\n",
      "1th fold: XGBRegressor RMSE: 2.5011\n",
      "2th fold: XGBRegressor RMSE: 1.7072\n",
      "3th fold: XGBRegressor RMSE: 5.0689\n",
      "\n",
      "XGBRegressor average RMSE: 3.0924\n",
      "XGBRegressor worst RMSE: 5.0689\n",
      "Corresponding penalty value: 3.8830\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB18\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'n_estimators': 1261, 'learning_rate': 0.009776234679498324, 'max_depth': 7, 'max_leaves': 14, 'colsample_bytree': 0.5610191174223894, 'subsample': 0.7475884550556351, 'reg_alpha': 0.17194260557609198, 'reg_lambda': 4.546602010393911, 'gamma': 1.2938999080000846}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.801\n",
      "RMSE_crossval: 3.092\n",
      "RMSE_test: 2.789\n",
      "MAE_test: 2.244\n",
      "Willmott's d Test: 0.913\n",
      "Nash-Sutcliffe Test: 0.516\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 19.5730 seconds\n",
      "\n",
      "Total elapsed time: 126.0410 seconds\n",
      "\n",
      "Output saved to XGBoost_output_test_26_3_pen_04.txt\n"
     ]
    }
   ],
   "source": [
    "!python ./models/XGBoost_procedural.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2a6be5-ae50-4a85-8422-5b81386cd953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-03-27 08:23:41,037]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV1\u001b[0m\n",
      "3it [00:06,  2.04s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5300\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3176\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8531\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5669\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8531\n",
      "Corresponding penalty value: 0.6814\n",
      "\u001b[32m[I 2025-03-27 08:23:47,155]\u001b[0m Trial 0 finished with value: 0.6813821324280969 and parameters: {'max_iter': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.7800932022121826, 'max_features': 0.5779972601681014, 'early_stopping': 'auto'}. Best is trial 0 with value: 0.6813821324280969.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5048\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4301\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7720\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5690\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7720\n",
      "Corresponding penalty value: 0.6502\n",
      "\u001b[32m[I 2025-03-27 08:23:49,853]\u001b[0m Trial 1 finished with value: 0.6501725111736055 and parameters: {'max_iter': 2003, 'learning_rate': 0.0708101770538266, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 4.162213204002109, 'max_features': 0.6061695553391381, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.6501725111736055.\u001b[0m\n",
      "3it [00:05,  1.78s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.4654\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3031\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.9205\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5630\n",
      "HistGradientBoostingRegressor worst RMSE: 0.9205\n",
      "Corresponding penalty value: 0.7060\n",
      "\u001b[32m[I 2025-03-27 08:23:55,211]\u001b[0m Trial 2 finished with value: 0.7060199383983539 and parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}. Best is trial 1 with value: 0.6501725111736055.\u001b[0m\n",
      "3it [00:02,  1.10it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6267\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2396\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7389\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5351\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7389\n",
      "Corresponding penalty value: 0.6166\n",
      "\u001b[32m[I 2025-03-27 08:23:57,942]\u001b[0m Trial 3 finished with value: 0.616609342896671 and parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}. Best is trial 3 with value: 0.616609342896671.\u001b[0m\n",
      "3it [00:03,  1.28s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.6134\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3016\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8552\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5901\n",
      "HistGradientBoostingRegressor worst RMSE: 0.8552\n",
      "Corresponding penalty value: 0.6961\n",
      "\u001b[32m[I 2025-03-27 08:24:01,774]\u001b[0m Trial 4 finished with value: 0.6960974202516619 and parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}. Best is trial 3 with value: 0.616609342896671.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "3it [00:02,  1.07it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.5747\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.2930\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.7116\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.5264\n",
      "HistGradientBoostingRegressor worst RMSE: 0.7116\n",
      "Corresponding penalty value: 0.6005\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV1\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.057\n",
      "RMSE_crossval: 0.526\n",
      "RMSE_test: 0.296\n",
      "MAE_test: 0.219\n",
      "Willmott's d Test: 0.998\n",
      "Nash-Sutcliffe Test: 0.992\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 25.9567 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:24:06,954]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV3\u001b[0m\n",
      "3it [00:08,  2.69s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.0776\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.3288\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4734\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9599\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4734\n",
      "Corresponding penalty value: 1.1653\n",
      "\u001b[32m[I 2025-03-27 08:24:15,025]\u001b[0m Trial 0 finished with value: 1.1653257002878623 and parameters: {'max_iter': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.7800932022121826, 'max_features': 0.5779972601681014, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.1653257002878623.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.1933\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4822\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.7254\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.1336\n",
      "HistGradientBoostingRegressor worst RMSE: 1.7254\n",
      "Corresponding penalty value: 1.3703\n",
      "\u001b[32m[I 2025-03-27 08:24:17,734]\u001b[0m Trial 1 finished with value: 1.3703292426881681 and parameters: {'max_iter': 2003, 'learning_rate': 0.0708101770538266, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 4.162213204002109, 'max_features': 0.6061695553391381, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.1653257002878623.\u001b[0m\n",
      "3it [00:06,  2.03s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7490\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4206\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4951\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8883\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4951\n",
      "Corresponding penalty value: 1.1310\n",
      "\u001b[32m[I 2025-03-27 08:24:23,832]\u001b[0m Trial 2 finished with value: 1.1310002286974368 and parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}. Best is trial 2 with value: 1.1310002286974368.\u001b[0m\n",
      "3it [00:02,  1.06it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.7893\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.6455\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4877\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9742\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4877\n",
      "Corresponding penalty value: 1.1796\n",
      "\u001b[32m[I 2025-03-27 08:24:26,659]\u001b[0m Trial 3 finished with value: 1.1795990829286624 and parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}. Best is trial 2 with value: 1.1310002286974368.\u001b[0m\n",
      "3it [00:04,  1.41s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3543\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4266\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.4346\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0718\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4346\n",
      "Corresponding penalty value: 1.2169\n",
      "\u001b[32m[I 2025-03-27 08:24:30,892]\u001b[0m Trial 4 finished with value: 1.2169243890402779 and parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}. Best is trial 2 with value: 1.1310002286974368.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}\n",
      "3it [00:05,  1.91s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 0.8694\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4779\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.3503\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.8992\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3503\n",
      "Corresponding penalty value: 1.0796\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV3\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.029\n",
      "RMSE_crossval: 0.899\n",
      "RMSE_test: 0.691\n",
      "MAE_test: 0.465\n",
      "Willmott's d Test: 0.993\n",
      "Nash-Sutcliffe Test: 0.971\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 33.2444 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:24:40,188]\u001b[0m A new study created in memory with name: hyperparameters_tuning_GV51\u001b[0m\n",
      "3it [00:09,  3.08s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.4822\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.6103\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1720\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0882\n",
      "HistGradientBoostingRegressor worst RMSE: 1.4822\n",
      "Corresponding penalty value: 1.2458\n",
      "\u001b[32m[I 2025-03-27 08:24:49,432]\u001b[0m Trial 0 finished with value: 1.2457645344594312 and parameters: {'max_iter': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.7800932022121826, 'max_features': 0.5779972601681014, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.2457645344594312.\u001b[0m\n",
      "3it [00:02,  1.10it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.3931\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4016\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 0.8178\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.2041\n",
      "HistGradientBoostingRegressor worst RMSE: 2.3931\n",
      "Corresponding penalty value: 1.6797\n",
      "\u001b[32m[I 2025-03-27 08:24:52,162]\u001b[0m Trial 1 finished with value: 1.6797029882093013 and parameters: {'max_iter': 2003, 'learning_rate': 0.0708101770538266, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 4.162213204002109, 'max_features': 0.6061695553391381, 'early_stopping': 'auto'}. Best is trial 0 with value: 1.2457645344594312.\u001b[0m\n",
      "3it [00:05,  1.99s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3531\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.5268\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1525\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0108\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3531\n",
      "Corresponding penalty value: 1.1477\n",
      "\u001b[32m[I 2025-03-27 08:24:58,125]\u001b[0m Trial 2 finished with value: 1.1477020253055248 and parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}. Best is trial 2 with value: 1.1477020253055248.\u001b[0m\n",
      "3it [00:03,  1.00s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2515\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.5944\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1882\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 1.0113\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2515\n",
      "Corresponding penalty value: 1.1074\n",
      "\u001b[32m[I 2025-03-27 08:25:01,134]\u001b[0m Trial 3 finished with value: 1.1074131668273175 and parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}. Best is trial 3 with value: 1.1074131668273175.\u001b[0m\n",
      "3it [00:04,  1.50s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.3850\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.4291\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1645\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9929\n",
      "HistGradientBoostingRegressor worst RMSE: 1.3850\n",
      "Corresponding penalty value: 1.1497\n",
      "\u001b[32m[I 2025-03-27 08:25:05,648]\u001b[0m Trial 4 finished with value: 1.1497076518675031 and parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}. Best is trial 3 with value: 1.1074131668273175.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "3it [00:02,  1.09it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 1.2406\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 0.5444\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 1.1725\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 0.9858\n",
      "HistGradientBoostingRegressor worst RMSE: 1.2406\n",
      "Corresponding penalty value: 1.0877\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "GV51\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.086\n",
      "RMSE_crossval: 0.986\n",
      "RMSE_test: 0.455\n",
      "MAE_test: 0.359\n",
      "Willmott's d Test: 0.997\n",
      "Nash-Sutcliffe Test: 0.988\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 30.6351 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:25:10,804]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB4\u001b[0m\n",
      "3it [00:04,  1.64s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.9963\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7654\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9782\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5800\n",
      "HistGradientBoostingRegressor worst RMSE: 4.9963\n",
      "Corresponding penalty value: 4.1465\n",
      "\u001b[32m[I 2025-03-27 08:25:15,727]\u001b[0m Trial 0 finished with value: 4.146490303686466 and parameters: {'max_iter': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.7800932022121826, 'max_features': 0.5779972601681014, 'early_stopping': 'auto'}. Best is trial 0 with value: 4.146490303686466.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.5251\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.6028\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.1322\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7534\n",
      "HistGradientBoostingRegressor worst RMSE: 4.5251\n",
      "Corresponding penalty value: 4.0621\n",
      "\u001b[32m[I 2025-03-27 08:25:18,422]\u001b[0m Trial 1 finished with value: 4.06205695595513 and parameters: {'max_iter': 2003, 'learning_rate': 0.0708101770538266, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 4.162213204002109, 'max_features': 0.6061695553391381, 'early_stopping': 'auto'}. Best is trial 1 with value: 4.06205695595513.\u001b[0m\n",
      "3it [00:04,  1.51s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.9325\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8821\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9082\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5743\n",
      "HistGradientBoostingRegressor worst RMSE: 4.9325\n",
      "Corresponding penalty value: 4.1176\n",
      "\u001b[32m[I 2025-03-27 08:25:22,942]\u001b[0m Trial 2 finished with value: 4.117571188272028 and parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}. Best is trial 1 with value: 4.06205695595513.\u001b[0m\n",
      "3it [00:01,  1.65it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.3904\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.2660\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.0892\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5819\n",
      "HistGradientBoostingRegressor worst RMSE: 4.3904\n",
      "Corresponding penalty value: 3.9053\n",
      "\u001b[32m[I 2025-03-27 08:25:24,767]\u001b[0m Trial 3 finished with value: 3.905307077319931 and parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}. Best is trial 3 with value: 3.905307077319931.\u001b[0m\n",
      "3it [00:01,  1.74it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.2238\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.8258\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.9919\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.6805\n",
      "HistGradientBoostingRegressor worst RMSE: 5.2238\n",
      "Corresponding penalty value: 4.2978\n",
      "\u001b[32m[I 2025-03-27 08:25:26,488]\u001b[0m Trial 4 finished with value: 4.297844038424324 and parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}. Best is trial 3 with value: 3.905307077319931.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "3it [00:02,  1.16it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.4213\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.3662\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.0733\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.2869\n",
      "HistGradientBoostingRegressor worst RMSE: 4.0733\n",
      "Corresponding penalty value: 3.6015\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB4\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.424\n",
      "RMSE_crossval: 3.287\n",
      "RMSE_test: 1.762\n",
      "MAE_test: 1.134\n",
      "Willmott's d Test: 0.949\n",
      "Nash-Sutcliffe Test: 0.843\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 19.9144 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:25:30,714]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB8\u001b[0m\n",
      "3it [00:05,  1.75s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.2243\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3121\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9946\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8437\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9946\n",
      "Corresponding penalty value: 4.7040\n",
      "\u001b[32m[I 2025-03-27 08:25:35,962]\u001b[0m Trial 0 finished with value: 4.704033300247723 and parameters: {'max_iter': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.7800932022121826, 'max_features': 0.5779972601681014, 'early_stopping': 'auto'}. Best is trial 0 with value: 4.704033300247723.\u001b[0m\n",
      "3it [00:02,  1.11it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.0604\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 7.2905\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.7597\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 6.0369\n",
      "HistGradientBoostingRegressor worst RMSE: 7.2905\n",
      "Corresponding penalty value: 6.5383\n",
      "\u001b[32m[I 2025-03-27 08:25:38,662]\u001b[0m Trial 1 finished with value: 6.538341707714294 and parameters: {'max_iter': 2003, 'learning_rate': 0.0708101770538266, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 4.162213204002109, 'max_features': 0.6061695553391381, 'early_stopping': 'auto'}. Best is trial 0 with value: 4.704033300247723.\u001b[0m\n",
      "3it [00:03,  1.24s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.1839\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.4679\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.9735\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.8751\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9735\n",
      "Corresponding penalty value: 4.7144\n",
      "\u001b[32m[I 2025-03-27 08:25:42,391]\u001b[0m Trial 2 finished with value: 4.714442137151679 and parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}. Best is trial 0 with value: 4.704033300247723.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.1186\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.3342\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.7806\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.7444\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7806\n",
      "Corresponding penalty value: 4.5589\n",
      "\u001b[32m[I 2025-03-27 08:25:45,067]\u001b[0m Trial 3 finished with value: 4.558887636993281 and parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}. Best is trial 3 with value: 4.558887636993281.\u001b[0m\n",
      "3it [00:03,  1.06s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.1436\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.5115\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.0659\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.9070\n",
      "HistGradientBoostingRegressor worst RMSE: 6.0659\n",
      "Corresponding penalty value: 4.7705\n",
      "\u001b[32m[I 2025-03-27 08:25:48,259]\u001b[0m Trial 4 finished with value: 4.770547149410258 and parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}. Best is trial 3 with value: 4.558887636993281.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "3it [00:02,  1.14it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 4.0787\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0903\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 6.1708\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 4.1133\n",
      "HistGradientBoostingRegressor worst RMSE: 6.1708\n",
      "Corresponding penalty value: 4.9363\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB8\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 1.248\n",
      "RMSE_crossval: 4.113\n",
      "RMSE_test: 2.999\n",
      "MAE_test: 2.042\n",
      "Willmott's d Test: 0.243\n",
      "Nash-Sutcliffe Test: -4.781\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 21.3447 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:25:52,064]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB10\u001b[0m\n",
      "3it [00:07,  2.50s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.8570\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 5.1271\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.0438\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 5.0093\n",
      "HistGradientBoostingRegressor worst RMSE: 5.8570\n",
      "Corresponding penalty value: 5.3484\n",
      "\u001b[32m[I 2025-03-27 08:25:59,579]\u001b[0m Trial 0 finished with value: 5.348395435120599 and parameters: {'max_iter': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.7800932022121826, 'max_features': 0.5779972601681014, 'early_stopping': 'auto'}. Best is trial 0 with value: 5.348395435120599.\u001b[0m\n",
      "3it [00:02,  1.10it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 6.3421\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 15.5336\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.8642\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 9.2466\n",
      "HistGradientBoostingRegressor worst RMSE: 15.5336\n",
      "Corresponding penalty value: 11.7614\n",
      "\u001b[32m[I 2025-03-27 08:26:02,298]\u001b[0m Trial 1 finished with value: 11.761396758704745 and parameters: {'max_iter': 2003, 'learning_rate': 0.0708101770538266, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 4.162213204002109, 'max_features': 0.6061695553391381, 'early_stopping': 'auto'}. Best is trial 0 with value: 5.348395435120599.\u001b[0m\n",
      "3it [00:06,  2.07s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.7804\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 5.9232\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.2744\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 5.3260\n",
      "HistGradientBoostingRegressor worst RMSE: 5.9232\n",
      "Corresponding penalty value: 5.5649\n",
      "\u001b[32m[I 2025-03-27 08:26:08,522]\u001b[0m Trial 2 finished with value: 5.564860522404931 and parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}. Best is trial 0 with value: 5.348395435120599.\u001b[0m\n",
      "3it [00:03,  1.06s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 6.1925\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 5.2444\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 3.6499\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 5.0290\n",
      "HistGradientBoostingRegressor worst RMSE: 6.1925\n",
      "Corresponding penalty value: 5.4944\n",
      "\u001b[32m[I 2025-03-27 08:26:11,704]\u001b[0m Trial 3 finished with value: 5.49440421133006 and parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}. Best is trial 0 with value: 5.348395435120599.\u001b[0m\n",
      "3it [00:04,  1.36s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.7450\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 4.8767\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.2314\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 4.9510\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7450\n",
      "Corresponding penalty value: 5.2686\n",
      "\u001b[32m[I 2025-03-27 08:26:15,789]\u001b[0m Trial 4 finished with value: 5.268592840484116 and parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}. Best is trial 4 with value: 5.268592840484116.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}\n",
      "3it [00:04,  1.41s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 5.7168\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 5.2688\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.0036\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 4.9964\n",
      "HistGradientBoostingRegressor worst RMSE: 5.7168\n",
      "Corresponding penalty value: 5.2846\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB10\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 0.200\n",
      "RMSE_crossval: 4.996\n",
      "RMSE_test: 4.291\n",
      "MAE_test: 2.897\n",
      "Willmott's d Test: 0.185\n",
      "Nash-Sutcliffe Test: -9.876\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 30.6171 seconds\n",
      "\n",
      "\u001b[32m[I 2025-03-27 08:26:22,683]\u001b[0m A new study created in memory with name: hyperparameters_tuning_MB18\u001b[0m\n",
      "3it [00:04,  1.45s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.1848\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7508\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.4631\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4663\n",
      "HistGradientBoostingRegressor worst RMSE: 5.4631\n",
      "Corresponding penalty value: 4.2650\n",
      "\u001b[32m[I 2025-03-27 08:26:27,049]\u001b[0m Trial 0 finished with value: 4.2650080840614 and parameters: {'max_iter': 1436, 'learning_rate': 0.09507192349792752, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.7800932022121826, 'max_features': 0.5779972601681014, 'early_stopping': 'auto'}. Best is trial 0 with value: 4.2650080840614.\u001b[0m\n",
      "3it [00:02,  1.12it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.0810\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.4845\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.1900\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.5852\n",
      "HistGradientBoostingRegressor worst RMSE: 5.1900\n",
      "Corresponding penalty value: 4.2271\n",
      "\u001b[32m[I 2025-03-27 08:26:29,731]\u001b[0m Trial 1 finished with value: 4.227117406123968 and parameters: {'max_iter': 2003, 'learning_rate': 0.0708101770538266, 'max_depth': 1, 'min_samples_leaf': 30, 'l2_regularization': 4.162213204002109, 'max_features': 0.6061695553391381, 'early_stopping': 'auto'}. Best is trial 1 with value: 4.227117406123968.\u001b[0m\n",
      "3it [00:04,  1.51s/it]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.1045\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7536\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.2414\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.3665\n",
      "HistGradientBoostingRegressor worst RMSE: 5.2414\n",
      "Corresponding penalty value: 4.1165\n",
      "\u001b[32m[I 2025-03-27 08:26:34,272]\u001b[0m Trial 2 finished with value: 4.116481131717153 and parameters: {'max_iter': 1260, 'learning_rate': 0.05248039559890747, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 3.0592644736118975, 'max_features': 0.569746930326021, 'early_stopping': 'auto'}. Best is trial 2 with value: 4.116481131717153.\u001b[0m\n",
      "3it [00:02,  1.31it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.2505\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.0667\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 4.9715\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4296\n",
      "HistGradientBoostingRegressor worst RMSE: 4.9715\n",
      "Corresponding penalty value: 4.0463\n",
      "\u001b[32m[I 2025-03-27 08:26:36,572]\u001b[0m Trial 3 finished with value: 4.046332089629295 and parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}. Best is trial 3 with value: 4.046332089629295.\u001b[0m\n",
      "3it [00:02,  1.04it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 3.0211\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 1.7684\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.4445\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.4114\n",
      "HistGradientBoostingRegressor worst RMSE: 5.4445\n",
      "Corresponding penalty value: 4.2246\n",
      "\u001b[32m[I 2025-03-27 08:26:39,462]\u001b[0m Trial 4 finished with value: 4.224633921736872 and parameters: {'max_iter': 662, 'learning_rate': 0.09488906486996079, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 1.5230688458668533, 'max_features': 0.5488360570031919, 'early_stopping': True}. Best is trial 3 with value: 4.046332089629295.\u001b[0m\n",
      "Best params from optuna: \n",
      " {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "3it [00:02,  1.23it/s]\n",
      "1th fold: HistGradientBoostingRegressor RMSE: 2.9205\n",
      "2th fold: HistGradientBoostingRegressor RMSE: 2.1767\n",
      "3th fold: HistGradientBoostingRegressor RMSE: 5.0007\n",
      "\n",
      "HistGradientBoostingRegressor average RMSE: 3.3660\n",
      "HistGradientBoostingRegressor worst RMSE: 5.0007\n",
      "Corresponding penalty value: 4.0199\n",
      "\n",
      "~~~ TARGET ~~~\n",
      "MB18\n",
      "\n",
      "~~~ MODEL ~~~\n",
      "Best parameters: {'max_iter': 1640, 'learning_rate': 0.07851974437968744, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 2.9620728443102124, 'max_features': 0.5232252063599989, 'early_stopping': True}\n",
      "\n",
      "~~~ TEST METRICS ~~~\n",
      "RMSE_train: 1.529\n",
      "RMSE_crossval: 3.366\n",
      "RMSE_test: 4.482\n",
      "MAE_test: 2.688\n",
      "Willmott's d Test: 0.763\n",
      "Nash-Sutcliffe Test: -0.249\n",
      "\n",
      "~~~ OTHER STATS ~~~\n",
      "Train data length: 38 months\n",
      "penalty_factor: 0.4\n",
      "Trial time: 19.9010 seconds\n",
      "\n",
      "Total elapsed time: 181.6148 seconds\n",
      "\n",
      "Output saved to GBRT_output_test_26_3_pen_04.txt\n"
     ]
    }
   ],
   "source": [
    "!python ./models/GBRT_procedural.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc86dc5-cf9a-43e3-add4-2197358097b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
