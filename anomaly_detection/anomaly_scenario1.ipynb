{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m---> 14\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m     15\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(root_dir))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_preparation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_data, split_data, mapping\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# LightGBM_inference.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "root_dir = Path(__file__).resolve().parent.parent\n",
    "sys.path.append(str(root_dir))\n",
    "from utils.data_preparation import preprocess_data, split_data, mapping\n",
    "from processing.custom_metrics import nash_sutcliffe, kling_gupta\n",
    "from models.best_params.LightGBM_params import HYPERPARAMETERS\n",
    "from tqdm import tqdm  # progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plotting_data/LOS_DAMM_Anomaly1.pkl', 'rb') as f:\n",
    "    plotting_data = pickle.load(f)\n",
    "\n",
    "# Extract data for plotting\n",
    "X_all = plotting_data['X_all']\n",
    "dates = plotting_data['dates']\n",
    "actual_y = plotting_data['actual_y']\n",
    "predictions = plotting_data['predictions']\n",
    "split_idx = plotting_data['split_idx']\n",
    "#coefficients = plotting_data['coefficients']\n",
    "RMSE = plotting_data['RMSE']\n",
    "y_test = actual_y.iloc[split_idx:]\n",
    "X_test = X_all.iloc[split_idx:]\n",
    "y_train = actual_y.iloc[:split_idx]\n",
    "train_predictions = predictions[:split_idx]\n",
    "test_predictions = predictions[split_idx:]\n",
    "test_dates = pd.to_datetime(dates.iloc[split_idx:])\n",
    "test_residuals = y_test - test_predictions\n",
    "train_residuals = np.abs(y_train - train_predictions)\n",
    "\n",
    "confidence = 0.50\n",
    "alpha = (1 - confidence) / 2\n",
    "lower_bound = np.quantile(test_residuals, alpha)\n",
    "upper_bound = np.quantile(test_residuals, 1 - alpha)\n",
    "print(lower_bound, upper_bound)\n",
    "def coverage_fraction(y, y_low, y_high):\n",
    "    return np.mean(np.logical_and(y >= y_low, y <= y_high))\n",
    "print(coverage_fraction(y_test, test_predictions + lower_bound, test_predictions + upper_bound))\n",
    "\n",
    "anomaly_start_date = pd.to_datetime('2023-01-12')\n",
    "anomaly_start_index_in_test = np.where(test_dates >= anomaly_start_date)[0][0]\n",
    "transition_period = len(test_dates) - anomaly_start_index_in_test\n",
    "final_factor = -0.0015\n",
    "\n",
    "test_anomaly = np.copy(y_test)\n",
    "\n",
    "for day in range(transition_period):\n",
    "        if anomaly_start_index_in_test + day < len(test_dates):\n",
    "            factor = (1 - np.abs(final_factor) * day / transition_period)\n",
    "            # positive or negative anomaly based on the sign of final_factor\n",
    "            test_anomaly[anomaly_start_index_in_test + day] *= factor if final_factor < 0 else 1 / factor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "beta = 2\n",
    "F2 = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall) if (beta**2 * precision + recall) > 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F2 Score: {F2:.2f}\")\n",
    "\"\"\"\n",
    "def cusum(y, k, h, index):\n",
    "    S = np.zeros_like(y)\n",
    "    alarms = []\n",
    "    S[0] = 0\n",
    "    alarm_triggered = False  # To track if an alarm was triggered\n",
    "\n",
    "    for i in range(index, len(y)):\n",
    "        if not alarm_triggered:\n",
    "            S[i] = max(0, S[i-1] + y[i] - k)\n",
    "            if S[i] > h:\n",
    "                alarms.append(i)\n",
    "                alarm_triggered = True  # Stop further alarms\n",
    "\n",
    "    return S, alarms\n",
    "\n",
    "# Assuming test_residuals is an array of residuals from your model\n",
    "positive_residuals = test_residuals[test_residuals > 0]\n",
    "negative_residuals = np.abs(test_residuals[test_residuals < 0])  # Take absolute for ease of quantile calculation\n",
    "\n",
    "k_percentile = 0.80  # 75th percentile for initial significant change detection\n",
    "h_percentile = 0.95  # 95th percentile for confirming a sustained shift\n",
    "\n",
    "k_upper = np.quantile(positive_residuals, k_percentile)\n",
    "h_upper = np.quantile(positive_residuals, h_percentile)\n",
    "\n",
    "k_lower = np.quantile(negative_residuals, k_percentile)\n",
    "h_lower = np.quantile(negative_residuals, h_percentile)\n",
    "\n",
    "print(k_lower, h_lower)\n",
    "print(k_upper, h_upper)\n",
    "\n",
    "deviations_upper = test_anomaly - (test_predictions + upper_bound)\n",
    "deviations_lower = (test_predictions + lower_bound) - test_anomaly\n",
    "\n",
    "S_upper, alarms_upper = cusum(deviations_upper.clip(min=0), k_upper, h_upper, anomaly_start_index_in_test)  \n",
    "S_lower, alarms_lower = cusum(deviations_lower.clip(min=0), k_lower, h_lower, anomaly_start_index_in_test)\n",
    "\n",
    "print(alarms_upper)\n",
    "print(alarms_lower)\n",
    "print(test_predictions[alarms_lower])\n",
    "\n",
    "plt.clf()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1, 1]}, sharex=False)  \n",
    "\n",
    "# Data and predictions\n",
    "#for alarm in alarms_upper:\n",
    "    #ax1.axvline(x=test_dates.iloc[alarm], color='purple', linestyle='--', label='Alarm Upper', linewidth=1)\n",
    "#for alarm in alarms_lower:\n",
    "    #ax1.axvline(x=test_dates.iloc[alarm], color='purple', linestyle='--', label='Alarm Lower', linewidth=1)\n",
    "#ax1.scatter(test_dates, y_test, color='blue', s=1, label='Actual data')\n",
    "#ax1.plot(test_dates, y_test, color='blue', linewidth=0.5, alpha=0.3)\n",
    "n = 4947\n",
    "ax1.plot(test_dates, test_anomaly, color='orange', linewidth=1, label='Anomaly')\n",
    "#ax1.plot(test_dates[:n], test_predictions[:n], color='red', linewidth=1, label='Prediction')\n",
    "ax1.plot(test_dates, (test_predictions + upper_bound), 'k-')\n",
    "ax1.plot(test_dates, (test_predictions + lower_bound), 'k-')\n",
    "#ax1.axvline(x=test_dates.iloc[5960], color='purple', linestyle='--', label='Alarm at 70% CI')\n",
    "#ax1.axvline(x=test_dates.iloc[3870], color='purple', linestyle='--', label='Alarm at 68% CI')\n",
    "#ax1.axvline(x=dates.iloc[split_idx], color='green', linestyle='--')\n",
    "ax1.axvline(x=test_dates.iloc[anomaly_start_index_in_test], color='orange', linestyle='--', label='Start of anomaly')\n",
    "ax1.set_ylabel('DPM_05 (m)', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "#ax1.legend(loc='upper right')\n",
    "ax1.grid()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "\n",
    "# CUSUM plots\n",
    "ax2.plot(test_dates, S_upper, color='purple', label='CUSUM Upper')\n",
    "ax2.axhline(y=h_upper, color='black', linestyle='--', label=f'h_upper={h_upper:.2f}')\n",
    "ax2.set_ylabel('CUSUM Upper', color='purple')\n",
    "ax2.tick_params(axis='y', labelcolor='purple')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "ax3.plot(test_dates, S_lower, color='purple', label='CUSUM Lower')\n",
    "ax3.axhline(y=h_lower, color='black', linestyle='--', label=f'h_lower={h_lower:.2f}')\n",
    "ax3.set_ylabel('CUSUM Lower', color='purple')\n",
    "ax3.tick_params(axis='y', labelcolor='purple')\n",
    "ax3.legend(loc='upper left')\n",
    "\n",
    "# Formatting\n",
    "plt.xticks(rotation=45)  \n",
    "fig.tight_layout()  \n",
    "\n",
    "# Text\n",
    "fig.subplots_adjust(right=0.75)\n",
    "rmse_text = f'RMSE: {RMSE:.3f}'\n",
    "#coeff_text = 'Coefficients:\\n' + '\\n'.join([f'{term}: {coeff:.2e}' for term, coeff in coefficients.items()])\n",
    "fig.text(0.77, 0.9, rmse_text, verticalalignment='top')\n",
    "#fig.text(0.77, 0.8, coeff_text, verticalalignment='top')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
